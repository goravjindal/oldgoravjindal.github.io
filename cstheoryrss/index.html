<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS Theory RSS | Gorav  Jindal</title>
    <meta name="author" content="Gorav  Jindal">
    <meta name="description" content="Gorav Jindal's personal and academic webpage
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://goravjindal.github.io/cstheoryrss/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Gorav </span>Jindal</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/cstheoryrss/">CS Theory RSS<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">CS Theory RSS</h1>
            <p class="post-description"></p>
          </header>

          <article>
            
<h1 id="cs-theory-rss-posts-last-6-months-from-httpstheoryreportatomxml">CS Theory RSS Posts (last 6 months), from <a href="https://theory.report/atom.xml" rel="external nofollow noopener" target="_blank">https://theory.report/atom.xml</a>
</h1>

<p><input type="text" id="search-box" placeholder="Search posts..." style="margin-bottom: 1em; width: 100%; padding: 0.5em; font-size: 1em;"></p>

<ul id="posts-list">
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-timest-temporal-information-motif-estimator-using-sampling-trees/">arXiv: Data Structures and Algorithms: TIMEST: Temporal Information Motif Estimator Using Sampling Trees</a> — <small>2025-07-29</small>
        <p>Authors: Yunjie Pan, Omkar Bhalerao, C. Seshadhri, Nishil Talati
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-the-min-max-average-cycle-weight-problem/">arXiv: Data Structures and Algorithms: The Min Max Average Cycle Weight Problem</a> — <small>2025-07-29</small>
        <p>Authors: Noga Klein Elmalem, Rica Gonen, Erel Segal-Halevi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-parallel-hierarchical-agglomerative-clustering-in-low-dimensions/">arXiv: Data Structures and Algorithms: Parallel Hierarchical Agglomerative Clustering in Low Dimensions</a> — <small>2025-07-29</small>
        <p>Authors: MohammadHossein Bateni, Laxman Dhulipala, Willem Fletcher, Kishen N Gowda, D Ellis Hershkowitz, Rajesh Jayaram, Jakub Łącki
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-online-rounding-schemes-for-k-rental-problems/">arXiv: Data Structures and Algorithms: Online Rounding Schemes for k -Rental Problems</a> — <small>2025-07-29</small>
        <p>Authors: Hossein Nekouyan, Bo Sun, Raouf Boutaba, Xiaoqi Tan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-online-learning-with-probing-for-sequential-user-centric-selection/">arXiv: Data Structures and Algorithms: Online Learning with Probing for Sequential User-Centric Selection</a> — <small>2025-07-29</small>
        <p>Authors: Tianyi Xu, Yiting Chen, Henger Li, Zheyong Bian, Emiliano Dall’Anese, Zizhan Zheng
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-mtaset-a-tree-based-set-for-efficient-range-queries-in-update-heavy/">arXiv: Data Structures and Algorithms: MTASet: A Tree-based Set for Efficient Range Queries in Update-heavy</a> — <small>2025-07-29</small>
        <p>Authors: Daniel Manor, Mor Perry, Moshe Sulamy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-improved-2-approximate-shortest-paths-for-close-vertex-pairs/">arXiv: Data Structures and Algorithms: Improved 2-Approximate Shortest Paths for close vertex pairs</a> — <small>2025-07-29</small>
        <p>Authors: Manoj Gupta
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-generating-satisfiable-benchmark-instances-for-stable-roommates-problems/">arXiv: Data Structures and Algorithms: Generating Satisfiable Benchmark Instances for Stable Roommates Problems</a> — <small>2025-07-29</small>
        <p>Authors: Baturay Yılmaz, Esra Erdem
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-fully-dynamic-spectral-and-cut-sparsifiers-for-directed-graphs/">arXiv: Data Structures and Algorithms: Fully Dynamic Spectral and Cut Sparsifiers for Directed Graphs</a> — <small>2025-07-29</small>
        <p>Authors: Yibin Zhao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-faster-exact-learning-of-k-term-dnfs-with-membership-and-equivalence/">arXiv: Data Structures and Algorithms: Faster exact learning of k-term DNFs with membership and equivalence</a> — <small>2025-07-29</small>
        <p>Authors: Josh Alman, Shivam Nadimpalli, Shyamal Patel, Rocco Servedio
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-deterministic-almost-linear-time-gomory-hu-trees/">arXiv: Data Structures and Algorithms: Deterministic Almost-Linear-Time Gomory-Hu Trees</a> — <small>2025-07-29</small>
        <p>Authors: Amir Abboud, Rasmus Kyng, Jason Li, Debmalya Panigrahi, Maximilian Probst Gutenberg, Thatchaphol Saranurak, Weixuan Yuan, Wuwei Yuan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-cleann-efficient-full-dynamism-in-graph-based-approximate-nearest/">arXiv: Data Structures and Algorithms: CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest</a> — <small>2025-07-29</small>
        <p>Authors: Ziyu Zhang, Yuanhao Wei, Joshua Engels, Julian Shun
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-an-algorithm-to-contract-framework-without-demand-queries/">arXiv: Data Structures and Algorithms: An Algorithm-to-Contract Framework without Demand Queries</a> — <small>2025-07-29</small>
        <p>Authors: Ilan Doron-Arad, Hadas Shachnai, Gilad Shmerler, Inbal Talgam-Cohen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-adaptive-bsts-for-single-source-and-all-to-all-requests-algorithms-and/">arXiv: Data Structures and Algorithms: Adaptive BSTs for Single-Source and All-to-All Requests: Algorithms and</a> — <small>2025-07-29</small>
        <p>Authors: Maryam Shiran
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-geometry-the-number-of-regular-simplices-in-higher-dimensions/">arXiv: Computational Geometry: The number of regular simplices in higher dimensions</a> — <small>2025-07-29</small>
        <p>Authors: Felix Christian Clemen, Adrian Dumitrescu, Dingyuan Liu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-geometry-general-strong-bound-on-the-uncrossed-number-which-is-tight-for-the-edge/">arXiv: Computational Geometry: General Strong Bound on the Uncrossed Number which is Tight for the Edge</a> — <small>2025-07-29</small>
        <p>Authors: Gaspard Charvy, Tomáš Masařík
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-complexity-the-power-of-negation-in-higher-order-datalog/">arXiv: Computational Complexity: The Power of Negation in Higher-Order Datalog</a> — <small>2025-07-29</small>
        <p>Authors: Angelos Charalambidis, Babis Kostopoulos, Christos Nomikos, Panos Rondogiannis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-complexity-racing-to-idle-energy-efficiency-of-matrix-multiplication-on/">arXiv: Computational Complexity: Racing to Idle: Energy Efficiency of Matrix Multiplication on</a> — <small>2025-07-29</small>
        <p>Authors: Mufakir Qamar Ansari, Mudabir Qamar Ansari
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-complexity-on-higher-order-busy-beaver-function/">arXiv: Computational Complexity: On Higher Order Busy Beaver Function</a> — <small>2025-07-29</small>
        <p>Authors: Zining Cao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/29/arxiv-computational-complexity-core-safety-values-for-provably-corrigible-agents/">arXiv: Computational Complexity: Core Safety Values for Provably Corrigible Agents</a> — <small>2025-07-29</small>
        <p>Authors: Aran Nayebi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/eccc-papers-tr25-104-how-to-construct-random-strings/">ECCC Papers: TR25-104 | How to Construct Random Strings |</a> — <small>2025-07-28</small>
        <p>We address the following fundamental question: is there an efficient deterministic algorithm that, given $1^n$, outputs a string of length $n$ that...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/cci-jobs-complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-1-2025/">CCI: jobs: Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 1, 2025)</a> — <small>2025-07-28</small>
        <p>A unique opportunity to work on fundamental questions at the intersection of disciplines.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/computational-complexity-tom-lehrer-passed-away-at-the-age-of-97/">Computational Complexity: Tom Lehrer Passed Away at the Age of 97</a> — <small>2025-07-28</small>
        <p>Tom Lehrer passed away on Saturday July 26 at the age of 97.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-string-consensus-problems-with-swaps-and-substitutions/">arXiv: Data Structures and Algorithms: String Consensus Problems with Swaps and Substitutions</a> — <small>2025-07-28</small>
        <p>Authors: Estéban Gabory, Laurent Bulteau, Gabriele Fici, Hilde Verbeek
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-query-efficient-structured-matrix-learning/">arXiv: Data Structures and Algorithms: Query Efficient Structured Matrix Learning</a> — <small>2025-07-28</small>
        <p>Authors: Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Cameron Musco, Christopher Musco, David Persson
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-edge-weighted-matching-in-the-dark/">arXiv: Data Structures and Algorithms: Edge-weighted Matching in the Dark</a> — <small>2025-07-28</small>
        <p>Authors: Zhiyi Huang, Enze Sun, Xiaowei Wu, Jiahao Zhao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-downward-self-reducibility-in-the-total-function-polynomial-hierarchy/">arXiv: Data Structures and Algorithms: Downward self-reducibility in the total function polynomial hierarchy</a> — <small>2025-07-28</small>
        <p>Authors: Karthik Gajulapalli, Surendra Ghentiyala, Zeyong Li, Sidhant Saraogi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-cycle-factors-of-regular-graphs-via-entropy/">arXiv: Data Structures and Algorithms: Cycle-factors of regular graphs via entropy</a> — <small>2025-07-28</small>
        <p>Authors: Micha Christoph, Nemanja Draganić, António Girão, Eoin Hurley, Lukas Michel, Alp Müyesser
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-budget-and-profit-approximations-for-spanning-tree-interdiction/">arXiv: Data Structures and Algorithms: Budget and Profit Approximations for Spanning Tree Interdiction</a> — <small>2025-07-28</small>
        <p>Authors: Rafail Ostrovsky, Yuval Rabani, Yoav Siman Tov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-a-truly-subcubic-combinatorial-algorithm-for-induced-4-cycle-detection/">arXiv: Data Structures and Algorithms: A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection</a> — <small>2025-07-28</small>
        <p>Authors: Amir Abboud, Shyan Akmal, Nick Fischer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-computational-geometry-relaxed-total-generalized-variation-regularized-piecewise-smooth/">arXiv: Computational Geometry: Relaxed Total Generalized Variation Regularized Piecewise Smooth</a> — <small>2025-07-28</small>
        <p>Authors: Huayan Zhang, Shanqiang Wang, Xiaochao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-computational-complexity-unconditional-pseudorandomness-against-shallow-quantum-circuits/">arXiv: Computational Complexity: Unconditional Pseudorandomness against Shallow Quantum Circuits</a> — <small>2025-07-28</small>
        <p>Authors: Soumik Ghosh, Sathyawageeswar Subramanian, Wei Zhan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-computational-complexity-edge-coloring-problems-with-forbidden-patterns-and-planted-colors/">arXiv: Computational Complexity: Edge-coloring problems with forbidden patterns and planted colors</a> — <small>2025-07-28</small>
        <p>Authors: Alexey Barsukov, Antoine Mottet, Davide Perinti
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/28/arxiv-computational-complexity-deadline-aware-joint-task-scheduling-and-offloading-in-mobile-edge/">arXiv: Computational Complexity: Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge</a> — <small>2025-07-28</small>
        <p>Authors: Ngoc Hung Nguyen, Van-Dinh Nguyen, Anh Tuan Nguyen, Nguyen Van Thieu, Hoang Nam Nguyen, Symeon Chatzinotas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/27/eccc-papers-tr25-103-2d-minimal-graph-rigidity-is-in-nc-for-one-crossing-minor-free-graphs/">ECCC Papers: TR25-103 | 2D Minimal Graph Rigidity is in NC for One-Crossing-Minor-Free Graphs |</a> — <small>2025-07-27</small>
        <p>Minimally rigid graphs can be recognized and embedded in the plane efficiently, i.e. in polynomial time. There is also an efficient randomized para...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/26/decentralized-thoughts-lagrange-s-theorem-through-the-algorithmic-lens/">Decentralized Thoughts: Lagrange's Theorem through the algorithmic lens</a> — <small>2025-07-26</small>
        <p>Groups lie at the heart of many cryptographic constructions. In this post, we revisit the classic Lagrange’s theorem through a more algorithmic len...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/cci-jobs-miller-research-postdoctoral-fellow-at-miller-institute-for-basic-research-in-science-uc-berkeley-apply-by-september-12-2025/">CCI: jobs: Miller Research Postdoctoral Fellow at Miller Institute for Basic Research in Science, UC Berkeley (apply by September 12, 2025)</a> — <small>2025-07-25</small>
        <p>The Miller Institute at UC Berkeley seeks exceptional PhD researchers for its 2026-2029 Miller Research Postdoctoral Fellowship. We’re looking for ...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-zeroth-order-log-concave-sampling/">arXiv: Data Structures and Algorithms: Zeroth-order log-concave sampling</a> — <small>2025-07-25</small>
        <p>Authors: Yunbum Kook
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-strong-sparsification-for-1-in-3-sat-via-polynomial-freiman-ruzsa/">arXiv: Data Structures and Algorithms: Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa</a> — <small>2025-07-25</small>
        <p>Authors: Benjamin Bedert, Tamio-Vesa Nakajima, Karolina Okrasa, Stanislav Živný
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-smoothed-analysis-of-online-metric-problems/">arXiv: Data Structures and Algorithms: Smoothed Analysis of Online Metric Problems</a> — <small>2025-07-25</small>
        <p>Authors: Christian Coester, Jack Umenberger
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-on-recognizing-graphs-representing-persistent-perfect-phylogenies/">arXiv: Data Structures and Algorithms: On recognizing graphs representing Persistent Perfect Phylogenies</a> — <small>2025-07-25</small>
        <p>Authors: Paola Bonizzoni, Gianluca Della Vedova, Mauricio Soto Gomez, Gabriella Trucco
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-dual-charging-for-half-integral-tsp/">arXiv: Data Structures and Algorithms: Dual Charging for Half-Integral TSP</a> — <small>2025-07-25</small>
        <p>Authors: Nathan Klein, Mehrshad Taziki
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-better-bounds-for-semi-streaming-single-source-shortest-paths/">arXiv: Data Structures and Algorithms: Better Bounds for Semi-Streaming Single-Source Shortest Paths</a> — <small>2025-07-25</small>
        <p>Authors: Sepehr Assadi, Gary Hoppenworth, Janani Sundaresan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-geometry-gromov-hausdorff-distance-between-chromatic-metric-pairs-and-stability/">arXiv: Computational Geometry: Gromov-Hausdorff distance between chromatic metric pairs and stability</a> — <small>2025-07-25</small>
        <p>Authors: Ondřej Draganov, Sophie Rosenmeier, Nicolò Zava
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-geometry-explainable-mapper-charting-llm-embedding-spaces-using/">arXiv: Computational Geometry: Explainable Mapper: Charting LLM Embedding Spaces Using</a> — <small>2025-07-25</small>
        <p>Authors: Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-geometry-a-new-approach-to-the-construction-of-subdivision-algorithms/">arXiv: Computational Geometry: A New Approach to the Construction of Subdivision Algorithms</a> — <small>2025-07-25</small>
        <p>Authors: Alexander Dietz
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-complexity-the-hidden-subgroup-problem-for-infinite-groups/">arXiv: Computational Complexity: The hidden subgroup problem for infinite groups</a> — <small>2025-07-25</small>
        <p>Authors: Greg Kuperberg
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-complexity-simulating-evolvability-as-a-learning-algorithm-empirical/">arXiv: Computational Complexity: Simulating Evolvability as a Learning Algorithm: Empirical</a> — <small>2025-07-25</small>
        <p>Authors: Nicholas Fidalgo, Puyuan Ye
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/25/arxiv-computational-complexity-fagin-s-theorem-for-semiring-turing-machines/">arXiv: Computational Complexity: Fagin's Theorem for Semiring Turing Machines</a> — <small>2025-07-25</small>
        <p>Authors: Guillermo Badia, Manfred Droste, Thomas Eiter, Rafael Kiesel, Carles Noguera, Erik Paul
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/computational-complexity-answer-to-my-group-one-group-two-prez-question/">Computational Complexity: Answer to my GROUP ONE/GROUP TWO Prez question</a> — <small>2025-07-24</small>
        <p>In a prior post I asked what criteria I used to place Prez and VP nominees since 1976 into two groups.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/decentralized-thoughts-an-analysis-of-latency-and-block-capacity-in-nakamoto-consensus/">Decentralized Thoughts: An Analysis of Latency and Block Capacity in Nakamoto Consensus</a> — <small>2025-07-24</small>
        <p>Achieving high throughput is essential for blockchain ecosystems to become competitive alternatives to their centralized counterparts across a wide...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-triadic-first-order-logic-queries-in-temporal-networks/">arXiv: Data Structures and Algorithms: Triadic First-Order Logic Queries in Temporal Networks</a> — <small>2025-07-24</small>
        <p>Authors: Omkar Bhalerao, Yunjie Pan, C. Seshadhri, Nishil Talati
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-stable-iterative-solvers-for-ill-conditioned-linear-systems/">arXiv: Data Structures and Algorithms: Stable Iterative Solvers for Ill-conditioned Linear Systems</a> — <small>2025-07-24</small>
        <p>Authors: Vasileios Kalantzis, Mark S. Squillante, Chai Wah Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-rlz-r-and-lz-end-r-enhancing-move-r/">arXiv: Data Structures and Algorithms: RLZ-r and LZ-End-r: Enhancing Move-r</a> — <small>2025-07-24</small>
        <p>Authors: Patrick Dinklage, Johannes Fischer, Lukas Nalbach, Jan Zumbrink
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-residual-prophet-inequalities/">arXiv: Data Structures and Algorithms: Residual Prophet Inequalities</a> — <small>2025-07-24</small>
        <p>Authors: Jose Correa, Sebastian Perez-Salazar, Dana Pizarro, Bruno Ziliotto
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-optimal-pure-differentially-private-sparse-histograms-in-near-linear/">arXiv: Data Structures and Algorithms: Optimal Pure Differentially Private Sparse Histograms in Near-Linear</a> — <small>2025-07-24</small>
        <p>Authors: Florian Kerschbaum, Steven Lee, Hao Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-fast-one-pass-sparse-approximation-of-the-top-eigenvectors-of-huge/">arXiv: Data Structures and Algorithms: Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge</a> — <small>2025-07-24</small>
        <p>Authors: Edem Boahen, Simone Brugiapaglia, Hung-Hsu Chou, Mark Iwen, Felix Krahmer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-compatibility-of-max-and-sum-objectives-for-committee-selection-and/">arXiv: Data Structures and Algorithms: Compatibility of Max and Sum Objectives for Committee Selection and</a> — <small>2025-07-24</small>
        <p>Authors: Yue Han, Elliot Anshelevich
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-advancing-quantum-state-preparation-using-limtdd/">arXiv: Data Structures and Algorithms: Advancing Quantum State Preparation using LimTDD</a> — <small>2025-07-24</small>
        <p>Authors: Xin Hong, Aochu Dai, Chenjian Li, Sanjiang Li, Shenggang Ying, Mingsheng Ying
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/cs-theory-events-ttic-summer-workshop-on-incentives-for-collaborative-learning-and-data-sharing/">CS Theory Events: TTIC Summer Workshop on Incentives for Collaborative Learning and Data Sharing</a> — <small>2025-07-23</small>
        <p>August 13-15, 2025 Toyota Technological Institute at Chicago https://sites.google.com/ttic.edu/incentivesdatasharing/home Submission deadline: July...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/gil-kalai-amazing-jie-ma-wujie-shen-and-shengjie-xie-gave-an-exponential-improvement-for-ramsey-lower-bounds/">Gil Kalai: Amazing: Jie Ma, Wujie Shen, and Shengjie Xie Gave an Exponential Improvement for Ramsey Lower Bounds</a> — <small>2025-07-23</small>
        <p>By Gil Kalai
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-toward-a-lightweight-and-robust-design-for-caching-with-predictions/">arXiv: Data Structures and Algorithms: Toward a Lightweight and Robust Design for Caching with Predictions</a> — <small>2025-07-23</small>
        <p>Authors: Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-the-cost-of-compression-tight-quadratic-black-box-attacks-on-sketches/">arXiv: Data Structures and Algorithms: The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches</a> — <small>2025-07-23</small>
        <p>Authors: Sara Ahmadian, Edith Cohen, Uri Stemmer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-online-joint-replenishment-problem-with-arbitrary-holding-and-backlog/">arXiv: Data Structures and Algorithms: Online Joint Replenishment Problem with Arbitrary Holding and Backlog</a> — <small>2025-07-23</small>
        <p>Authors: Yossi Azar, Shahar Lewkowicz
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-online-combinatorial-optimization-with-graphical-dependencies/">arXiv: Data Structures and Algorithms: Online Combinatorial Optimization with Graphical Dependencies</a> — <small>2025-07-23</small>
        <p>Authors: Zhimeng Gao, Evangelia Gergatsouli, Kalen Patton, Sahil Singla
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-longest-unbordered-factors-on-run-length-encoded-strings/">arXiv: Data Structures and Algorithms: Longest Unbordered Factors on Run-Length Encoded Strings</a> — <small>2025-07-23</small>
        <p>Authors: Shoma Sekizaki, Takuya Mieno
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-best-of-both-worlds-guarantees-with-fairer-endings/">arXiv: Data Structures and Algorithms: Best-of-Both-Worlds Guarantees with Fairer Endings</a> — <small>2025-07-23</small>
        <p>Authors: Telikepalli Kavitha, Surya Panchapakesan, Rohit Vaish, Vignesh Viswanathan, Jatin Yadav
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-an-unconditional-lower-bound-for-the-active-set-method-in-convex/">arXiv: Data Structures and Algorithms: An unconditional lower bound for the active-set method in convex</a> — <small>2025-07-23</small>
        <p>Authors: Eleon Bach, Yann Disser, Sophie Huiberts, Nils Mosis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-an-exact-solver-for-maximizing-a-submodular-function-subject-to-a/">arXiv: Data Structures and Algorithms: An Exact Solver for Maximizing a Submodular Function Subject to a</a> — <small>2025-07-23</small>
        <p>Authors: Sabine Münch, Stephen Raach
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-a-best-possible-general-form-of-the-master-theorem-for/">arXiv: Data Structures and Algorithms: A Best Possible General Form of the Master Theorem for</a> — <small>2025-07-23</small>
        <p>Authors: Carl D. Offner
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-computational-geometry-improved-wake-up-time-for-euclidean-freeze-tag-problem/">arXiv: Computational Geometry: Improved Wake-Up Time For Euclidean Freeze-Tag Problem</a> — <small>2025-07-23</small>
        <p>Authors: Sharareh Alipour, Arash Ahadi, Kajal Baghestani
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-computational-geometry-analysis-of-design-algorithms-and-fabrication-of-a-graph-based/">arXiv: Computational Geometry: Analysis of Design Algorithms and Fabrication of a Graph-based</a> — <small>2025-07-23</small>
        <p>Authors: Mehdi Gorjian, Gregory A. Luhan, Stephen M. Caffey
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-computational-complexity-monotone-circuit-complexity-of-matching/">arXiv: Computational Complexity: Monotone Circuit Complexity of Matching</a> — <small>2025-07-23</small>
        <p>Authors: Bruno Cavalar, Mika Göös, Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-computational-complexity-constructing-material-network-representations-for-intelligent-amorphous/">arXiv: Computational Complexity: Constructing material network representations for intelligent amorphous</a> — <small>2025-07-23</small>
        <p>Authors: S. -Y. Zhang, J. Tian, S. -L. Liu, H. -M. Zhang, H. -Y. Bai, Y. -C. Hu, W. -H. Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/23/arxiv-computational-complexity-computational-aspects-of-the-trace-norm-contraction-coefficient/">arXiv: Computational Complexity: Computational aspects of the trace norm contraction coefficient</a> — <small>2025-07-23</small>
        <p>Authors: Idris Delsol, Omar Fawzi, Jan Kochanowski, Akshay Ramachandran
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/ben-recht-digging-in-the-crates/">Ben Recht: Digging in the crates</a> — <small>2025-07-22</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/eccc-papers-tr25-102-monotone-circuit-complexity-of-matching/">ECCC Papers: TR25-102 | Monotone Circuit Complexity of Matching |</a> — <small>2025-07-22</small>
        <p>We show that the perfect matching function on $n$-vertex graphs requires monotone circuits of size $\smash{2^{n^{\Omega(1)}}}$. This improves on th...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/computational-complexity-trevisan-prize-deadline-july-31-for-notification-intent-aug-31-for-nomination/">Computational Complexity: Trevisan Prize- Deadline July 31 for Notification Intent, Aug 31 for nomination.</a> — <small>2025-07-22</small>
        <p>A new prize:
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-topological-social-choice-designing-a-noise-robust-polar-distance-for/">arXiv: Data Structures and Algorithms: Topological Social Choice: Designing a Noise-Robust Polar Distance for</a> — <small>2025-07-22</small>
        <p>Authors: Athanasios Andrikopoulos, Nikolaos Sampanis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-tighter-lower-bounds-for-single-source-personalized-pagerank/">arXiv: Data Structures and Algorithms: Tighter Lower Bounds for Single Source Personalized PageRank</a> — <small>2025-07-22</small>
        <p>Authors: Xinpeng Jiang, Haoyu Liu, Siqiang Luo, Xiaokui Xiao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-quantum-state-preparation-based-on-limtdd/">arXiv: Data Structures and Algorithms: Quantum State Preparation Based on LimTDD</a> — <small>2025-07-22</small>
        <p>Authors: Xin Hong, Chenjian Li, Aochu Dai, Sanjiang Li, Shenggang Ying, Mingsheng Ying
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-probing-efx-via-pmms-non-existence-results-in-discrete-fair-division/">arXiv: Data Structures and Algorithms: Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division</a> — <small>2025-07-22</small>
        <p>Authors: Jarosław Byrka, Franciszek Malinka, Tomasz Ponitka
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-predict-reposition-and-allocate-a-greedy-and-flow-based-architecture/">arXiv: Data Structures and Algorithms: Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture</a> — <small>2025-07-22</small>
        <p>Authors: Aqsa Ashraf Makhdomi, Iqra Altaf Gillani
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-on-zeros-and-algorithms-for-disordered-systems-mean-field-spin-glasses/">arXiv: Data Structures and Algorithms: On zeros and algorithms for disordered systems: mean-field spin glasses</a> — <small>2025-07-22</small>
        <p>Authors: Ferenc Bencs, Kuikui Liu, Guus Regts
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-on-algorithmic-robustness-of-corrupted-markov-chains/">arXiv: Data Structures and Algorithms: On Algorithmic Robustness of Corrupted Markov Chains</a> — <small>2025-07-22</small>
        <p>Authors: Jason Gaitonde, Elchanan Mossel
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-new-algorithms-for-2-sat-and-3-sat/">arXiv: Data Structures and Algorithms: New Algorithms for #2-SAT and #3-SAT</a> — <small>2025-07-22</small>
        <p>Authors: Junqiang Peng, Zimo Sheng, Mingyu Xiao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-language-generation-in-the-limit-noise-loss-and-feedback/">arXiv: Data Structures and Algorithms: Language Generation in the Limit: Noise, Loss, and Feedback</a> — <small>2025-07-22</small>
        <p>Authors: Yannan Bai, Debmalya Panigrahi, Ian Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-k-pca-for-non-squared-euclidean-distances-polynomial-time/">arXiv: Data Structures and Algorithms: k-PCA for (non-squared) Euclidean Distances: Polynomial Time</a> — <small>2025-07-22</small>
        <p>Authors: Daniel Greenhut, Dan Feldman
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-job-scheduling-under-base-and-additional-fees-with-applications-to/">arXiv: Data Structures and Algorithms: Job Scheduling under Base and Additional Fees, with Applications to</a> — <small>2025-07-22</small>
        <p>Authors: Yi-Ting Hsieh, Mong-Jen Kao, Jhong-Yun Liu, Hung-Lung Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-fast-algorithms-for-graph-arboricity-and-related-problems/">arXiv: Data Structures and Algorithms: Fast Algorithms for Graph Arboricity and Related Problems</a> — <small>2025-07-22</small>
        <p>Authors: Ruoxu Cen, Henry Fleischmann, George Z. Li, Jason Li, Debmalya Panigrahi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-dvorak-dell-grohe-rattan-theorem-via-an-asymptotic-argument/">arXiv: Data Structures and Algorithms: Dvorak-Dell-Grohe-Rattan theorem via an asymptotic argument</a> — <small>2025-07-22</small>
        <p>Authors: Alexander Kozachinskiy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-differentially-private-synthetic-graphs-preserving-triangle-motif-cuts/">arXiv: Data Structures and Algorithms: Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts</a> — <small>2025-07-22</small>
        <p>Authors: Pan Peng, Hangyu Xu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-characterizing-and-testing-configuration-stability-in-two-dimensional/">arXiv: Data Structures and Algorithms: Characterizing and Testing Configuration Stability in Two-Dimensional</a> — <small>2025-07-22</small>
        <p>Authors: Yonatan Nakar, Dana Ron
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-certificate-sensitive-subset-sum-realizing-instance-complexity/">arXiv: Data Structures and Algorithms: Certificate-Sensitive Subset Sum: Realizing Instance Complexity</a> — <small>2025-07-22</small>
        <p>Authors: Jesus Salas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-better-models-and-algorithms-for-learning-ising-models-from-dynamics/">arXiv: Data Structures and Algorithms: Better Models and Algorithms for Learning Ising Models from Dynamics</a> — <small>2025-07-22</small>
        <p>Authors: Jason Gaitonde, Ankur Moitra, Elchanan Mossel
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-asynchronous-collective-tree-exploration-a-distributed-algorithm-and-a/">arXiv: Data Structures and Algorithms: Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a</a> — <small>2025-07-22</small>
        <p>Authors: Romain Cosson, Laurent Massoulié
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-an-n-o-loglog-n-time-approximation-scheme-for-capacitated-vrp-in/">arXiv: Data Structures and Algorithms: An n{O(loglog n)} time approximation scheme for capacitated VRP in</a> — <small>2025-07-22</small>
        <p>Authors: René Sitters
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-addressing-bias-in-algorithmic-solutions-exploring-vertex-cover-and/">arXiv: Data Structures and Algorithms: Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and</a> — <small>2025-07-22</small>
        <p>Authors: Sheikh Shakil Akhtar, Jayakrishnan Madathil, Pranabendu Misra, Geevarghese Philip
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-a-myhill-nerode-type-characterization-of-2detlin-languages/">arXiv: Data Structures and Algorithms: A Myhill-Nerode Type Characterization of 2detLIN Languages</a> — <small>2025-07-22</small>
        <p>Authors: Benedek Nagy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-a-black-box-approach-for-exogenous-replenishment-in-online-resource/">arXiv: Data Structures and Algorithms: A Black-Box Approach for Exogenous Replenishment in Online Resource</a> — <small>2025-07-22</small>
        <p>Authors: Suho Kang, Ziyang Liu, Rajan Udwani
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-1-64-approximation-for-chromatic-correlation-clustering-via-chromatic/">arXiv: Data Structures and Algorithms: 1.64-Approximation for Chromatic Correlation Clustering via Chromatic</a> — <small>2025-07-22</small>
        <p>Authors: Dahoon Lee, Chenglin Fan, Euiwoong Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-geometry-variable-min-cut-max-flow-bounds-and-algorithms-in-finite-regime/">arXiv: Computational Geometry: Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime</a> — <small>2025-07-22</small>
        <p>Authors: Rivka Gitik, Alejandro Cohen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-geometry-trajlens-visual-analysis-for-constructing-cell-developmental/">arXiv: Computational Geometry: TrajLens: Visual Analysis for Constructing Cell Developmental</a> — <small>2025-07-22</small>
        <p>Authors: Qipeng Wang, Shaolun Ruan, Rui Sheng, Yong Wang, Min Zhu, Huamin Qu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-geometry-on-quad-mesh-extraction-from-messy-grid-preserving-maps/">arXiv: Computational Geometry: On Quad Mesh Extraction From Messy Grid Preserving Maps</a> — <small>2025-07-22</small>
        <p>Authors: Nicolas Ray
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-geometry-k-pca-for-non-squared-euclidean-distances-polynomial-time/">arXiv: Computational Geometry: k-PCA for (non-squared) Euclidean Distances: Polynomial Time</a> — <small>2025-07-22</small>
        <p>Authors: Daniel Greenhut, Dan Feldman
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-complexity-studying-homing-and-synchronizing-sequences-for-timed-finite-state/">arXiv: Computational Complexity: Studying homing and synchronizing sequences for Timed Finite State</a> — <small>2025-07-22</small>
        <p>Authors: Evgenii Vinarskii, Jakub Ruszil, Adam Roman, Natalia Kushik
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-complexity-pseudorandomness-of-expander-walks-via-fourier-analysis-on-groups/">arXiv: Computational Complexity: Pseudorandomness of Expander Walks via Fourier Analysis on Groups</a> — <small>2025-07-22</small>
        <p>Authors: Fernando Granha Jeronimo, Tushant Mittal, Sourya Roy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-complexity-efficient-algorithms-for-relevant-quantities-of-friedkin-johnsen-opinion/">arXiv: Computational Complexity: Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion</a> — <small>2025-07-22</small>
        <p>Authors: Gengyu Wang, Runze Zhang, Zhongzhi Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/22/arxiv-computational-complexity-complexity-of-faceted-explanations-in-propositional-abduction/">arXiv: Computational Complexity: Complexity of Faceted Explanations in Propositional Abduction</a> — <small>2025-07-22</small>
        <p>Authors: Johannes Schmidt, Mohamed Maizia, Victor Lagerkvist, Johannes K. Fichte
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/the-learning-theory-alliance-blog-testing-assumptions-of-learning-algorithms/">The Learning Theory Alliance Blog: Testing Assumptions of Learning Algorithms</a> — <small>2025-07-21</small>
        <p>Today’s technical post is by Arsen Vasilyan. This focuses on the very exciting new “testable learning” he introduced with Rubinfeld in a 2023 paper...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/windows-on-theory-ai-safety-course-intro-blog/">Windows on Theory: AI Safety Course Intro Blog</a> — <small>2025-07-21</small>
        <p>I am teaching CS 2881: AI Safety this fall at Harvard. This blog is primarily aimed at students at Harvard or MIT (where we have a cross-registerin...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-weighted-matching-in-a-poly-streaming-model/">arXiv: Data Structures and Algorithms: Weighted Matching in a Poly-Streaming Model</a> — <small>2025-07-21</small>
        <p>Authors: Ahammed Ullah, S. M. Ferdous, Alex Pothen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-treedepth-inapproximability-and-exponential-eth-lower-bound/">arXiv: Data Structures and Algorithms: Treedepth Inapproximability and Exponential ETH Lower Bound</a> — <small>2025-07-21</small>
        <p>Authors: Édouard Bonnet, Daniel Neuen, Marek Sokołowski
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-tight-bounds-for-answering-adaptively-chosen-concentrated-queries/">arXiv: Data Structures and Algorithms: Tight Bounds for Answering Adaptively Chosen Concentrated Queries</a> — <small>2025-07-21</small>
        <p>Authors: Emma Rapoport, Edith Cohen, Uri Stemmer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-strassen-2times2-matrix-multiplication-from-a-3-dimensional-volume/">arXiv: Data Structures and Algorithms: Strassen 2times2 Matrix Multiplication from a 3-dimensional Volume</a> — <small>2025-07-21</small>
        <p>Authors: Benoit Jacob
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-sparse-navigable-graphs-for-nearest-neighbor-search-algorithms-and/">arXiv: Data Structures and Algorithms: Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and</a> — <small>2025-07-21</small>
        <p>Authors: Sanjeev Khanna, Ashwin Padaki, Erik Waingarten
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-quantum-pattern-matching-with-wildcards/">arXiv: Data Structures and Algorithms: Quantum Pattern Matching with Wildcards</a> — <small>2025-07-21</small>
        <p>Authors: Masoud Seddighin, Saeed Seddighin
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-optimal-antimatroid-sorting/">arXiv: Data Structures and Algorithms: Optimal antimatroid sorting</a> — <small>2025-07-21</small>
        <p>Authors: Benjamin Aram Berendsohn
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-improved-girth-approximation-in-weighted-undirected-graphs/">arXiv: Data Structures and Algorithms: Improved girth approximation in weighted undirected graphs</a> — <small>2025-07-21</small>
        <p>Authors: Avi Kadria, Liam Roditty, Aaron Sidford, Virginia Vassilevska Williams, Uri Zwick
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-faster-multi-source-reachability-and-approximate-distances-via/">arXiv: Data Structures and Algorithms: Faster Multi-Source Reachability and Approximate Distances via</a> — <small>2025-07-21</small>
        <p>Authors: Michael Elkin, Chhaya Trehan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-combinatorics-of-palindromes/">arXiv: Data Structures and Algorithms: Combinatorics of Palindromes</a> — <small>2025-07-21</small>
        <p>Authors: Michael Itzhaki
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-an-efficient-massively-parallel-constant-factor-approximation-algorithm/">arXiv: Data Structures and Algorithms: An Efficient Massively Parallel Constant-Factor Approximation Algorithm</a> — <small>2025-07-21</small>
        <p>Authors: Vincent Cohen-Addad, Fabian Kuhn, Zahra Parsaeian
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-geometry-isotropic-remeshing-with-inter-angle-optimization/">arXiv: Computational Geometry: Isotropic Remeshing with Inter-Angle Optimization</a> — <small>2025-07-21</small>
        <p>Authors: Hanbing Zheng, Chenlei Lv
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-geometry-generalized-cluster-algorithms-for-potts-lattice-gauge-theory/">arXiv: Computational Geometry: Generalized cluster algorithms for Potts lattice gauge theory</a> — <small>2025-07-21</small>
        <p>Authors: Anthony E. Pizzimenti, Paul Duncan, Benjamin Schweinhart
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-complexity-proceedings-of-the-15th-international-workshop-on-non-classical-models/">arXiv: Computational Complexity: Proceedings of the 15th International Workshop on Non-Classical Models</a> — <small>2025-07-21</small>
        <p>Authors: Nelma Moreira, Luca Prigioniero
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-complexity-fast-computational-deep-thermalization/">arXiv: Computational Complexity: Fast computational deep thermalization</a> — <small>2025-07-21</small>
        <p>Authors: Shantanav Chakraborty, Soonwon Choi, Soumik Ghosh, Tudor Giurgică-Tiron
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-complexity-exact-versus-approximate-representations-of-boolean-functions-in-the-de/">arXiv: Computational Complexity: Exact versus Approximate Representations of Boolean Functions in the De</a> — <small>2025-07-21</small>
        <p>Authors: Arkadev Chattopadhyay, Yogesh Dahiya, Shachar Lovett
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/21/arxiv-computational-complexity-characterizing-p-simulation-between-theories/">arXiv: Computational Complexity: Characterizing p-Simulation Between Theories</a> — <small>2025-07-21</small>
        <p>Authors: Hunter Monroe
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/20/computational-complexity-a-prez-question-can-ai-do-it-can-you-can-i/">Computational Complexity: A Prez Question: Can AI do it? Can you? Can I?</a> — <small>2025-07-20</small>
        <p> I am curious how AI or humans can do on the following question.

I have listed out the nominees for Prez and VP (Vice Prez) since 1976 and put the...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/20/eccc-papers-tr25-101-exact-versus-approximate-representations-of-boolean-functions-in-the-de-morgan-basis/">ECCC Papers: TR25-101 | Exact versus Approximate Representations of Boolean Functions in the De Morgan Basis |</a> — <small>2025-07-20</small>
        <p>A seminal result of Nisan and Szegedy (STOC, 1992) shows that for any total Boolean function, the degree of the real polynomial that computes the f...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/20/eccc-papers-tr25-100-equality-is-far-weaker-than-constant-cost-communication/">ECCC Papers: TR25-100 | Equality is Far Weaker Than Constant-Cost Communication |</a> — <small>2025-07-20</small>
        <p>We exhibit an $n$-bit communication problem with a constant-cost randomized protocol but which requires $n^{\Omega(1)}$ deterministic (or even non-...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/20/david-eppstein-twenty-years-of-blogging/">David Eppstein: Twenty years of blogging</a> — <small>2025-07-20</small>
        <p>I made my first post to this blog twenty years ago, on July 20, 2005.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/19/nisheeth-vishnoi-what-is-intelligence-architecture-divergence-and-fiction/">Nisheeth Vishnoi: What is Intelligence? Architecture, Divergence, and Fiction</a> — <small>2025-07-19</small>
        <p>A computational anatomy of intelligence. How faculties interact, architectures diverge, and coherence emerges through self-constructed fictions
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/cci-jobs-postdoctoral-fellow-position-at-university-of-houston-apply-by-september-30-2025/">CCI: jobs: Postdoctoral fellow position at University of Houston apply by September 30, 2025</a> — <small>2025-07-18</small>
        <p>A postdoc is available in distributed and scalable machine learning, security, and fault tolerance in distributed computing at the CS department, U...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/eccc-papers-tr25-099-the-algebraic-cost-of-a-boolean-sum/">ECCC Papers: TR25-099 | The Algebraic Cost of a Boolean Sum |</a> — <small>2025-07-18</small>
        <p>It is a well-known fact that the permanent polynomial is complete for the complexity class VNP, and it is largely suspected that the determinant do...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/eccc-papers-tr25-099-the-algebraic-cost-of-a-boolean-sum-ian-orzel-srikanth-srinivasan-s-bastien-tavenas-amir-yehudayoff/">ECCC Papers: TR25-099 | The Algebraic Cost of a Boolean Sum |</a> — <small>2025-07-18</small>
        <p>It is a well-known fact that the permanent polynomial is complete for the complexity class VNP, and it is largely suspected that the determinant do...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/francis-bach-revisiting-scaling-laws-via-the-z-transform/">Francis Bach: Revisiting scaling laws via the z-transform</a> — <small>2025-07-18</small>
        <p>In the last few years, we have seen a surge of empirical and theoretical works about “scaling laws”, whose goals are to characterize the performanc...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/decentralized-thoughts-2-round-bft-in-simplex-style/">Decentralized Thoughts: 2-round BFT in Simplex style</a> — <small>2025-07-18</small>
        <p>Simplex is a recent partially synchronous Byzantine Fault Tolerant (BFT) protocol that is gaining popularity. We take this opportunity to rehash se...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-waiting-is-worth-it-and-can-be-improved-with-predictions/">arXiv: Data Structures and Algorithms: Waiting is worth it and can be improved with predictions</a> — <small>2025-07-18</small>
        <p>Authors: Ya-Chun Liang, Meng-Hsi Li, Chung-Shou Liao, Clifford Stein
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-the-price-of-diversity-of-the-traveling-salesman-problem/">arXiv: Data Structures and Algorithms: The Price of Diversity of the Traveling Salesman Problem</a> — <small>2025-07-18</small>
        <p>Authors: Mark de Berg, Andrés López Martínez, Frits Spieksma
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-splittable-spanning-trees-and-balanced-forests-in-dense-random-graphs/">arXiv: Data Structures and Algorithms: Splittable Spanning Trees and Balanced Forests in Dense Random Graphs</a> — <small>2025-07-18</small>
        <p>Authors: David Gillman, Jacob Platnick, Dana Randall
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-online-rounding-for-set-cover-under-subset-arrivals/">arXiv: Data Structures and Algorithms: Online Rounding for Set Cover under Subset Arrivals</a> — <small>2025-07-18</small>
        <p>Authors: Jarosław Byrka, Yongho Shin
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-max-cut-with-multiple-cardinality-constraints/">arXiv: Data Structures and Algorithms: Max-Cut with Multiple Cardinality Constraints</a> — <small>2025-07-18</small>
        <p>Authors: Yury Makarychev, Madhusudhan Reddy Pittu, Ali Vakilian
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-maintaining-routing-structures-under-deletions-via-self-pruning/">arXiv: Data Structures and Algorithms: Maintaining Routing Structures under Deletions via Self-Pruning</a> — <small>2025-07-18</small>
        <p>Authors: Bernhard Haeupler, Antti Roeyskoe
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-kernelization-for-h-coloring/">arXiv: Data Structures and Algorithms: Kernelization for H-Coloring</a> — <small>2025-07-18</small>
        <p>Authors: Yael Berkman, Ishay Haviv
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-fast-approximate-rank-determination-and-selection-with-group-testing/">arXiv: Data Structures and Algorithms: Fast Approximate Rank Determination and Selection with Group Testing</a> — <small>2025-07-18</small>
        <p>Authors: Adiesha Liyanage, Braeden Sopp, Brendan Mumey
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-efficiently-constructing-sparse-navigable-graphs/">arXiv: Data Structures and Algorithms: Efficiently Constructing Sparse Navigable Graphs</a> — <small>2025-07-18</small>
        <p>Authors: Alex Conway, Laxman Dhulipala, Martin Farach-Colton, Rob Johnson, Ben Landrum, Christopher Musco, Yarin Shechter, Torsten Suel, Richard Wen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-efficient-semi-external-breadth-first-search/">arXiv: Data Structures and Algorithms: Efficient Semi-External Breadth-First Search</a> — <small>2025-07-18</small>
        <p>Authors: Xiaolong Wan, Xixian Han
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-cut-matching-games-for-bipartiteness-ratio-of-undirected-graphs/">arXiv: Data Structures and Algorithms: Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs</a> — <small>2025-07-18</small>
        <p>Authors: Tasuku Soma, Mingquan Ye, Yuichi Yoshida
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computing-and-bounding-equilibrium-concentrations-in-athermic-chemical/">arXiv: Data Structures and Algorithms: Computing and Bounding Equilibrium Concentrations in Athermic Chemical</a> — <small>2025-07-18</small>
        <p>Authors: Hamidreza Akef, Minki Hhan, David Soloveichik
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computing-and-bounding-equilibrium-concentrations-in-athermic-chemical-systems/">arXiv: Data Structures and Algorithms: Computing and Bounding Equilibrium Concentrations in Athermic Chemical</a> — <small>2025-07-18</small>
        <p>Authors: Hamidreza Akef, Minki Hhan, David Soloveichik
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computational-statistical-tradeoffs-from-np-hardness/">arXiv: Data Structures and Algorithms: Computational-Statistical Tradeoffs from NP-hardness</a> — <small>2025-07-18</small>
        <p>Authors: Guy Blanc, Caleb Koch, Carmen Strassle, Li-Yang Tan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-analysis-of-langevin-midpoint-methods-using-an-anticipative-girsanov/">arXiv: Data Structures and Algorithms: Analysis of Langevin midpoint methods using an anticipative Girsanov</a> — <small>2025-07-18</small>
        <p>Authors: Matthew S. Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-analysis-of-langevin-midpoint-methods-using-an-anticipative-girsanov-theorem/">arXiv: Data Structures and Algorithms: Analysis of Langevin midpoint methods using an anticipative Girsanov</a> — <small>2025-07-18</small>
        <p>Authors: Matthew S. Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-an-eptas-for-multiprocessor-scheduling-with-rejection-under-a-machine/">arXiv: Data Structures and Algorithms: An EPTAS for multiprocessor scheduling with rejection under a machine</a> — <small>2025-07-18</small>
        <p>Authors: Mingyang Gong, Brendan Mumey
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-an-eptas-for-multiprocessor-scheduling-with-rejection-under-a-machine-cost-constraint/">arXiv: Data Structures and Algorithms: An EPTAS for multiprocessor scheduling with rejection under a machine</a> — <small>2025-07-18</small>
        <p>Authors: Mingyang Gong, Brendan Mumey
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-a-1-2-approximation-for-budgeted-k-submodular-maximization/">arXiv: Data Structures and Algorithms: A 1/2-Approximation for Budgeted k-Submodular Maximization</a> — <small>2025-07-18</small>
        <p>Authors: Chenhao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-geometry-a-discrete-analog-of-tutte-s-barycentric-embeddings-on-surfaces/">arXiv: Computational Geometry: A Discrete Analog of Tutte's Barycentric Embeddings on Surfaces</a> — <small>2025-07-18</small>
        <p>Authors: Éric Colin de Verdière, Vincent Despré, Loïc Dubois
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-complexity-the-serial-scaling-hypothesis/">arXiv: Computational Complexity: The Serial Scaling Hypothesis</a> — <small>2025-07-18</small>
        <p>Authors: Yuxi Liu, Konpat Preechakul, Kananart Kuwaranancharoen, Yutong Bai
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-complexity-ranking-vectors-clustering-theory-and-applications/">arXiv: Computational Complexity: Ranking Vectors Clustering: Theory and Applications</a> — <small>2025-07-18</small>
        <p>Authors: Ali Fattahi, Ali Eshragh, Babak Aslani, Meysam Rabiee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-complexity-formulaone-measuring-the-depth-of-algorithmic-reasoning-beyond/">arXiv: Computational Complexity: FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond</a> — <small>2025-07-18</small>
        <p>Authors: Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekha...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-complexity-formulaone-measuring-the-depth-of-algorithmic-reasoning-beyond-competitive-programming/">arXiv: Computational Complexity: FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond</a> — <small>2025-07-18</small>
        <p>Authors: Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekha...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/18/arxiv-computational-complexity-computational-statistical-tradeoffs-from-np-hardness/">arXiv: Computational Complexity: Computational-Statistical Tradeoffs from NP-hardness</a> — <small>2025-07-18</small>
        <p>Authors: Guy Blanc, Caleb Koch, Carmen Strassle, Li-Yang Tan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/ben-recht-the-unpredictability-conundrum/">Ben Recht: The unpredictability conundrum</a> — <small>2025-07-17</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/eccc-papers-tr25-098-ips-lower-bounds-for-formulas-and-sum-of1-roabps/">ECCC Papers: TR25-098 | IPS Lower Bounds for Formulas and Sum of1 ROABPs |</a> — <small>2025-07-17</small>
        <p>We give new lower bounds for the fragments of the Ideal Proof System (IPS) introduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/eccc-papers-tr25-098-ips-lower-bounds-for-formulas-and-sum-of1-roabps-utsab-ghosal-prerona-chatterjee-partha-mukhopadhyay-amit-sinhababu/">ECCC Papers: TR25-098 | IPS Lower Bounds for Formulas and Sum of1 ROABPs |</a> — <small>2025-07-17</small>
        <p>We give new lower bounds for the fragments of the Ideal Proof System (IPS) introduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-weighted-k-server-admits-an-exponentially-competitive-algorithm/">arXiv: Data Structures and Algorithms: Weighted k-Server Admits an Exponentially Competitive Algorithm</a> — <small>2025-07-17</small>
        <p>Authors: Adithya Bijoy, Ankit Mondal, Ashish Chiplunkar
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-pathfinding-in-self-deleting-graphs/">arXiv: Data Structures and Algorithms: Pathfinding in Self-Deleting Graphs</a> — <small>2025-07-17</small>
        <p>Authors: Michal Dvořák, Dušan Knop, Michal Opler, Jan Pokorný, Ondřej Suchý, Krisztina Szilágyi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-online-block-packing/">arXiv: Data Structures and Algorithms: Online Block Packing</a> — <small>2025-07-17</small>
        <p>Authors: Ariel Ben Eliezer, Noam Nisan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-kernelization-for-list-h-coloring-for-graphs-with-small-vertex-cover/">arXiv: Data Structures and Algorithms: Kernelization for list H-coloring for graphs with small vertex cover</a> — <small>2025-07-17</small>
        <p>Authors: Marta Piecyk, Astrid Pieterse, Paweł Rzążewski, Magnus Wahlström
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-finite-pinwheel-scheduling-the-k-visits-problem/">arXiv: Data Structures and Algorithms: Finite Pinwheel Scheduling: the k-Visits Problem</a> — <small>2025-07-17</small>
        <p>Authors: Sotiris Kanellopoulos, Christos Pergaminelis, Maria Kokkou, Euripides Markou, Aris Pagourtzis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-fastrechain-highly-responsive-and-low-overhead-centralized-route-scheduling-in-clos-datacenter-networks/">arXiv: Data Structures and Algorithms: FastReChain: Highly Responsive and Low-Overhead Centralized Route</a> — <small>2025-07-17</small>
        <p>Authors: Zihan Zhu, Dongchao Wu, Zhanbang Zhang, Jian Yang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-approaching-optimality-for-solving-dense-linear-systems-with-low-rank-structure/">arXiv: Data Structures and Algorithms: Approaching Optimality for Solving Dense Linear Systems with Low-Rank</a> — <small>2025-07-17</small>
        <p>Authors: Michał Dereziński, Aaron Sidford
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-a-near-complete-resolution-of-the-exponential-time-complexity-of-k-opt-for-the-traveling-salesman-problem/">arXiv: Data Structures and Algorithms: A near-complete resolution of the exponential-time complexity of k-opt</a> — <small>2025-07-17</small>
        <p>Authors: Sophia Heimann, Hung P. Hoang, Stefan Hougardy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-computational-complexity-which-graph-motif-parameters-count/">arXiv: Computational Complexity: Which graph motif parameters count?</a> — <small>2025-07-17</small>
        <p>Authors: Markus Bläser, Radu Curticapean, Julian Dörfler, Christian Ikenmeyer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-computational-complexity-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for/">arXiv: Computational Complexity: Searching for Falsified Clause in Random (log n)-CNFs is Hard for</a> — <small>2025-07-17</small>
        <p>Authors: Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov, Weiqiang Yuan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/17/arxiv-computational-complexity-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for-randomized-communication/">arXiv: Computational Complexity: Searching for Falsified Clause in Random log n-CNFs is Hard for</a> — <small>2025-07-17</small>
        <p>Authors: Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov, Weiqiang Yuan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/eccc-papers-tr25-097-on-the-limits-of-computationally-sound-ipps-in-the-isolated-model-hadar-strauss/">ECCC Papers: TR25-097 | On the Limits of Computationally Sound IPPs in the Isolated Model |</a> — <small>2025-07-16</small>
        <p>Interactive proofs of proximity (IPPs) are a relaxation of interactive proofs, analogous to property testing, in which soundness is required to hol...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/computational-complexity-turing-wagner-ruth/">Computational Complexity: Turing, Wagner, Ruth</a> — <small>2025-07-16</small>
        <p>Douglas Hofstadter first published Gödel, Escher, Bach: an Eternal Golden Braid in 1979 and my then high school self tried, and failed, to read tho...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/eccc-papers-tr25-096-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for-randomized-communication-artur-riazanov-anastasia-sofronova-dmitry-sokolov-weiqiang-yuan/">ECCC Papers: TR25-096 | Searching for Falsified Clause in Random log{n}-CNFs is Hard for Randomized Communication |</a> — <small>2025-07-16</small>
        <p>We show that for a randomly sampled unsatisfiable $O(\log n)$-CNF over $n$ variables the randomized two-party communication cost of finding a claus...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-solving-random-planted-csps-below-the-n-k-2-threshold/">arXiv: Data Structures and Algorithms: Solving Random Planted CSPs below the n{k/2} Threshold</a> — <small>2025-07-16</small>
        <p>Authors: Arpon Basu, Jun-Ting Hsieh, Andrew D. Lin, Peter Manohar
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-solving-linear-programs-with-differential-privacy/">arXiv: Data Structures and Algorithms: Solving Linear Programs with Differential Privacy</a> — <small>2025-07-16</small>
        <p>Authors: Alina Ene, Huy Le Nguyen, Ta Duy Nguyen, Adrian Vladu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-scheduling-on-identical-machines-with-setup-time-and-unknown-execution-time/">arXiv: Data Structures and Algorithms: Scheduling on Identical Machines with Setup Time and Unknown Execution</a> — <small>2025-07-16</small>
        <p>Authors: Yasushi Kawase, Kazuhisa Makino, Vinh Long Phan, Hanna Sumita
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-rapid-mixing-of-glauber-dynamics-for-monotone-systems-via-entropic-independence/">arXiv: Data Structures and Algorithms: Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic</a> — <small>2025-07-16</small>
        <p>Authors: Weiming Feng, Minji Yang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-permutation-patterns-in-streams/">arXiv: Data Structures and Algorithms: Permutation patterns in streams</a> — <small>2025-07-16</small>
        <p>Authors: Benjamin Aram Berendsohn
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-on-tight-robust-coresets-for-k-medians-clustering/">arXiv: Data Structures and Algorithms: On Tight Robust Coresets for k-Medians Clustering</a> — <small>2025-07-16</small>
        <p>Authors: Lingxiao Huang, Zhenyu Jiang, Yi Li, Xuan Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-multipass-linear-sketches-for-geometric-lp-type-problems/">arXiv: Data Structures and Algorithms: Multipass Linear Sketches for Geometric LP-Type Problems</a> — <small>2025-07-16</small>
        <p>Authors: N. Efe Çekirge, William Gay, David P. Woodruff
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-improved-sampling-algorithms-and-poincar-inequalities-for-non-log-concave-distributions/">arXiv: Data Structures and Algorithms: Improved sampling algorithms and Poincar inequalities for</a> — <small>2025-07-16</small>
        <p>Authors: Yuchen He, Zhehan Lei, Jianan Shao, Chihao Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-fully-dynamic-euclidean-k-means/">arXiv: Data Structures and Algorithms: Fully Dynamic Euclidean k-Means</a> — <small>2025-07-16</small>
        <p>Authors: Sayan Bhattacharya, Martín Costa, Ermiya Farokhnejad, Shaofeng H. -C. Jiang, Yaonan Jin, Jianing Lou
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-fpt-parameterisations-of-fractional-and-generalised-hypertree-width/">arXiv: Data Structures and Algorithms: FPT Parameterisations of Fractional and Generalised Hypertree Width</a> — <small>2025-07-16</small>
        <p>Authors: Matthias Lanzinger, Igor Razgon, Daniel Unterberger
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-finding-order-preserving-subgraphs/">arXiv: Data Structures and Algorithms: Finding Order-Preserving Subgraphs</a> — <small>2025-07-16</small>
        <p>Authors: Haruya Imamura, Yasuaki Kobayashi, Yota Otachi, Toshiki Saitoh, Keita Sato, Asahi Takaoka, Ryo Yoshinaka
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-faster-algorithms-for-k-orthogonal-vectors-in-low-dimension/">arXiv: Data Structures and Algorithms: Faster algorithms for k-Orthogonal Vectors in low dimension</a> — <small>2025-07-16</small>
        <p>Authors: Anita Dürr, Evangelos Kipouridis, Karol Węgrzycki
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-efficient-branch-and-bound-for-submodular-function-maximization-under-knapsack-constraint/">arXiv: Data Structures and Algorithms: Efficient Branch-and-Bound for Submodular Function Maximization under</a> — <small>2025-07-16</small>
        <p>Authors: Yimin Hao, Yi Zhou, Chao Xu, Zhang-Hua Fu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-distributionally-robust-optimization-with-adversarial-data-contamination/">arXiv: Data Structures and Algorithms: Distributionally Robust Optimization with Adversarial Data Contamination</a> — <small>2025-07-16</small>
        <p>Authors: Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-deterministic-lower-bounds-for-k-edge-connectivity-in-the-distributed-sketching-model/">arXiv: Data Structures and Algorithms: Deterministic Lower Bounds for k-Edge Connectivity in the Distributed</a> — <small>2025-07-16</small>
        <p>Authors: Peter Robinson, Ming Ming Tan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-compressed-data-structures-for-heegaard-splittings/">arXiv: Data Structures and Algorithms: Compressed data structures for Heegaard splittings</a> — <small>2025-07-16</small>
        <p>Authors: Henrique Ennes, Clément Maria
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-access-control-for-information-theoretically-secure-key-document-stores/">arXiv: Data Structures and Algorithms: Access Control for Information-Theoretically Secure Key-Document Stores</a> — <small>2025-07-16</small>
        <p>Authors: Yin Li, Sharad Mehrota, Shantanu Sharma, Komal Kumari
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-a-fast-coloring-oracle-for-average-case-hypergraphs/">arXiv: Data Structures and Algorithms: A Fast Coloring Oracle for Average Case Hypergraphs</a> — <small>2025-07-16</small>
        <p>Authors: Cassandra Marcussen, Edward Pyne, Ronitt Rubinfeld, Asaf Shapira, Shlomo Tauber
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-geometry-tileable-surfaces/">arXiv: Computational Geometry: Tileable Surfaces</a> — <small>2025-07-16</small>
        <p>Authors: David Brander, Jens Gravesen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-geometry-on-tight-robust-coresets-for-k-medians-clustering/">arXiv: Computational Geometry: On Tight Robust Coresets for k-Medians Clustering</a> — <small>2025-07-16</small>
        <p>Authors: Lingxiao Huang, Zhenyu Jiang, Yi Li, Xuan Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-geometry-compressed-data-structures-for-heegaard-splittings/">arXiv: Computational Geometry: Compressed data structures for Heegaard splittings</a> — <small>2025-07-16</small>
        <p>Authors: Henrique Ennes, Clément Maria
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-geometry-bicriteria-polygon-aggregation-with-arbitrary-shapes/">arXiv: Computational Geometry: Bicriteria Polygon Aggregation with Arbitrary Shapes</a> — <small>2025-07-16</small>
        <p>Authors: Lotte Blank, David Eppstein, Jan-Henrik Haunert, Herman Haverkort, Benedikt Kolbe, Philip Mayer, Petra Mutzel, Alexander Naumann, Jonas Sa...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-on-the-complexity-of-the-skolem-problem-at-low-orders/">arXiv: Computational Complexity: On the Complexity of the Skolem Problem at Low Orders</a> — <small>2025-07-16</small>
        <p>Authors: Piotr Bacik, Joël Ouaknine, James Worrell
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-on-the-complexity-of-the-optimal-correlated-equilibria-in-extensive-form-games/">arXiv: Computational Complexity: On the Complexity of the Optimal Correlated Equilibria in Extensive-Form</a> — <small>2025-07-16</small>
        <p>Authors: Vincent Cheval, Florian Horn, Soumyajit Paul, Mahsa Shirmohammadi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-fpt-parameterisations-of-fractional-and-generalised-hypertree-width/">arXiv: Computational Complexity: FPT Parameterisations of Fractional and Generalised Hypertree Width</a> — <small>2025-07-16</small>
        <p>Authors: Matthias Lanzinger, Igor Razgon, Daniel Unterberger
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-equality-is-far-weaker-than-constant-cost-communication/">arXiv: Computational Complexity: Equality is Far Weaker than Constant-Cost Communication</a> — <small>2025-07-16</small>
        <p>Authors: Mika Göös, Nathaniel Harms, Artur Riazanov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-eigenvalue-bounds-for-symmetric-markov-chains-on-multislices-with-applications/">arXiv: Computational Complexity: Eigenvalue Bounds for Symmetric Markov Chains on Multislices With</a> — <small>2025-07-16</small>
        <p>Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/16/arxiv-computational-complexity-a-fast-coloring-oracle-for-average-case-hypergraphs/">arXiv: Computational Complexity: A Fast Coloring Oracle for Average Case Hypergraphs</a> — <small>2025-07-16</small>
        <p>Authors: Cassandra Marcussen, Edward Pyne, Ronitt Rubinfeld, Asaf Shapira, Shlomo Tauber
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/eccc-papers-tr25-095-godel-in-cryptography-effectively-zero-knowledge-proofs-for-np-with-no-interaction-no-setup-and-perfect-soundness-rahul-ilango/">ECCC Papers: TR25-095 | Godel in Cryptography: Effectively Zero-Knowledge Proofs for NP with No Interaction, No Setup, and Perfect Soundness |</a> — <small>2025-07-15</small>
        <p>A zero-knowledge proof demonstrates that a fact (like that a Sudoku puzzle has a solution) is true while, counterintuitively, revealing nothing els...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/gil-kalai-joram-s-seminar-2025-hypercontractivity-groups-and-representations/">Gil Kalai: Jorams seminar 2025: Hypercontractivity, Groups and Representations</a> — <small>2025-07-15</small>
        <p>Joram’s seminar 2025
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/david-eppstein-linkage/">David Eppstein: Linkage</a> — <small>2025-07-15</small>
        <p>
  Dozens of the world’s most cited scientists stop falsely claiming to work in Saudi Arabia ((\mathbb{M})). Perhaps relatedly, Clarivate has tight...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/ben-recht-metascience-of-pull-requests/">Ben Recht: Metascience of pull requests</a> — <small>2025-07-15</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-simultaneous-network-design-with-restricted-link-usage/">arXiv: Data Structures and Algorithms: Simultaneous Network Design with Restricted Link Usage</a> — <small>2025-07-15</small>
        <p>Authors: Naonori Kakimura, Péter Madarasi, Jannik Matuschke, Kitti Varga
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-phase-transition-of-the-sinkhorn-knopp-algorithm/">arXiv: Data Structures and Algorithms: Phase transition of the Sinkhorn-Knopp algorithm</a> — <small>2025-07-15</small>
        <p>Authors: Kun He
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-paths-and-intersections-exact-emulators-for-planar-graphs/">arXiv: Data Structures and Algorithms: Paths and Intersections: Exact Emulators for Planar Graphs</a> — <small>2025-07-15</small>
        <p>Authors: George Z. Li, Zihan Tan, Tianyi Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-nearly-tight-sample-complexity-for-matroid-online-contention-resolution/">arXiv: Data Structures and Algorithms: Nearly Tight Sample Complexity for Matroid Online Contention Resolution</a> — <small>2025-07-15</small>
        <p>Authors: Moran Feldman, Ola Svensson, Rico Zenklusen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-minimum-peak-cost-flows-over-time/">arXiv: Data Structures and Algorithms: Minimum-Peak-Cost Flows Over Time</a> — <small>2025-07-15</small>
        <p>Authors: Mariia Anapolska, Emma Ahrens, Christina Büsing, Felix Engelhardt, Timo Gersing, Corinna Mathwieser, Sabrian Schmitz, Sophia Wrede
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-m-eternal-domination-and-variants-on-some-classes-of-finite-and-infinite-graphs/">arXiv: Data Structures and Algorithms: m-Eternal Domination and Variants on Some Classes of Finite and Infinite</a> — <small>2025-07-15</small>
        <p>Authors: Tiziana Calamoneri, Federico Corò, Neeldhara Misra, Saraswati G. Nanoti, Giacomo Paesani
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-improved-directed-expander-decompositions/">arXiv: Data Structures and Algorithms: Improved Directed Expander Decompositions</a> — <small>2025-07-15</small>
        <p>Authors: Henry Fleischmann, George Z. Li, Jason Li
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-improved-bicriteria-approximation-for-k-edge-connectivity/">arXiv: Data Structures and Algorithms: Improved bicriteria approximation for k-edge-connectivity</a> — <small>2025-07-15</small>
        <p>Authors: Zeev Nutov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-explicit-bounds-and-parallel-algorithms-for-counting-multiply-gleeful-numbers/">arXiv: Data Structures and Algorithms: Explicit Bounds and Parallel Algorithms for Counting Multiply Gleeful</a> — <small>2025-07-15</small>
        <p>Authors: Sara Moore, Jonathan P. Sorenson
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-covering-a-few-submodular-constraints-and-applications/">arXiv: Data Structures and Algorithms: Covering a Few Submodular Constraints and Applications</a> — <small>2025-07-15</small>
        <p>Authors: Tanvi Bajpai, Chandra Chekuri, Pooja Kulkarni
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-computing-the-probability-of-intersection/">arXiv: Data Structures and Algorithms: Computing the probability of intersection</a> — <small>2025-07-15</small>
        <p>Authors: Alexander Barvinok
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-colorful-minors/">arXiv: Data Structures and Algorithms: Colorful Minors</a> — <small>2025-07-15</small>
        <p>Authors: Evangelos Protopapas, Dimitrios M. Thilikos, Sebastian Wiederrecht
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-bicriteria-submodular-maximization/">arXiv: Data Structures and Algorithms: Bicriteria Submodular Maximization</a> — <small>2025-07-15</small>
        <p>Authors: Moran Feldman, Alan Kuhnle
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-average-sensitivity-of-hierarchical-k-median-clustering/">arXiv: Data Structures and Algorithms: Average Sensitivity of Hierarchical k-Median Clustering</a> — <small>2025-07-15</small>
        <p>Authors: Shijie Li, Weiqiang He, Ruobing Bai, Pan Peng
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-approximating-maximum-cut-on-interval-graphs-and-split-graphs-beyond-goemans-williamson/">arXiv: Data Structures and Algorithms: Approximating Maximum Cut on Interval Graphs and Split Graphs beyond</a> — <small>2025-07-15</small>
        <p>Authors: Jungho Ahn, Ian DeHaan, Eun Jung Kim, Euiwoong Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-a-fixed-parameter-tractable-approach-for-solving-the-vertex-cover-problem-in-polynomial-time-complexity/">arXiv: Data Structures and Algorithms: A Fixed Parameter Tractable Approach for Solving the Vertex Cover</a> — <small>2025-07-15</small>
        <p>Authors: Mumuksh Tayal
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-the-network-satisfaction-problem-for-relation-algebras-with-at-most-4-atoms/">arXiv: Computational Complexity: The Network Satisfaction Problem for Relation Algebras with at most 4</a> — <small>2025-07-15</small>
        <p>Authors: Manuel Bodirsky, Moritz Jahn, Matěj Konečný, Simon Knäuer, Paul Winkler
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-simultaneous-network-design-with-restricted-link-usage/">arXiv: Computational Complexity: Simultaneous Network Design with Restricted Link Usage</a> — <small>2025-07-15</small>
        <p>Authors: Naonori Kakimura, Péter Madarasi, Jannik Matuschke, Kitti Varga
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-m-eternal-domination-and-variants-on-some-classes-of-finite-and-infinite-graphs/">arXiv: Computational Complexity: m-Eternal Domination and Variants on Some Classes of Finite and Infinite</a> — <small>2025-07-15</small>
        <p>Authors: Tiziana Calamoneri, Federico Corò, Neeldhara Misra, Saraswati G. Nanoti, Giacomo Paesani
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-ips-lower-bounds-for-formulas-and-sum-of-roabps/">arXiv: Computational Complexity: IPS Lower Bounds for Formulas and Sum of ROABPs</a> — <small>2025-07-15</small>
        <p>Authors: Prerona Chatterjee, Utsab Ghosal, Partha Mukhopadhyay, Amit Sinhababu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-directed-disjoint-paths-remains-w-1-hard-on-acyclic-digraphs-without-large-grid-minors/">arXiv: Computational Complexity: Directed disjoint paths remains W[1]-hard on acyclic digraphs without</a> — <small>2025-07-15</small>
        <p>Authors: Ken-ichi Kawarabayashi, Nicola Lorenz, Marcelo Garlet Milani, Jacob Stegemann
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-consensus-inconsistency-emergence-what-s-paraconsistency-got-to-do-with-it/">arXiv: Computational Complexity: Consensus, Inconsistency, Emergence: what's paraconsistency got to do</a> — <small>2025-07-15</small>
        <p>Authors: Gabriel Rocha
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-communication-complexity-is-np-hard/">arXiv: Computational Complexity: Communication Complexity is NP-hard</a> — <small>2025-07-15</small>
        <p>Authors: Shuichi Hirahara, Rahul Ilango, Bruno Loff
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/15/arxiv-computational-complexity-a-critique-of-deng-s-p-np/">arXiv: Computational Complexity: A Critique of Deng's P=NP</a> — <small>2025-07-15</small>
        <p>Authors: Isabel Humphreys, Matthew Iceland, Harry Liuson, Dylan McKellips, Leo Sciortino
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/eccc-papers-tr25-094-communication-complexity-is-np-hard-shuichi-hirahara-rahul-ilango-bruno-loff/">ECCC Papers: TR25-094 | Communication Complexity is NP-hard |</a> — <small>2025-07-14</small>
        <p>In the paper where he first defined Communication Complexity, Yao asks: \emph{Is computing $CC(f)$ (the 2-way communication complexity of a given f...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/eccc-papers-tr25-093-eigenvalue-bounds-for-symmetric-markov-chains-on-multislices-with-applications-prashanth-amireddy-amik-raj-behera-srikanth-srinivasan-madhu-sudan/">ECCC Papers: TR25-093 | Eigenvalue Bounds for Symmetric Markov Chains on Multislices With Applications |</a> — <small>2025-07-14</small>
        <p>We consider random walks on “balanced multislices”
of any “grid” that respects the “symmetries” of the grid, and show that a broad class of such wa...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/property-testing-review-news-for-june-2025/">Property Testing Review: News for June 2025</a> — <small>2025-07-14</small>
        <p>Another (sigh) delayed post. A moderately busy month, with 4 papers with sublinear graph algorithms and, of course, distribution testing.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-to-buy-or-not-to-buy-deterministic-rent-or-buy-problems-on-node-weighted-graphs/">arXiv: Data Structures and Algorithms: To buy or not to buy: deterministic rent-or-buy problems on</a> — <small>2025-07-14</small>
        <p>Authors: Sander Borst, Moritz Venzin
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-the-parallel-complexity-of-finding-a-matroid-basis/">arXiv: Data Structures and Algorithms: On the Parallel Complexity of Finding a Matroid Basis</a> — <small>2025-07-14</small>
        <p>Authors: Sanjeev Khanna, Aaron Putterman, Junkai Song
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-the-constant-factor-approximability-of-minimum-cost-constraint-satisfaction-problems/">arXiv: Data Structures and Algorithms: On the Constant-Factor Approximability of Minimum Cost Constraint</a> — <small>2025-07-14</small>
        <p>Authors: Ian DeHaan, Neng Huang, Euiwoong Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-fair-epsilon-net-and-geometric-hitting-set/">arXiv: Data Structures and Algorithms: On Fair Epsilon Net and Geometric Hitting Set</a> — <small>2025-07-14</small>
        <p>Authors: Mohsen Dehghankar, Stavros Sintos, Abolfazl Asudeh
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-mallows-model-with-learned-distance-metrics-sampling-and-maximum-likelihood-estimation/">arXiv: Data Structures and Algorithms: Mallows Model with Learned Distance Metrics: Sampling and Maximum</a> — <small>2025-07-14</small>
        <p>Authors: Yeganeh Alimohammadi, Kiana Asgari
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-h-planarity-and-parametric-extensions-when-modulators-act-globally/">arXiv: Data Structures and Algorithms: H-Planarity and Parametric Extensions: when Modulators Act Globally</a> — <small>2025-07-14</small>
        <p>Authors: Fedor V. Fomin, Petr A. Golovach, Laure Morelle, Dimitrios M. Thilikos
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-finding-a-solution-to-the-erd-s-ginzburg-ziv-theorem-in-o-n-log-log-log-n-time/">arXiv: Data Structures and Algorithms: Finding a solution to the Erds-Ginzburg-Ziv theorem in</a> — <small>2025-07-14</small>
        <p>Authors: Yui Hin Arvin Leung
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-fast-and-efficient-merge-of-sorted-input-lists-in-hardware-using-list-offset-merge-sorters/">arXiv: Data Structures and Algorithms: Fast and Efficient Merge of Sorted Input Lists in Hardware Using List</a> — <small>2025-07-14</small>
        <p>Authors: Robert B. Kent, Marios S. Pattichis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-beer-path-problems-in-temporal-graphs/">arXiv: Data Structures and Algorithms: Beer Path Problems in Temporal Graphs</a> — <small>2025-07-14</small>
        <p>Authors: Andrea D’Ascenzo, Giuseppe F. Italiano, Sotiris Kanellopoulos, Anna Mpanti, Aris Pagourtzis, Christos Pergaminelis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-approximation-algorithms-for-the-cumulative-vehicle-routing-problem-with-stochastic-demands/">arXiv: Data Structures and Algorithms: Approximation Algorithms for the Cumulative Vehicle Routing Problem with</a> — <small>2025-07-14</small>
        <p>Authors: Jingyang Zhao, Mingyu Xiao
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-computational-geometry-flexible-arrangement-of-two-bennett-tubes/">arXiv: Computational Geometry: Flexible arrangement of two Bennett tubes</a> — <small>2025-07-14</small>
        <p>Authors: Georg Nawratil
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-computational-geometry-computing-optimal-trajectories-for-a-tethered-pursuer/">arXiv: Computational Geometry: Computing optimal trajectories for a tethered pursuer</a> — <small>2025-07-14</small>
        <p>Authors: Aurelio Barrera-Vicent, José Miguel Díaz-Báñez, Fabio Rodríguez, Vanesa Sánchez-Canales
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-computational-geometry-a-robust-approach-to-detect-intersections-between-triangles-with-different-numerical-representations/">arXiv: Computational Geometry: A Robust Approach to Detect Intersections between Triangles with</a> — <small>2025-07-14</small>
        <p>Authors: Luca Garau, Gianmarco Cherchi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-computational-complexity-on-the-constant-factor-approximability-of-minimum-cost-constraint-satisfaction-problems/">arXiv: Computational Complexity: On the Constant-Factor Approximability of Minimum Cost Constraint</a> — <small>2025-07-14</small>
        <p>Authors: Ian DeHaan, Neng Huang, Euiwoong Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/14/arxiv-computational-complexity-communication-complexity-of-pointer-chasing-via-the-fixed-set-lemma/">arXiv: Computational Complexity: Communication complexity of pointer chasing via the fixed-set lemma</a> — <small>2025-07-14</small>
        <p>Authors: Emanuele Viola
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/13/computational-complexity-how-much-money-did-francis-scott-key-give-to-have-a-building-named-after-him/">Computational Complexity: How much money did Francis Scott Key give to have a building named after him?</a> — <small>2025-07-13</small>
        <p>UMCP has a building named
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/12/eccc-papers-tr25-092-complexity-theoretic-inductive-inference-shuichi-hirahara-mikito-nanashima/">ECCC Papers: TR25-092 | Complexity-Theoretic Inductive Inference |</a> — <small>2025-07-12</small>
        <p>Inductive inference, introduced by Solomonoff (Information and Control, 1964), is a foundational concept in knowledge acquisition, formulated as th...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/ben-recht-are-developers-finally-out-of-a-job/">Ben Recht: Are developers finally out of a job?</a> — <small>2025-07-11</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/cci-jobs-postdoc-in-complexity-theory-at-university-of-warwick-apply-by-july-31-2025/">CCI: jobs: Postdoc in Complexity Theory at University of Warwick apply by July 31, 2025</a> — <small>2025-07-11</small>
        <p>A postdoctoral position is available in the research group of Igor Carboni Oliveira at the University of Warwick. Candidates interested in computat...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-on-the-complexity-of-hyperpath-and-minimal-separator-enumeration-in-directed-hypergraphs/">arXiv: Data Structures and Algorithms: On the Complexity of Hyperpath and Minimal Separator Enumeration in</a> — <small>2025-07-11</small>
        <p>Authors: Kazuhiro Kurita, Kevin Mann
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-finding-sparse-induced-subgraphs-on-graphs-of-bounded-induced-matching-treewidth/">arXiv: Data Structures and Algorithms: Finding sparse induced subgraphs on graphs of bounded induced matching</a> — <small>2025-07-11</small>
        <p>Authors: Hans L. Bodlaender, Fedor V. Fomin, Tuukka Korhonen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-finding-one-local-optimum-is-easy-but-what-about-two/">arXiv: Data Structures and Algorithms: Finding One Local Optimum Is Easy -- But What about Two?</a> — <small>2025-07-11</small>
        <p>Authors: Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-efficient-and-adaptive-estimation-of-local-triadic-coefficients/">arXiv: Data Structures and Algorithms: Efficient and Adaptive Estimation of Local Triadic Coefficients</a> — <small>2025-07-11</small>
        <p>Authors: Ilie Sarpe, Aristides Gionis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-a-randomized-rounding-approach-for-dag-edge-deletion/">arXiv: Data Structures and Algorithms: A Randomized Rounding Approach for DAG Edge Deletion</a> — <small>2025-07-11</small>
        <p>Authors: Sina Kalantarzadeh, Nathan Klein, Victor Reis
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-geometry-the-smooth-power-of-the-neandertal-method/">arXiv: Computational Geometry: The Smooth Power of the Neandertal Method</a> — <small>2025-07-11</small>
        <p>Authors: Aaron Montag, Tim Reinhardt, Jürgen Richter-Gebert
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-geometry-approximation-depth-of-convex-polytopes/">arXiv: Computational Geometry: Approximation Depth of Convex Polytopes</a> — <small>2025-07-11</small>
        <p>Authors: Egor Bakaev, Florestan Brunck, Amir Yehudayoff
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-geometry-a-simple-proof-of-a-p-2-theorem-for-non-piercing-regions/">arXiv: Computational Geometry: A simple proof of a p,2-theorem for non-piercing regions</a> — <small>2025-07-11</small>
        <p>Authors: Chaya Keller, Shakhar Smorodinsky
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-turing-complete-navier-stokes-steady-states-via-cosymplectic-geometry/">arXiv: Computational Complexity: Turing complete Navier-Stokes steady states via cosymplectic geometry</a> — <small>2025-07-11</small>
        <p>Authors: Søren Dyhr, Ángel González-Prieto, Eva Miranda, Daniel Peralta-Salas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-the-richness-of-csp-non-redundancy/">arXiv: Computational Complexity: The Richness of CSP Non-redundancy</a> — <small>2025-07-11</small>
        <p>Authors: Joshua Brakensiek, Venkatesan Guruswami, Bart M. P. Jansen, Victor Lagerkvist, Magnus Wahlström
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-testing-isomorphism-of-boolean-functions-over-finite-abelian-groups/">arXiv: Computational Complexity: Testing Isomorphism of Boolean Functions over Finite Abelian Groups</a> — <small>2025-07-11</small>
        <p>Authors: Swarnalipa Datta, Arijit Ghosh, Chandrima Kayal, Manaswi Paraashar, Manmatha Roy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-on-the-complexity-of-hyperpath-and-minimal-separator-enumeration-in-directed-hypergraphs/">arXiv: Computational Complexity: On the Complexity of Hyperpath and Minimal Separator Enumeration in</a> — <small>2025-07-11</small>
        <p>Authors: Kazuhiro Kurita, Kevin Mann
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-nonogram-complexity-of-inference-and-phase-transition-behavior/">arXiv: Computational Complexity: Nonogram: Complexity of Inference and Phase Transition Behavior</a> — <small>2025-07-11</small>
        <p>Authors: Aaron Foote, Danny Krizanc
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/11/arxiv-computational-complexity-finding-one-local-optimum-is-easy-but-what-about-two/">arXiv: Computational Complexity: Finding One Local Optimum Is Easy -- But What about Two?</a> — <small>2025-07-11</small>
        <p>Authors: Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/ben-recht-an-open-mindset/">Ben Recht: An open mindset</a> — <small>2025-07-10</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/eccc-papers-tr25-091-tree-pcps-tamer-mour-alon-rosen-ron-rothblum/">ECCC Papers: TR25-091 | Tree PCPs |</a> — <small>2025-07-10</small>
        <p>Probabilistically checkable proofs (PCPs) allow encoding a computation so that it can be quickly verified by only reading a few symbols. Inspired b...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/eccc-papers-tr25-090-linear-prover-iops-in-log-star-rounds-ron-rothblum-noor-athamnah-noga-ron-zewi/">ECCC Papers: TR25-090 | Linear Prover IOPs in Log Star Rounds |</a> — <small>2025-07-10</small>
        <p>Interactive Oracle Proofs (IOPs) form the backbone of some of the most efficient general-purpose cryptographic proof-systems. In an IOP, the prover...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-prediction-augmented-mechanism-design-for-weighted-facility-location/">arXiv: Data Structures and Algorithms: Prediction-Augmented Mechanism Design for Weighted Facility Location</a> — <small>2025-07-10</small>
        <p>Authors: Yangguang Shi, Zhenyu Xue
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-parallel-batch-dynamic-coreness-decomposition-with-worst-case-guarantees/">arXiv: Data Structures and Algorithms: Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees</a> — <small>2025-07-10</small>
        <p>Authors: Mohsen Ghaffari, Jaehyun Koo
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-parallel-batch-dynamic-algorithms-for-spanners-and-extensions/">arXiv: Data Structures and Algorithms: Parallel Batch-Dynamic Algorithms for Spanners, and Extensions</a> — <small>2025-07-10</small>
        <p>Authors: Mohsen Ghaffari, Jaehyun Koo
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-multi-queue-ssd-i-o-modeling-its-implications-for-data-structure-design/">arXiv: Data Structures and Algorithms: Multi-Queue SSD I/O Modeling &amp; Its Implications for Data Structure</a> — <small>2025-07-10</small>
        <p>Authors: Erin Ransom, Andrew Lim, Michael Mitzenmacher
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-faster-estimation-of-the-average-degree-of-a-graph-using-random-edges-and-structural-queries/">arXiv: Data Structures and Algorithms: Faster Estimation of the Average Degree of a Graph Using Random Edges</a> — <small>2025-07-10</small>
        <p>Authors: Lorenzo Beretta, Deeparnab Chakrabarty, C. Seshadhri
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-faster-algorithms-for-2k-1-stretch-distance-oracles/">arXiv: Data Structures and Algorithms: Faster Algorithms for 2k-1-Stretch Distance Oracles</a> — <small>2025-07-10</small>
        <p>Authors: Avi Kadria, Liam Roditty
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-designing-parallel-algorithms-for-community-detection-using-arachne/">arXiv: Data Structures and Algorithms: Designing Parallel Algorithms for Community Detection using Arachne</a> — <small>2025-07-10</small>
        <p>Authors: Fuhuan Li, Zhihui Du, David A. Bader
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-computational-geometry-topological-machine-learning-with-unreduced-persistence-diagrams/">arXiv: Computational Geometry: Topological Machine Learning with Unreduced Persistence Diagrams</a> — <small>2025-07-10</small>
        <p>Authors: Nicole Abreu, Parker B. Edwards, Francis Motta
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-computational-geometry-an-improved-bound-for-plane-covering-paths/">arXiv: Computational Geometry: An Improved Bound for Plane Covering Paths</a> — <small>2025-07-10</small>
        <p>Authors: Hugo A. Akitaya, Greg Aloupis, Ahmad Biniaz, Prosenjit Bose, Jean-Lou De Carufel, Cyril Gavoille, John Iacono, Linda Kleist, Michiel Smid,...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-computational-complexity-trainability-of-quantum-models-beyond-known-classical-simulability/">arXiv: Computational Complexity: Trainability of Quantum Models Beyond Known Classical Simulability</a> — <small>2025-07-10</small>
        <p>Authors: Sabri Meyer, Francesco Scala, Francesco Tacchino, Aurelien Lucchi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/10/arxiv-computational-complexity-efficient-algorithms-for-quantum-hashing/">arXiv: Computational Complexity: Efficient Algorithms for Quantum Hashing</a> — <small>2025-07-10</small>
        <p>Authors: Ilnar Zinnatullin, Kamil Khadiev
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/eccc-papers-tr25-089-chain-rules-for-time-bounded-kolmogorov-complexity-valentine-kabanets-antonina-kolokolova/">ECCC Papers: TR25-089 | Chain Rules for Time-Bounded Kolmogorov Complexity |</a> — <small>2025-07-09</small>
        <p>Time-bounded conditional Kolmogorov complexity of a string $x$ given $y$, $K^t(x\mid y)$, is the length of a shortest program that, given $y$, prin...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/computational-complexity-the-customers-of-the-academy/">Computational Complexity: The Customers of the Academy</a> — <small>2025-07-09</small>
        <p>I had an epiphany reading an article in the Trenton Times when I lived in New Jersey at the turn of the century. The article interviewed companies ...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-parameterized-restless-temporal-path/">arXiv: Data Structures and Algorithms: Parameterized Restless Temporal Path</a> — <small>2025-07-09</small>
        <p>Authors: Justine Cauvi, Laurent Viennot
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-non-adaptive-evaluation-of-k-of-n-functions-tight-gap-and-a-unit-cost-ptas/">arXiv: Data Structures and Algorithms: Non-Adaptive Evaluation of k-of-n Functions: Tight Gap and a</a> — <small>2025-07-09</small>
        <p>Authors: Mads Anker Nielsen, Lars Rohwedder, Kevin Schewior
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-learning-augmented-online-covering-problems/">arXiv: Data Structures and Algorithms: Learning-Augmented Online Covering Problems</a> — <small>2025-07-09</small>
        <p>Authors: Afrouz Jabal Ameli, Laura Sanita, Moritz Venzin
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-instance-optimal-quantum-state-certification-with-entangled-measurements/">arXiv: Data Structures and Algorithms: Instance-Optimal Quantum State Certification with Entangled Measurements</a> — <small>2025-07-09</small>
        <p>Authors: Ryan O’Donnell, Chirag Wadhwa
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-an-optimal-algorithm-for-shortest-paths-in-unweighted-disk-graphs/">arXiv: Data Structures and Algorithms: An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs</a> — <small>2025-07-09</small>
        <p>Authors: Bruce W. Brewer, Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-a-formal-refutation-of-the-blockchain-trilemma/">arXiv: Data Structures and Algorithms: A Formal Refutation of the Blockchain Trilemma</a> — <small>2025-07-09</small>
        <p>Authors: Craig Wright
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-25-additional-problems-extension-to-the-book-125-problems-in-text-algorithms/">arXiv: Data Structures and Algorithms: 25 Additional Problems -- Extension to the Book 125 Problems in Text</a> — <small>2025-07-09</small>
        <p>Authors: Maxime Crochemore, Thierry Lecroq, Wojtek Rytter
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-geometry-k-means-considered-harmful-on-arbitrary-topological-changes-in-mapper-complexes/">arXiv: Computational Geometry: k-means considered harmful: On arbitrary topological changes in Mapper</a> — <small>2025-07-09</small>
        <p>Authors: Mikael Vejdemo-Johansson
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-geometry-fast-and-accurate-collision-probability-estimation-for-autonomous-vehicles-using-adaptive-sigma-point-sampling/">arXiv: Computational Geometry: Fast and Accurate Collision Probability Estimation for Autonomous</a> — <small>2025-07-09</small>
        <p>Authors: Charles Champagne Cossette, Taylor Scott Clawson, Andrew Feit
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-geometry-an-optimal-algorithm-for-shortest-paths-in-unweighted-disk-graphs/">arXiv: Computational Geometry: An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs</a> — <small>2025-07-09</small>
        <p>Authors: Bruce W. Brewer, Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-unitary-designs-in-nearly-optimal-depth/">arXiv: Computational Complexity: Unitary designs in nearly optimal depth</a> — <small>2025-07-09</small>
        <p>Authors: Laura Cui, Thomas Schuster, Fernando Brandao, Hsin-Yuan Huang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-parameterized-restless-temporal-path/">arXiv: Computational Complexity: Parameterized Restless Temporal Path</a> — <small>2025-07-09</small>
        <p>Authors: Justine Cauvi, Laurent Viennot
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-on-the-complexity-of-problems-on-graphs-defined-on-groups/">arXiv: Computational Complexity: On the Complexity of Problems on Graphs Defined on Groups</a> — <small>2025-07-09</small>
        <p>Authors: Bireswar Das, Dipan Dey, Jinia Ghosh
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-lineal-extensions-of-kakeya-sets-missing-every-ee-random-point/">arXiv: Computational Complexity: Lineal Extensions of Kakeya Sets Missing Every ee-Random Point</a> — <small>2025-07-09</small>
        <p>Authors: Neil Lutz, Spencer Park Martin, Rain White
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-generalized-and-unified-equivalences-between-hardness-and-pseudoentropy/">arXiv: Computational Complexity: Generalized and Unified Equivalences between Hardness and Pseudoentropy</a> — <small>2025-07-09</small>
        <p>Authors: Lunjia Hu, Salil Vadhan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-complexity-results-of-persuasion/">arXiv: Computational Complexity: Complexity Results of Persuasion</a> — <small>2025-07-09</small>
        <p>Authors: Alban Grastien
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/09/arxiv-computational-complexity-a-formal-refutation-of-the-blockchain-trilemma/">arXiv: Computational Complexity: A Formal Refutation of the Blockchain Trilemma</a> — <small>2025-07-09</small>
        <p>Authors: Craig Wright
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/nisheeth-vishnoi-what-is-intelligence-layers-of-emergence/">Nisheeth Vishnoi: What is Intelligence? Layers of Emergence</a> — <small>2025-07-08</small>
        <p>How Intelligence Arises from Nature, One Layer at a Time
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/cs-theory-events-proof-complexity-2025/">CS Theory Events: Proof Complexity 2025</a> — <small>2025-07-08</small>
        <p>August 11-13, 2025 Oxford, UK https://feasible-math.org/events/PC25/ Proof complexity is a vibrant area in the intersection of computational comple...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-truthful-credible-and-optimal-auctions-for-matroids-via-blockchains-and-commitments/">arXiv: Data Structures and Algorithms: Truthful, Credible, and Optimal Auctions for Matroids via Blockchains</a> — <small>2025-07-08</small>
        <p>Authors: Aadityan Ganesh, Qianfan Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-tight-guarantees-for-cut-relative-survivable-network-design-via-a-decomposition-technique/">arXiv: Data Structures and Algorithms: Tight Guarantees for Cut-Relative Survivable Network Design via a</a> — <small>2025-07-08</small>
        <p>Authors: Nikhil Kumar, JJ Nan, Chaitanya Swamy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-planar-edge-coloring-theorem-of-vizing-in-o-n-log-n-time/">arXiv: Data Structures and Algorithms: The planar edge-coloring theorem of Vizing in Onlog n time</a> — <small>2025-07-08</small>
        <p>Authors: Patryk Jędrzejczak, Łukasz Kowalik
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-fair-periodic-assignment-problem/">arXiv: Data Structures and Algorithms: The Fair Periodic Assignment Problem</a> — <small>2025-07-08</small>
        <p>Authors: Rolf van Lieshout, Bart van Rossum
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-recent-advances-in-maximum-entropy-sampling/">arXiv: Data Structures and Algorithms: Recent Advances in Maximum-Entropy Sampling</a> — <small>2025-07-08</small>
        <p>Authors: Marcia Fampa, Jon Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-quantum-algorithms-for-bandits-with-knapsacks-with-improved-regret-and-time-complexities/">arXiv: Data Structures and Algorithms: Quantum Algorithms for Bandits with Knapsacks with Improved Regret and</a> — <small>2025-07-08</small>
        <p>Authors: Yuexin Su, Ziyi Yang, Peiyuan Huang, Tongyang Li, Yinyu Ye
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-makespan-scheduling-under-scenarios/">arXiv: Data Structures and Algorithms: Online Makespan Scheduling under Scenarios</a> — <small>2025-07-08</small>
        <p>Authors: Ekin Ergen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-convex-optimization-with-switching-cost-with-only-one-single-gradient-evaluation/">arXiv: Data Structures and Algorithms: Online Convex Optimization with Switching Cost with Only One Single</a> — <small>2025-07-08</small>
        <p>Authors: Harsh Shah, Purna Chandrasekhar, Rahul Vaze
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-maximizing-the-margin-between-desirable-and-undesirable-elements-in-a-covering-problem/">arXiv: Data Structures and Algorithms: Maximizing the Margin between Desirable and Undesirable Elements in a</a> — <small>2025-07-08</small>
        <p>Authors: Sophie Boileau, Andrew Hong, David Liben-Nowell, Alistair Pattison, Anna N. Rafferty, Charlie Roslansky
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-liar-s-vertex-edge-domination-in-subclasses-of-chordal-graphs/">arXiv: Data Structures and Algorithms: Liar's vertex-edge domination in subclasses of chordal graphs</a> — <small>2025-07-08</small>
        <p>Authors: Debojyoti Bhattacharya, Subhabrata Paul
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-improved-algorithms-for-effective-resistance-computation-on-graphs/">arXiv: Data Structures and Algorithms: Improved Algorithms for Effective Resistance Computation on Graphs</a> — <small>2025-07-08</small>
        <p>Authors: Yichun Yang, Rong-Hua Li, Meihao Liao, Guoren Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-hipermotif-novel-parallel-subgraph-isomorphism-in-large-scale-property-graphs/">arXiv: Data Structures and Algorithms: HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property</a> — <small>2025-07-08</small>
        <p>Authors: Mohammad Dindoost, Oliver Alvarado Rodriguez, Bartosz Bryg, Ioannis Koutis, David A. Bader
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-heights-of-butterfly-trees/">arXiv: Data Structures and Algorithms: Heights of butterfly trees</a> — <small>2025-07-08</small>
        <p>Authors: John Peca-Medlin, Chenyang Zhong
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-greedy-dynamic-matching/">arXiv: Data Structures and Algorithms: Greedy Dynamic Matching</a> — <small>2025-07-08</small>
        <p>Authors: Nick Arnosti, Felipe Simon
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-distributed-approximation-algorithms-for-minimum-dominating-set-in-locally-nice-graphs/">arXiv: Data Structures and Algorithms: Distributed Approximation Algorithms for Minimum Dominating Set in</a> — <small>2025-07-08</small>
        <p>Authors: Marthe Bonamy, Cyril Gavoille, Timothé Picavet, Alexandra Wesolek
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/">arXiv: Data Structures and Algorithms: Decremental Greedy Polygons and Polyhedra Without Sharp Angles</a> — <small>2025-07-08</small>
        <p>Authors: David Eppstein
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-combination-generators-with-optimal-cache-utilization-and-communication-free-parallel-execution/">arXiv: Data Structures and Algorithms: Combination generators with optimal cache utilization and communication</a> — <small>2025-07-08</small>
        <p>Authors: Xi He, Max. A. Little
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-color-distance-oracles-and-snippets-separation-between-exact-and-approximate-solutions/">arXiv: Data Structures and Algorithms: Color Distance Oracles and Snippets: Separation Between Exact and</a> — <small>2025-07-08</small>
        <p>Authors: Noam Horowicz, Tsvi Kopelowitz
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-bicriteria-approximation-for-k-edge-connectivity/">arXiv: Data Structures and Algorithms: Bicriteria approximation for k-edge-connectivity</a> — <small>2025-07-08</small>
        <p>Authors: Zeev Nutov, Reut Cohen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-agentic-distributed-computing/">arXiv: Data Structures and Algorithms: Agentic Distributed Computing</a> — <small>2025-07-08</small>
        <p>Authors: Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-combinatorial-n-fold-ilps-using-the-steinitz-lemma/">arXiv: Data Structures and Algorithms: A simple algorithm for Combinatorial n-fold ILPs using the Steinitz</a> — <small>2025-07-08</small>
        <p>Authors: Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-note-on-finding-long-directed-cycles-above-the-minimum-degree-bound-in-2-connected-digraphs/">arXiv: Data Structures and Algorithms: A note on finding long directed cycles above the minimum degree bound in</a> — <small>2025-07-08</small>
        <p>Authors: Jadwiga Czyżewska, Marcin Pilipczuk
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-geometry-node-neighbor-subnetworks-and-hk-core-decomposition/">arXiv: Computational Geometry: Node-neighbor subnetworks and Hk-core decomposition</a> — <small>2025-07-08</small>
        <p>Authors: Dinghua Shi, Yang Zhao, Guanrong Chen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-geometry-input-sensitive-reconfiguration-of-sliding-cubes/">arXiv: Computational Geometry: Input-Sensitive Reconfiguration of Sliding Cubes</a> — <small>2025-07-08</small>
        <p>Authors: Hugo Akitaya, Matias Korman, Frederick Stock
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-geometry-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/">arXiv: Computational Geometry: Decremental Greedy Polygons and Polyhedra Without Sharp Angles</a> — <small>2025-07-08</small>
        <p>Authors: David Eppstein
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-geometry-computing-largest-subsets-of-points-whose-convex-hulls-have-bounded-area-and-diameter/">arXiv: Computational Geometry: Computing Largest Subsets of Points Whose Convex Hulls have Bounded Area</a> — <small>2025-07-08</small>
        <p>Authors: Gianmarco Picarella, Marc van Kreveld, Frank Staals, Sjoerd de Vries
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-geometry-approximation-and-hardness-of-polychromatic-tsp/">arXiv: Computational Geometry: Approximation and Hardness of Polychromatic TSP</a> — <small>2025-07-08</small>
        <p>Authors: Thomas Schibler, Subhash Suri, Jie Xue
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-testing-for-renamability-to-classes-of-clause-sets/">arXiv: Computational Complexity: Testing for Renamability to Classes of Clause Sets</a> — <small>2025-07-08</small>
        <p>Authors: Albert Brandl, Christian G. Fermüller, Gernot Salzer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-pfcs-prime-factorization-cache-system-for-deterministic-data-relationship-discovery/">arXiv: Computational Complexity: PFCS: Prime Factorization Cache System for Deterministic Data</a> — <small>2025-07-08</small>
        <p>Authors: Duy Le
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-low-sets-for-counting-functions/">arXiv: Computational Complexity: Low sets for counting functions</a> — <small>2025-07-08</small>
        <p>Authors: Yaroslav Ivanashev
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/david-eppstein-ready-lists/">David Eppstein: Ready lists</a> — <small>2025-07-07</small>
        <p>Beginning computer science students learn about stacks, queues, and priority queues, different ways of organizing and ordering a collection of task...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/ben-recht-you-keep-using-that-word/">Ben Recht: You keep using that word</a> — <small>2025-07-07</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/gil-kalai-happy-birthday-saharon-shelah-and-yuri-gurevich/">Gil Kalai: Happy Birthday Saharon Shelah and Yuri Gurevich!</a> — <small>2025-07-07</small>
        <p>Let me briefly report on two birthday conferences for long-time friends and colleagues Saharon Shelah and Yuri Gurevich. Yuri fest took place in Mu...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/">arXiv: Data Structures and Algorithms: On the Approximability of Train Routing and the Min-Max Disjoint Paths</a> — <small>2025-07-07</small>
        <p>Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-going-beyond-surfaces-in-diameter-approximation/">arXiv: Data Structures and Algorithms: Going Beyond Surfaces in Diameter Approximation</a> — <small>2025-07-07</small>
        <p>Authors: Michał Włodarczyk
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-discovering-algorithms-with-computational-language-processing/">arXiv: Data Structures and Algorithms: Discovering Algorithms with Computational Language Processing</a> — <small>2025-07-07</small>
        <p>Authors: Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-bayesian-optimal-stopping-with-maximum-value-knowledge/">arXiv: Data Structures and Algorithms: Bayesian Optimal Stopping with Maximum Value Knowledge</a> — <small>2025-07-07</small>
        <p>Authors: Pieter Kleer, Daan Noordenbos
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-barvinok-s-interpolation-method-meets-weitz-s-correlation-decay-approach/">arXiv: Data Structures and Algorithms: Barvinok's interpolation method meets Weitz's correlation decay approach</a> — <small>2025-07-07</small>
        <p>Authors: Ferenc Bencs, Guus Regts
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-quantum-computation-with-correlated-measurements-implications-for-the-complexity-landscape/">arXiv: Computational Complexity: Quantum Computation with Correlated Measurements: Implications for the</a> — <small>2025-07-07</small>
        <p>Authors: David Miloschewsky, Supartha Podder
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/">arXiv: Computational Complexity: On the Approximability of Train Routing and the Min-Max Disjoint Paths</a> — <small>2025-07-07</small>
        <p>Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-complexity-of-learning-matchings-and-half-graphs-via-edge-queries/">arXiv: Computational Complexity: Complexity of learning matchings and half graphs via edge queries</a> — <small>2025-07-07</small>
        <p>Authors: Nikhil S. Mande, Swagato Sanyal, Viktor Zamaraev
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-are-depth-2-regular-expressions-hard-to-intersect/">arXiv: Computational Complexity: Are Depth-2 Regular Expressions Hard to Intersect?</a> — <small>2025-07-07</small>
        <p>Authors: Rocco Ascone, Giulia Bernardini, Alessio Conte, Veronica Guerrini, Giulia Punzi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-a-near-optimal-polynomial-distance-lemma-over-boolean-slices/">arXiv: Computational Complexity: A Near-Optimal Polynomial Distance Lemma Over Boolean Slices</a> — <small>2025-07-07</small>
        <p>Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/06/computational-complexity-the-new-lower-bound-on-busy-beaver-of-6/">Computational Complexity: The New Lower Bound on Busy Beaver of 6.</a> — <small>2025-07-06</small>
        <p> We denote the busy beaver function by BB.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/06/eccc-papers-tr25-088-factorization-norms-and-an-inverse-theorem-for-maxcut-igor-balla-lianna-hambardzumyan-istvan-tomon/">ECCC Papers: TR25-088 | Factorization norms and an inverse theorem for MaxCut |</a> — <small>2025-07-06</small>
        <p>We prove that Boolean matrices with bounded $\gamma_2$-norm or bounded normalized trace norm must contain a linear-sized all-ones or all-zeros subm...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-online-conformal-prediction-with-efficiency-guarantees/">arXiv: Data Structures and Algorithms: Online Conformal Prediction with Efficiency Guarantees</a> — <small>2025-07-04</small>
        <p>Authors: Vaidehi Srinivas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-structure-of-replicable-hypothesis-testers/">arXiv: Data Structures and Algorithms: On the Structure of Replicable Hypothesis Testers</a> — <small>2025-07-04</small>
        <p>Authors: Anders Aamand, Maryam Aliakbarpour, Justin Y. Chen, Shyam Narayanan, Sandeep Silwal
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-complexity-of-knapsack-under-explorable-uncertainty-hardness-and-algorithms/">arXiv: Data Structures and Algorithms: On the Complexity of Knapsack under Explorable Uncertainty: Hardness and</a> — <small>2025-07-04</small>
        <p>Authors: Jens Schlöter
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-adversarial-robustness-of-online-importance-sampling/">arXiv: Data Structures and Algorithms: On the Adversarial Robustness of Online Importance Sampling</a> — <small>2025-07-04</small>
        <p>Authors: Yotam Kenneth-Mordoch, Shay Sapir
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-numerical-linear-algebra-in-linear-space/">arXiv: Data Structures and Algorithms: Numerical Linear Algebra in Linear Space</a> — <small>2025-07-04</small>
        <p>Authors: Yiping Liu, Hoai-An Nguyen, Junzhao Yang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-new-algorithms-for-girth-and-cycle-detection/">arXiv: Data Structures and Algorithms: New algorithms for girth and cycle detection</a> — <small>2025-07-04</small>
        <p>Authors: Liam Roditty, Plia Trabelsi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-indexing-tries-within-entropy-bounded-space/">arXiv: Data Structures and Algorithms: Indexing Tries within Entropy-Bounded Space</a> — <small>2025-07-04</small>
        <p>Authors: Lorenzo Carfagna, Carlo Tosoni
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-faster-algorithm-for-bounded-tree-edit-distance-in-the-low-distance-regime/">arXiv: Data Structures and Algorithms: Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance</a> — <small>2025-07-04</small>
        <p>Authors: Tomasz Kociumaka, Ali Shahali
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-connected-k-median-with-disjoint-and-non-disjoint-clusters/">arXiv: Data Structures and Algorithms: Connected k-Median with Disjoint and Non-disjoint Clusters</a> — <small>2025-07-04</small>
        <p>Authors: Jan Eube, Kelin Luo, Dorian Reineccius, Heiko Röglin, Melanie Schmidt
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-bounded-weighted-edit-distance-dynamic-algorithms-and-matching-lower-bounds/">arXiv: Data Structures and Algorithms: Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower</a> — <small>2025-07-04</small>
        <p>Authors: Itai Boneh, Egor Gorbachev, Tomasz Kociumaka
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-an-easy-proof-of-a-weak-version-of-chernoff-inequality/">arXiv: Data Structures and Algorithms: An Easy Proof of a Weak Version of Chernoff inequality</a> — <small>2025-07-04</small>
        <p>Authors: Sariel Har-Peled
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-a-computational-proof-of-the-highest-scoring-boggle-board/">arXiv: Data Structures and Algorithms: A Computational Proof of the Highest-Scoring Boggle Board</a> — <small>2025-07-04</small>
        <p>Authors: Dan Vanderkam
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-computational-geometry-a-linear-time-algorithm-for-finding-minimum-flip-sequences-between-plane-spanning-paths-in-convex-point-sets/">arXiv: Computational Geometry: A Linear Time Algorithm for Finding Minimum Flip Sequences between Plane</a> — <small>2025-07-04</small>
        <p>Authors: Oswin Aichholzer, Joseph Dorfer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-computational-complexity-stiefel-optimization-is-np-hard/">arXiv: Computational Complexity: Stiefel optimization is NP-hard</a> — <small>2025-07-04</small>
        <p>Authors: Zehua Lai, Lek-Heng Lim, Tianyun Tang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/ben-recht-standard-error-of-what-now/">Ben Recht: Standard error of what now?</a> — <small>2025-07-03</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-sparse-pivot-dynamic-correlation-clustering-for-node-insertions/">arXiv: Data Structures and Algorithms: SPARSE-PIVOT: Dynamic correlation clustering for node insertions</a> — <small>2025-07-03</small>
        <p>Authors: Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrović
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-optimal-dispersion-under-asynchrony/">arXiv: Data Structures and Algorithms: Optimal Dispersion Under Asynchrony</a> — <small>2025-07-03</small>
        <p>Authors: Debasish Pattanayak, Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-faster-algorithm-for-second-s-t-mincut-and-breaking-quadratic-barrier-for-dual-edge-sensitivity-for-s-t-mincut/">arXiv: Data Structures and Algorithms: Faster Algorithm for Second s,t-mincut and Breaking Quadratic barrier</a> — <small>2025-07-03</small>
        <p>Authors: Surender Baswana, Koustav Bhanja, Anupam Roy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-dynamic-similarity-graph-construction-with-kernel-density-estimation/">arXiv: Data Structures and Algorithms: Dynamic Similarity Graph Construction with Kernel Density Estimation</a> — <small>2025-07-03</small>
        <p>Authors: Steinar Laenen, Peter Macgregor, He Sun
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-breaking-the-n-1-5-additive-error-barrier-for-private-and-efficient-graph-sparsification-via-private-expander-decomposition/">arXiv: Data Structures and Algorithms: Breaking the n{1.5} Additive Error Barrier for Private and Efficient</a> — <small>2025-07-03</small>
        <p>Authors: Anders Aamand, Justin Y. Chen, Mina Dalirrooyfard, Slobodan Mitrović, Yuriy Nevmyvaka, Sandeep Silwal, Yinzhan Xu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-a-deterministic-partition-tree-and-applications/">arXiv: Data Structures and Algorithms: A Deterministic Partition Tree and Applications</a> — <small>2025-07-03</small>
        <p>Authors: Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-search-based-robot-motion-planning-with-distance-based-adaptive-motion-primitives/">arXiv: Computational Geometry: Search-Based Robot Motion Planning With Distance-Based Adaptive Motion</a> — <small>2025-07-03</small>
        <p>Authors: Benjamin Kraljusic, Zlatan Ajanovic, Nermin Covic, Bakir Lacevic
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-multiple-watchman-routes-in-staircase-polygons/">arXiv: Computational Geometry: Multiple Watchman Routes in Staircase Polygons</a> — <small>2025-07-03</small>
        <p>Authors: Anna Brötzner, Bengt J. Nilsson, Christiane Schmidt
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-stable-and-theoretically-grounded-gromov-wasserstein-distance-for-reeb-graph-comparison-using-persistence-images/">arXiv: Computational Geometry: A Stable and Theoretically Grounded Gromov-Wasserstein Distance for Reeb</a> — <small>2025-07-03</small>
        <p>Authors: Erin W. Chambers, Guangyu Meng
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-deterministic-partition-tree-and-applications/">arXiv: Computational Geometry: A Deterministic Partition Tree and Applications</a> — <small>2025-07-03</small>
        <p>Authors: Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-symport-antiport-p-systems-with-membrane-separation-characterize-p-p/">arXiv: Computational Complexity: Symport/Antiport P Systems with Membrane Separation Characterize P#P</a> — <small>2025-07-03</small>
        <p>Authors: Vivien Ducros, Claudio Zandron
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-pcpp-based-reconfiguration-inapproximability-query-complexity-vs-soundness-gap-trade-offs/">arXiv: Computational Complexity: PCPP-Based Reconfiguration Inapproximability: Query Complexity vs.</a> — <small>2025-07-03</small>
        <p>Authors: Venkatesan Guruswami, Xuandi Ren, Kewen Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-hardness-of-quantum-distribution-learning-and-quantum-cryptography/">arXiv: Computational Complexity: Hardness of Quantum Distribution Learning and Quantum Cryptography</a> — <small>2025-07-03</small>
        <p>Authors: Taiga Hiroka, Min-Hsiu Hsieh, Tomoyuki Morimae
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/computational-complexity-a-professor-again/">Computational Complexity: A Professor Again</a> — <small>2025-07-02</small>
        <p>A new dean has taken my place, and I have returned to the professoriate at Illinois Tech, ending thirteen years in administration, six as dean and ...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/gil-kalai-some-events/">Gil Kalai: Some Events</a> — <small>2025-07-02</small>
        <p>Annual meeting of the Israeli Mathematical Union and student talks day, July 6 and 7
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-quantum-speedups-for-polynomial-time-dynamic-programming-algorithms/">arXiv: Data Structures and Algorithms: Quantum Speedups for Polynomial-Time Dynamic Programming Algorithms</a> — <small>2025-07-02</small>
        <p>Authors: Susanna Caroppo, Giordano Da Lozzo, Giuseppe Di Battista, Michael T. Goodrich, Martin Nöllenburg
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-on-the-in-approximability-of-the-monitoring-edge-geodetic-set-problem/">arXiv: Data Structures and Algorithms: On the InApproximability of the Monitoring Edge Geodetic Set Problem</a> — <small>2025-07-02</small>
        <p>Authors: Davide Bilò, Giodano Colli, Luca Forlizzi, Stefano Leucci
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-lazy-b-trees/">arXiv: Data Structures and Algorithms: Lazy B-Trees</a> — <small>2025-07-02</small>
        <p>Authors: Casper Moldrup Rysgaard, Sebastian Wild
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-hamiltonicity-parameterized-by-mim-width-is-indeed-para-np-hard/">arXiv: Data Structures and Algorithms: Hamiltonicity Parameterized by Mim-Width is Indeed Para-NP-Hard</a> — <small>2025-07-02</small>
        <p>Authors: Benjamin Bergougnoux, Lars Jaffke
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-best-agent-identification-for-general-game-playing/">arXiv: Data Structures and Algorithms: Best Agent Identification for General Game Playing</a> — <small>2025-07-02</small>
        <p>Authors: Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-trimmed-multipoint-evaluation/">arXiv: Data Structures and Algorithms: A Simple Algorithm for Trimmed Multipoint Evaluation</a> — <small>2025-07-02</small>
        <p>Authors: Nick Fischer, Melvin Kallmayer, Leo Wennmann
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-empirical-analysis-of-heuristic-and-approximation-algorithms-for-the-the-mutual-visibility-problem/">arXiv: Computational Geometry: Empirical Analysis Of Heuristic and Approximation Algorithms for the The</a> — <small>2025-07-02</small>
        <p>Authors: Vanja Stojanović, Bor Pangeršič
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-compact-representation-of-semilinear-and-terrain-like-graphs/">arXiv: Computational Geometry: Compact Representation of Semilinear and Terrain-like Graphs</a> — <small>2025-07-02</small>
        <p>Authors: Jean Cardinal, Yelena Yuditsky
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-analyzing-time-varying-scalar-fields-using-piecewise-linear-morse-cerf-theory/">arXiv: Computational Geometry: Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf</a> — <small>2025-07-02</small>
        <p>Authors: Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-complexity-sensitivity-and-query-complexity-under-uncertainty/">arXiv: Computational Complexity: Sensitivity and Query Complexity under Uncertainty</a> — <small>2025-07-02</small>
        <p>Authors: Deepu Benson, Balagopal Komarath, Nikhil Mande, Sai Soumya Nalli, Jayalal Sarma, Karteek Sreenivasaiah
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-complexity-logarithmic-depth-decomposition-of-approximate-multi-controlled-single-qubit-gates-without-ancilla-qubits/">arXiv: Computational Complexity: Logarithmic Depth Decomposition of Approximate Multi-Controlled</a> — <small>2025-07-02</small>
        <p>Authors: Jefferson D. S. Silva, Adenilton J. da Silva
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/david-eppstein-geometric-street-art-in-kanazawa/">David Eppstein: Geometric street art in Kanazawa</a> — <small>2025-07-01</small>
        <p>Kanazawa was this year’s host of Computational Geometry Week and the Symposium on Computational Geometry, and a great place to visit for lots of re...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/ben-recht-two-years-of-substacking/">Ben Recht: Two years of substacking</a> — <small>2025-07-01</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-passage-traversing-optimal-path-planning-with-sampling-based-algorithms/">arXiv: Computational Geometry: Passage-traversing optimal path planning with sampling-based algorithms</a> — <small>2025-07-01</small>
        <p>Authors: Jing Huang, Hao Su, Kwok Wai Samuel Au
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-moving-matter-using-a-single-simple-robot-to-reconfigure-a-connected-set-of-building-blocks/">arXiv: Computational Geometry: Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected</a> — <small>2025-07-01</small>
        <p>Authors: Javier Garcia, Jonas Friemel, Ramin Kosfeld, Michael Yannuzzi, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt, Harm Kube,...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-escher-tile-deformation-via-closed-form-solution/">arXiv: Computational Geometry: Escher Tile Deformation via Closed-Form Solution</a> — <small>2025-07-01</small>
        <p>Authors: Crane He Chen, Vladimir G. Kim
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-c-4-free-subgraphs-of-high-degree-with-geometric-applications/">arXiv: Computational Geometry: C_4-free subgraphs of high degree with geometric applications</a> — <small>2025-07-01</small>
        <p>Authors: Zach Hunter, Aleksa Milojević, Istvan Tomon, Benny Sudakov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-factorization-norms-and-an-inverse-theorem-for-maxcut/">arXiv: Computational Complexity: Factorization norms and an inverse theorem for MaxCut</a> — <small>2025-07-01</small>
        <p>Authors: Igor Balla, Lianna Hambardzumyan, István Tomon
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-constant-depth-circuits-for-polynomial-gcd-over-any-characteristic/">arXiv: Computational Complexity: Constant-depth circuits for polynomial GCD over any characteristic</a> — <small>2025-07-01</small>
        <p>Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-closure-under-factorization-from-a-result-of-furstenberg/">arXiv: Computational Complexity: Closure under factorization from a result of Furstenberg</a> — <small>2025-07-01</small>
        <p>Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu S. Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-characterizing-small-circuit-classes-from-fac-0-to-fac-1-via-discrete-ordinary-differential-equations/">arXiv: Computational Complexity: Characterizing Small Circuit Classes from FAC0 to FAC1 via Discrete</a> — <small>2025-07-01</small>
        <p>Authors: Melissa Antonelli, Arnaud Durand, Juha Kontinen
</p>
      </li>
    
  </ul>

<script src="https://unpkg.com/lunr/lunr.js"></script>

<script>
  const posts = [
    
    {
      "title": "arXiv: Data Structures and Algorithms: TIMEST: Temporal Information Motif Estimator Using Sampling Trees",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-timest-temporal-information-motif-estimator-using-sampling-trees/",
      "content": "Authors: Yunjie Pan, Omkar Bhalerao, C. Seshadhri, Nishil Talati\n\nThe mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\nMotif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\nIn this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\nWe give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The Min Max Average Cycle Weight Problem",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-the-min-max-average-cycle-weight-problem/",
      "content": "Authors: Noga Klein Elmalem, Rica Gonen, Erel Segal-Halevi\n\nWhen an old apartment building is demolished and rebuilt, how can we fairly\nredistribute the new apartments to minimize envy among residents? We reduce\nthis question to a combinatorial optimization problem called the *Min Max\nAverage Cycle Weight* problem. In that problem we seek to assign objects to\nagents in a way that minimizes the maximum average weight of directed cycles in\nan associated envy graph. While this problem reduces to maximum-weight matching\nwhen starting from a clean slate (achieving polynomial-time solvability), we\nshow that this is not the case when we account for preexisting conditions, such\nas residents’ satisfaction with their original apartments. Whether the problem\nis polynomial-time solvable in the general case remains an intriguing open\nproblem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Parallel Hierarchical Agglomerative Clustering in Low Dimensions",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-parallel-hierarchical-agglomerative-clustering-in-low-dimensions/",
      "content": "Authors: MohammadHossein Bateni, Laxman Dhulipala, Willem Fletcher, Kishen N Gowda, D Ellis Hershkowitz, Rajesh Jayaram, Jakub Łącki\n\nHierarchical Agglomerative Clustering (HAC) is an extensively studied and\nwidely used method for hierarchical clustering in $\\mathbb{R}^k$ based on\nrepeatedly merging the closest pair of clusters according to an input linkage\nfunction $d$. Highly parallel (i.e., NC) algorithms are known for\n$(1+\\epsilon)$-approximate HAC (where near-minimum rather than minimum pairs\nare merged) for certain linkage functions that monotonically increase as merges\nare performed. However, no such algorithms are known for many important but\nnon-monotone linkage functions such as centroid and Ward’s linkage.\nIn this work, we show that a general class of non-monotone linkage functions\n– which include centroid and Ward’s distance – admit efficient NC algorithms\nfor $(1+\\epsilon)$-approximate HAC in low dimensions. Our algorithms are based\non a structural result which may be of independent interest: the height of the\nhierarchy resulting from any constant-approximate HAC on $n$ points for this\nclass of linkage functions is at most $\\operatorname{poly}(\\log n)$ as long as\n$k = O(\\log \\log n / \\log \\log \\log n)$. Complementing our upper bounds, we\nshow that NC algorithms for HAC with these linkage functions in\n\\emph{arbitrary} dimensions are unlikely to exist by showing that HAC is\nCC-hard when $d$ is centroid distance and $k = n$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Rounding Schemes for k -Rental Problems",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-online-rounding-schemes-for-k-rental-problems/",
      "content": "Authors: Hossein Nekouyan, Bo Sun, Raouf Boutaba, Xiaoqi Tan\n\nWe study two online resource-allocation problems with reusability in an\nadversarial setting, namely kRental-Fixed and kRental-Variable. In both\nproblems, a decision-maker manages $k$ identical reusable units and faces a\nsequence of rental requests over time. We develop theoretically grounded\nrelax-and-round algorithms with provable competitive-ratio guarantees for both\nsettings. For kRental-Fixed, we present an optimal randomized algorithm that\nattains the best possible competitive ratio: it first computes an optimal\nfractional allocation via a price-based approach, then applies a novel lossless\nonline rounding scheme to obtain an integral solution. For kRental-Variable, we\nprove that lossless online rounding is impossible. We introduce a\nlimited-correlation rounding technique that treats each unit independently\nwhile introducing controlled dependencies across allocation decisions involving\nthe same unit. Coupled with a carefully crafted price-based method for\ncomputing the fractional allocation, this yields an order-optimal competitive\nratio for the variable-duration setting.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Learning with Probing for Sequential User-Centric Selection",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-online-learning-with-probing-for-sequential-user-centric-selection/",
      "content": "Authors: Tianyi Xu, Yiting Chen, Henger Li, Zheyong Bian, Emiliano Dall’Anese, Zizhan Zheng\n\nWe formalize sequential decision-making with information acquisition as the\nprobing-augmented user-centric selection (PUCS) framework, where a learner\nfirst probes a subset of arms to obtain side information on resources and\nrewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such\nas ridesharing, wireless scheduling, and content recommendation, in which both\nresources and payoffs are initially unknown and probing is costly. For the\noffline setting with known distributions, we present a greedy probing algorithm\nwith a constant-factor approximation guarantee $\\zeta = (e-1)/(2e-1)$. For the\nonline setting with unknown distributions, we introduce OLPA, a stochastic\ncombinatorial bandit algorithm that achieves a regret bound\n$\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound\n$\\Omega(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic\nfactors. Experiments on real-world data demonstrate the effectiveness of our\nsolutions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: MTASet: A Tree-based Set for Efficient Range Queries in Update-heavy",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-mtaset-a-tree-based-set-for-efficient-range-queries-in-update-heavy/",
      "content": "Authors: Daniel Manor, Mor Perry, Moshe Sulamy\n\nIn concurrent data structures, the efficiency of set operations can vary\nsignificantly depending on the workload characteristics. Numerous concurrent\nset implementations are optimized and fine-tuned to excel in scenarios\ncharacterized by predominant read operations. However, they often perform\npoorly when confronted with workloads that heavily prioritize updates.\nAdditionally, current leading-edge concurrent sets optimized for update-heavy\ntasks typically lack efficiency in handling atomic range queries. This study\nintroduces the MTASet, which leverages a concurrent (a,b)-tree implementation.\nEngineered to accommodate update-heavy workloads and facilitate atomic range\nqueries, MTASet surpasses existing counterparts optimized for tasks in range\nquery operations by up to 2x. Notably, MTASet ensures linearizability.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved 2-Approximate Shortest Paths for close vertex pairs",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-improved-2-approximate-shortest-paths-for-close-vertex-pairs/",
      "content": "Authors: Manoj Gupta\n\nAn influential result by Dor, Halperin, and Zwick (FOCS 1996, SICOMP 2000)\nimplies an algorithm that can compute approximate shortest paths for all vertex\npairs in $\\tilde{O}(n^{2+O\\left(\\frac{1}{k}\\right )})$ time, ensuring that the\noutput distance is at most twice the actual shortest path, provided the pairs\nare at least $k$ apart, where $k \\ge 2$. We present the first improvement on\nthis result in over 25 years. Our algorithm achieves roughly same\n$\\tilde{O}(n^{2+\\frac{1}{k}})$ runtime but applies to vertex pairs merely\n$O(\\log k)$ apart, where $\\log k \\ge 1$. When $k=\\log n$, the running time of\nour algorithm is $\\tilde{O}(n^2)$ and it works for all pairs at least $O(\\log\n\\log n)$ apart. Our algorithm is combinatorial, randomized, and returns correct\nresults for all pairs with a high probability.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Generating Satisfiable Benchmark Instances for Stable Roommates Problems",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-generating-satisfiable-benchmark-instances-for-stable-roommates-problems/",
      "content": "Authors: Baturay Yılmaz, Esra Erdem\n\nWhile the existence of a stable matching for the stable roommates problem\npossibly with incomplete preference lists (SRI) can be decided in polynomial\ntime, SRI problems with some fairness criteria are intractable. Egalitarian SRI\nthat tries to maximize the total satisfaction of agents if a stable matching\nexists, is such a hard variant of SRI. For experimental evaluations of methods\nto solve these hard variants of SRI, several well-known algorithms have been\nused to randomly generate benchmark instances. However, these benchmark\ninstances are not always satisfiable, and usually have a small number of stable\nmatchings if one exists. For such SRI instances, despite the NP-hardness of\nEgalitarian SRI, it is practical to find an egalitarian stable matching by\nenumerating all stable matchings. In this study, we introduce a novel algorithm\nto generate benchmark instances for SRI that have very large numbers of\nsolutions, and for which it is hard to find an egalitarian stable matching by\nenumerating all stable matchings.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fully Dynamic Spectral and Cut Sparsifiers for Directed Graphs",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-fully-dynamic-spectral-and-cut-sparsifiers-for-directed-graphs/",
      "content": "Authors: Yibin Zhao\n\nRecent years have seen extensive research on directed graph sparsification.\nIn this work, we initiate the study of fast fully dynamic spectral and cut\nsparsification algorithms for directed graphs.\nWe introduce a new notion of spectral sparsification called degree-balance\npreserving spectral approximation, which maintains the difference between the\nin-degree and out-degree of each vertex. The approximation error is measured\nwith respect to the corresponding undirected Laplacian. This notion is\nequivalent to direct Eulerian spectral approximation when the input graph is\nEulerian. Our algorithm achieves an amortized update time of\n$O(\\varepsilon^{-2} \\cdot \\text{polylog}(n))$ and produces a sparsifier of size\n$O(\\varepsilon^{-2} n \\cdot \\text{polylog}(n))$. Additionally, we present an\nalgorithm that maintains a constant-factor approximation sparsifier of size\n$O(n \\cdot \\text{polylog}(n))$ against an adaptive adversary for\n$O(\\text{polylog}(n))$-partially symmetrized graphs, a notion introduced in\n[Kyng-Meierhans-Probst Gutenberg ‘22]. A $\\beta$-partial symmetrization of a\ndirected graph $\\vec{G}$ is the union of $\\vec{G}$ and $\\beta \\cdot G$, where\n$G$ is the corresponding undirected graph of $\\vec{G}$. This algorithm also\nachieves a polylogarithmic amortized update time.\nMoreover, we develop a fully dynamic algorithm for maintaining a cut\nsparsifier for $\\beta$-balanced directed graphs, where the ratio between\nweighted incoming and outgoing edges of any cut is at most $\\beta$. This\nalgorithm explicitly maintains a cut sparsifier of size\n$O(\\varepsilon^{-2}\\beta n \\cdot \\text{polylog}(n))$ in worst-case update time\n$O(\\varepsilon^{-2}\\beta \\cdot \\text{polylog}(n))$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster exact learning of k-term DNFs with membership and equivalence",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-faster-exact-learning-of-k-term-dnfs-with-membership-and-equivalence/",
      "content": "Authors: Josh Alman, Shivam Nadimpalli, Shyamal Patel, Rocco Servedio\n\nIn 1992 Blum and Rudich [BR92] gave an algorithm that uses membership and\nequivalence queries to learn $k$-term DNF formulas over ${0,1}^n$ in time\n$\\textsf{poly}(n,2^k)$, improving on the naive $O(n^k)$ running time that can\nbe achieved without membership queries [Val84]. Since then, many alternative\nalgorithms [Bsh95, Kus97, Bsh97, BBB+00] have been given which also achieve\nruntime $\\textsf{poly}(n,2^k)$.\nWe give an algorithm that uses membership and equivalence queries to learn\n$k$-term DNF formulas in time $\\textsf{poly}(n) \\cdot 2^{\\tilde{O}(\\sqrt{k})}$.\nThis is the first improvement for this problem since the original work of Blum\nand Rudich [BR92].\nOur approach employs the Winnow2 algorithm for learning linear threshold\nfunctions over an enhanced feature space which is adaptively constructed using\nmembership queries. It combines a strengthened version of a technique that\neffectively reduces the length of DNF terms from the original work of [BR92]\nwith a range of additional algorithmic tools (attribute-efficient learning\nalgorithms for low-weight linear threshold functions and techniques for finding\nrelevant variables from junta testing) and analytic ingredients (extremal\npolynomials and noise operators) that are novel in the context of query-based\nDNF learning.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Deterministic Almost-Linear-Time Gomory-Hu Trees",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-deterministic-almost-linear-time-gomory-hu-trees/",
      "content": "Authors: Amir Abboud, Rasmus Kyng, Jason Li, Debmalya Panigrahi, Maximilian Probst Gutenberg, Thatchaphol Saranurak, Weixuan Yuan, Wuwei Yuan\n\nGiven an $m$-edge, undirected, weighted graph $G=(V,E,w)$, a Gomory-Hu tree\n$T$ (Gomory and Hu, 1961) is a tree over the vertex set $V$ such that all-pairs\nmincuts in $G$ are preserved exactly in $T$.\nIn this article, we give the first almost-optimal $m^{1+o(1)}$-time\ndeterministic algorithm for constructing a Gomory-Hu tree. Prior to our work,\nthe best deterministic algorithm for this problem dated back to the original\nalgorithm of Gomory and Hu that runs in $nm^{1+o(1)}$ time (using current\nmaxflow algorithms). In fact, this is the first almost-linear time\ndeterministic algorithm for even simpler problems, such as finding the\n$k$-edge-connected components of a graph.\nOur new result hinges on two separate and novel components that each\nintroduce a distinct set of de-randomization tools of independent interest:\n\n  a deterministic reduction from the all-pairs mincuts problem to the\nsingle-souce mincuts problem incurring only subpolynomial overhead, and\n  a deterministic almost-linear time algorithm for the single-source mincuts\nproblem.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-cleann-efficient-full-dynamism-in-graph-based-approximate-nearest/",
      "content": "Authors: Ziyu Zhang, Yuanhao Wei, Joshua Engels, Julian Shun\n\nApproximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Algorithm-to-Contract Framework without Demand Queries",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-an-algorithm-to-contract-framework-without-demand-queries/",
      "content": "Authors: Ilan Doron-Arad, Hadas Shachnai, Gilad Shmerler, Inbal Talgam-Cohen\n\nConsider costly tasks that add up to the success of a project, and must be\nfitted by an agent into a given time-frame. This is an instance of the classic\nbudgeted maximization problem, which admits an approximation scheme (FPTAS).\nNow assume the agent is performing these tasks on behalf of a principal, who is\nthe one to reap the rewards if the project succeeds. The principal must design\na contract to incentivize the agent. Is there still an approximation scheme? In\nthis work, our ultimate goal is an algorithm-to-contract transformation, which\ntransforms algorithms for combinatorial problems (like budgeted maximization)\nto tackle incentive constraints that arise in contract design. Our approach\ndiverges from previous works on combinatorial contract design by avoiding an\nassumption of black-box access to a demand oracle.\nWe first show how to “lift” the FPTAS for budgeted maximization to obtain the\nbest-possible multiplicative and additive FPTAS for the contract design\nproblem. We establish this through our “local-global” framework, in which the\n“local” step is to (approximately) solve a two-sided strengthened variant of\nthe demand problem. The “global” step then utilizes the local one to find the\napproximately optimal contract. We apply our framework to a host of\ncombinatorial constraints including multi-dimensional budgets, budgeted\nmatroid, and budgeted matching constraints. In all cases we achieve an\napproximation essentially matching the best approximation for the purely\nalgorithmic problem. We also develop a method to tackle multi-agent contract\nsettings, where the team of working agents must abide to combinatorial\nfeasibility constraints.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Adaptive BSTs for Single-Source and All-to-All Requests: Algorithms and",
      "url": "/cstheoryrss/2025/07/29/arxiv-data-structures-and-algorithms-adaptive-bsts-for-single-source-and-all-to-all-requests-algorithms-and/",
      "content": "Authors: Maryam Shiran\n\nAdaptive binary search trees are a fundamental data structure for organizing\nhierarchical information. Their ability to dynamically adjust to access\npatterns makes them particularly valuable for building responsive and efficient\nnetworked and distributed systems.\nWe present a unified framework for adaptive binary search trees with fixed\nrestructuring cost, analyzed under two models: the single-source model, where\nthe cost of querying a node is proportional to its distance from a fixed\nsource, and the all-to-all model, where the cost of serving a request depends\non the distance between the source and destination nodes. We propose an offline\nalgorithm for the single-source model and extend it to the all-to-all model.\nFor both models, we prove upper bounds on the cost incurred by our algorithms.\nFurthermore, we show the existence of input sequences for which any offline\nalgorithm must incur a cost comparable to ours.\nIn the online setting, we develop a general mathematical framework for\ndeterministic online adaptive binary search trees and propose a deterministic\nonline strategy for the single-source case, which naturally extends to the\nall-to-all model. We also establish lower bounds on the competitive ratio of\nany deterministic online algorithm, highlighting fundamental limitations of\nonline adaptivity.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: The number of regular simplices in higher dimensions",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-geometry-the-number-of-regular-simplices-in-higher-dimensions/",
      "content": "Authors: Felix Christian Clemen, Adrian Dumitrescu, Dingyuan Liu\n\nWe study the extremal function $S^k_d(n)$, defined as the maximum number of\nregular $(k-1)$-simplices spanned by $n$ points in $\\mathbb{R}^d$. For any\nfixed $d\\geq2k\\geq6$, we determine the asymptotic behavior of $S^k_d(n)$ up to\na multiplicative constant in the lower-order term. In particular, when $k=3$,\nwe determine the exact value of $S^3_d(n)$, for all even dimensions $d\\geq6$\nand sufficiently large $n$. This resolves a conjecture of Erd\\H{o}s in a\nstronger form. The proof leverages techniques from hypergraph Tur'an theory\nand linear algebra.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: General Strong Bound on the Uncrossed Number which is Tight for the Edge",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-geometry-general-strong-bound-on-the-uncrossed-number-which-is-tight-for-the-edge/",
      "content": "Authors: Gaspard Charvy, Tomáš Masařík\n\nWe investigate a very recent concept for visualizing various aspects of a\ngraph in the plane using a collection of drawings introduced by Hlin\\v{e}n'y\nand Masa\\v{r}'ik [GD 2023]. Formally, given a graph $G$, we aim to find an\nuncrossed collection containing drawings of $G$ in the plane such that each\nedge of $G$ is not crossed in at least one drawing in the collection. The\nuncrossed number of $G$ ($unc(G)$) is the smallest integer $k$ such that an\nuncrossed collection for $G$ of size $k$ exists. The uncrossed number is\nlower-bounded by the well-known thickness, which is an edge-decomposition of\n$G$ into planar graphs. This connection gives a trivial lower-bound\n$\\lceil\\frac{|E(G)|}{3|V(G)|-6}\\rceil \\le unc(G)$. In a recent paper, Balko,\nHlin\\v{e}n'y, Masa\\v{r}'ik, Orthaber, Vogtenhuber, and Wagner [GD 2024]\npresented the first non-trivial and general lower-bound on the uncrossed\nnumber. We summarize it in terms of dense graphs (where\n$|E(G)|=\\epsilon(|V(G)|)^2$ for some $\\epsilon&gt;0$):\n$\\lceil\\frac{|E(G)|}{c_\\epsilon|V(G)|}\\rceil \\le unc(G)$, where $c_\\epsilon\\ge\n2.82$ is a constant depending on $\\epsilon$.\nWe improve the lower-bound to state that\n$\\lceil\\frac{|E(G)|}{3|V(G)|-6-\\sqrt{2|E(G)|}+\\sqrt{6(|V(G)|-2)}}\\rceil \\le\nunc(G)$. Translated to dense graphs regime, the bound yields a multiplicative\nconstant $c’_\\epsilon=3-\\sqrt{(2-\\epsilon)}$ in the expression\n$\\lceil\\frac{|E(G)|}{c’_\\epsilon|V(G)|+o(|V(G)|)}\\rceil \\le unc(G)$. Hence, it\nis tight (up to low-order terms) for $\\epsilon \\approx \\frac{1}{2}$ as\nwarranted by complete graphs.\nIn fact, we formulate our result in the language of the maximum uncrossed\nsubgraph number, that is, the maximum number of edges of $G$ that are not\ncrossed in a drawing of $G$ in the plane. In that case, we also provide a\nconstruction certifying that our bound is asymptotically tight (up to low-order\nterms) on dense graphs for all $\\epsilon&gt;0$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: The Power of Negation in Higher-Order Datalog",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-complexity-the-power-of-negation-in-higher-order-datalog/",
      "content": "Authors: Angelos Charalambidis, Babis Kostopoulos, Christos Nomikos, Panos Rondogiannis\n\nWe investigate the expressive power of Higher-Order Datalog$^\\neg$ under both\nthe well-founded and the stable model semantics, establishing tight connections\nwith complexity classes. We prove that under the well-founded semantics, for\nall $k\\geq 1$, $(k+1)$-Order Datalog$^\\neg$ captures k-EXP, a result that holds\nwithout explicit ordering of the input database. The proof of this fact can be\nperformed either by using the powerful existential predicate variables of the\nlanguage or by using partially applied relations and relation enumeration.\nFurthermore, we demonstrate that this expressive power is retained within a\nstratified fragment of the language. Under the stable model semantics, we show\nthat $(k+1)$-Order Datalog$^\\neg$ captures co-(k-NEXP) using cautious reasoning\nand k-NEXP using brave reasoning, again with analogous results for the\nstratified fragment augmented with choice rules. Our results establish a\nhierarchy of expressive power, highlighting an interesting trade-off between\norder and non-determinism in the context of higher-order logic programming:\nincreasing the order of programs under the well-founded semantics can surpass\nthe expressive power of lower-order programs under the stable model semantics.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Racing to Idle: Energy Efficiency of Matrix Multiplication on",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-complexity-racing-to-idle-energy-efficiency-of-matrix-multiplication-on/",
      "content": "Authors: Mufakir Qamar Ansari, Mudabir Qamar Ansari\n\nThe paradigm shift towards multi-core and heterogeneous computing, driven by\nthe fundamental power and thermal limits of single-core processors, has\nestablished energy efficiency as a first-class design constraint in\nhigh-performance computing (HPC). Heterogeneous systems, integrating\ntraditional multi-core CPUs with specialized accelerators like discrete (dGPU)\nand integrated (iGPU) graphics processing units, offer a compelling path to\nnavigating the trade-offs between performance and power. However, quantifying\nthese trade-offs on widely accessible hardware remains a critical area of\nstudy. This paper presents a direct, empirical measurement of the performance\nand energy-to-solution of a canonical HPC workload – a 4096x4096 matrix-matrix\nmultiplication – on three distinct compute architectures within a single\nconsumer-grade laptop: a multi-core AMD Ryzen 7 5800H CPU, a discrete NVIDIA\nGeForce GTX 1650 GPU, and an integrated AMD Radeon Vega GPU. Using standard,\nvalidated, and minimally intrusive tools such as Linux perf and nvidia-smi, we\nfind that the discrete GPU is not only the performance leader, achieving a\n93.5x speedup over the CPU, but is also the most energy-efficient, consuming\nonly 2% of the energy used by the CPU, resulting in a 50-fold improvement in\nenergy efficiency. These findings provide a practical demonstration of the\n“race to idle” principle and offer clear, quantitative guidance on\narchitectural choices for energy-aware software development.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On Higher Order Busy Beaver Function",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-complexity-on-higher-order-busy-beaver-function/",
      "content": "Authors: Zining Cao\n\nIn this paper, we extend Busy Beaver function to a class of higher order Busy\nBeaver functions based on Turing oracle machine. We prove some results about\nthe relation between decidability of number theoretical formula and higher\norder Busy Beaver functions, and the relation between computability of max-min\npartial recursive functions and higher order Busy Beaver functions. We also\npresent some conjectures on higher order Busy Beaver functions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Core Safety Values for Provably Corrigible Agents",
      "url": "/cstheoryrss/2025/07/29/arxiv-computational-complexity-core-safety-values-for-provably-corrigible-agents/",
      "content": "Authors: Aran Nayebi\n\nWe introduce the first implementable framework for corrigibility, with\nprovable guarantees in multi-step, partially observed environments. Our\nframework replaces a single opaque reward with five *structurally separate*\nutility heads – deference, switch-access preservation, truthfulness,\nlow-impact behavior via a belief-based extension of Attainable Utility\nPreservation, and bounded task reward – combined lexicographically by strict\nweight gaps. Theorem 1 proves exact single-round corrigibility in the partially\nobservable off-switch game; Theorem 3 extends the guarantee to multi-step,\nself-spawning agents, showing that even if each head is \\emph{learned} to\nmean-squared error $\\varepsilon$ and the planner is $\\varepsilon$-sub-optimal,\nthe probability of violating \\emph{any} safety property is bounded while still\nensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,\nwhich merge all norms into one learned scalar, our separation makes obedience\nand impact-limits dominate even when incentives conflict. For open-ended\nsettings where adversaries can modify the agent, we prove that deciding whether\nan arbitrary post-hack agent will ever violate corrigibility is undecidable by\nreduction to the halting problem, then carve out a finite-horizon ``decidable\nisland’’ where safety can be certified in randomized polynomial time and\nverified with privacy-preserving, constant-round zero-knowledge proofs.\nConsequently, the remaining challenge is the ordinary ML task of data coverage\nand generalization: reward-hacking risk is pushed into evaluation quality\nrather than hidden incentive leak-through, giving clearer implementation\nguidance for today’s LLM assistants and future autonomous systems.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-104 | How to Construct Random Strings |",
      "url": "/cstheoryrss/2025/07/28/eccc-papers-tr25-104-how-to-construct-random-strings/",
      "content": "We address the following fundamental question: is there an efficient deterministic algorithm that, given $1^n$, outputs a string of length $n$ that has polynomial-time bounded Kolmogorov complexity $\\tilde{\\Omega}(n)$ or even $n - o(n)$?\nUnder plausible complexity-theoretic assumptions, stating for example that there is an $\\epsilon &gt; 0$ for which $TIME[T(n)] \\not \\subseteq TIME^{NP}[T(n)^{\\epsilon}]/2^{\\epsilon n}$ for appropriately chosen time-constructible $T$, we show that the answer to this question is positive (answering a question of [RSW22]), and that the Range Avoidance problem [KKMP21, Korten21, RSW22] is efficiently solvable for uniform sequences of circuits with close to minimal stretch (answering a question of [ILW23]).\nWe obtain our results by giving efficient constructions of pseudo-random generators with almost optimal seed length against algorithms with small advice, under assumptions of the form mentioned above. We also apply our results to give the first complexity-theoretic evidence for explicit constructions of objects such as rigid matrices (in the sense of Valiant) and Ramsey graphs with near-optimal parameters.\n\nRead original post\n"
    },
    
    {
      "title": "CCI: jobs: Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 1, 2025)",
      "url": "/cstheoryrss/2025/07/28/cci-jobs-complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-1-2025/",
      "content": "A unique opportunity to work on fundamental questions at the intersection of disciplines.\n\n*Freedom to pursue your own research agenda without boundaries *Up to 3 years in residence at SFI\n*Dedicated funds for research &amp; collaboration\n*A structured leadership training program\n*Competitive salary &amp; paid family leave\n*Opportunities for transdisciplinary collaboration w/ leading researchers worldwide\n\nWebsite: http://www.santafe.edu/sfifellowship\nEmail: Hilary Skolnik hilary@santafe.edu\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: Tom Lehrer Passed Away at the Age of 97",
      "url": "/cstheoryrss/2025/07/28/computational-complexity-tom-lehrer-passed-away-at-the-age-of-97/",
      "content": "Tom Lehrer passed away on Saturday July 26 at the age of 97.\n\nHe worked in both of my fields of interest: Parody Songs and Mathematics.\n\n1)  He got a BA in Mathematics from Harvard, Magna Cum Laude, in 1946.\n\n2) While he was an undergraduate he wrote an performed the song Fight Fiercely Harvardwhich was a gentle football fight song. IDEA: Use the melody to write a song about Harvard’s current fight with the Trump Administration.\n\n3) He wrote some political songs. Some were performed by Nancy Ames on the British Satirical Show That was the week That Was. Tom L didn’t like that probably because they cut some of the more controversial lyrics. He later wrote and performed songs for another political satire show, The Frost Report Here are some of his political songs and comments on them:\n\nWho’s Next - about which countries have or will have nuclear weapons. IDEA: Update it.\n\nThe Vatican Rag- about the Catholic Church- controversial now, rather tame now. If you heard it now you won’t understand why it was ever controversial. Such is the nature of biting satire. I noticed this in an earlier post, see here.  As such, I view old political novelty songs as entertaining history.\n\n4) He went to graduate school for Math at Harvard. He worked on it on-and-off and had other jobs but left Harvard in 1965 (see his Wikipedia entry here for the full story).\n\n5) One of the things he was doing while he was at Harvard was compose, sing, and record songs. Here are the some of particular interest to my readers:\n\nNew Math - I was actually a victim or beneficiary of the new math.\n\nLobachevsky- Historically inaccurate but funny.\n\nThe Elements- This might be Tom L’s best known song. Its to the tune of  I am the very model of a  Modern Major General; however, some of the songs that use that Tune seem to be parodies of The Elements.I have a website of parodies of Modern Major General here.Unfortunately the song that is most clearly a parody of  The Elements, Dr Jane’s The Muscles of the Kitty Cat,seems to have disappeared from You Tube. It is not on Spotify. (Spellcheck thinks that Spotify is not a word.) I can’t find it anywhere on the web. I DO have it on CD.\n\nThe Decimal Song- About using base 10. This was on The Frost Report.Not on any album so you might not know this one, though it is on you tube.\n\nThat’s Mathematics- Originally written to be the theme song for a PBS math show now titled Square One Television.They did not use it. He later added a lyric about Andrew Wiles. Square One Television often features math songs. Here are my favorites: The Mathematics of Love, 8% of my love,That’s Combinatorics, Polka Patterns (by Weird Al).\n\nThat’s Mathematics sung by Mathematicians A nice tribute to him. It was done a few years ago. Tom L knew about it and was delighted.\n\nThe Derivative song I could not find on line.  It is not on any album. Oh well.\n\n6) A few years ago Tom L put his songs in the public domain, see here. That website also includes lyrics for songs that were never recorded. IDEA: Record them!\n\n7) Tom L claims to have invented Jello Shots as a way to get around alcohol-free requirements. The Great Luke Ski wrote a song about Tom L in the style of Tom L. Its not on You Tube but it is at FUMP (FUnny Music project) here (click on play on second song)\n\n8)  His singing career was fairly short. Three albums, a few tours, a few other songs. Weird Al has 14 albums, Alan Sherman has 10 albums (Alan Sherman was born four years earlier than Tom L but died in 1973). However, the percent of great song on Tom L’s albums is around 90%, whereas for Weird Al and Alan Sherman its around 60% (this is just my opinion).  Also, Tom L had a day job. He has said he never really retired from singing, he wrote when he felt like it, and over time didn’t feel like it. For what he said about retiring from singing, see his Wikipedia page here.\n\n9)  There are two  stories about Tom L I bring up - one seems to be TRUE though I thought it was FALSE, and the other IS FALSE.\n\na) He stopped political satire because:\n\nPolitical satire became obsolete when Henry Kissinger won the Nobel Peace Prize.\n\nI have the following (possibly false) memory:\n\nTom L has denied this and points out that he had pretty much stopped many years earlier. And I’ll point out that he wrote non-political novelty songs as well (that is Tom L did, not Henry K).\n\nBUT- Wikipedia and other sources say that its true. Who am I do disagree with the Google Gods?\n\nb) He was sued by Wernher Von Braun’s family for his song about Wernher. This is false and the web says that it is false. Tom L denied it in a 2003 interview. I have a (possibly false) memory of reading that he wished it was true because it would mean people are still listening to his music.\n\n9) On Jan 1, 2025 he became one of the rare people who:\n\n– Lived during two square years (1936 and 2025).\n\n– Was of age and mental ability to appreciate that they had done this\n\nI had a blog on people who lived through 2 square years here.\n\n10) I end with what might have been his last song\n\nI’m spending Hanukkah in Santa Monica\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: String Consensus Problems with Swaps and Substitutions",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-string-consensus-problems-with-swaps-and-substitutions/",
      "content": "Authors: Estéban Gabory, Laurent Bulteau, Gabriele Fici, Hilde Verbeek\n\nString consensus problems aim at finding a string that minimizes some given\ndistance with respect to an input set of strings. In particular, in the\n\\textsc{Closest String} problem, we are given a set of strings of equal length\nand a radius $d$. The objective is to find a new string that differs from each\ninput string by at most $d$ substitutions. We study a generalization of this\nproblem where, in addition to substitutions, swaps of adjacent characters are\nalso permitted, each operation incurring a unit cost. Amir et al. showed that\nthis generalized problem is NP-hard, even when only swaps are allowed. In this\npaper, we show that it is FPT with respect to the parameter $d$. Moreover, we\ninvestigate a variant in which the goal is to minimize the sum of distances\nfrom the output string to all input strings. For this version, we present a\npolynomial-time algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Query Efficient Structured Matrix Learning",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-query-efficient-structured-matrix-learning/",
      "content": "Authors: Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Cameron Musco, Christopher Musco, David Persson\n\nWe study the problem of learning a structured approximation (low-rank,\nsparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector\nproduct (matvec) queries of the form $x \\rightarrow Ax$ and $x \\rightarrow\nA^Tx$. This problem is of central importance to algorithms across scientific\ncomputing and machine learning, with applications to fast multiplication and\ninversion for structured matrices, building preconditioners for first-order\noptimization, and as a model for differential operator learning. Prior work\nfocuses on obtaining query complexity upper and lower bounds for learning\nspecific structured matrix families that commonly arise in applications.\nWe initiate the study of the problem in greater generality, aiming to\nunderstand the query complexity of learning approximations from general matrix\nfamilies. Our main result focuses on finding a near-optimal approximation to\n$A$ from any finite-sized family of matrices, $\\mathcal{F}$. Standard results\nfrom matrix sketching show that $O(\\log|\\mathcal{F}|)$ matvec queries suffice\nin this setting. This bound can also be achieved, and is optimal, for\nvector-matrix-vector queries of the form $x,y\\rightarrow x^TAy$, which have\nbeen widely studied in work on rank-$1$ matrix sensing.\nSurprisingly, we show that, in the matvec model, it is possible to obtain a\nnearly quadratic improvement in complexity, to\n$\\tilde{O}(\\sqrt{\\log|\\mathcal{F}|})$. Further, we prove that this bound is\ntight up to log-log factors.Via covering number arguments, our result extends\nto well-studied infinite families. As an example, we establish that a\nnear-optimal approximation from any \\emph{linear matrix family} of dimension\n$q$ can be learned with $\\tilde{O}(\\sqrt{q})$ matvec queries, improving on an\n$O(q)$ bound achievable via sketching techniques and vector-matrix-vector\nqueries.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Edge-weighted Matching in the Dark",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-edge-weighted-matching-in-the-dark/",
      "content": "Authors: Zhiyi Huang, Enze Sun, Xiaowei Wu, Jiahao Zhao\n\nWe present a $0.659$-competitive Quadratic Ranking algorithm for the\nOblivious Bipartite Matching problem, a distribution-free version of\nQuery-Commit Matching. This result breaks the $1-\\frac{1}{e}$ barrier,\naddressing an open question raised by Tang, Wu, and Zhang (JACM 2023).\nMoreover, the competitive ratio of this distribution-free algorithm improves\nthe best existing $0.641$ ratio for Query-Commit Matching achieved by the\ndistribution-dependent algorithm of Chen, Huang, Li, and Tang (SODA 2025).\nQuadratic Ranking is a novel variant of the classic Ranking algorithm. We\nparameterize the algorithm with two functions, and let two key expressions in\nthe definition and analysis of the algorithm be quadratic forms of the two\nfunctions. We show that the quadratic forms are the unique choices that satisfy\na set of natural properties. Further, they allow us to optimize the choice of\nthe two functions using powerful quadratic programming solvers.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Downward self-reducibility in the total function polynomial hierarchy",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-downward-self-reducibility-in-the-total-function-polynomial-hierarchy/",
      "content": "Authors: Karthik Gajulapalli, Surendra Ghentiyala, Zeyong Li, Sidhant Saraogi\n\nA problem $\\mathcal{P}$ is considered downward self-reducible, if there\nexists an efficient algorithm for $\\mathcal{P}$ that is allowed to make queries\nto only strictly smaller instances of $\\mathcal{P}$. Downward self-reducibility\nhas been well studied in the case of decision problems, and it is well known\nthat any downward self-reducible problem must lie in $\\mathsf{PSPACE}$. Harsha,\nMitropolsky and Rosen [ITCS, 2023] initiated the study of downward self\nreductions in the case of search problems. They showed the following\ninteresting collapse: if a problem is in $\\mathsf{TFNP}$ and also downward\nself-reducible, then it must be in $\\mathsf{PLS}$. Moreover, if the problem\nadmits a unique solution then it must be in $\\mathsf{UEOPL}$.\nWe demonstrate that this represents just the tip of a much more general\nphenomenon, which holds for even harder search problems that lie higher up in\nthe total function polynomial hierarchy ($\\mathsf{TF\\Sigma_i^P}$). In fact,\neven if we allow our downward self-reduction to be much more powerful, such a\ncollapse will still occur.\nWe show that any problem in $\\mathsf{TF\\Sigma_i^P}$ which admits a randomized\ndownward self-reduction with access to a $\\mathsf{\\Sigma_{i-1}^P}$ oracle must\nbe in $\\mathsf{PLS}^{\\mathsf{\\Sigma_{i-1}^P}}$. If the problem has\n\\textit{essentially unique solutions} then it lies in\n$\\mathsf{UEOPL}^{\\mathsf{\\Sigma_{i-1}^P}}$.\nAs one (out of many) application of our framework, we get new upper bounds\nfor the problems $\\mathrm{Range Avoidance}$ and $\\mathrm{Linear Ordering\nPrinciple}$ and show that they are both in $\\mathsf{UEOPL}^{\\mathsf{NP}}$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Cycle-factors of regular graphs via entropy",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-cycle-factors-of-regular-graphs-via-entropy/",
      "content": "Authors: Micha Christoph, Nemanja Draganić, António Girão, Eoin Hurley, Lukas Michel, Alp Müyesser\n\nIt is a classical result that a random permutation of $n$ elements has, on\naverage, about $\\log n$ cycles. We generalise this fact to all directed\n$d$-regular graphs on $n$ vertices by showing that, on average, a random\ncycle-factor of such a graph has $\\mathcal{O}((n\\log d)/d)$ cycles. This is\ntight up to the constant factor and improves the best previous bound of the\nform $\\mathcal{O}(n/\\sqrt{\\log d})$ due to Vishnoi. Our results also yield\nrandomised polynomial-time algorithms for finding such a cycle-factor and for\nfinding a tour of length $(1+\\mathcal{O}((\\log d)/d)) \\cdot n$ if the graph is\nconnected. This makes progress on a conjecture of Magnant and Martin and on a\nproblem studied by Vishnoi and by Feige, Ravi, and Singh. Our proof uses the\nlanguage of entropy to exploit the fact that the upper and lower bounds on the\nnumber of perfect matchings in regular bipartite graphs are extremely close.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Budget and Profit Approximations for Spanning Tree Interdiction",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-budget-and-profit-approximations-for-spanning-tree-interdiction/",
      "content": "Authors: Rafail Ostrovsky, Yuval Rabani, Yoav Siman Tov\n\nWe give polynomial time logarithmic approximation guarantees for the budget\nminimization, as well as for the profit maximization versions of minimum\nspanning tree interdiction. In this problem, the goal is to remove some edges\nof an undirected graph with edge weights and edge costs, so as to increase the\nweight of a minimum spanning tree. In the budget minimization version, the goal\nis to minimize the total cost of the removed edges, while achieving a desired\nincrease $\\Delta$ in the weight of the minimum spanning tree. An alternative\nobjective within the same framework is to maximize the profit of interdiction,\nnamely the increase in the weight of the minimum spanning tree, subject to a\nbudget constraint. There are known polynomial time $O(1)$ approximation\nguarantees for a similar objective (maximizing the total cost of the tree,\nrather than the increase). However, the guarantee does not seem to apply to the\nincrease in cost. Moreover, the same techniques do not seem to apply to the\nbudget version.\nOur approximation guarantees are motivated by studying the question of\nminimizing the cost of increasing the minimum spanning tree by any amount. We\nshow that in contrast to the budget and profit problems, this version of\ninterdiction is polynomial time-solvable, and we give an efficient algorithm\nfor solving it. The solution motivates a graph-theoretic relaxation of the\nNP-hard interdiction problem. The gain in minimum spanning tree weight, as a\nfunction of the set of removed edges, is super-modular. Thus, the budget\nproblem is an instance of minimizing a linear function subject to a\nsuper-modular covering constraint. We use the graph-theoretic relaxation to\ndesign and analyze a batch greedy-based algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection",
      "url": "/cstheoryrss/2025/07/28/arxiv-data-structures-and-algorithms-a-truly-subcubic-combinatorial-algorithm-for-induced-4-cycle-detection/",
      "content": "Authors: Amir Abboud, Shyan Akmal, Nick Fischer\n\nWe present the first truly subcubic, combinatorial algorithm for detecting an\ninduced $4$-cycle in a graph. The running time is $O(n^{2.84})$ on $n$-node\ngraphs, thus separating the task of detecting induced $4$-cycles from detecting\ntriangles, which requires $n^{3-o(1)}$ time combinatorially under the popular\nBMM hypothesis.\nSignificant work has gone into characterizing the exact time complexity of\ninduced $H$-detection, relative to the complexity of detecting cliques of\nvarious sizes. Prior work identified the question of whether induced $4$-cycle\ndetection is triangle-hard as the only remaining case towards completing the\nlowest level of the classification, dubbing it a “curious” case [Dalirrooyfard,\nVassilevska W., FOCS 2022]. Our result can be seen as a negative resolution of\nthis question.\nOur algorithm deviates from previous techniques in the large body of subgraph\ndetection algorithms and employs the trendy topic of graph decomposition that\nhas hitherto been restricted to more global problems (as in the use of expander\ndecompositions for flow problems) or to shaving subpolynomial factors (as in\nthe application of graph regularity lemmas). While our algorithm is slower than\nthe (non-combinatorial) state-of-the-art $\\tilde{O}(n^{\\omega})$-time algorithm\nbased on polynomial identity testing [Vassilevska W., Wang, Williams, Yu, SODA\n2014], combinatorial advancements often come with other benefits. In\nparticular, we give the first nontrivial deterministic algorithm for detecting\ninduced $4$-cycles.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Relaxed Total Generalized Variation Regularized Piecewise Smooth",
      "url": "/cstheoryrss/2025/07/28/arxiv-computational-geometry-relaxed-total-generalized-variation-regularized-piecewise-smooth/",
      "content": "Authors: Huayan Zhang, Shanqiang Wang, Xiaochao Wang\n\nThe Mumford-Shah (MS) model is an important technique for mesh segmentation.\nMany existing researches focus on piecewise constant MS mesh segmentation model\nwith total variation regularization, which pursue the shortest length of\nboundaries. Different from previous efforts, in this article, we propose a\nnovel piecewise smooth MS mesh segmentation model by utilizing the relaxed\ntotal generalized variation regularization (rTGV). The new model assumes that\nthe feature function of a mesh can be approximated by the sum of piecewise\nconstant function and asmooth function, and the rTGV regularization is able to\ncharacterize the high order discontinuity of the geometric structure. The newly\nintroduced method is effective in segmenting meshes with irregular structures\nand getting the better boundaries rather than the shortest boundaries. We solve\nthe new model by alternating minimization and alternating direction method of\nmultipliers (ADMM). Our algorithm is discussed from several aspects, and\ncomparisons with several state-of-art methods. Experimental results show that\nour method can yield competitive results when compared to other approaches. In\naddition, our results compare favorably to those of the several state-of-art\ntechniques when evaluated on the Princeton Segmentation Benchmark. Furthermore,\nthe quantitative errors and computational costs confirm the robustness and\nefficiency of the proposed method.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Unconditional Pseudorandomness against Shallow Quantum Circuits",
      "url": "/cstheoryrss/2025/07/28/arxiv-computational-complexity-unconditional-pseudorandomness-against-shallow-quantum-circuits/",
      "content": "Authors: Soumik Ghosh, Sathyawageeswar Subramanian, Wei Zhan\n\nQuantum computational pseudorandomness has emerged as a fundamental notion\nthat spans connections to complexity theory, cryptography and fundamental\nphysics. However, all known constructions of efficient quantum-secure\npseudorandom objects rely on complexity theoretic assumptions.\nIn this work, we establish the first unconditionally secure efficient\npseudorandom constructions against shallow-depth quantum circuit classes. We\nprove that:\n$\\bullet$ Any quantum state 2-design yields unconditional pseudorandomness\nagainst both $\\mathsf{QNC}^0$ circuits with arbitrarily many ancillae and\n$\\mathsf{AC}^0\\circ\\mathsf{QNC}^0$ circuits with nearly linear ancillae.\n$\\bullet$ Random phased subspace states, where the phases are picked using a\n4-wise independent function, are unconditionally pseudoentangled against the\nabove circuit classes.\n$\\bullet$ Any unitary 2-design yields unconditionally secure parallel-query\npseudorandom unitaries against geometrically local $\\mathsf{QNC}^0$\nadversaries, even with limited $\\mathsf{AC}^0$ postprocessing.\nOur indistinguishability results for 2-designs stand in stark contrast to the\nstandard setting of quantum pseudorandomness against $\\mathsf{BQP}$ circuits,\nwherein they can be distinguishable from Haar random ensembles using more than\ntwo copies or queries. Our work demonstrates that quantum computational\npseudorandomness can be achieved unconditionally for natural classes of\nrestricted adversaries, opening new directions in quantum complexity theory.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Edge-coloring problems with forbidden patterns and planted colors",
      "url": "/cstheoryrss/2025/07/28/arxiv-computational-complexity-edge-coloring-problems-with-forbidden-patterns-and-planted-colors/",
      "content": "Authors: Alexey Barsukov, Antoine Mottet, Davide Perinti\n\nEdge-coloring problems with forbidden patterns refer to decision problems\nwhose input is a graph $\\mathbb G$ and where the goal is to determine whether\nthe edges of $\\mathbb G$ can be colored (with a fixed finite set of colors) in\na way that in the resulting colored graph $(\\mathbb G, \\xi)$, none of a fixed\nset of edge-colored obstructions admits a homomorphism to $(\\mathbb G, \\xi)$.\nIn the coloring extension setting, some of the edges of $\\mathbb G$ are already\ncolored and the goal is to find an extension of this coloring omitting the\nobstructions. We show that for certain sets of obstructions, there is a\npolynomial-time equivalence between the coloring problem and the extension\nproblem. We also show that for natural sets of obstructions, such coloring\nproblems exhibit a P vs. NP-complete complexity dichotomy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge",
      "url": "/cstheoryrss/2025/07/28/arxiv-computational-complexity-deadline-aware-joint-task-scheduling-and-offloading-in-mobile-edge/",
      "content": "Authors: Ngoc Hung Nguyen, Van-Dinh Nguyen, Anh Tuan Nguyen, Nguyen Van Thieu, Hoang Nam Nguyen, Symeon Chatzinotas\n\nThe demand for stringent interactive quality-of-service has intensified in\nboth mobile edge computing (MEC) and cloud systems, driven by the imperative to\nimprove user experiences. As a result, the processing of computation-intensive\ntasks in these systems necessitates adherence to specific deadlines or\nachieving extremely low latency. To optimize task scheduling performance,\nexisting research has mainly focused on reducing the number of late jobs whose\ndeadlines are not met. However, the primary challenge with these methods lies\nin the total search time and scheduling efficiency. In this paper, we present\nthe optimal job scheduling algorithm designed to determine the optimal task\norder for a given set of tasks. In addition, users are enabled to make informed\ndecisions for offloading tasks based on the information provided by servers.\nThe details of performance analysis are provided to show its optimality and low\ncomplexity with the linearithmic time O(nlogn), where $n$ is the number of\ntasks. To tackle the uncertainty of the randomly arriving tasks, we further\ndevelop an online approach with fast outage detection that achieves rapid\nacceptance times with time complexity of O(n). Extensive numerical results are\nprovided to demonstrate the effectiveness of the proposed algorithm in terms of\nthe service ratio and scheduling cost.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-103 | 2D Minimal Graph Rigidity is in NC for One-Crossing-Minor-Free Graphs |",
      "url": "/cstheoryrss/2025/07/27/eccc-papers-tr25-103-2d-minimal-graph-rigidity-is-in-nc-for-one-crossing-minor-free-graphs/",
      "content": "Minimally rigid graphs can be recognized and embedded in the plane efficiently, i.e. in polynomial time. There is also an efficient randomized parallel algorithm, i.e. in RNC. We present NC-algorithms to recognize whether one-crossing-minor-free graphs are minimally rigid. In the special case of $K_{3,3}$-free graphs, we also compute an infinitesimally rigid embedding in NC.\n\nRead original post\n"
    },
    
    {
      "title": "Decentralized Thoughts: Lagrange's Theorem through the algorithmic lens",
      "url": "/cstheoryrss/2025/07/26/decentralized-thoughts-lagrange-s-theorem-through-the-algorithmic-lens/",
      "content": "Groups lie at the heart of many cryptographic constructions. In this post, we revisit the classic Lagrange’s theorem through a more algorithmic lens. Largange’s theorem is a simple structure theorem that will be useful for many more advanced results. Recall that a group is a non-empty set $G$ and a…\n\nRead original post\n"
    },
    
    {
      "title": "CCI: jobs: Miller Research Postdoctoral Fellow at Miller Institute for Basic Research in Science, UC Berkeley (apply by September 12, 2025)",
      "url": "/cstheoryrss/2025/07/25/cci-jobs-miller-research-postdoctoral-fellow-at-miller-institute-for-basic-research-in-science-uc-berkeley-apply-by-september-12-2025/",
      "content": "The Miller Institute at UC Berkeley seeks exceptional PhD researchers for its 2026-2029 Miller Research Postdoctoral Fellowship. We’re looking for outstanding STEM scientists who are passionate about interdisciplinary basic science research. This is a three-year fellowship on the Berkeley campus. Candidates must be nominated; self-nominations are not accepted. Nominations due September 12, 2025.\n\nWebsite: https://miller.berkeley.edu/fellowship\nEmail: millerinstitute@berkeley.edu\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Zeroth-order log-concave sampling",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-zeroth-order-log-concave-sampling/",
      "content": "Authors: Yunbum Kook\n\nWe study the zeroth-order query complexity of log-concave sampling,\nspecifically uniform sampling from convex bodies using membership oracles. We\npropose a simple variant of the proximal sampler that achieves the query\ncomplexity with matched R'enyi orders between the initial warmness and output\nguarantee. Specifically, for any $\\varepsilon&gt;0$ and $q\\geq2$, the sampler,\ninitialized at $\\pi_{0}$, outputs a sample whose law is $\\varepsilon$-close in\n$q$-R'enyi divergence to $\\pi$, the uniform distribution over a convex body in\n$\\mathbb{R}^{d}$, using\n$\\widetilde{O}(qM_{q}^{q/(q-1)}d^{2}\\,\\lVert\\operatorname{cov}\\pi\\rVert\\log\\frac{1}{\\varepsilon})$\nmembership queries, where\n$M_{q}=\\lVert\\text{d}\\pi_{0}/\\text{d}\\pi\\rVert_{L^{q}(\\pi)}$.\nWe further introduce a simple annealing scheme that produces a warm start in\n$q$-R'enyi divergence (i.e., $M_{q}=O(1)$) using\n$\\widetilde{O}(qd^{2}R^{3/2}\\,\\lVert\\operatorname{cov}\\pi\\rVert^{1/4})$\nqueries, where $R^{2}=\\mathbb{E}_{\\pi}[|\\cdot|^{2}]$. This interpolates between\nknown complexities for warm-start generation in total variation and\nR'enyi-infinity divergence. To relay a R'enyi warmness across the annealing\nscheme, we establish hypercontractivity under simultaneous heat flow and\ntranslate it into an improved mixing guarantee for the proximal sampler under a\nlogarithmic Sobolev inequality. These results extend naturally to general\nlog-concave distributions accessible via evaluation oracles, incurring\nadditional quadratic queries.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-strong-sparsification-for-1-in-3-sat-via-polynomial-freiman-ruzsa/",
      "content": "Authors: Benjamin Bedert, Tamio-Vesa Nakajima, Karolina Okrasa, Stanislav Živný\n\nWe introduce a new notion of sparsification, called \\emph{strong\nsparsification}, in which constraints are not removed but variables can be\nmerged. As our main result, we present a strong sparsification algorithm for\n1-in-3-SAT. The correctness of the algorithm relies on establishing a\nsub-quadratic bound on the size of certain sets of vectors in $\\mathbb{F}_2^d$.\nThis result, obtained using the recent \\emph{Polynomial Freiman-Ruzsa Theorem}\n(Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent\ninterest. As an application, we improve the state-of-the-art algorithm for\napproximating linearly-ordered colourings of 3-uniform hypergraphs (H{\\aa}stad,\nMartinsson, Nakajima and{\\v{Z}}ivn{'{y}}, APPROX 2024).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Smoothed Analysis of Online Metric Problems",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-smoothed-analysis-of-online-metric-problems/",
      "content": "Authors: Christian Coester, Jack Umenberger\n\nWe study three classical online problems – $k$-server, $k$-taxi, and chasing\nsize $k$ sets – through a lens of smoothed analysis. Our setting allows\nrequest locations to be adversarial up to small perturbations, interpolating\nbetween worst-case and average-case models. Specifically, we show that if the\nmetric space is contained in a ball in any normed space and requests are drawn\nfrom distributions whose density functions are upper bounded by $1/\\sigma$\ntimes the uniform density over the ball, then all three problems admit\npolylog$(k/\\sigma)$-competitive algorithms. Our approach is simple: it reduces\nsmoothed instances to fully adversarial instances on finite metrics and\nleverages existing algorithms in a black-box manner. We also provide a lower\nbound showing that no algorithm can achieve a competitive ratio\nsub-polylogarithmic in $k/\\sigma$, matching our upper bounds up to the exponent\nof the polylogarithm. In contrast, the best known competitive ratios for these\nproblems in the fully adversarial setting are $2k-1$, $\\infty$ and\n$\\Theta(k^2)$, respectively.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On recognizing graphs representing Persistent Perfect Phylogenies",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-on-recognizing-graphs-representing-persistent-perfect-phylogenies/",
      "content": "Authors: Paola Bonizzoni, Gianluca Della Vedova, Mauricio Soto Gomez, Gabriella Trucco\n\nThe Persistent Perfect phylogeny, also known as Dollo-1, has been introduced\nas a generalization of the well-known perfect phylogenetic model for binary\ncharacters to deal with the potential loss of characters. The problem of\ndeciding the existence of a Persistent Perfect phylogeny can be reduced to the\none of recognizing a class of bipartite graphs whose nodes are species and\ncharacters. Thus an interesting question is solving directly the problem of\nrecognizing such graphs. We present a polynomial-time algorithm for deciding\nPersistent Perfect phylogeny existence in maximal graphs, where no character’s\nspecies set is contained within another character’s species set. Our solution,\nthat relies only on graph properties, narrows the gap between the linear-time\nsimple algorithm for Perfect Phylogeny and the NP-hardness results for the\nDollo-$k$ phylogeny with $k&gt;1$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Dual Charging for Half-Integral TSP",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-dual-charging-for-half-integral-tsp/",
      "content": "Authors: Nathan Klein, Mehrshad Taziki\n\nWe show that the max entropy algorithm is a randomized 1.49776 approximation\nfor half-integral TSP, improving upon the previous known bound of 1.49993 from\nKarlin et al. This also improves upon the best-known approximation for\nhalf-integral TSP due to Gupta et al. Our improvement results from using the\ndual, instead of the primal, to analyze the expected cost of the matching. We\nbelieve this method of analysis could lead to a simpler proof that max entropy\nis a better-than-3/2 approximation in the general case.\nWe also give a 1.4671 approximation for half integral LP solutions with no\nproper minimum cuts and an even number of vertices, improving upon the bound of\nHaddadan and Newman of 1.476. We then extend the analysis to the case when\nthere are an odd number of vertices $n$ at the cost of an additional $O(1/n)$\nfactor.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Better Bounds for Semi-Streaming Single-Source Shortest Paths",
      "url": "/cstheoryrss/2025/07/25/arxiv-data-structures-and-algorithms-better-bounds-for-semi-streaming-single-source-shortest-paths/",
      "content": "Authors: Sepehr Assadi, Gary Hoppenworth, Janani Sundaresan\n\nIn the semi-streaming model, an algorithm must process any $n$-vertex graph\nby making one or few passes over a stream of its edges, use $O(n \\cdot\n\\text{polylog }n)$ words of space, and at the end of the last pass, output a\nsolution to the problem at hand. Approximating (single-source) shortest paths\non undirected graphs is a longstanding open question in this model. In this\nwork, we make progress on this question from both upper and lower bound fronts:\nWe present a simple randomized algorithm that for any $\\epsilon &gt; 0$, with\nhigh probability computes $(1+\\epsilon)$-approximate shortest paths from a\ngiven source vertex in [\nO\\left(\\frac{1}{\\epsilon} \\cdot n \\log^3 n \\right)~\\text{space} \\quad\n\\text{and} \\quad O\\left(\\frac{1}{\\epsilon} \\cdot \\left(\\frac{\\log n}{\\log\\log\nn} \\right) ^2\\right) ~\\text{passes}.\n] The algorithm can also be derandomized and made to work on dynamic streams\nat a cost of some extra $\\text{poly}(\\log n, 1/\\epsilon)$ factors only in the\nspace. Previously, the best known algorithms for this problem required\n$1/\\epsilon \\cdot \\log^{c}(n)$ passes, for an unspecified large constant $c$.\nWe prove that any semi-streaming algorithm that with large constant\nprobability outputs any constant approximation to shortest paths from a given\nsource vertex (even to a single fixed target vertex and only the distance, not\nnecessarily the path) requires [ \\Omega\\left(\\frac{\\log n}{\\log\\log n}\\right)\n~\\text{passes}. ] We emphasize that our lower bound holds for any\nconstant-factor approximation of shortest paths. Previously, only constant-pass\nlower bounds were known and only for small approximation ratios below two.\nOur results collectively reduce the gap in the pass complexity of\napproximating single-source shortest paths in the semi-streaming model from\n$\\text{polylog } n$ vs $\\omega(1)$ to only a quadratic gap.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Gromov-Hausdorff distance between chromatic metric pairs and stability",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-geometry-gromov-hausdorff-distance-between-chromatic-metric-pairs-and-stability/",
      "content": "Authors: Ondřej Draganov, Sophie Rosenmeier, Nicolò Zava\n\nChromatic metric pairs consist of a metric space and a coloring function\npartitioning a subset thereof into various colors. It is a natural extension of\nthe notion of chromatic point sets studied in chromatic topological data\nanalysis. A useful tool in the field is the six-pack, a collection of six\npersistence diagrams, summarizing homological information about how the colored\nsubsets interact. We introduce a suitable generalization of the\nGromov-Hausdorff distance to compare chromatic metric pairs. We show some basic\nproperties and validate this definition by obtaining the stability of the\nsix-pack with respect to that distance. We conclude by discussing its\nrestriction to metric pairs and its role in the stability of the \\v{C}ech\npersistence diagrams.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Explainable Mapper: Charting LLM Embedding Spaces Using",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-geometry-explainable-mapper-charting-llm-embedding-spaces-using/",
      "content": "Authors: Xinyuan Yan, Rita Sevastjanova, Sinie van der Ben, Mennatallah El-Assady, Bei Wang\n\nLarge language models (LLMs) produce high-dimensional embeddings that capture\nrich semantic and syntactic relationships between words, sentences, and\nconcepts. Investigating the topological structures of LLM embedding spaces via\nmapper graphs enables us to understand their underlying structures.\nSpecifically, a mapper graph summarizes the topological structure of the\nembedding space, where each node represents a topological neighborhood\n(containing a cluster of embeddings), and an edge connects two nodes if their\ncorresponding neighborhoods overlap. However, manually exploring these\nembedding spaces to uncover encoded linguistic properties requires considerable\nhuman effort. To address this challenge, we introduce a framework for\nsemi-automatic annotation of these embedding properties. To organize the\nexploration process, we first define a taxonomy of explorable elements within a\nmapper graph such as nodes, edges, paths, components, and trajectories. The\nannotation of these elements is executed through two types of customizable\nLLM-based agents that employ perturbation techniques for scalable and automated\nanalysis. These agents help to explore and explain the characteristics of\nmapper elements and verify the robustness of the generated explanations. We\ninstantiate the framework within a visual analytics workspace and demonstrate\nits effectiveness through case studies. In particular, we replicate findings\nfrom prior research on BERT’s embedding properties across various layers of its\narchitecture and provide further observations into the linguistic properties of\ntopological neighborhoods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A New Approach to the Construction of Subdivision Algorithms",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-geometry-a-new-approach-to-the-construction-of-subdivision-algorithms/",
      "content": "Authors: Alexander Dietz\n\nIn this thesis, a new approach for constructing subdivision algorithms for\ngeneralized quadratic and cubic B-spline subdivision for subdivision surfaces\nand volumes is presented. First, a catalog of quality criteria for these\nsubdivision algorithms is developed, serving as a guideline for the\nconstruction process.\nThe construction begins by generating the desired subdominant eigenvectors as\nthe vertices of regular convex 3-polytopes for volumes using circle packings.\nSubsequently, these polytopes are utilized to construct a\nColin-de-Verdiere-matrix for the generalized quadratic and a\nColin-de-Verdiere-like matrix for the generalized cubic B-spline subdivision.\nThese matrices are then adjusted using the matrix exponential to obtain\nsubdivision matrices with the desired properties.\nAll subdivision algorithms introduced in this paper empirically exhibit a\nsubdominant eigenvalue of 1/2 with the desired algebraic and geometric\nmultiplicity. For the quadratic case, this property can even be formally\nproven. Moreover, the corresponding eigenvectors form a convex polytope in the\ncentral region for the generalized quadratic B-spline subdivision algorithms,\nwhile for the generalized cubic B-spline subdivision algorithms, they represent\nthe refinement of a convex polytope. Additionally, the constructed subdivision\nalgorithms fulfill various other quality criteria, such as affine invariance\nand convex hull preservation and respecting all symmetries. Furthermore, it is\ndemonstrated that the original Catmull-Clark algorithm is not suitable for\ngeneralization to volumetric subdivision and that the established subdivision\nalgorithms [Baj+02] and [JM99] do not exhibit a suitable spectrum for several\ncombinatorial configurations. Additionally, research approaches for the\nvolumetric case are proposed, aiming to generalize from hexahedral to arbitrary\nstructures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: The hidden subgroup problem for infinite groups",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-complexity-the-hidden-subgroup-problem-for-infinite-groups/",
      "content": "Authors: Greg Kuperberg\n\nFollowing the example of Shor’s algorithm for period-finding in the integers,\nwe explore the hidden subgroup problem (HSP) for discrete infinite groups. On\nthe hardness side, we show that HSP is NP-hard for the additive group of\nrational numbers, and for normal subgroups of non-abelian free groups. We also\nindirectly reduce a version of the short vector problem to HSP in\n$\\mathbb{Z}^k$ with pseudo-polynomial query cost. On the algorithm side, we\ngeneralize the Shor-Kitaev algorithm for HSP in $\\mathbb{Z}^k$ (with standard\npolynomial query cost) to the case where the hidden subgroup has deficient rank\nor equivalently infinite index. Finally, we outline a stretched exponential\ntime algorithm for the abelian hidden shift problem (AHShP), extending prior\nwork of the author as well as Regev and Peikert. It follows that HSP in any\nfinitely generated, virtually abelian group also has a stretched exponential\ntime algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Simulating Evolvability as a Learning Algorithm: Empirical",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-complexity-simulating-evolvability-as-a-learning-algorithm-empirical/",
      "content": "Authors: Nicholas Fidalgo, Puyuan Ye\n\nThe theory of evolvability, introduced by Valiant (2009), formalizes\nevolution as a constrained learning algorithm operating without labeled\nexamples or structural knowledge. While theoretical work has established the\nevolvability of specific function classes under idealized conditions, the\nframework remains largely untested empirically. In this paper, we implement a\ngenetic algorithm that faithfully simulates Valiant’s model and conduct\nextensive experiments across six Boolean function classes: monotone\nconjunctions, monotone disjunctions, parity, majority, general conjunctions,\nand general disjunctions. Our study examines evolvability under uniform and\nnon-uniform distributions, investigates the effects of fixed initial hypotheses\nand the removal of neutral mutations, and highlights how these constraints\nalter convergence behavior. We validate known results (e.g., evolvability of\nmonotone conjunctions, non-evolvability of parity) and offer the first\nempirical evidence on the evolvability of majority and general Boolean classes.\nOur findings reveal sharp performance drops at intermediate dimensions and\nexpose the essential role of neutral mutations in escaping fitness plateaus. We\nalso demonstrate that evolvability can depend strongly on the input\ndistribution. These insights clarify practical limits of evolutionary search\nand suggest new directions for theoretical work, including potential\nrefinements to evolvability definitions and bounds. Our implementation provides\na rigorous, extensible framework for empirical analysis and serves as a testbed\nfor future explorations of learning through evolution.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Fagin's Theorem for Semiring Turing Machines",
      "url": "/cstheoryrss/2025/07/25/arxiv-computational-complexity-fagin-s-theorem-for-semiring-turing-machines/",
      "content": "Authors: Guillermo Badia, Manfred Droste, Thomas Eiter, Rafael Kiesel, Carles Noguera, Erik Paul\n\nIn recent years, quantitative complexity over semirings has been intensively\ninvestigated. An important problem in this context is to connect computational\ncomplexity with logical expressiveness. In this paper we improve on the model\nof \\emph{Semiring Turing Machines} (distinct from so called weighted Turing\nmachines) introduced by Eiter \\&amp; Kiesel (Semiring Reasoning Frameworks in AI\nand Their Computational Complexity, \\emph{J. Artif. Intell. Res.}, 2023). Our\ncentral result is a Fagin-style theorem for a new quantitative complexity class\nusing a suitable weighted logical formalism. We show that the quantitative\ncomplexity class that we call \\NPnewinf{$\\mathcal{R}$}, where $\\mathcal{R}$ is\na commutative semiring, can be captured using a version of weighted existential\nsecond-order logic that allows for predicates interpreted as semiring-annotated\nrelations. This result provides a precise logical characterization of the power\nseries that form the class \\NPnewinf{$\\mathcal{R}$}. We also give the exact\nrelation between Eiter \\&amp; Kiesel’s version of NP, called\n\\NPoldinf{$\\mathcal{R}$}, and the class \\NPnewinf{$\\mathcal{R}$}. Incidentally,\nwe are able to recapture all the complexity results by Eiter \\&amp; Kiesel (2023)\nin our new model, connecting a quantitative version of NP to various counting\ncomplexity classes.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: Answer to my GROUP ONE/GROUP TWO Prez question",
      "url": "/cstheoryrss/2025/07/24/computational-complexity-answer-to-my-group-one-group-two-prez-question/",
      "content": "In a prior post I asked what criteria I used to place Prez and VP nominees since 1976 into two groups.\n\nIn the book AbundanceI read that since 1984 all of the Democratic nominees for Prez and VP except Tim Walz had gone to law school. I decided to get data on that, along with Republicans, and also go back to 1976 since leaving out 1980 (Jimmy Carter did not go to law school) seemed like a cheat. So GROUP ONE all went to law school, and GROUP TWO did not. I restate the groups and note which law school and a few other fun facts. There are a few glitches along the way. And then I have comments on the problem and AI (when was the last time there was a blog post that did not mention AI?)\n\nGROUP ONE:\n\nVP-1976 and 1980. Prez-1984\nWalter Mondale. University of Minnesota Law School. 1956.\n\nPrez-1976\nGerald Ford. Has an LLB from Yale. 1941. What is an LLB? Some law degrees were called LLBs in an earlier time. This is a glitch. Some places on the web call it an undergraduate degree in Law (the B stands  for Bachelors) but some say it’s equivalent to a JD. Fords’s seems to be equivalent to a JD.\n\nVP-1976. Prez-1996\nBob Dole. Has an LLB from Washburn University in Topeka Kansas in 1952 . See entry on Ford for what an LLB is. From the Wikipedia entry on Bob Dole it seems like the LLB was an undergraduate degree, but its hard to tell. \n\nVP-1984\nGeraldine Ferraro. Fordham University School of Law. 1960.\n\nPrez-1988\nMichael Dukakis. Harvard Law School. 1960.\n\nVP-1988\nLloyd Bentson. LLB from the  University of Texas Law School. 1942. See Entry on Ford for what an LLB is. From the Wikipedia entry I cannot tell if it was the equivalent of a JD.\n\nVP-1988 and 1992\nDan Quayle. Indiana University Robert H. McKinney School of Law. 1974.\n\nPrez-1992 and 1996\nBill Clinton. Yale Law. 1973.\n\nVP-1992 and  1996. Prez-2000\nAl Gore.  Vanderbilt University Law School. He quit to run for the House of Representatives. I still count this but it’s a glitch. \n\nVP-2000\nJoe Lieberman.  Yale Law School. 1967.\n\nPrez-2004\nJohn Kerry.  Boston College 1976.\n\nVP-2004\nJohn Edwards.  University of North Carolina School of Law. 1977.\n\nPrez-2008 and 2012\nBarack Obama.  Harvard Law School. 1991.\n\nPrez-2012\nMitt Romney.  MBA/JD (a joint program) from Harvard. 1975. (This surprised me.)\n\nVP-2008 and 2012. Prez-2020\nJoe Biden.  Syracuse University College of Law. 1968.\n\nPrez-2016\nHillary Clinton.  Yale Law School. 1973.\n\nVP-2016\nTim Kaine. Harvard Law School. 1983.\n\nVP-2016 and 2020\nMike Pence. Indiana University Robert H. McKinney School of Law. 1986.\n\nVP-2020. Prez-2024\nKamala Harris. University of California, Hastings College of the Law. 1989.\n\nVP-2024\nJ.D Vance. Yale Law School. 2013.\n\nThe only names that were flagged for being misspelled are Dukakis, Bentson, and Kamala.)\n\n\nGROUP TWO\n\nPrez-1976 and 1980\nJimmy Carter\n\nPrez-1980 and 1984\nRonald Reagan\n\nVP-1980 and 1984, Prez-1988 and 1992.\nGeorge H.W. Bush\n\n(The only people who were nominated for VP twice and Prez twice are John Adams and George H.W. Bush. Richard Nixon was nominated for VP twice and for Prez three times.)\n\nVP-1996\nJack Kemp\n\nPrez-2000 and 2004\nGeorge W. Bush\n\nVP-2000 and 2004\nDick Cheney\n\nPrez-2008\nJohn McCain\n\nVP-2008\nSarah Palin\n\nVP-2012\nPaul Ryan (This surprised me.) \n\nPrez-2016 and 2020 and 2024\nDonald Trump\n\nVP-2024\nTim Walz\n\n(The only name flagged for being misspelled was Walz.)\n\n\n\nSome notes\n\nIn these notes I treat Bentson, Dole, Ford, who all got LLB’s,  as having gone to law school and finished it.\n\n1) Of the 16 Democrats, 14 went to law school and 13 finished law school.\n\n2) Of the 14 Republicans, 6 went to law school (all finished).\n\n3) The LLB’s and the fact that Al Gore started but did not finish law school are examples of edge cases which are cases that are odd outliers which an AI might not have been trained on or know to look for. Over time will these diminish or will we always need humans to help with that?\n\n4) I was surprised that Mitt Romney had a double-degree MBA/JD since (a) I didn’t know there were such things and (b) since he worked at Bain Capital I thought of him as a business person— MBA— which is correct but incomplete.\n\n5) I was surprised that Ford, Dole, and Bentson had LLBs since I never heard of that before.\n\n6) I was surprised that Paul Ryan does not have a law degree. Seems like the type that would have one.\n\n7) Let LL mean Prez and VP both went to law school. Let LN mean prez went, VP didn’t go. NL and NN are obvious. We considered 13 elections. Dems: 10 LL, 2 NL, 1 LN. Reps: 5 NN, 5 NL, 2 LN, 1 LL. Since I was surprised that Romeny went to law school AND I was surprised that Ryan did not, I would have thought 2012 for Reps was NL but it was really LN.\n\n8) One of the commenters used several AI programs on the question and NONE solved it. Some humans DID solve it.\n\na) Some comments suggested that an AI should be able to list several ways the lists differ, and have probabilities of which ones are sensible.  My take: maybe in the future but not now.\n\nb) Is this kind of question fair to ask an AI (or for that matter a person). They have to guess what I have in mind. Be that as it may, the AIs tried on the program.\n\nDID NOT list out a different criteria that was right\n\nbut\n\nINSTEAD gave criteria that were just wrong.\n\n c) A commenter wrote  that the study was not rigorous. That’s correct. So\nview this blog post as the starting point: study how AI’s do on this question\nand others like it, keeping track of which AI and how the question is posed. Then we will have a better sense.\n\n9) Is this a sign that AI is not as good as people think OR is it just a hiccup?\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "Decentralized Thoughts: An Analysis of Latency and Block Capacity in Nakamoto Consensus",
      "url": "/cstheoryrss/2025/07/24/decentralized-thoughts-an-analysis-of-latency-and-block-capacity-in-nakamoto-consensus/",
      "content": "Achieving high throughput is essential for blockchain ecosystems to become competitive alternatives to their centralized counterparts across a wide range of domains. For example, high-frequency trading on decentralized platforms cannot be competitive unless transaction processing times are reduced to well below one second. The predominant strategy to address this challenge…\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Triadic First-Order Logic Queries in Temporal Networks",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-triadic-first-order-logic-queries-in-temporal-networks/",
      "content": "Authors: Omkar Bhalerao, Yunjie Pan, C. Seshadhri, Nishil Talati\n\nMotif counting is a fundamental problem in network analysis, and there is a\nrich literature of theoretical and applied algorithms for this problem. Given a\nlarge input network $G$, a motif $H$ is a small “pattern” graph indicative of\nspecial local structure. Motif/pattern mining involves finding all matches of\nthis pattern in the input $G$. The simplest, yet challenging, case of motif\ncounting is when $H$ has three vertices, often called a “triadic” query. Recent\nwork has focused on “temporal graph mining”, where the network $G$ has edges\nwith timestamps (and directions) and $H$ has time constraints.\nInspired by concepts in logic and database theory, we introduce the study of\n“thresholded First Order Logic (FOL) Motif Analysis” for massive temporal\nnetworks. A typical triadic motif query asks for the existence of three\nvertices that form a desired temporal pattern. An “FOL” motif query is obtained\nby having both existential and thresholded universal quantifiers. This allows\nfor query semantics that can mine richer information from networks. A typical\ntriadic query would be “find all triples of vertices $u,v,w$ such that they\nform a triangle within one hour”. A thresholded FOL query can express “find all\npairs $u,v$ such that for half of $w$ where $(u,w)$ formed an edge, $(v,w)$\nalso formed an edge within an hour”.\nWe design the first algorithm, FOLTY, for mining thresholded FOL triadic\nqueries. The theoretical running time of FOLTY matches the best known running\ntime for temporal triangle counting in sparse graphs. We give an efficient\nimplementation of FOLTY using specialized temporal data structures. FOLTY has\nexcellent empirical behavior, and can answer triadic FOL queries on graphs with\nnearly 70M edges is less than hour on commodity hardware. Our work has the\npotential to start a new research direction in the classic well-studied problem\nof motif analysis.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Stable Iterative Solvers for Ill-conditioned Linear Systems",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-stable-iterative-solvers-for-ill-conditioned-linear-systems/",
      "content": "Authors: Vasileios Kalantzis, Mark S. Squillante, Chai Wah Wu\n\nIterative solvers for large-scale linear systems such as Krylov subspace\nmethods can diverge when the linear system is ill-conditioned, thus\nsignificantly reducing the applicability of these iterative methods in practice\nfor high-performance computing solutions of such large-scale linear systems. To\naddress this fundamental problem, we propose general algorithmic frameworks to\nmodify Krylov subspace iterative solution methods which ensure that the\nalgorithms are stable and do not diverge. We then apply our general frameworks\nto current implementations of the corresponding iterative methods in SciPy and\ndemonstrate the efficacy of our stable iterative approach with respect to\nnumerical experiments across a wide range of synthetic and real-world\nill-conditioned linear systems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: RLZ-r and LZ-End-r: Enhancing Move-r",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-rlz-r-and-lz-end-r-enhancing-move-r/",
      "content": "Authors: Patrick Dinklage, Johannes Fischer, Lukas Nalbach, Jan Zumbrink\n\nIn pattern matching on strings, a locate query asks for an enumeration of all\nthe occurrences of a given pattern in a given text. The r-index [Gagie et al.,\n2018] is a recently presented compressed self index that stores the text and\nauxiliary information in compressed space. With some modifications, locate\nqueries can be answered in optimal time [Nishimoto &amp; Tabei, 2021], which has\nrecently been proven relevant in practice in the form of Move-r [Bertram et\nal., 2024]. However, there remains the practical bottleneck of evaluating\nfunction $\\Phi$ for every occurrence to report. This motivates enhancing the\nindex by a compressed representation of the suffix array featuring efficient\nrandom access, trading off space for faster answering of locate queries\n[Puglisi &amp; Zhukova, 2021]. In this work, we build upon this idea considering\ntwo suitable compression schemes: Relative Lempel-Ziv [Kuruppu et al., 2010],\nimproving the work by Puglisi and Zhukova, and LZ-End [Kreft &amp; Navarro, 2010],\nintroducing a different trade-off where compression is better than for Relative\nLempel-Ziv at the cost of slower access times. We enhance both the r-index and\nMove-r by the compressed suffix arrays and evaluate locate query performance in\nan experiment. We show that locate queries can be sped up considerably in both\nthe r-index and Move-r, especially if the queried pattern has many occurrences.\nThe choice between two different compression schemes offers new trade-offs\nregarding index size versus query performance.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Residual Prophet Inequalities",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-residual-prophet-inequalities/",
      "content": "Authors: Jose Correa, Sebastian Perez-Salazar, Dana Pizarro, Bruno Ziliotto\n\nWe introduce a variant of the classic prophet inequality, called\n\\emph{residual prophet inequality} (RPI). In the RPI problem, we consider a\nfinite sequence of $n$ nonnegative independent random values with known\ndistributions, and a known integer $0\\leq k\\leq n-1$. Before the gambler\nobserves the sequence, the top $k$ values are removed, whereas the remaining\n$n-k$ values are streamed sequentially to the gambler. For example, one can\nassume that the top $k$ values have already been allocated to a higher-priority\nagent. Upon observing a value, the gambler must decide irrevocably whether to\naccept or reject it, without the possibility of revisiting past values.\nWe study two variants of RPI, according to whether the gambler learns online\nof the identity of the variable that he sees (FI model) or not (NI model). Our\nmain result is a randomized algorithm in the FI model with \\emph{competitive\nratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is\ndata-driven and requires access only to the $k+1$ largest values of a single\nsample from the $n$ input distributions. In the NI model, we provide a similar\nalgorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze\nindependent and identically distributed instances when $k=1$. We build a\nsingle-threshold algorithm with a competitive ratio of at least 0.4901, and\nshow that no single-threshold strategy can get a competitive ratio greater than\n0.5464.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Optimal Pure Differentially Private Sparse Histograms in Near-Linear",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-optimal-pure-differentially-private-sparse-histograms-in-near-linear/",
      "content": "Authors: Florian Kerschbaum, Steven Lee, Hao Wu\n\nWe introduce an algorithm that releases a pure differentially private sparse\nhistogram over $n$ participants drawn from a domain of size $d \\gg n$. Our\nmethod attains the optimal $\\ell_\\infty$-estimation error and runs in strictly\n$O(n \\ln \\ln d)$ time in the word-RAM model, thereby improving upon the\nprevious best known deterministic-time bound of $\\tilde{O}(n^2)$ and resolving\nthe open problem of breaking this quadratic barrier (Balcer and Vadhan, 2019).\nCentral to our algorithm is a novel private item blanket technique with\ntarget-length padding, which transforms the approximate differentially private\nstability-based histogram algorithm into a pure differentially private one.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-fast-one-pass-sparse-approximation-of-the-top-eigenvectors-of-huge/",
      "content": "Authors: Edem Boahen, Simone Brugiapaglia, Hung-Hsu Chou, Mark Iwen, Felix Krahmer\n\nMotivated by applications such as sparse PCA, in this paper we present\nprovably-accurate one-pass algorithms for the sparse approximation of the top\neigenvectors of extremely massive matrices based on a single compact linear\nsketch. The resulting compressive-sensing-based approaches can approximate the\nleading eigenvectors of huge approximately low-rank matrices that are too large\nto store in memory based on a single pass over its entries while utilizing a\ntotal memory footprint on the order of the much smaller desired sparse\neigenvector approximations. Finally, the compressive sensing recovery algorithm\nitself (which takes the gathered compressive matrix measurements as input, and\nthen outputs sparse approximations of its top eigenvectors) can also be\nformulated to run in a time which principally depends on the size of the sought\nsparse approximations, making its runtime sublinear in the size of the large\nmatrix whose eigenvectors one aims to approximate. Preliminary experiments on\nhuge matrices having $\\sim 10^{16}$ entries illustrate the developed theory and\ndemonstrate the practical potential of the proposed approach.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Compatibility of Max and Sum Objectives for Committee Selection and",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-compatibility-of-max-and-sum-objectives-for-committee-selection-and/",
      "content": "Authors: Yue Han, Elliot Anshelevich\n\nWe study a version of the metric facility location problem (or, equivalently,\nvariants of the committee selection problem) in which we must choose $k$\nfacilities in an arbitrary metric space to serve some set of clients $C$. We\nconsider four different objectives, where each client $i\\in C$ attempts to\nminimize either the sum or the maximum of its distance to the chosen\nfacilities, and where the overall objective either considers the sum or the\nmaximum of the individual client costs. Rather than optimizing a single\nobjective at a time, we study how compatible these objectives are with each\nother, and show the existence of solutions which are simultaneously\nclose-to-optimum for any pair of the above objectives. Our results show that\nwhen choosing a set of facilities or a representative committee, it is often\npossible to form a solution which is good for several objectives at the same\ntime, instead of sacrificing one desideratum to achieve another.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Advancing Quantum State Preparation using LimTDD",
      "url": "/cstheoryrss/2025/07/24/arxiv-data-structures-and-algorithms-advancing-quantum-state-preparation-using-limtdd/",
      "content": "Authors: Xin Hong, Aochu Dai, Chenjian Li, Sanjiang Li, Shenggang Ying, Mingsheng Ying\n\nQuantum state preparation (QSP) is a fundamental task in quantum computing\nand quantum information processing. It is critical to the execution of many\nquantum algorithms, including those in quantum machine learning. In this paper,\nwe propose a family of efficient QSP algorithms tailored to different numbers\nof available ancilla qubits - ranging from no ancilla qubits, to a single\nancilla qubit, to a sufficiently large number of ancilla qubits. Our algorithms\nare based on a novel decision diagram that is fundamentally different from the\napproaches used in previous QSP algorithms. Specifically, our approach exploits\nthe power of Local Invertible Map Tensor Decision Diagrams (LimTDDs) - a highly\ncompact representation of quantum states that combines tensor networks and\ndecision diagrams to reduce quantum circuit complexity. Extensive experiments\ndemonstrate that our methods significantly outperform existing approaches and\nexhibit better scalability for large-scale quantum states, both in terms of\nruntime and gate complexity. Furthermore, our method shows exponential\nimprovement in best-case scenarios. This paper is an extended version of [1],\nwith three more algorithms proposed.\n\nRead original post\n"
    },
    
    {
      "title": "CS Theory Events: TTIC Summer Workshop on Incentives for Collaborative Learning and Data Sharing",
      "url": "/cstheoryrss/2025/07/23/cs-theory-events-ttic-summer-workshop-on-incentives-for-collaborative-learning-and-data-sharing/",
      "content": "August 13-15, 2025 Toyota Technological Institute at Chicago https://sites.google.com/ttic.edu/incentivesdatasharing/home Submission deadline: July 31, 2025 Registration deadline: July 31, 2025 Machine Learning (ML) has achieved remarkable milestones in recent years, but its future hinges on a robust, ethically grounded, and well-incentivized data infrastructure. The next era of AI innovation requires specialized data that is scarce, proprietary, … Continue reading TTIC Summer Workshop on Incentives for Collaborative Learning and Data Sharing\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Amazing: Jie Ma, Wujie Shen, and Shengjie Xie Gave an Exponential Improvement for Ramsey Lower Bounds",
      "url": "/cstheoryrss/2025/07/23/gil-kalai-amazing-jie-ma-wujie-shen-and-shengjie-xie-gave-an-exponential-improvement-for-ramsey-lower-bounds/",
      "content": "By Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Toward a Lightweight and Robust Design for Caching with Predictions",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-toward-a-lightweight-and-robust-design-for-caching-with-predictions/",
      "content": "Authors: Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng\n\nThe online caching problem aims to minimize cache misses when serving a\nsequence of requests under a limited cache size. While naive learning-augmented\ncaching algorithms achieve ideal $1$-consistency, they lack robustness\nguarantees. Existing robustification methods either sacrifice $1$-consistency\nor introduce significant computational overhead. In this paper, we introduce\n\\textsc{Guard}, a lightweight robustification framework that enhances the\nrobustness of a broad class of learning-augmented caching algorithms to $2H_k +\n2$, while preserving their $1$-consistency. \\textsc{Guard} achieves the current\nbest-known trade-off between consistency and robustness, with only\n$\\mathcal{O}(1)$ additional per-request overhead, thereby maintaining the\noriginal time complexity of the base algorithm. Extensive experiments across\nmultiple real-world datasets and prediction models validate the effectiveness\nof \\textsc{Guard} in practice.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The Cost of Compression: Tight Quadratic Black-Box Attacks on Sketches",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-the-cost-of-compression-tight-quadratic-black-box-attacks-on-sketches/",
      "content": "Authors: Sara Ahmadian, Edith Cohen, Uri Stemmer\n\nDimensionality reduction via linear sketching is a powerful and widely used\ntechnique, but it is known to be vulnerable to adversarial inputs. We study the\nblack-box adversarial setting, where a fixed, hidden sketching matrix A in\n$R^{k X n}$ maps high-dimensional vectors v $\\in R^n$ to lower-dimensional\nsketches A v in $R^k$, and an adversary can query the system to obtain\napproximate ell2-norm estimates that are computed from the sketch.\nWe present a universal, nonadaptive attack that, using tilde(O)($k^2$)\nqueries, either causes a failure in norm estimation or constructs an\nadversarial input on which the optimal estimator for the query distribution\n(used by the attack) fails. The attack is completely agnostic to the sketching\nmatrix and to the estimator: It applies to any linear sketch and any query\nresponder, including those that are randomized, adaptive, or tailored to the\nquery distribution.\nOur lower bound construction tightly matches the known upper bounds of\ntilde(Omega)($k^2$), achieved by specialized estimators for Johnson\nLindenstrauss transforms and AMS sketches. Beyond sketching, our results\nuncover structural parallels to adversarial attacks in image classification,\nhighlighting fundamental vulnerabilities of compressed representations.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Joint Replenishment Problem with Arbitrary Holding and Backlog",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-online-joint-replenishment-problem-with-arbitrary-holding-and-backlog/",
      "content": "Authors: Yossi Azar, Shahar Lewkowicz\n\nIn their seminal paper Moseley, Niaparast, and Ravi introduced the Joint\nReplenishment Problem (JRP) with holding and backlog costs that models the\ntrade-off between ordering costs, holding costs, and backlog costs in supply\nchain planning systems. Their model generalized the classical the make-to-order\nversion as well make-to-stock version. For the case where holding costs\nfunction of all items are the same and all backlog costs are the same, they\nprovide a constant competitive algorithm, leaving designing a constant\ncompetitive algorithm for arbitrary functions open. Moreover, they noticed that\ntheir algorithm does not work for arbitrary (request dependent) holding costs\nand backlog costs functions. We resolve their open problem and design a\nconstant competitive algorithm that works for arbitrary request dependent\nfunctions. Specifically, we establish a 4-competitive algorithm for the\nsingle-item case and a 16-competitive for the general (multi-item) version. The\nalgorithm of Moseley, Niaparast, and Ravi is based on fixed priority on the\nrequests to items, and request to an item are always served by order of\ndeadlines. In contrast, we design an algorithm with dynamic priority over the\nrequests such that instead of servicing a prefix by deadline of requests, we\nmay need to service a general subset of the requests.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Combinatorial Optimization with Graphical Dependencies",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-online-combinatorial-optimization-with-graphical-dependencies/",
      "content": "Authors: Zhimeng Gao, Evangelia Gergatsouli, Kalen Patton, Sahil Singla\n\nMost existing work in online stochastic combinatorial optimization assumes\nthat inputs are drawn from independent distributions – a strong assumption\nthat often fails in practice. At the other extreme, arbitrary correlations are\nequivalent to worst-case inputs via Yao’s minimax principle, making good\nalgorithms often impossible. This motivates the study of intermediate models\nthat capture mild correlations while still permitting non-trivial algorithms.\nIn this paper, we study online combinatorial optimization under Markov Random\nFields (MRFs), a well-established graphical model for structured dependencies.\nMRFs parameterize correlation strength via the maximum weighted degree\n$\\Delta$, smoothly interpolating between independence ($\\Delta = 0$) and full\ncorrelation ($\\Delta \\to \\infty$). While na\"ively this yields\n$e^{O(\\Delta)}$-competitive algorithms and $\\Omega(\\Delta)$ hardness, we ask:\nwhen can we design tight $\\Theta(\\Delta)$-competitive algorithms?\nWe present general techniques achieving $O(\\Delta)$-competitive algorithms\nfor both minimization and maximization problems under MRF-distributed inputs.\nFor minimization problems with coverage constraints (e.g., Facility Location\nand Steiner Tree), we reduce to the well-studied $p$-sample model. For\nmaximization problems (e.g., matchings and combinatorial auctions with XOS\nbuyers), we extend the “balanced prices” framework for online allocation\nproblems to MRFs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Longest Unbordered Factors on Run-Length Encoded Strings",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-longest-unbordered-factors-on-run-length-encoded-strings/",
      "content": "Authors: Shoma Sekizaki, Takuya Mieno\n\nA border of a string is a non-empty proper prefix of the string that is also\na suffix. A string is unbordered if it has no border. The longest unbordered\nfactor is a fundamental notion in stringology, closely related to string\nperiodicity. This paper addresses the longest unbordered factor problem: given\na string of length $n$, the goal is to compute its longest factor that is\nunbordered. While recent work has achieved subquadratic and near-linear time\nalgorithms for this problem, the best known worst-case time complexity remains\n$O(n \\log n)$ [Kociumaka et al., ISAAC 2018]. In this paper, we investigate the\nproblem in the context of compressed string processing, particularly focusing\non run-length encoded (RLE) strings. We first present a simple yet crucial\nstructural observation relating unbordered factors and RLE-compressed strings.\nBuilding on this, we propose an algorithm that solves the problem in $O(m^{1.5}\n\\log^2 m)$ time and $O(m \\log^2 m)$ space, where $m$ is the size of the\nRLE-compressed input string. To achieve this, our approach simulates a key idea\nfrom the $O(n^{1.5})$-time algorithm by [Gawrychowski et al., SPIRE 2015],\nadapting it to the RLE setting through new combinatorial insights. When the RLE\nsize $m$ is sufficiently small compared to $n$, our algorithm may show\nlinear-time behavior in $n$, potentially leading to improved performance over\nexisting methods in such cases.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Best-of-Both-Worlds Guarantees with Fairer Endings",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-best-of-both-worlds-guarantees-with-fairer-endings/",
      "content": "Authors: Telikepalli Kavitha, Surya Panchapakesan, Rohit Vaish, Vignesh Viswanathan, Jatin Yadav\n\nFair allocation of indivisible goods is a fundamental problem at the\ninterface of economics and computer science. Traditional approaches focus\neither on randomized allocations that are fair in expectation or deterministic\nallocations that are approximately fair. Recent work reconciles both these\napproaches via best-of-both-worlds guarantees, wherein one seeks randomized\nallocations that are fair in expectation (ex-ante fair) while being supported\non approximately fair allocations (ex-post fair). Prior work has shown that\nunder additive valuations, there always exists a randomized allocation that is\nex-ante stochastic-dominance envy-free (sd-EF) and ex-post envy-free up to one\ngood (EF1).\nOur work is motivated by the goal of achieving stronger ex-post fairness\nguarantees such as envy-freeness up to any good (EFX) along with meaningful\nex-ante guarantees. We make the following contributions:\n1) We first consider lexicographic preferences, a subdomain of additive\nvaluations where ex-post EFX allocations always exist and can be computed\nefficiently. On the negative side, we show that ex-ante sd-EF is fundamentally\nincompatible with ex-post EFX, prompting a relaxation of the ex-ante benchmark.\nWe then present a poly. time algorithm that achieves ex-post EFX and PO\ntogether with ex-ante 9/10-EF. Our algorithm uses dependent rounding and\nleverages structural properties of EFX and PO allocations.\n2)For monotone valuations, we study EFX-with-charity: a relaxation of EFX\nwhere some goods remain unallocated, with no agent envying the unallocated\npool. We show that ex-post EFX-with-charity can be achieved alongside ex-ante\n0.5-EF.\n3)Finally, for subadditive valuations, we strengthen our previous ex-post\nguarantee to EFX-with-bounded-charity, where at most n-1 goods (n= no. of\nagents) remain unallocated, at the price of weakening the ex-ante guarantee to\n0.5-proportionality.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An unconditional lower bound for the active-set method in convex",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-an-unconditional-lower-bound-for-the-active-set-method-in-convex/",
      "content": "Authors: Eleon Bach, Yann Disser, Sophie Huiberts, Nils Mosis\n\nWe prove that the active-set method needs an exponential number of iterations\nin the worst-case to maximize a convex quadratic function subject to linear\nconstraints, regardless of the pivot rule used. This substantially improves\nover the best previously known lower bound [IPCO 2025], which needs objective\nfunctions of polynomial degrees $\\omega(\\log d)$ in dimension $d$, to a bound\nusing a convex polynomial of degree 2. In particular, our result firmly\nresolves the open question [IPCO 2025] of whether a constant degree suffices,\nand it represents significant progress towards linear objectives, where the\nactive-set method coincides with the simplex method and a lower bound for all\npivot rules would constitute a major breakthrough.\nOur result is based on a novel extended formulation, recursively constructed\nusing deformed products. Its key feature is that it projects onto a polygonal\napproximation of a parabola while preserving all of its exponentially many\nvertices. We define a quadratic objective that forces the active-set method to\nfollow the parabolic boundary of this projection, without allowing any\nshortcuts along chords corresponding to edges of its full-dimensional preimage.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Exact Solver for Maximizing a Submodular Function Subject to a",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-an-exact-solver-for-maximizing-a-submodular-function-subject-to-a/",
      "content": "Authors: Sabine Münch, Stephen Raach\n\nWe study the problem of maximizing a monotone increasing submodular function\nover a set of weighted elements subject to a knapsack constraint.\nAlthough this problem is NP-hard, many applications require exact solutions,\nas approximate solutions are often insufficient in practice.\nTo address this need, we propose an exact branch-and-bound algorithm tailored\nfor the submodular knapsack problem and introduce several acceleration\ntechniques to enhance its efficiency. We evaluate these techniques on instances\nof three benchmark problems and compare the proposed solvers to two solvers by\nSakaue and Ishihata, which are considered state-of-the-art, demonstrating that\nthe presented methods outperform the existing methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Best Possible General Form of the Master Theorem for",
      "url": "/cstheoryrss/2025/07/23/arxiv-data-structures-and-algorithms-a-best-possible-general-form-of-the-master-theorem-for/",
      "content": "Authors: Carl D. Offner\n\nWe give here a general, best-possible, and smoothly-derived form of the\nMaster Theorem for divide-and-conquer recurrences.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Improved Wake-Up Time For Euclidean Freeze-Tag Problem",
      "url": "/cstheoryrss/2025/07/23/arxiv-computational-geometry-improved-wake-up-time-for-euclidean-freeze-tag-problem/",
      "content": "Authors: Sharareh Alipour, Arash Ahadi, Kajal Baghestani\n\nThe Freeze-Tag Problem (FTP) involves activating a set of initially asleep\nrobots as quickly as possible, starting from a single awake robot. Once\nactivated, a robot can assist in waking up other robots. Each active robot\nmoves at unit speed. The objective is to minimize the makespan, i.e., the time\nrequired to activate the last robot. A key performance measure is the wake-up\nratio, defined as the maximum time needed to activate any number of robots in\nany primary positions. This work focuses on the geometric (Euclidean) version\nof FTP in $\\mathbb{R}^d$ under the $\\ell_p$ norm, where the initial distance\nbetween each asleep robot and the single active robot is at most 1. For\n$(\\mathbb{R}^2, \\ell_2)$, we improve the previous upper bound of 4.62 ([7],\nCCCG 2024) to 4.31. Note that it is known that 3.82 is a lower bound for the\nwake-up ratio. In $\\mathbb{R}^3$, we propose a new strategy that achieves a\nwake-up ratio of 12 for $(\\mathbb{R}^3, \\ell_1)$ and 12.76 for $(\\mathbb{R}^3,\n\\ell_2)$, improving upon the previous bounds of 13 and $13\\sqrt{3}$,\nrespectively, reported in [2].\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Analysis of Design Algorithms and Fabrication of a Graph-based",
      "url": "/cstheoryrss/2025/07/23/arxiv-computational-geometry-analysis-of-design-algorithms-and-fabrication-of-a-graph-based/",
      "content": "Authors: Mehdi Gorjian, Gregory A. Luhan, Stephen M. Caffey\n\nThis paper presents a novel algorithmic framework for the computational\ndesign, simulation, and fabrication of a hexagonal grid-based double-curvature\nstructure with planar hexagonal panels. The journey begins with constructing a\nrobust data structure through the meticulous subdivision of an equilateral\ntriangle surface, forming a foundational triangular grid. This grid is the\nbasis for a graph that encapsulates hexagons, laying the groundwork for\nsimulating dynamic interactions and form-finding. The developed algorithm\nensures a well-structured hexagonal grid data representation, and the\nexperimental results showcase the successful implementation of the algorithm,\nleading to the fabrication of planar hexagons mirroring physics-generated mesh\nsurfaces.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Monotone Circuit Complexity of Matching",
      "url": "/cstheoryrss/2025/07/23/arxiv-computational-complexity-monotone-circuit-complexity-of-matching/",
      "content": "Authors: Bruno Cavalar, Mika Göös, Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov\n\nWe show that the perfect matching function on $n$-vertex graphs requires\nmonotone circuits of size $\\smash{2^{n^{\\Omega(1)}}}$. This improves on the\n$n^{\\Omega(\\log n)}$ lower bound of Razborov (1985). Our proof uses the\nstandard approximation method together with a new sunflower lemma for\nmatchings.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Constructing material network representations for intelligent amorphous",
      "url": "/cstheoryrss/2025/07/23/arxiv-computational-complexity-constructing-material-network-representations-for-intelligent-amorphous/",
      "content": "Authors: S. -Y. Zhang, J. Tian, S. -L. Liu, H. -M. Zhang, H. -Y. Bai, Y. -C. Hu, W. -H. Wang\n\nDesigning high-performance amorphous alloys is demanding for various\napplications. But this process intensively relies on empirical laws and\nunlimited attempts. The high-cost and low-efficiency nature of the traditional\nstrategies prevents effective sampling in the enormous material space. Here, we\npropose material networks to accelerate the discovery of binary and ternary\namorphous alloys. The network topologies reveal hidden material candidates that\nwere obscured by traditional tabular data representations. By scrutinizing the\namorphous alloys synthesized in different years, we construct dynamical\nmaterial networks to track the history of the alloy discovery. We find that\nsome innovative materials designed in the past were encoded in the networks,\ndemonstrating their predictive power in guiding new alloy design. These\nmaterial networks show physical similarities with several real-world networks\nin our daily lives. Our findings pave a new way for intelligent materials\ndesign, especially for complex alloys.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Computational aspects of the trace norm contraction coefficient",
      "url": "/cstheoryrss/2025/07/23/arxiv-computational-complexity-computational-aspects-of-the-trace-norm-contraction-coefficient/",
      "content": "Authors: Idris Delsol, Omar Fawzi, Jan Kochanowski, Akshay Ramachandran\n\nWe show that approximating the trace norm contraction coefficient of a\nquantum channel within a constant factor is NP-hard. Equivalently, this shows\nthat determining the optimal success probability for encoding a bit in a\nquantum system undergoing noise is NP-hard. This contrasts with the classical\nanalogue of this problem that can clearly by solved efficiently. Our hardness\nresults also hold for deciding if the contraction coefficient is equal to 1. As\na consequence, we show that deciding if a non-commutative graph has an\nindependence number of at least 2 is NP-hard. In addition, we establish a\nconverging hierarchy of semidefinite programming upper bounds on the\ncontraction coefficient.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Digging in the crates",
      "url": "/cstheoryrss/2025/07/22/ben-recht-digging-in-the-crates/",
      "content": "\n\nWith Google’s abdication of web indexing, your humble blogger is left to index their archives themselves. Dear reader, I’m terrible at this. If only you could see the horror of my Google Docs folder. I periodically force myself to collect draft documents in the hope that this archiving will be useful for later final projects. This blog, which I consider a public repository of first drafts, is no exception. If you use the Substack app or only get argmin by email, you probably never see the doors to the archives. But since I was trying to collect my posts this week, I thought some of you might enjoy a tour.\n\nI used to run this blog through github, and all of those old posts are still around, but now you have to append “archives” to the URL: archives.argmin.net.\n\nIf you go to argmin.net and scroll down a bit, you’ll see a link here:\n\n\n\nI can’t figure out how to convince the Substack CMS to put this link higher on the page. Oh well. It’s also linked on the “About” page that no one visits. Regardless, the whole Jekyll blog structure remains intact at the link. If, for example, you wanted to read my survey of reinforcement learning for control applications, it’s here in all of its glory. I still get requests for these old posts and have tried to make them easy to find. Google, of course, refuses to reindex them. Oh well!\n\nOn the top banner, I have some other links to Substack posts I’ve collected thematically.\n\n\n\nMy course lecture blogging has its own tab, and each course has its own webpage. You can revisit, for example, my original live blogging of my graduate machine learning class in 2023.\n\nI also have collected some posts into themes. An index of my Meehl blogging is linked there. These remind me that I need to find someone else’s class to blog through next summer. It’s fun and I highly recommend it. If you still lurk around on Twitter, you should follow Damek Davis, who is tweeting through Percy Liang’s “Language Models from Scratch” class, which has been an incredible public service.\n\nAs I mentioned at the start, I was trying to figure out how to collect the blogs I’ve written this summer into themes, and I’m not sure any theme has been coherent enough to warrant its own page. But here’s my attempt at collecting them.\n\nA prominent theme this summer was forecasting. I wrote three posts (post 1, post 2, post 3) introducing the defensive forecasting survey I wrote with Juanky Perdomo. I followed this up with a post on the politics of forecasting. I also wrote about methodological challenges in forecasts, like when hedge funds try to convince people they have secret AI sauce but have just reinvented local weighted averaging. And though my post isn’t explicitly about forecasting, I did write about that METR study that compared forecasts to measurements of AI productivity gains. Though more about machine learning in general, last week’s post on why it’s hard to “prove” unpredictability fits into this theme.\n\nI also found myself writing a lot of academic navel gazing. There were about ten posts about scientific culture and gatekeeping. I had a fun four-post series on the history of academic computer science. I read through Louis Fein’s pitch to the ACM to create computer science departments and how computer scientists created a mythology around the field’s origins. I also looked into how Fein was written out of the history of CS, and how his speculative vision for the future of computer science was boring and bureaucratic.\n\nI wrote about scientific communal notions of validity and how they are more cultural style guides than divining rods of epistemological truth. I read Neil Postman’s “Social Science as Moral Theology,” which partially explains why social science feels the need to rest its rhetoric so heavily on quantitative constructs.2 I tried to thread the needle between how expertise is created and curated communally by academics but that doesn’t necessitate our current broken system of pre-publication peer review. And on a theme I want to revisit soon, I wrote about how metaanalysis of statistical significance is deeply confounded by the complex dynamic feedback mechanisms of academic expertise creation. In fact, the more I look into crises in science, the more I find that science has always been a mess. Trying to gatekeep that mess is and has been largely unproductive.\n\nFinally, and I suppose quite thematically related, I spent a lot of time on the state of academic machine learning. I worry about its focus on bureaucratic (and statistical) gatekeeping rather than open data and models. I asked what it would take for academics to re-engage with fully open generative AI. A third post tried to tie this argument together. These posts have me doing a lot of soul searching about my research future.\n\nHousekeeping note: I’ll be traveling for the next couple of weeks and won’t be posting while I’m away. I’ll be back the first week of August. I have a queue of ideas for what I want to write that I’ll get back to when I return, and hopefully they won’t be too outdated by then. The discourse moves fast these days! I’ll see you in August.\n\nSubscribe now\n\n1\n\nRereading these, I wonder if I should write a 2025 version of this surveying the role of “RL” in language modeling. I’m sort of thinking I should. It at least deserves a blog post!\n\n2\n\nThough not from this summer, this post about Healy and Fourcade’s The Ordinal Society is closely related.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-102 | Monotone Circuit Complexity of Matching |",
      "url": "/cstheoryrss/2025/07/22/eccc-papers-tr25-102-monotone-circuit-complexity-of-matching/",
      "content": "We show that the perfect matching function on $n$-vertex graphs requires monotone circuits of size $\\smash{2^{n^{\\Omega(1)}}}$. This improves on the $n^{\\Omega(\\log n)}$ lower bound of Razborov (1985). Our proof uses the standard approximation method together with a new sunflower lemma for matchings.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: Trevisan Prize- Deadline July 31 for Notification Intent, Aug 31 for nomination.",
      "url": "/cstheoryrss/2025/07/22/computational-complexity-trevisan-prize-deadline-july-31-for-notification-intent-aug-31-for-nomination/",
      "content": "A new prize:\n\nThe Trevisan Prize, in honor of Luca Trevisan, who died in 2024 (blog obit is here, open problems column in his honor is here), has been announced.\n\n The link is  here.\n\nThe deadline for notification of intent is July 31 which is soon.\n\n The deadline for the nomination is Aug 31.\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Topological Social Choice: Designing a Noise-Robust Polar Distance for",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-topological-social-choice-designing-a-noise-robust-polar-distance-for/",
      "content": "Authors: Athanasios Andrikopoulos, Nikolaos Sampanis\n\nTopological Data Analysis (TDA) has emerged as a powerful framework for\nextracting robust and interpretable features from noisy high-dimensional data.\nIn the context of Social Choice Theory, where preference profiles and\ncollective decisions are geometrically rich yet sensitive to perturbations, TDA\nremains largely unexplored. This work introduces a novel conceptual bridge\nbetween these domains by proposing a new metric framework for persistence\ndiagrams tailored to noisy preference data.We define a polar coordinate-based\ndistance that captures both the magnitude and orientation of topological\nfeatures in a smooth and differentiable manner. Our metric addresses key\nlimitations of classical distances, such as bottleneck and Wasserstein,\nincluding instability under perturbation, lack of continuity, and\nincompatibility with gradient-based learning. The resulting formulation offers\nimproved behavior in both theoretical and applied settings.To the best of our\nknowledge, this is the first study to systematically apply persistent homology\nto social choice systems, providing a mathematically grounded method for\ncomparing topological summaries of voting structures and preference dynamics.\nWe demonstrate the superiority of our approach through extensive experiments,\nincluding robustness tests and supervised learning tasks, and we propose a\nmodular pipeline for building predictive models from online preference data.\nThis work contributes a conceptually novel and computationally effective tool\nto the emerging interface of topology and decision theory, opening new\ndirections in interpretable machine learning for political and economic\nsystems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Tighter Lower Bounds for Single Source Personalized PageRank",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-tighter-lower-bounds-for-single-source-personalized-pagerank/",
      "content": "Authors: Xinpeng Jiang, Haoyu Liu, Siqiang Luo, Xiaokui Xiao\n\nWe study lower bounds for approximating the Single Source Personalized\nPageRank (SSPPR) query, which measures the probability distribution of an\n$\\alpha$-decay random walk starting from a source node $s$. Existing lower\nbounds remain loose-$\\Omega\\left(\\min(m, 1/\\delta)\\right)$ for relative error\n(SSPPR-R) and $\\Omega\\left(\\min(n, 1/\\epsilon)\\right)$ for additive error\n(SSPPR-A). To close this gap, we establish tighter bounds for both settings.\nFor SSPPR-R, we show a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\delta)}{\\delta}\\right)\\right)$ for any $\\delta \\in (0,1)$. For\nSSPPR-A, we prove a lower bound of $\\Omega\\left(\\min\\left(m,\n\\frac{\\log(1/\\epsilon)}{\\epsilon}\\right)\\right)$ for any $\\epsilon \\in (0,1)$,\nassuming the graph has $m \\in \\mathcal{O}(n^{2-\\beta})$ edges for any\narbitrarily small constant $\\beta \\in (0,1)$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum State Preparation Based on LimTDD",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-quantum-state-preparation-based-on-limtdd/",
      "content": "Authors: Xin Hong, Chenjian Li, Aochu Dai, Sanjiang Li, Shenggang Ying, Mingsheng Ying\n\nQuantum state preparation is a fundamental task in quantum computing and\nquantum information processing. With the rapid advancement of quantum\ntechnologies, efficient quantum state preparation has become increasingly\nimportant. This paper proposes a novel approach for quantum state preparation\nbased on the Local Invertible Map Tensor Decision Diagram (LimTDD). LimTDD\ncombines the advantages of tensor networks and decision diagrams, enabling\nefficient representation and manipulation of quantum states. Compared with the\nstate-of-the-art quantum state preparation method, LimTDD demonstrates\nsubstantial improvements in efficiency when dealing with complex quantum\nstates, while also reducing the complexity of quantum circuits. Examples\nindicate that, in the best-case scenario, our method can achieve exponential\nefficiency gains over existing methods. This study not only highlights the\npotential of LimTDD in quantum state preparation but also provides a robust\ntheoretical and practical foundation for the future development of quantum\ncomputing technologies.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-probing-efx-via-pmms-non-existence-results-in-discrete-fair-division/",
      "content": "Authors: Jarosław Byrka, Franciszek Malinka, Tomasz Ponitka\n\nWe study the fair division of indivisible items and provide new insights into\nthe EFX problem, which is widely regarded as the central open question in fair\ndivision, and the PMMS problem, a strictly stronger variant of EFX. Our first\nresult constructs a three-agent instance with two monotone valuations and one\nadditive valuation in which no PMMS allocation exists. Since EFX allocations\nare known to exist under these assumptions, this establishes a formal\nseparation between EFX and PMMS.\nWe prove existence of fair allocations for three important special cases. We\nshow that EFX allocations exist for personalized bivalued valuations, where for\neach agent $i$ there exist values $a_i &gt; b_i$ such that agent $i$ assigns value\n$v_i({g}) \\in {a_i, b_i}$ to each good $g$. We establish an analogous\nexistence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also\nprove that PMMS allocations exist for binary-valued MMS-feasible valuations,\nwhere each bundle $S$ has value $v_i(S) \\in {0, 1}$. Notably, this result\nholds even without assuming monotonicity of valuations and thus applies to the\nfair division of chores and mixed manna. Finally, we study a class of\nvaluations called pair-demand valuations, which extend the well-studied\nunit-demand valuations to the case where each agent derives value from at most\ntwo items, and we show that PMMS allocations exist in this setting. Our proofs\nare constructive, and we provide polynomial-time algorithms for all three\nexistence results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Predict, Reposition, and Allocate: A Greedy and Flow-Based Architecture",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-predict-reposition-and-allocate-a-greedy-and-flow-based-architecture/",
      "content": "Authors: Aqsa Ashraf Makhdomi, Iqra Altaf Gillani\n\nThe rapid proliferation of food delivery platforms has reshaped urban\nmobility but has also contributed significantly to environmental degradation\nthrough increased greenhouse gas emissions. Existing optimization mechanisms\nproduce sub-optimal outcomes as they do not consider environmental\nsustainability their optimization objective. This study proposes a novel\neco-friendly food delivery optimization framework that integrates demand\nprediction, delivery person routing, and order allocation to minimize\nenvironmental impact while maintaining service efficiency. Since recommending\nroutes is NP-Hard, the proposed approach utilizes the submodular and monotone\nproperties of the objective function and designs an efficient greedy\noptimization algorithm. Thereafter, it formulates order allocation problem as a\nnetwork flow optimization model, which, to the best of our knowledge, has not\nbeen explored in the context of food delivery. A three-layered network\narchitecture is designed to match orders with delivery personnel based on\ncapacity constraints and spatial demand. Through this framework, the proposed\napproach reduces the vehicle count, and creates a sustainable food delivery\necosystem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On zeros and algorithms for disordered systems: mean-field spin glasses",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-on-zeros-and-algorithms-for-disordered-systems-mean-field-spin-glasses/",
      "content": "Authors: Ferenc Bencs, Kuikui Liu, Guus Regts\n\nSpin glasses are fundamental probability distributions at the core of\nstatistical physics, the theory of average-case computational complexity, and\nmodern high-dimensional statistical inference. In the mean-field setting, we\ndesign deterministic quasipolynomial-time algorithms for estimating the\npartition function to arbitrarily high accuracy for nearly all inverse\ntemperatures in the second moment regime. In particular, for the\nSherrington–Kirkpatrick model, our algorithms succeed for almost the entire\nreplica-symmetric phase. To achieve this, we study the locations of the zeros\nof the partition function. Notably, our methods are conceptually simple, and\napply equally well to the spherical case and the case of Ising spins.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On Algorithmic Robustness of Corrupted Markov Chains",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-on-algorithmic-robustness-of-corrupted-markov-chains/",
      "content": "Authors: Jason Gaitonde, Elchanan Mossel\n\nWe study the algorithmic robustness of general finite Markov chains in terms\nof their stationary distributions to general, adversarial corruptions of the\ntransition matrix. We show that for Markov chains admitting a spectral gap,\nvariants of the \\emph{PageRank} chain are robust in the sense that, given an\n\\emph{arbitrary} corruption of the edges emanating from an $\\epsilon$-measure\nof the nodes, the PageRank distribution of the corrupted chain will be\n$\\mathsf{poly}(\\varepsilon)$ close in total variation to the original\ndistribution under mild conditions on the restart distribution. Our work thus\nshows that PageRank serves as a simple regularizer against broad, realistic\ncorruptions with algorithmic guarantees that are dimension-free and scale\ngracefully in terms of necessary and natural parameters.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: New Algorithms for #2-SAT and #3-SAT",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-new-algorithms-for-2-sat-and-3-sat/",
      "content": "Authors: Junqiang Peng, Zimo Sheng, Mingyu Xiao\n\nThe #2-SAT and #3-SAT problems involve counting the number of satisfying\nassignments (also called models) for instances of 2-SAT and 3-SAT,\nrespectively. In 2010, Zhou et al. proposed an $\\mathcal{O}^*(1.1892^m)$-time\nalgorithm for #2-SAT and an efficient approach for #3-SAT, where $m$ denotes\nthe number of clauses. In this paper, we show that the weighted versions of\n#2-SAT and #3-SAT can be solved in $\\mathcal{O}^*(1.1082^m)$ and\n$\\mathcal{O}^*(1.4423^m)$ time, respectively. These results directly apply to\nthe unweighted cases and achieve substantial improvements over the previous\nresults. These advancements are enabled by the introduction of novel reduction\nrules, a refined analysis of branching operations, and the application of path\ndecompositions on the primal and dual graphs of the formula.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Language Generation in the Limit: Noise, Loss, and Feedback",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-language-generation-in-the-limit-noise-loss-and-feedback/",
      "content": "Authors: Yannan Bai, Debmalya Panigrahi, Ian Zhang\n\nKleinberg and Mullainathan (2024) recently proposed a formal framework called\nlanguage generation in the limit and showed that given a sequence of example\nstrings from an unknown target language drawn from any countable collection, an\nalgorithm can correctly generate unseen strings from the target language within\nfinite time. This notion was further refined by Li, Raman, and Tewari (2024),\nwho defined stricter categories of non-uniform and uniform generation. They\nshowed that a finite union of uniformly generatable collections is generatable\nin the limit, and asked if the same is true for non-uniform generation.\nWe begin by resolving the question in the negative: we give a uniformly\ngeneratable collection and a non-uniformly generatable collection whose union\nis not generatable in the limit. We then use facets of this construction to\nfurther our understanding of several variants of language generation. The first\ntwo, generation with noise and without samples, were introduced by Raman and\nRaman (2025) and Li, Raman, and Tewari (2024) respectively. We show the\nequivalence of these models for uniform and non-uniform generation, and provide\na characterization of non-uniform noisy generation. The former paper asked if\nthere is any separation between noisy and non-noisy generation in the limit –\nwe show that such a separation exists even with a single noisy string. Finally,\nwe study the framework of generation with feedback, introduced by Charikar and\nPabbaraju (2025), where the algorithm is strengthened by allowing it to ask\nmembership queries. We show finite queries add no power, but infinite queries\nyield a strictly more powerful model.\nIn summary, the results in this paper resolve the union-closedness of\nlanguage generation in the limit, and leverage those techniques (and others) to\ngive precise characterizations for natural variants that incorporate noise,\nloss, and feedback.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: k-PCA for (non-squared) Euclidean Distances: Polynomial Time",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-k-pca-for-non-squared-euclidean-distances-polynomial-time/",
      "content": "Authors: Daniel Greenhut, Dan Feldman\n\nGiven an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Job Scheduling under Base and Additional Fees, with Applications to",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-job-scheduling-under-base-and-additional-fees-with-applications-to/",
      "content": "Authors: Yi-Ting Hsieh, Mong-Jen Kao, Jhong-Yun Liu, Hung-Lung Wang\n\nWe are concerned with the problem of scheduling $n$ jobs onto $m$ identical\nmachines. Each machine has to be in operation for a prescribed time, and the\nobjective is to minimize the total machine working time. Precisely, let $c_i$\nbe the prescribed time for machine $i$, where $i\\in[m]$, and $p_j$ be the\nprocessing time for job $j$, where $j\\in[n]$. The problem asks for a schedule\n$\\sigma\\colon\\, J\\to M$ such that $\\sum_{i=1}^m\\max{c_i,\n\\sum_{j\\in\\sigma^{-1}(i)}p_j}$ is minimized, where $J$ and $M$ denote the sets\nof jobs and machines, respectively. We show that First Fit Decreasing (FFD)\nleads to a $1.5$-approximation, and this problem admits a polynomial-time\napproximation scheme (PTAS). The idea is further applied to mixed-criticality\nsystem scheduling to yield improved approximation results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fast Algorithms for Graph Arboricity and Related Problems",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-fast-algorithms-for-graph-arboricity-and-related-problems/",
      "content": "Authors: Ruoxu Cen, Henry Fleischmann, George Z. Li, Jason Li, Debmalya Panigrahi\n\nWe give an algorithm for finding the arboricity of a weighted, undirected\ngraph, defined as the minimum number of spanning forests that cover all edges\nof the graph, in $\\sqrt{n} m^{1+o(1)}$ time. This improves on the previous best\nbound of $\\tilde{O}(nm)$ for weighted graphs and $\\tilde{O}(m^{3/2}) $ for\nunweighted graphs (Gabow 1995) for this problem. The running time of our\nalgorithm is dominated by a logarithmic number of calls to a directed global\nminimum cut subroutine – if the running time of the latter problem improves to\n$m^{1+o(1)}$ (thereby matching the running time of maximum flow), the running\ntime of our arboricity algorithm would improve further to $m^{1+o(1)}$.\nWe also give a new algorithm for computing the entire cut hierarchy –\nlaminar multiway cuts with minimum cut ratio in recursively defined induced\nsubgraphs – in $m n^{1+o(1)}$ time. The cut hierarchy yields the ideal edge\nloads (Thorup 2001) in a fractional spanning tree packing of the graph which,\nwe show, also corresponds to a max-entropy solution in the spanning tree\npolytope. For the cut hierarchy problem, the previous best bound was\n$\\tilde{O}(n^2 m)$ for weighted graphs and $\\tilde{O}(n m^{3/2})$ for\nunweighted graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Dvorak-Dell-Grohe-Rattan theorem via an asymptotic argument",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-dvorak-dell-grohe-rattan-theorem-via-an-asymptotic-argument/",
      "content": "Authors: Alexander Kozachinskiy\n\nTwo graphs $G_1,G_2$ are distinguished by the Weisfeiler–Leman isomorphism\ntest if and only if there is a tree $T$ that has a different number of\nhomomorphisms to $G_1$ and to $G_2$. There are two known proofs of this fact –\na logical proof by Dvorak and a linear-algebraic proof by Dell, Grohe, and\nRattan. We give another simple proof, based on ordering WL-labels and\nasymptotic arguments.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Differentially Private Synthetic Graphs Preserving Triangle-Motif Cuts",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-differentially-private-synthetic-graphs-preserving-triangle-motif-cuts/",
      "content": "Authors: Pan Peng, Hangyu Xu\n\nWe study the problem of releasing a differentially private (DP) synthetic\ngraph $G’$ that well approximates the triangle-motif sizes of all cuts of any\ngiven graph $G$, where a motif in general refers to a frequently occurring\nsubgraph within complex networks. Non-private versions of such graphs have\nfound applications in diverse fields such as graph clustering, graph\nsparsification, and social network analysis. Specifically, we present the first\n$(\\varepsilon,\\delta)$-DP mechanism that, given an input graph $G$ with $n$\nvertices, $m$ edges and local sensitivity of triangles $\\ell_{3}(G)$, generates\na synthetic graph $G’$ in polynomial time, approximating the triangle-motif\nsizes of all cuts $(S,V\\setminus S)$ of the input graph $G$ up to an additive\nerror of $\\tilde{O}(\\sqrt{m\\ell_{3}(G)}n/\\varepsilon^{3/2})$. Additionally, we\nprovide a lower bound of $\\Omega(\\sqrt{mn}\\ell_{3}(G)/\\varepsilon)$ on the\nadditive error for any DP algorithm that answers the triangle-motif size\nqueries of all $(S,T)$-cut of $G$. Finally, our algorithm generalizes to\nweighted graphs, and our lower bound extends to any $K_h$-motif cut for any\nconstant $h\\geq 2$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Characterizing and Testing Configuration Stability in Two-Dimensional",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-characterizing-and-testing-configuration-stability-in-two-dimensional/",
      "content": "Authors: Yonatan Nakar, Dana Ron\n\nWe consider the problems of characterizing and testing the stability of\ncellular automata configurations that evolve on a two-dimensional torus\naccording to threshold rules with respect to the von-Neumann neighborhood.\nWhile stable configurations for Threshold-1 (OR) and Threshold-5 (AND) are\ntrivial (and hence easily testable), the other threshold rules exhibit much\nmore diverse behaviors. We first characterize the structure of stable\nconfigurations with respect to the Threshold-2 (similarly, Threshold-4) and\nThreshold-3 (Majority) rules. We then design and analyze a testing algorithm\nthat distinguishes between configurations that are stable with respect to the\nThreshold-2 rule, and those that are $\\epsilon$-far from any stable\nconfiguration, where the query complexity of the algorithm is independent of\nthe size of the configuration and depends quadratically on $1/\\epsilon$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Certificate-Sensitive Subset Sum: Realizing Instance Complexity",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-certificate-sensitive-subset-sum-realizing-instance-complexity/",
      "content": "Authors: Jesus Salas\n\nWe present, to our knowledge, the first deterministic, certificate-sensitive\nalgorithm for a canonical NP-complete problem whose runtime provably adapts to\nthe structure of each input. For a Subset-Sum instance $(S, t)$, let\n$\\Sigma(S)$ denote the set of distinct subset sums and define $U =\n|\\Sigma(S)|$. This set serves as an information-theoretically minimal witness,\nthe instance-complexity (IC) certificate.\nOur solver, IC-SubsetSum, enumerates every element of $\\Sigma(S)$ in\ndeterministic time $O(U \\cdot n^2)$ and space $O(U \\cdot n)$. A randomized\nvariant achieves expected runtime $O(U \\cdot n)$. The algorithm’s complexity is\nthus directly governed by the certificate size, and this structure-sensitive\nperformance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 -\n\\varepsilon})$ for some constant $\\varepsilon &gt; 0$, the first such result to\nstrictly outperform classical methods on every instance.\nWe revisit fine-grained reductions that rely on the classical $2^{n/2}$\nhardness of SubsetSum and show that these arguments hold only for\ncollision-free instances where $U$ is maximal. IC-SubsetSum reframes this\nbarrier structurally and introduces a new paradigm for certificate-sensitive\nalgorithms across NP-complete problems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Better Models and Algorithms for Learning Ising Models from Dynamics",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-better-models-and-algorithms-for-learning-ising-models-from-dynamics/",
      "content": "Authors: Jason Gaitonde, Ankur Moitra, Elchanan Mossel\n\nWe study the problem of learning the structure and parameters of the Ising\nmodel, a fundamental model of high-dimensional data, when observing the\nevolution of an associated Markov chain. A recent line of work has studied the\nnatural problem of learning when observing an evolution of the well-known\nGlauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Mossel STOC 2024], which provides an arguably more realistic\ngenerative model than the classical i.i.d. setting. However, this prior work\ncrucially assumes that all site update attempts are observed, \\emph{even when\nthis attempt does not change the configuration}: this strong observation model\nis seemingly essential for these approaches. While perhaps possible in\nrestrictive contexts, this precludes applicability to most realistic settings\nwhere we can observe \\emph{only} the stochastic evolution itself, a minimal and\nnatural assumption for any process we might hope to learn from. However,\ndesigning algorithms that succeed in this more realistic setting has remained\nan open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,\nGaitonde, Moitra, Mossel, STOC 2025].\nIn this work, we give the first algorithms that efficiently learn the Ising\nmodel in this much more natural observation model that only observes when the\nconfiguration changes. For Ising models with maximum degree $d$, our algorithm\nrecovers the underlying dependency graph in time $\\mathsf{poly}(d)\\cdot n^2\\log\nn$ and then the actual parameters in additional $\\widetilde{O}(2^d n)$ time,\nwhich qualitatively matches the state-of-the-art even in the i.i.d. setting in\na much weaker observation model. Our analysis holds more generally for a\nbroader class of reversible, single-site Markov chains that also includes the\npopular Metropolis chain by leveraging more robust properties of reversible\nMarkov chains.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-asynchronous-collective-tree-exploration-a-distributed-algorithm-and-a/",
      "content": "Authors: Romain Cosson, Laurent Massoulié\n\nWe study the problem of collective tree exploration in which a team of $k$\nmobile agents must collectively visit all nodes of an unknown tree in as few\nmoves as possible. The agents all start from the root and discover adjacent\nedges as they progress in the tree. Communication is distributed in the sense\nthat agents share information by reading and writing on whiteboards located at\nall nodes. Movements are asynchronous, in the sense that the speeds of all\nagents are controlled by an adversary at all times. All previous competitive\nguarantees for collective tree exploration are either distributed but\nsynchronous, or asynchronous but centralized. In contrast, we present a\ndistributed asynchronous algorithm that explores any tree of $n$ nodes and\ndepth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear\nin $D$, and a variant algorithm with a guarantee in $O(k/\\log k)(n+kD)$, i.e.,\nwith a competitive ratio in $O(k/\\log k)$. We note that our regret guarantee is\nasymptotically optimal (i.e., $1$-competitive) from the perspective of\naverage-case complexity. We then present a new general lower bound on the\ncompetitive ratio of asynchronous collective tree exploration, in\n$\\Omega(\\log^2 k)$. This lower bound applies to both the distributed and\ncentralized settings, and improves upon the previous lower bound in\n$\\Omega(\\log k)$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An n{O(loglog n)} time approximation scheme for capacitated VRP in",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-an-n-o-loglog-n-time-approximation-scheme-for-capacitated-vrp-in/",
      "content": "Authors: René Sitters\n\nWe present a quasi polynomial time approximation scheme (Q-PTAS) for the\ncapacitated vehicle routing problem (CVRP) on $n$ points in the Euclidean plane\nfor arbitrary capacity $c$. The running time is $n^{f(\\epsilon)\\cdot\\log\\log\nn}$ for any $c$, and where $f$ is a function of $\\epsilon$ only. This is a\nmajor improvement over the so far best known running time of\n$n^{\\log^{O(1/\\epsilon)}n}$ time and a big step towards a PTAS for Euclidean\nCVRP.\nIn our algorithm, we first give a polynomial time reduction of the CVRP in\n$\\mathbb{R}^d$ (for any fixed $d$) to an uncapacitated routing problem in\n$\\mathbb{R}^d$ that we call the $m$-paths problem. Here, one needs to find\nexactly $m$ paths between two points $a$ and $b$, covering all the given points\nin the Euclidean space. We then give a Q-PTAS for the $m$-paths problem in the\npane. Any PTAS for the (arguably easier to handle) Euclidean $m$-paths problem\nis most likely to imply a PTAS for the Euclidean CVRP.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-addressing-bias-in-algorithmic-solutions-exploring-vertex-cover-and/",
      "content": "Authors: Sheikh Shakil Akhtar, Jayakrishnan Madathil, Pranabendu Misra, Geevarghese Philip\n\nA typical goal of research in combinatorial optimization is to come up with\nfast algorithms that find optimal solutions to a computational problem. The\nprocess that takes a real-world problem and extracts a clean mathematical\nabstraction of it often throws out a lot of “side information” which is deemed\nirrelevant. However, the discarded information could be of real significance to\nthe end-user of the algorithm’s output. All solutions of the same cost are not\nnecessarily of equal impact in the real-world; some solutions may be much more\ndesirable than others, even at the expense of additional increase in cost. If\nthe impact, positive or negative, is mostly felt by some specific (minority)\nsubgroups of the population, the population at large will be largely unaware of\nit. In this work we ask the question of finding solutions to combinatorial\noptimization problems that are “unbiased” with respect to a collection of\nspecified subgroups of the total population.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Myhill-Nerode Type Characterization of 2detLIN Languages",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-a-myhill-nerode-type-characterization-of-2detlin-languages/",
      "content": "Authors: Benedek Nagy\n\nLinear automata are automata with two reading heads starting from the two\nextremes of the input, are equivalent to 5’ -&gt; 3’ Watson-Crick (WK) finite\nautomata. The heads read the input in opposite directions and the computation\nfinishes when the heads meet. These automata accept the class LIN of linear\nlanguages. The deterministic counterpart of these models, on the one hand, is\nless expressive, as only a proper subset of LIN, the class 2detLIN is accepted;\nand on the other hand, they are also equivalent in the sense of the class of\nthe accepted languages. Now, based on these automata models, we characterize\nthe class of 2detLIN languages with a Myhill-Nerode type of equivalence\nclasses. However, as these automata may do the computation of both the prefix\nand the suffix of the input, we use prefix-suffix pairs in our classes.\nAdditionally, it is proven that finitely many classes in the characterization\nmatch with the 2detLIN languages, but we have some constraints on the used\nprefix-suffix pairs, i.e., the characterization should have the property to be\ncomplete and it must not have any crossing pairs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Black-Box Approach for Exogenous Replenishment in Online Resource",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-a-black-box-approach-for-exogenous-replenishment-in-online-resource/",
      "content": "Authors: Suho Kang, Ziyang Liu, Rajan Udwani\n\nIn a typical online resource allocation problem, we start with a fixed\ninventory of resources and make online allocation decisions in response to\nresource requests that arrive sequentially over a finite horizon. We consider\nsettings where the inventory is replenished over time according to an unknown\nexogenous process. We introduce black-box methods that extend any existing\nalgorithm, originally designed without considering replenishment, into one that\nworks with an arbitrary (adversarial or stochastic) replenishment process. Our\napproach preserves the original algorithm’s competitive ratio in regimes with\nlarge initial inventory, thereby enabling the seamless integration of exogenous\nreplenishment into a large body of existing algorithmic results for both\nadversarial and stochastic arrival models.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: 1.64-Approximation for Chromatic Correlation Clustering via Chromatic",
      "url": "/cstheoryrss/2025/07/22/arxiv-data-structures-and-algorithms-1-64-approximation-for-chromatic-correlation-clustering-via-chromatic/",
      "content": "Authors: Dahoon Lee, Chenglin Fan, Euiwoong Lee\n\nChromatic Correlation Clustering (CCC) generalizes Correlation Clustering by\nassigning multiple categorical relationships (colors) to edges and imposing\nchromatic constraints on the clusters. Unlike traditional Correlation\nClustering, which only deals with binary $(+/-)$ relationships, CCC captures\nricher relational structures. Despite its importance, improving the\napproximation for CCC has been difficult due to the limitations of standard LP\nrelaxations. We present a randomized $1.64$-approximation algorithm to the CCC\nproblem, significantly improving the previous factor of $2.15$. Our approach\nextends the cluster LP framework to the chromatic setting by introducing a\nchromatic cluster LP relaxation and an rounding algorithm that utilizes both a\ncluster-based and a greedy pivot-based strategy. The analysis bypasses the\nintegrality gap of $2$ for the CCC version of standard LP and highlights the\npotential of the cluster LP framework to address other variants of clustering\nproblems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Variable Min-Cut Max-Flow Bounds and Algorithms in Finite Regime",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-geometry-variable-min-cut-max-flow-bounds-and-algorithms-in-finite-regime/",
      "content": "Authors: Rivka Gitik, Alejandro Cohen\n\nThe maximum achievable capacity from source to destination in a network is\nlimited by the min-cut max-flow bound; this serves as a converse limit. In\npractice, link capacities often fluctuate due to dynamic network conditions. In\nthis work, we introduce a novel analytical framework that leverages tools from\ncomputational geometry to analyze throughput in heterogeneous networks with\nvariable link capacities in a finite regime. Within this model, we derive new\nperformance bounds and demonstrate that increasing the number of links can\nreduce throughput variability by nearly $90\\%$. We formally define a notion of\nnetwork stability and show that an unstable graph can have an exponential\nnumber of different min-cut sets, up to $O(2^{|E|})$. To address this\ncomplexity, we propose an algorithm that enforces stability with time\ncomplexity $O(|E|^2 + |V|)$, and further suggest mitigating the\ndelay-throughput tradeoff using adaptive rateless random linear network coding\n(AR-RLNC).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: TrajLens: Visual Analysis for Constructing Cell Developmental",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-geometry-trajlens-visual-analysis-for-constructing-cell-developmental/",
      "content": "Authors: Qipeng Wang, Shaolun Ruan, Rui Sheng, Yong Wang, Min Zhu, Huamin Qu\n\nConstructing cell developmental trajectories is a critical task in\nsingle-cell RNA sequencing (scRNA-seq) analysis, enabling the inference of\npotential cellular progression paths. However, current automated methods are\nlimited to establishing cell developmental trajectories within individual\nsamples, necessitating biologists to manually link cells across samples to\nconstruct complete cross-sample evolutionary trajectories that consider\ncellular spatial dynamics. This process demands substantial human effort due to\nthe complex spatial correspondence between each pair of samples. To address\nthis challenge, we first proposed a GNN-based model to predict cross-sample\ncell developmental trajectories. We then developed TrajLens, a visual analytics\nsystem that supports biologists in exploring and refining the cell\ndevelopmental trajectories based on predicted links. Specifically, we designed\nthe visualization that integrates features on cell distribution and\ndevelopmental direction across multiple samples, providing an overview of the\nspatial evolutionary patterns of cell populations along trajectories.\nAdditionally, we included contour maps superimposed on the original cell\ndistribution data, enabling biologists to explore them intuitively. To\ndemonstrate our system’s performance, we conducted quantitative evaluations of\nour model with two case studies and expert interviews to validate its\nusefulness and effectiveness.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: On Quad Mesh Extraction From Messy Grid Preserving Maps",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-geometry-on-quad-mesh-extraction-from-messy-grid-preserving-maps/",
      "content": "Authors: Nicolas Ray\n\nExtracting a quad mesh from a grid preserving map is straightforward in\ntheory, but typical inputs are not exactly grid preserving maps. Previous works\ncan manage minor deviations from grid preserving maps, but without a clear\nspecification of what is acceptable. This work clarifies how typical inputs\ndiffer from a grid preserving map, and shows how the differences with a grid\npreserving map can be reflected by a sequence of operations acting on a\ndiscrete structure. It opens research opportunities for the design of a robust\nquad extraction algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: k-PCA for (non-squared) Euclidean Distances: Polynomial Time",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-geometry-k-pca-for-non-squared-euclidean-distances-polynomial-time/",
      "content": "Authors: Daniel Greenhut, Dan Feldman\n\nGiven an integer $k\\geq1$ and a set $P$ of $n$ points in $\\REAL^d$, the\nclassic $k$-PCA (Principle Component Analysis) approximates the affine\n\\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear\nsubspace that minimizes its sum of squared Euclidean distances\n($\\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.\nThe \\emph{$k$-subspace median} is the subspace that minimizes its sum of\n(non-squared) Euclidean distances ($\\ell_{2,1}$-mixed norm), i.e., their\nmedian. The median subspace is usually more sparse and robust to noise/outliers\nthan the mean, but also much harder to approximate since, unlike the\n$\\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Studying homing and synchronizing sequences for Timed Finite State",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-complexity-studying-homing-and-synchronizing-sequences-for-timed-finite-state/",
      "content": "Authors: Evgenii Vinarskii, Jakub Ruszil, Adam Roman, Natalia Kushik\n\nThe paper introduces final state identification (synchronizing and homing)\nsequences for Timed Finite State Machines (TFSMs) with output delays and\ninvestigates their properties. We formally define the notions of homing\nsequences (HSs) and synchronizing sequences (SSs) for these TFSMs and\ndemonstrate that several properties that hold for untimed machines do not\nnecessarily apply to timed ones. Furthermore, we explore the applicability of\nvarious approaches for deriving SSs and HSs for Timed FSMs with output delays,\nsuch as truncated successor tree-based and FSM abstraction-based methods.\nCorrespondingly, we identify the subclasses of TFSMs for which these approaches\ncan be directly applied and those for which other methods are required.\nAdditionally, we evaluate the complexity of existence check and derivation of\n(shortest) HSs / SSs for TFSMs with output delays.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Pseudorandomness of Expander Walks via Fourier Analysis on Groups",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-complexity-pseudorandomness-of-expander-walks-via-fourier-analysis-on-groups/",
      "content": "Authors: Fernando Granha Jeronimo, Tushant Mittal, Sourya Roy\n\nOne approach to study the pseudorandomness properties of walks on expander\ngraphs is to label the vertices of an expander with elements from an alphabet\n$\\Sigma$, and study the mean of functions over $\\Sigma^n$. We say expander\nwalks $\\varepsilon$-fool a function if, for any unbiased labeling of the\nvertices, the expander walk mean is $\\varepsilon$-close to the true mean. We\nshow that:\n\n  The class of symmetric functions is $O(|\\Sigma|\\cdot\\lambda)$-fooled by\nexpander walks over any generic $\\lambda$-expander, and any alphabet $\\Sigma$ .\nThis generalizes the result of Cohen, Peri, Ta-Shma [STOC’21] which analyzes it\nfor $|\\Sigma| =2$, and exponentially improves the previous bound of\n$O(|\\Sigma|^{O(|\\Sigma|)}\\cdot \\lambda)$, by Golowich and Vadhan [CCC’22].\nAdditionally, if the expander is a Cayley graph over $\\mathbb{Z}_{|\\Sigma|}$,\nwe get a further improved bound of $O(\\sqrt{|\\Sigma|}\\cdot\\lambda)$.\nMorever, when $\\Sigma$ is a finite group $G$, we show the following for\nfunctions over $G^n$:\n  The class of symmetric class functions is\n$O\\Big({\\frac{\\sqrt{|G|}}{D}\\cdot\\lambda}\\Big)$-fooled by expander walks over\n“structured” $\\lambda$-expanders, if $G$ is $D$-quasirandom.\n  We show a lower bound of $\\Omega(\\lambda)$ for symmetric functions for any\nfinite group $G$ (even for “structured” $\\lambda$-expanders).\n  We study the Fourier spectrum of a class of non-symmetric functions arising\nfrom word maps, and show that they are exponentially fooled by expander walks.\nOur proof employs Fourier analysis over general groups, which contrasts with\nearlier works that have studied either the case of $\\mathbb{Z}_2$ or\n$\\mathbb{Z}$. This enables us to get quantitatively better bounds even for\nunstructured sets.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Efficient Algorithms for Relevant Quantities of Friedkin-Johnsen Opinion",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-complexity-efficient-algorithms-for-relevant-quantities-of-friedkin-johnsen-opinion/",
      "content": "Authors: Gengyu Wang, Runze Zhang, Zhongzhi Zhang\n\nOnline social networks have become an integral part of modern society,\nprofoundly influencing how individuals form and exchange opinions across\ndiverse domains ranging from politics to public health. The Friedkin-Johnsen\nmodel serves as a foundational framework for modeling opinion formation\ndynamics in such networks. In this paper, we address the computational task of\nefficiently determining the equilibrium opinion vector and associated metrics\nincluding polarization and disagreement, applicable to both directed and\nundirected social networks. We propose a deterministic local algorithm with\nrelative error guarantees, scaling to networks exceeding ten million nodes.\nFurther acceleration is achieved through integration with successive\nover-relaxation techniques, where a relaxation factor optimizes convergence\nrates. Extensive experiments on diverse real-world networks validate the\npractical effectiveness of our approaches, demonstrating significant\nimprovements in computational efficiency and scalability compared to\nconventional methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Complexity of Faceted Explanations in Propositional Abduction",
      "url": "/cstheoryrss/2025/07/22/arxiv-computational-complexity-complexity-of-faceted-explanations-in-propositional-abduction/",
      "content": "Authors: Johannes Schmidt, Mohamed Maizia, Victor Lagerkvist, Johannes K. Fichte\n\nAbductive reasoning is a popular non-monotonic paradigm that aims to explain\nobserved symptoms and manifestations. It has many applications, such as\ndiagnosis and planning in artificial intelligence and database updates. In\npropositional abduction, we focus on specifying knowledge by a propositional\nformula. The computational complexity of tasks in propositional abduction has\nbeen systematically characterized - even with detailed classifications for\nBoolean fragments. Unsurprisingly, the most insightful reasoning problems\n(counting and enumeration) are computationally highly challenging. Therefore,\nwe consider reasoning between decisions and counting, allowing us to understand\nexplanations better while maintaining favorable complexity. We introduce facets\nto propositional abductions, which are literals that occur in some explanation\n(relevant) but not all explanations (dispensable). Reasoning with facets\nprovides a more fine-grained understanding of variability in explanations\n(heterogeneous). In addition, we consider the distance between two\nexplanations, enabling a better understanding of heterogeneity/homogeneity. We\ncomprehensively analyze facets of propositional abduction in various settings,\nincluding an almost complete characterization in Post’s framework.\n\nRead original post\n"
    },
    
    {
      "title": "The Learning Theory Alliance Blog: Testing Assumptions of Learning Algorithms",
      "url": "/cstheoryrss/2025/07/21/the-learning-theory-alliance-blog-testing-assumptions-of-learning-algorithms/",
      "content": "Today’s technical post is by Arsen Vasilyan. This focuses on the very exciting new “testable learning” he introduced with Rubinfeld in a 2023 paper. There’s been a flurry of work since then, so this is a good chance to catch up in case you’re behind!\n\n\n\n1. The Goal: Learning with Noisy Labels\n\n1.1 Introduction\n\nMany learning algorithms simply stop working when some of the training examples are mislabeled. For example, suppose we are using a linear program to learn a linear classifier. Then, a single mislabeled data-point can make the linear program infeasible, and the algorithm fails to output a solution. Today, we will discuss how to design learning algorithms that are provably robust to such noise.\n\nFor noise-resistant learning algorithms, a key consideration emerges: what can these algorithms assume about how the data-points are distributed? We will discuss three theoretical frameworks addressing this question:\n\n\n  Framework 1 — the distribution-free framework — makes no assumption on how data-points are generated. For every distribution over datapoints, the algorithm has to run efficiently and be robust to noise. This framework is very well-understood, but is computationally intractable. Even the simplest concept classes lead to computationally hard learning tasks in this framework.\n  Framework 2 — the distribution-specific framework — assumes that data-points come from some well-behaved distribution, such as the Gaussian distribution. Over the last 30 years, the distribution-specific framework has led to a wealth of provably efficient algorithms. However, these algorithms fail to be noise-resistant when their assumptions do not hold.\n  Framework 3 — the testable framework — relies on an assumption on the data-point distribution only for the run-time of an algorithm, but not for the algorithm’s robustness to noise. Even if data-points do not come from some well-behaved distribution, the algorithm should be robust to noise. However, in this case, the algorithm might take a long time to run.\n\n\nThis blog post will mostly focus on the third framework, which was recently introduced in [RV ’23] in the context of learning with noise, and further explored in [GKK ’23, DKKLZ ’23, GKSV ’23, GKSV ’24, GSSV ’24, DKLZ’24, STW ’24, GKSV ’25]. In brief, although Framework 3 is more stringent than Framework 2, there is a toolkit of techniques that we can use to upgrade many Framework 2 algorithms into Framework 3.\n\n1.2 FAQ on the Testable Framework (Framework 3)\n\nWe get a lot of questions about Framework 3, and so we begin with the following FAQs:\n\n\n  Q: Why is the framework called testable? \nA: All current algorithms in Framework 3 follow the following general recipe for upgrading Framework 2 algorithms into Framework 3 — the procedure suggests the name testable learning. See Section 2.2 for more about this recipe.\n    \n      a) Run a Framework 2 algorithm and obtain a hypothesis .\n      b) Run a tester that is guaranteed to output “accept” whenever the assumption holds.\n      c) If the tester accepted, return the hypothesis .\n      d) Otherwise, the assumption must have been violated so we can run a computationally expensive algorithm (See Section 1.3 for more about those).\n    \n  \n  Q: To implement this tester, cant we just check that the distribution is “close” to a Gaussian using tools from distribution testing? \nA: For many notions of “closeness” this is statistically impossible: for example one cannot test whether an unknown distribution is Gaussian or far from Gaussian in total variation distance.1 For other notions of closeness, such as the earth-mover distance, these tools require a number of samples and run-time that is exponential in the dimension. In learning theory, we are looking for much faster run-times (see [RV ’23] for more discussion).\n  Q: What if the assumption is violated only slightly? I am concerned that this will cause a Framework 3 algorithm to run slowly as a result. \nA: Many algorithms in Framework 3 can be modified to run fast whenever the assumption is only approximately satisfied in total variation distance [GKSV ’25]. This setting is called Tolerant Testable Learning, and discussed more in Section 3.2.\n  Q: The algorithm is guaranteed to run fast for only one specific distribution. What if I want it to run fast for an entire family of distributions? \nA: This setting, called universal testable learning, has also been studied. [GKSV ’23] studies it for the family of log-concave distributions, and it turns out to be intimately connected with Sum-of-Squares relaxations [KS17].\n  Q: Framework 3 is defined to work with learning under label noise (a.k.a. agnostic learning). What about (noise-free) PAC learning? \nA: Frameworks 2 and 3 are essentially equivalent in the noise-free setting. In this setting, one can always tell whether the learning algorithm successfully produced a good hypothesis: just estimate its prediction error by drawing a fresh set of examples. If the prediction error is large, this must be because the assumption is violated, so Framework 3 does not require us to run fast. In this case, we can produce a classifier by running a computationally expensive algorithm (See Section 1.3 for more about those).\n  Q: What is the sample complexity of this framework? Is it related to VC dimension? \nA: [GKK ’23]have shown that the sample complexity of this model is characterized by the Rademacher complexity of the hypothesis class. However, in this blog post we will focus on the run-time rather than sample complexity.\n\n\nWe will now introduce the three frameworks in more detail, survey more of the known results and highlight general ideas for designing such algorithms.\n\n1.3 Three Frameworks for Learning with Noisy Labels\n\nLet us be more formal now.  will denote our hypothesis class, containing binary-valued functions over the domain . We get independent examples  from a distribution  and each  is labeled bysome unknown binary-valuedfunction2 . To model arbitrary label noise, we place no assumption on , and our goal is to get as close as possible to the smallest error among all functions  from the class :\n\n![\\displaystyle \\text{opt}{\\mathcal{C}}:=\\min{f\\in\\mathcal{C}}\\underbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[f(x)\\neq f_{\\text{noisy labels}}(x)]}{\\text{Prediction error of \\ensuremath{f}.}}. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%3A%3D%5Cmin_%7Bf%5Cin%5Cmathcal%7BC%7D%7D%5Cunderbrace%7B%5CPr_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bf%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D_%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bf%7D.%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\nFor instance, ![{\\text{opt}{\\text{Linear Classifiers}}}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) denotes the smallest classification error achievable by any linear classifier.\n\n\n\nFramework 1 [Distribution-free Framework] For any distribution  and function , the learning algorithm should run in time  and with high probability3 output a classifier  with\n\n![\\displaystyle \\overbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[h(x)\\neq f_{\\text{noisy labels}}(x)]}^{\\text{Prediction error of \\ensuremath{h}.}}\\leq\\underbrace{\\overbrace{\\text{opt}{\\mathcal{C}}}^{\\text{Optimal prediction error in \\ensuremath{\\mathcal{C}.}}}+\\varepsilon}{\\text{\\ensuremath{\\text{\\text{\\ensuremath{\\text{Weaker guarantees, such as O(\\ensuremath{\\text{opt}{\\mathcal{C}}})+\\ensuremath{\\varepsilon},\\ also considered.}}}}}}}. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Coverbrace%7B%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bh%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D%5E%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bh%7D.%7D%7D%5Cleq%5Cunderbrace%7B%5Coverbrace%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%5E%7B%5Ctext%7BOptimal+prediction+error+in+%5Censuremath%7B%5Cmathcal%7BC%7D.%7D%7D%7D%2B%5Cvarepsilon%7D_%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7BWeaker+guarantees%2C+such+as+O%28%5Censuremath%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Censuremath%7B%5Cvarepsilon%7D%2C%5C+also+considered.%7D%7D%7D%7D%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\n\n\nThis task, also known as agnostic learning, can be solved sample-efficiently. According to a central theorem in the VC theory,  samples suffice (where  is the VC dimension of ). For example, if  is the class of linear classifiers, then , so  samples are enough.\n\nHowever, when considering the run-time , the Framework 1 is revealed to be intractable. For example, no -time algorithm is known in Framework 1 when  is taken to be the class of linear classifiers (which is arguably the most basic hypothesis class). Furthermore, even the task of deciding if ![{\\text{ \\ensuremath{\\text{opt}{\\text{Linear Classifiers}}}}\\leq0.01}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B+%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%7D%7D%5Cleq0.01%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) or ![{\\text{opt}{\\text{Linear Classifiers}}\\geq0.49}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%5Cgeq0.49%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) is known to be NP-hard [GR’06, FGKP’06] for linear classifiers and believed to require  time. In summary, these Framework 1 tasks take  samples but the run-time  is .\n\nThese intractability results hold for certain carefully-constructed worst-case choices of . What happens if  is some specific commonly-occurring probability distribution? For instance, we may want to find a good linear classifier when the data-points come from a Gaussian distribution or some other well-behaved distribution . This has motivated research in the following framework:\n\n\n\nFramework 2 [Distribution-Specific Framework] For any distribution  and function , if , then the learning algorithm should run in time  and with high probability output a classifier  with\n\n![\\displaystyle \\overbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[h(x)\\neq f_{\\text{noisy labels}}(x)]}^{\\text{Prediction error of \\ensuremath{h}.}}\\leq\\underbrace{\\overbrace{\\text{opt}{\\mathcal{C}}}^{\\text{Optimal prediction error in \\ensuremath{\\mathcal{C}.}}}+\\varepsilon}{\\text{\\ensuremath{\\text{\\text{\\ensuremath{\\text{Weaker guarantees, such as O(\\ensuremath{\\text{opt}{\\mathcal{C}}})+\\ensuremath{\\varepsilon},\\ also considered.}}}}}}}. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Coverbrace%7B%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bh%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D%5E%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bh%7D.%7D%7D%5Cleq%5Cunderbrace%7B%5Coverbrace%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%5E%7B%5Ctext%7BOptimal+prediction+error+in+%5Censuremath%7B%5Cmathcal%7BC%7D.%7D%7D%7D%2B%5Cvarepsilon%7D_%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7BWeaker+guarantees%2C+such+as+O%28%5Censuremath%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Censuremath%7B%5Cvarepsilon%7D%2C%5C+also+considered.%7D%7D%7D%7D%7D%7D%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\n\n\nThis framework is also often referred to as distribution-specific agnostic learning. For many natural choices of distribution , the aforementioned hardness results for Framework 1 can be sidestepped in Framework 2. When the class  is the class of linear classifiers and the distribution  is a Gaussian distribution, the algorithm of [KKMS ’08, DGJSV ’10] can achieve an error ![{\\text{opt}{\\text{Linear Classifiers}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) with run-time , which is a lot better than the  run-time in Framework 1. This run-time is believed to be optimal [DKZ ’20, GGK ’20, DKPZ ’21, DKR ’23], but can be sped up to  if one is happy with a slightly larger error4 of ![{O(\\text{opt}{\\text{Linear Classifiers}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) [ABL ’14, DKTZ ’22].\n\nYet, Framework 2 relies on the potentially unverifiable assumption that the distribution  equals . Note that it is impossible to verify whether  is exactly equal to the Gaussian distribution. Unfortunately, when , the ![{\\text{opt}{\\mathcal{C}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) error guarantee of an algorithm in Framework 2 becomes null and void. Remember how a linear-programming approach can fully fail to find a linear classifier with even a single mislabeled example? We see that Framework 2 also permits an algorithm to fully fail when .\n\nThis limitation is addressed by the following more challenging framework, in which the algorithm must always output a near-optimal classifier (with high probability, as in Framework 1) but must run quickly only when the assumption holds (as in Framework 2):\n\n\n\nFramework 3 [Testable Framework] For any distribution  and function , the learning algorithm should with high probability output a classifier  with\n\n![\\displaystyle \\overbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[h(x)\\neq f_{\\text{noisy labels}}(x)]}^{\\text{Prediction error of \\ensuremath{h}.}}\\leq\\underbrace{\\overbrace{\\text{opt}{\\mathcal{C}}}^{\\text{Optimal prediction error in \\ensuremath{\\mathcal{C}.}}}+\\varepsilon}{\\text{\\ensuremath{\\text{Weaker guarantees, such as O(\\ensuremath{\\text{opt}{\\mathcal{C}}})+\\ensuremath{\\varepsilon},\\ also considered.}}}}. \\ \\ \\ \\ \\ (1)](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Coverbrace%7B%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bh%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D%5E%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bh%7D.%7D%7D%5Cleq%5Cunderbrace%7B%5Coverbrace%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%5E%7B%5Ctext%7BOptimal+prediction+error+in+%5Censuremath%7B%5Cmathcal%7BC%7D.%7D%7D%7D%2B%5Cvarepsilon%7D_%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7BWeaker+guarantees%2C+such+as+O%28%5Censuremath%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Censuremath%7B%5Cvarepsilon%7D%2C%5C+also+considered.%7D%7D%7D%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\nFurthermore, if , then with high probability the learning algorithm should run5 in time .\n\n\n\nThis framework is also often referred to as testable learning (for reasons explained in Section 2.2). When a Framework 3 algorithm produces a classifier , the user can be confident that  is nearly-optimal (Equation 1) whether or not , but the fast run-time is only guaranteed when .\n\n\n\nEven though Framework 3 requires more from the learning algorithm than Framework 2, a growing body of research demonstrates that Framework 3 is often as computationally tractable as Framework 2. This research direction was initiated in [RV ’23] which mainly considered linear classifiers under the Gaussian distribution, and was subsequently extended to many more hypothesis classes and distributions  [GKK ’23, DKKLZ ’23, GKSV ’23, GKSV ’24, GSSV ’24, DKLZ’24, STW ’24, GKSV ’25]. In this blog post, we will survey this research direction and explore some of the techniques used to design such algorithms.\n\n2. How to Modify Framework 2 Algorithms to Work in Framework 3.\n\nIn this section we will discuss a general recipe for converting Framework 2 algorithms into Framework 3 by augmenting them with an appropriate tester. As a case study, we will focus on one of the most widely-studied Framework 2 algorithms: the Low-Degree Algorithm. We will see how it can be upgraded into Framework 3 using the Moment-Matching Tester. Later, in Section 3, we will see how a similar recipe can be used for other algorithms as well.\n\n2.1 What is an Example of Framework 2 Algorithm? The Low-Degree Algorithm.\n\nWe begin by examining the following Framework 2 algorithm.\n\n\n\nDegree-k Low-Degree Algorithm [KKMS ’08]:\n\nGiven: access to independent Gaussian examples labeled by unknown function  and a parameter .\n\nOutput: hypothesis .\n\n\n   { Gaussian examples labeled by function }.\n  \n    Compute\n\n    \n      \n        \n          ![\\displaystyle p^{*}\\leftarrow\\underset{\\boldsymbol{\\text{degree}}-k\\text{ polynomial }p}{\\text{argmin}}\\left[\\mathbb{E}{(x{i},f_{\\text{noisy labels}}(x_{i}))\\sim S}\n          p(x_{i})-f_{\\text{noisy labels}}(x_{i})\n          \\right] ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+p%5E%7B%2A%7D%5Cleftarrow%5Cunderset%7B%5Cboldsymbol%7B%5Ctext%7Bdegree%7D%7D-k%5Ctext%7B+polynomial+%7Dp%7D%7B%5Ctext%7Bargmin%7D%7D%5Cleft%5B%5Cmathbb%7BE%7D_%7B%28x_%7Bi%7D%2Cf_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x_%7Bi%7D%29%29%5Csim+S%7D%7Cp%28x_%7Bi%7D%29-f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x_%7Bi%7D%29%7C%5Cright%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n        \n      \n    \n\n    by solving a linear program.\n  \n  Output hypothesis  mapping  in  to .\n\n\n\n\nIt can be shown [KKMS ’08, DGJSV ’10] that, for , the resulting classifier  will achieve prediction error ![{\\text{O(\\ensuremath{\\text{opt}{\\text{Linear Classifiers}}}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BO%28%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). Furthermore, with a slightly more sophisticated version of step 3, the prediction error improves to ![{\\text{\\ensuremath{\\text{opt}{\\text{Linear Classifiers}}}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) [KKMS ’08, DGJSV ’10]. The run-time is .\n\nThis approach also yields a classifier  with error ![{\\text{\\ensuremath{\\text{opt}{\\text{\\ensuremath{\\mathcal{C}}}}}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7B%5Censuremath%7B%5Cmathcal%7BC%7D%7D%7D%7D%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) for many other hypothesis classes , such as ANDs of linear classifiers or indicators of convex sets in  [KOS ’08]. The same approach can even be used when the class  is constant-depth circuits and the distribution  is uniform over binary bit-strings [KKMS ’08]. To achieve all these results, we only need to run the algorithm above with a larger value of the degree parameter . The run-time  will increase, but as long as we insist on error bound of ![{\\text{opt}{\\mathcal{C}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) in Framework 2, this approach is known to be optimal for many hypothesis classes  [DFTWW’15, DKZ ’20, GGK ’20, DKPZ ’21, DKR ’23]. (Additionally, in order to achieve error ![{\\text{\\ensuremath{\\text{opt}{\\text{\\ensuremath{\\mathcal{C}}}}}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7B%5Censuremath%7B%5Cmathcal%7BC%7D%7D%7D%7D%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) rather than ![{\\text{O(\\ensuremath{\\text{opt}{\\text{\\ensuremath{\\mathcal{C}}}}})}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BO%28%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7B%5Censuremath%7B%5Cmathcal%7BC%7D%7D%7D%7D%7D%29%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) one needs to replace step 3 with a slightly more sophisticated version of this step [KKMS ’08]. From now on, we will make a tacit assumption that this improved version of step 3 is used.)\n\n2.2 Converting the Low-Degree Algorithm into Framework 3 via the Moment-Matching Test.\n\nFor a wide range of concept classes , you can get Framework 3 algorithms by combining the Low-Degree Algorithm with a suitable tester . Here is a general recipe to extend Framework 2 algorithms so they run in Framework 3:\n\n\n  Run6 an algorithm  for class  in Framework 2 to get a classifier \n  Run some algorithm , which we will call the tester, that accesses  and outputs Accept or Reject.\n  If  accepts, then return the classifier  from step (1).\n  If  rejects, then run a (potentially very slow) algorithm  for class  in Framework 1. (See Section 1.3 for more about those)\n\n\nLet us compare Framework 2 and Framework 3, to see what specifications the tester  needs to meet to ensure that the procedure above satisfies Framework 3. We see that it would suffice if algorithm  accepted whenever  and rejected whenever . Unfortunately, for example when  is the Gaussian distribution, there is provably no tester  that can distinguish if  or .\n\nHowever, we can get away with less stringent requirements for  and still achieve our goal:\n\n\n  Completeness: whenever , the tester  accepts with high probability.\n  \n    Soundness: For all distributions , either the tester  will with high probability reject , or  is such that the algorithm  will with high probability give a hypothesis  satisfying the -optimality guarantee\n\n    ![\\displaystyle \\overbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[h(x)\\neq f_{\\text{noisy labels}}(x)]}^{\\text{Prediction error of \\ensuremath{h}.}}\\leq\\overbrace{\\text{opt}{\\mathcal{C}}}^{\\text{Optimal prediction error in \\ensuremath{\\mathcal{C}.}}}+\\varepsilon. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Coverbrace%7B%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bh%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D%5E%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bh%7D.%7D%7D%5Cleq%5Coverbrace%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%5E%7B%5Ctext%7BOptimal+prediction+error+in+%5Censuremath%7B%5Cmathcal%7BC%7D.%7D%7D%7D%2B%5Cvarepsilon.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n  \n  Fast Run Time: the tester  runs in time at most .\n\n\nThe point of the Soundness condition is to permit the algorithm  to accept a distribution  even if  but  is still “good enough” for the algorithm .\n\nLet us come back to using the recipe above, taking  to be the Low-Degree Algorithm. The recipe above can be executed using the following algorithm7 as the tester :\n\n\n\nDegree- Moment-Matching Tester [RV ’23, GKK ’23]:\n\n\n  Given: access to independent examples from , a reference distribution , parameter .\n  Output: Accept or Reject.\n\n\n\n   { examples from }.\n  For all monomials  of total degree at most :\n    \n      If , output Reject and terminate. \n(Note: For many distributions  of interest, such as Gaussian distribution, the quantity  can be computed directly. One can also draw samples from  and use them to estimate .)\n    \n  \n  If this step is reached, output Accept.\n\n\n\n\nSince in  dimensions there are at most  monomials of degree , the Moment-Matching Tester above runs in time .\n\nOverall, using the recipe above to combine the degree- Low-Degree Algorithm with the degree- Moment-Matching Tester, yields Framework 3 algorithms for many concept classes—including linear classifiers, ANDs of linear classifiers, and constant-depth circuits. As a concrete example, when  is the class of linear classifiers, the resulting algorithm in Framework 3 has a run-time bound  of . This run-time matches best algorithm of in Framework 2 (believed to be optimal).\n\nThe proof of correctness for these algorithms in Framework 3 is far from automatic. As explained in Section 2.3, the notion of sandwiching polynomials from the field of pseudorandomness turns out to be very important for the proof of correctness [GKK ’23].\n\nRemark: many papers referenced here phrase their main result as a tester  that satisfies the three aforementioned conditions of completeness, soundness and fast run-time (together with a Framework 2 algorithm ). Note that, as described above and also noted in [RV ’23], having such a tester gives8 an algorithm in Framework 3 (in fact it is equivalent to having an algorithm in Framework 3 [RV ’23]).\n\n2.3 Analysis of the Moment-Matching Tester through Sandwiching Polynomials.\n\nSoon, we will discuss more Framework 3 algorithms, but let us first discuss the proof of correctness for the Moment-Matching Tester. Recall that it needs to satisfy three conditions: Completeness, Soundness and Fast Run Time. Among these three, the Soundness condition is the most challenging one to prove. [GKK ’23] give a principled way of doing this, which we will briefly sketch now. A key step is to show that every function  in the class  has -sandwiching polynomials of degree  under , i.e. a pair of polynomials  and  satisfying:\n\n\n  Sandwiching: for every point , we have .\n  -Closeness: we have .\n\n\nFor example, linear classifiers have -sandwiching polynomials of degree  under the Gaussian distribution [DGJSV ’10]. This notion was first studied in the field of pseudorandomness, because the existence of sandwiching polynomials for  can be leveraged to approximate the expectation  while only making deterministic queries to .\n\nIt is shown in [GKK ’23] that whenever such a pair of polynomials exists for every  in the hypothesis class , then for the Moment-Matching Tester, the Soundness condition holds. Let us briefly sketch the argument, denoting by  the function in  with the smallest prediction error ![{\\text{opt}{\\mathcal{C}}}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). By assumption, there is a pair of sandwiching polynomials  and  for .\n\nIf the distribution  is such that the Moment-Matching Tester is likely to pass, then for every monomial  of degree at most  we have . Therefore,\n\n\n  \n    \n      ![\\displaystyle \\mathbb{E}{x\\sim D{\\text{Examples}}}\\left[\\left\n      f^{*}(x)-p_{\\text{down}}(x)\\right\n      \\right] \\ \\leq\\mathbb{E}{x\\sim D{\\text{Examples}}}[p_{\\text{up}}(x)-p_{\\text{down}}(x)]\\approx\\mathbb{E}{x\\sim D{\\text{Assumption}}}[p_{\\text{up}}(x)-p_{\\text{down}}(x)]\\leq\\varepsilon, ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Cleft%5B%5Cleft%7Cf%5E%7B%2A%7D%28x%29-p_%7B%5Ctext%7Bdown%7D%7D%28x%29%5Cright%7C%5Cright%5D+%5C%5C+%5Cleq%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bp_%7B%5Ctext%7Bup%7D%7D%28x%29-p_%7B%5Ctext%7Bdown%7D%7D%28x%29%5D%5Capprox%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BAssumption%7D%7D%7D%5Bp_%7B%5Ctext%7Bup%7D%7D%28x%29-p_%7B%5Ctext%7Bdown%7D%7D%28x%29%5D%5Cleq%5Cvarepsilon%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n    \n  \n\n\nwhere the first step uses the sandwiching property, the second step breaks  into monomials and then applies9  to each monomial . The last step above uses the -Closeness property.\n\n\n  \n    \n      Finally, the upper bound on ![{\\mathbb{E}{x\\sim D{\\text{Examples}}}\\left[\\left\n      f^{*}(x)-p_{\\text{down}}(x)\\right\n      \\right]}](https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Cleft%5B%5Cleft%7Cf%5E%7B%2A%7D%28x%29-p_%7B%5Ctext%7Bdown%7D%7D%28x%29%5Cright%7C%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) tells us that the Low-Degree Algorithm finds a polynomial  with\n    \n  \n\n\n\n  \n    \n      ![\\displaystyle \\frac{1}{2}\\mathbb{E}{x\\sim D{\\text{Examples}}}\\left[\\left\n      f_{\\text{noisy labels}}(x)-p^{*}(x)\\right\n      \\right]\\lesssim\\frac{1}{2}\\mathbb{E}{x\\sim D{\\text{Examples}}}\\left[\\left\n      f_{\\text{noisy labels}}(x)-p_{\\text{down}}(x)\\right\n      \\right] \\lesssim \\ \\underbrace{\\frac{1}{2}\\mathbb{E}{x\\sim D{\\text{Examples}}}\\left[\\left\n      f_{\\text{noisy labels}}(x)-f^{*}(x)\\right\n      \\right]}{=\\text{opt}{\\mathcal{C}}\\text{ because } f^{*} \\text{ is best classifier in }\\mathcal{C}+\\varepsilon}. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Cleft%5B%5Cleft%7Cf_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29-p%5E%7B%2A%7D%28x%29%5Cright%7C%5Cright%5D%5Clesssim%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Cleft%5B%5Cleft%7Cf_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29-p_%7B%5Ctext%7Bdown%7D%7D%28x%29%5Cright%7C%5Cright%5D+%5Clesssim+%5C%5C+%5Cunderbrace%7B%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Cleft%5B%5Cleft%7Cf_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29-f%5E%7B%2A%7D%28x%29%5Cright%7C%5Cright%5D%7D_%7B%3D%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%5Ctext%7B+because+%7D+f%5E%7B%2A%7D+%5Ctext%7B+is+best+classifier+in+%7D%5Cmathcal%7BC%7D%2B%5Cvarepsilon%7D.+&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002)\n    \n  \n\n\n3. Going Beyond Low-Degree Algorithm.\n\nTo recap: in Framework 2, the Low-Degree Algorithm works for many hypothesis classes , giving a classifier  with error ![{\\text{opt}{\\mathcal{C}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). In Framework 3, this algorithm can be used together with the Moment-Matching Tester to get computationally efficient algorithms. However, this approach has a number of limitations:\n\n\n  Run-time for the Low-Degree Algorithm tends to be exponential in . For example, to get error ![{\\text{\\ensuremath{\\text{opt}{\\text{Linear Classifiers}}}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7Bopt%7D%7B%5Ctext%7BLinear+Classifiers%7D%7D%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002), the Low-Degree Algorithms needs to run in time .\n  The algorithms are improper, which means the hypothesis  they give is not itself in the class . To be concrete, compare the two following two tasks:\n    \n      (a) We get a labeled data-set , and we want to fit approximately the best linear classifier to .\n      (b) We get a labeled data set , and we want to fit a classifier to  of the form  where  is some polynomial, this classifier should approximately be as good as the best linear classifier on  .\nThe Low-Degree Algorithm is solving task (b) not task (a). However, most people would agree that task (a) is far more natural.* The Moment-Matching Tester is guaranteed to accept when the distribution  equals to a specific distribution , but still might reject when  is very similar to . Formally, one can construct a distribution  that will be rejected by the degree- Moment-Matching Tester, even though .\n    \n  \n\n\nWe will now discuss subsequent work that focuses on removing these limitations.\n\n3.1 The Matter of Efficiency: Polynomial-Time Algorithms in Framework 3.\n\n3.1.1 Learning Beyond Low-Degree Algorithm.\n\nIn contrast with the Low-Degree Algorithm, some algorithms in Framework 2 are tailor-made for specific classes  and have run-times , at the price of looser error guarantees such as ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) or ![{\\widetilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). For example, consider the following algorithm:\n\n\n\nAveraging Algorithm [KKMS ’08]:\n\n\n  Given: access to independent standard Gaussian examples , labeled by unknown function .\n  Output: hypothesis .\n\n\n\n   { Gaussian examples  labeled by }.\n  .\n  Output  mapping  in  to \n\n\n\n\nWhen the distribution  is the standard Gaussian, this simple Framework 2 algorithm runs in time , and gives a classifier  with error ![{\\widetilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). Here ![{\\text{opt}{\\mathcal{C}}}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) is the best prediction error of an origin-centered linear classifier (i.e. a classifier of the form ) [KKMS ’08]. The analysis of the Averaging Algorithm is self-contained and only takes three pages [KKMS ’08], and a key idea is to denote the optimal classifier as  and decompose  into  and  as follows:\n\n\n\narguing10 as follows:\n\n\n  \n    \n      \n        \n          For a Gaussian dataset , the angle  will be at most  with high probability. This is argued by observing that the inner product  is likely to be large while the inner product with directions orthogonal to  will likely be much smaller. Likewise, the norm ![{\n          w_{\\text{signal}}\n          }](https://s0.wp.com/latex.php?latex=%7B%7Cw_%7B%5Ctext%7Bsignal%7D%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) can be shown to be close to ![{\\Theta(\n          S\n          )}](https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%7CS%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) with high probability.\n        \n      \n    \n  \n  \n    \n      \n        \n          Since the classifier  has the optimal error ![{\\text{opt}{\\mathcal{C}}}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002), only ![{O(\\text{opt}{\\mathcal{C}})}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) fraction of points in  will contribute to  (with high probability over ). Yet, it can be shown that small subsets of a Gaussian data-set have small averages. Formally, with high probability, if  comes from the standard Gaussian and has size , every subset  of size ![{\\alpha\n          S\n          }](https://s0.wp.com/latex.php?latex=%7B%5Calpha%7CS%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) satisfies\n        \n      \n    \n\n    \n      \n        \n          ![\\displaystyle \\left\n          \\sum_{x_{i}\\in S’}\\left[x_{i}\\right]\\right\n          \\leq\\left(\\tilde{O}\\left(\\alpha\\right)+\\varepsilon\\right)\n          S\n          . ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%7C%5Csum_%7Bx_%7Bi%7D%5Cin+S%27%7D%5Cleft%5Bx_%7Bi%7D%5Cright%5D%5Cright%7C%5Cleq%5Cleft%28%5Ctilde%7BO%7D%5Cleft%28%5Calpha%5Cright%29%2B%5Cvarepsilon%5Cright%29%7CS%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n        \n      \n    \n\n    \n      \n        \n          This lets us upper-bound the norm ![{\n          w_{\\text{noise}}\n          }](https://s0.wp.com/latex.php?latex=%7B%7Cw_%7B%5Ctext%7Bnoise%7D%7D%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) with ![{\\left(\\tilde{O}(\\text{opt}_{\\mathcal{C}})+\\varepsilon\\right)\\cdot\n          S\n          }](https://s0.wp.com/latex.php?latex=%7B%5Cleft%28%5Ctilde%7BO%7D%28%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%5Cright%29%5Ccdot%7CS%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002).\n        \n      \n    \n  \n  \n    Steps (a) and (b) together can be used to conclude that\n\n    ![\\displaystyle \\angle(w,w^{})=\\angle(w_{\\text{signal}}+w_{\\text{noise}},w^{})\\leq\\tilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cangle%28w%2Cw%5E%7B%2A%7D%29%3D%5Cangle%28w%7B%5Ctext%7Bsignal%7D%7D%2Bw_%7B%5Ctext%7Bnoise%7D%7D%2Cw%5E%7B%2A%7D%29%5Cleq%5Ctilde%7BO%7D%28%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\n    We now use the bound on the angle  to bound how much less accurate the classifier  can be compared to . Indeed, for a Gaussian sample , the probability that  is , which allows us to conclude that\n\n    ![\\displaystyle \\Pr_{x\\sim D_{\\text{Examples}}}[\\text{sign}(w{\\cdot x})\\neq f_{\\text{noisy labels}}(x)]\\leq\\ \\underbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[\\text{sign}(w^{}{\\cdot x})\\neq\\text{sign}(w{\\cdot x})]}_{=\\Theta(\\angle(w,w^{}))\\leq\\tilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon}+\\underbrace{\\Pr{x\\sim D_{\\text{Examples}}}[\\text{sign}(w^{*}{\\cdot x})\\neq f_{\\text{noisy labels}}(x)]}{=\\text{opt}{\\mathcal{C}}}=\\tilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon. ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5B%5Ctext%7Bsign%7D%28w%7B%5Ccdot+x%7D%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%5Cleq%5C%5C+%5Cunderbrace%7B%5CPr_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5B%5Ctext%7Bsign%7D%28w%5E%7B%2A%7D%7B%5Ccdot+x%7D%29%5Cneq%5Ctext%7Bsign%7D%28w%7B%5Ccdot+x%7D%29%5D%7D_%7B%3D%5CTheta%28%5Cangle%28w%2Cw%5E%7B%2A%7D%29%29%5Cleq%5Ctilde%7BO%7D%28%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D%2B%5Cunderbrace%7B%5CPr_%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5B%5Ctext%7Bsign%7D%28w%5E%7B%2A%7D%7B%5Ccdot+x%7D%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D_%7B%3D%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%3D%5Ctilde%7BO%7D%28%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon.+&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002)\n  \n\n\nA series of subsequent works developed new algorithms, improving the prediction error to ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) [ABL ’14, DKTZ ’20, DKTZ ’22]. Also, unlike the Low-Degree Algorithm, these algorithms are proper, i.e. the hypothesis  they produce is itself a linear classifier, rather than a complicated function of the form .\n\nHowever, all these algorithms inherently operate in Framework 2 rather than Framework 3, relying on the Gaussianity assumption not only for their run-time but also for their accuracy guarantee. For example, we can see that all three aforementioned steps — (a), (b) and (c) — in the accuracy analysis of the Averaging Algorithm use Gaussianity in crucial ways.\n\n3.1.2 Modified Moment-Matching Tester.\n\nCan we again use the recipe from Section 2.2 and the Moment-Matching Tester to get a -time algorithm in Framework 3 based on the Averaging Algorithm? Conceptually, the Moment-Matching Tester checks that the distribution  is indistinguishable from  by low-degree monomials. It is therefore unsurprising that this tester works well with the Low-Degree Algorithm, as this algorithm is based on finding the best-fitting polynomial. By the same token, one would not expect the Moment-Matching Tester to work well with tailor-made algorithms such as the Averaging Algorithm, as these algorithms do not use polynomials in any way.\n\nSurprisingly, a modified version of the Moment-Matching Tester can nevertheless be used in this way. First, we run one of these algorithms and obtain a hypothesis . As in Section 2.2, we need to decide whether to output the classifier  or to run a slow Framework 1 Algorithm. This is again done by running a tester , but here the tester also uses the vector  obtained prior to running the tester:\n\n\n\nStrip Tester [DKKLZ ’23, GKSV ’23, GKSV ’24]:\n\n\n  Given: access to independent examples from , a reference distribution , unit vector  in .\n  Output: Accept or Reject.\n\n\n\n   { independent examples from }.\n  For all monomials  of total degree at most  and integers :\n    \n      \n        Define\n\n        ![\\displaystyle \\mathbf{1}{w\\cdot x\\in[i\\varepsilon,(i+1)\\varepsilon]}=\\begin{cases} 1 &amp; \\text{if }w\\cdot x\\in[i\\varepsilon,(i+1)\\varepsilon]\\ 0 &amp; \\text{otherwise.} \\end{cases} ](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathbf%7B1%7D%7Bw%5Ccdot+x%5Cin%5Bi%5Cvarepsilon%2C%28i%2B1%29%5Cvarepsilon%5D%7D%3D%5Cbegin%7Bcases%7D+1+%26+%5Ctext%7Bif+%7Dw%5Ccdot+x%5Cin%5Bi%5Cvarepsilon%2C%28i%2B1%29%5Cvarepsilon%5D%5C%5C+0+%26+%5Ctext%7Botherwise.%7D+%5Cend%7Bcases%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n      \n      \n        If ![{\\lvert\\mathbb{E}{x\\sim S}[m(x)\\mathbf{1}{w\\cdot x\\in[i\\varepsilon,(i+1)\\varepsilon]}]-\\mathbb{E}{x\\sim D{\\text{Assumption}}}[m(x)\\mathbf{1}{w\\cdot x\\in[i\\varepsilon,(i+1)\\varepsilon]}]\\rvert&gt;\\left(\\varepsilon/d\\right)^{O(1)}}](https://s0.wp.com/latex.php?latex=%7B%5Clvert%5Cmathbb%7BE%7D%7Bx%5Csim+S%7D%5Bm%28x%29%5Cmathbf%7B1%7D_%7Bw%5Ccdot+x%5Cin%5Bi%5Cvarepsilon%2C%28i%2B1%29%5Cvarepsilon%5D%7D%5D-%5Cmathbb%7BE%7D_%7Bx%5Csim+D_%7B%5Ctext%7BAssumption%7D%7D%7D%5Bm%28x%29%5Cmathbf%7B1%7D_%7Bw%5Ccdot+x%5Cin%5Bi%5Cvarepsilon%2C%28i%2B1%29%5Cvarepsilon%5D%7D%5D%5Crvert%3E%5Cleft%28%5Cvarepsilon%2Fd%5Cright%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002), output Reject and terminate.\n      \n    \n  \n  If this step is reached, output Accept.\n\n\n\n\nEssentially, the algorithm above breaks the -dimensional space into strips along the vector  and runs the degree- moment tester for each of the strips.\n\nCombining this Strip Tester with the Framework 2 algorithm of [DKTZ ’20], yields an algorithm in Framework 3 with prediction error ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and run-time  [DKKLZ ’23, GKSV ’23, GKSV ’24], where  is the class of origin-centered linear classifiers.\n\nMoreover, like the Averaging Algorithm, this algorithm is proper, i.e. the hypothesis  is itself a linear classifier. This addresses the second limitation of the Low Degree Algorithm we pointed out earlier.\n\n3.2 Assumption-Tolerance and the Spectral Tester.\n\nFinally, we briefly discuss some recent work on addressing the third limitation of the Moment-Matching Tester described in the beginning of Section 3. To recap, the limitation is that the Moment-Matching Tester might reject distributions that are very close to the distribution  but not exactly equal to it. To address this, the paper considers the following11 more stringent version of Framework 3:\n\n\n\nFramework 4 [Tolerant Testable Framework] For any  and  the learning algorithm should with high probability output a classifier  with\n\n![\\displaystyle \\overbrace{\\Pr_{x\\sim D_{\\text{Examples}}}[h(x)\\neq f_{\\text{noisy labels}}(x)]}^{\\text{Prediction error of \\ensuremath{h}.}}\\leq\\underbrace{\\overbrace{\\text{opt}{\\mathcal{C}}}^{\\text{Optimal prediction error in \\ensuremath{\\mathcal{C}.}}}+\\varepsilon}{\\text{\\ensuremath{\\text{Weaker guarantees such as O(\\ensuremath{\\text{opt}{\\mathcal{C}}})+\\ensuremath{\\varepsilon\\ }also considered.}}}}. \\ \\ \\ \\ \\ (2)](https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Coverbrace%7B%5CPr%7Bx%5Csim+D_%7B%5Ctext%7BExamples%7D%7D%7D%5Bh%28x%29%5Cneq+f_%7B%5Ctext%7Bnoisy+labels%7D%7D%28x%29%5D%7D%5E%7B%5Ctext%7BPrediction+error+of+%5Censuremath%7Bh%7D.%7D%7D%5Cleq%5Cunderbrace%7B%5Coverbrace%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%5E%7B%5Ctext%7BOptimal+prediction+error+in+%5Censuremath%7B%5Cmathcal%7BC%7D.%7D%7D%7D%2B%5Cvarepsilon%7D_%7B%5Ctext%7B%5Censuremath%7B%5Ctext%7BWeaker+guarantees+such+as+O%28%5Censuremath%7B%5Ctext%7Bopt%7D_%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Censuremath%7B%5Cvarepsilon%5C+%7Dalso+considered.%7D%7D%7D%7D.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)\n\nFurthermore, for some absolute constant , if , then with high probability the learning algorithm should run in time .\n\n\n\nIn [GSSV ’24], a general methodology is developed for designing algorithms in this more general framework. For example, when  is the Gaussian distribution and  is the class of linear classifiers, a run-time of  is achieved, matching the best algorithms in Frameworks 2 and 3.\n\nIn brief, one of the key insights is that the degree- Moment-Matching tester can often be replaced by what is called the degree- Spectral Tester. Given a data-set , this tester checks that\n\n\n\nThe second insight is that the degree- Spectral Tester can be implemented in time  using an eigenvalue computation. The final insight12 is that when  one can remove  fraction of elements from  and have it pass the Spectral Tester. [GSSV ’24] designs an algorithm that efficiently finds which  fraction of elements needs to be removed from  to achieve this.\n\n4. Other recent work.\n\nThis blog post focused on side-stepping the intractability of Framework 1 via making assumptions on the distribution  and not making any assumptions on the labeling function . Yet, improved algorithms are possible when the labeling function  is also assumed to be well-behaved. For example, the Random Classification Noise assumption essentially presupposes that  is formed by taking a hypothesis  in the class  and flipping each function value with some probability . The work of [GKSV ’25] gives algorithms for which (like in Framework 3) the failure of the Random Classification Noise assumptions can affect only the run-time rather than the accuracy guarantee. [GKSV ’25] also designs such algorithms for the Massart Noise assumption that is far more general than the Random Classification Noise assumption.\n\nThe work of [STW ’24] shows how to use the Low-Degree Algorithm and the Moment-Matching Tester to get algorithms in Framework 3 for the challenging hypothesis class of polynomial threshold functions.\n\nThe work of [GKSV ’23] extends Framework 3 to families of distributions. Rather than being required to run in time  only when  for a specific distribution , the algorithms are required to run in time  when  belongs to an entire family of distributions ![{\\mathcal{D}{\\text{Assumption}}}](https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D%7B%5Ctext%7BAssumption%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002). Designing such algorithms turns out to be intimately connected with the field of Sum-of-Squares relaxations [KS17].\n\n[KKV24, GSSV’24, CKKSV’24, KSV’24] build on the approaches described here to test distribution shift, i.e. to test that the unlabeled data found during deployment of a classifier  comes from the same distribution as the training data. Similar to the test in Section 2.2, the test is required to either guarantee that  has a good prediction accuracy on this new dataset, or to detect that the new dataset came from a data distribution that differs from the distribution used during training.\n\n5. Open Problems.\n\nThere are unsolved problems for all three frameworks we discussed today. Even in Framework 1, where there are still large gaps in our understanding of some basic problems:\n\n\n\nOpen problem 1: Is there an algorithm in Framework 1 with accuracy ![{\\text{opt}{\\mathcal{C}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and run-time bound , when  is the class of linear classifiers? What about algorithms with run-times  or  when  is fixed to be a small constant (say )?\n\n\n\nTo the best of our understanding, assuming the Exponential Time Hypothesis, the NP-hardness results of [GR’06, FGKP’06] imply that no -time algorithm exists for this problem for a proper learning algorithm, i.e. an algorithm that itself outputs a linear classifier. However, when general improper algorithms are considered (i.e. algorithms with no restrictions on what classifier they can produce), no such hardness result is known.\n\nThe following is an open question in Framework 2:\n\n\n\nOpen problem 2: Is there an algorithm in Framework 2 with accuracy ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and run-time bound , when  is the class of linear classifiers and  is the uniform distribution over ? What about algorithms with weaker accuracy bounds such as ![{\\widetilde{O}(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BO%7D%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and ![{O(\\sqrt{\\text{opt}{\\mathcal{C}}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002)?\n\n\n\nFor a long time, we have had algorithms with run-time  and accuracy ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) when  is the standard Gaussian distribution [ABL ’14, DKTZ ’20, DKTZ ’22]. Ultimately, one would hope to achieve this for all product distributions over  and not only the Gaussian distribution, but even for the uniform distribution over  such algorithms are yet to be developed.\n\nFinally, the following is an open question in Framework 3:\n\n\n\nOpen problem 3: Is there an algorithm in Framework 3 with accuracy ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and run-time bound , when  is the class of general linear classifiers and  is the standard Gaussian distribution?\n\n\n\nNote that [DKLZ’24] gives an algorithm with a run-time bound  and accuracy ![{O(\\sqrt{\\text{opt}{\\mathcal{C}}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002), [RV ’23, GKK ’23] give algorithms with accuracy ![{\\text{opt}{\\mathcal{C}}+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7B%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) and run-time . As mentioned earlier, [DKKLZ ’23, GKSV ’23, GKSV ’24] give algorithms with accuracy ![{O(\\text{opt}{\\mathcal{C}})+\\varepsilon}](https://s0.wp.com/latex.php?latex=%7BO%28%5Ctext%7Bopt%7D%7B%5Cmathcal%7BC%7D%7D%29%2B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002) but only when  is the class of origin-centered linear classifiers.\n\nAcknowledgements\n\nWe are grateful to Gautam Kamath, Adam Klivans, and Ronitt Rubinfeld for their valuable feedback on a draft of this blog post.\n\nFootnotes\n\n\n  A proof sketch: Draw $latex {N^{2}}&amp;fg=000000$ samples $latex {S}&amp;fg=000000$ from the Gaussian distribution and let $latex {D_{\\text{sub-sample}}}&amp;fg=000000$ be uniform over $latex {S}&amp;fg=000000$. The distribution $latex {D_{\\text{sub-sample}}}&amp;fg=000000$ is $latex {\\Omega(1)}&amp;fg=000000$-far from Gaussian in total variation distance, but it can be shown that $latex {\\Omega(N)}&amp;fg=000000$ samples are necessary to distinguish such $latex {D_{\\text{sub-sample}}}&amp;fg=000000$ from the Gaussian distribution. We can take $latex {N}&amp;fg=000000$ to be arbitrarily large, so no finite-sample tester exists. ︎\n  One can also consider labels $latex {\\left{ y_{i}\\right} }&amp;fg=000000$ that are themselves random variables rather than a deterministic function of example $latex {x}&amp;fg=000000$. Everything is this blog post will apply to that setting as well. ︎\n  Throughout blog post, we will assume a success probability of (say) $latex {0.99}&amp;fg=000000$. This probability can be improved to $latex {1-\\delta}&amp;fg=000000$ by repeating the process $latex {\\log1/\\delta}&amp;fg=000000$ times and selecting the classifier that does best on a fresh set of samples. ︎\n  Note: even for this easier task, no algorithm is known in Framework 2 with run-time better than $latex {2^{O(d)}}&amp;fg=000000$. ︎\n  Henceforth, for simplicity, when we say “a Framework 3 algorithm $latex {\\mathcal{A}}&amp;fg=000000$ runs in time $latex {T}&amp;fg=000000$” we really mean “$latex {\\mathcal{A}}&amp;fg=000000$ runs in time $latex {T}&amp;fg=000000$ when $latex {D_{\\text{Examples}}=D_{\\text{Assumption}}}&amp;fg=000000$” as Framework 3 does not require a run-time bound when $latex {D_{\\text{Examples}}\\neq D_{\\text{Assumption}}}&amp;fg=000000$. ︎\n  If the algorithm runs longer than $latex {T}&amp;fg=000000$ or fails to output a classifier, stop and go to last step. ︎\n  The tester below generalizes the tester of [AGM ’03, AAKMRX ’07, OZ ’18] for testing $latex {k}&amp;fg=000000$-wise independence. ︎\n  Inspecting the general recipe described in this section, we see that, strictly speaking, to execute this recipe one needs not only a tester $latex {\\mathcal{T}}&amp;fg=000000$ but also an algorithm $latex {\\mathcal{A}’}&amp;fg=000000$ for class $latex {\\mathcal{C}}&amp;fg=000000$ in Framework 1 (which is allowed to be very slow). Existence of such $latex {\\mathcal{A}’}&amp;fg=000000$ is a very mild condition and holds for all concept classes $latex {\\mathcal{C}}&amp;fg=000000$ for which this problem has been considered. ︎\n  To do this, one needs to show that none of the coefficients of $latex {p_{\\text{up}}(x)-p_{\\text{down}}(x)}&amp;fg=000000$ is too large, which turns out to be true. ︎\n  For the rest of this subsection we will refer to Standard Gaussian distribution as simply Gaussian and origin-centered linear classifiers as simply linear classifiers. ︎\n  The definition is inspired by the setting of tolerant property testing [PRR06]. ︎\n  This last insight is closely related to the method used in [DKS18] to solve a different problem. ︎\n\n\nBy avasilyan\n\nRead original post\n"
    },
    
    {
      "title": "Windows on Theory: AI Safety Course Intro Blog",
      "url": "/cstheoryrss/2025/07/21/windows-on-theory-ai-safety-course-intro-blog/",
      "content": "I am teaching CS 2881: AI Safety this fall at Harvard. This blog is primarily aimed at students at Harvard or MIT (where we have a cross-registering agreement) who are considering taking the course. However, it may be of interest to others as well. For more of my thoughts on AI safety, see the blogs Six Thoughts on AI safety and Machines of Faithful Obedience.\n\nIMPORTANT: At the end of this blog is Homework Zero. If you are a Harvard or MIT student that is interested in taking the course, then you will need to submit this homework to apply for a seat. See details below.\n\nWhy AI Safety?\n\nIf you are considering taking this course, you are probably aware that there is a significant chance that AI will cause profound changes to our world over the next years and decades. However, there is significant disagreement about the magnitude of these changes, as well as whether they will be positive or negative.\n\nHere is an illustrative plot of various potential scenarios for the next decade that people had predicted. (The GDP and life expectancy numbers are just illustrative- these were not explicitly predicted by the cited people, but are o3’s interpretations of the scenarios, see appendix below.)\n\n\n\nAs the saying goes, predictions are hard, especially about the future. Even the most AI-hawkish predictors sometimes underestimate its advances. For example, Paul Christiano has predicted a less than 8% chance of AI achieving IMO gold performance by 2025. (You can decide what this means for interpreting his predictions of a 15% chance for a Dyson Sphere by 2030 and 40% by 2040.)\n\nAnything between utopia and catastrophe has been predicted. Clearly, we would like the impact of AI in 2035 to be up and to the right in this plot. This course will focus on what we know about the technical aspects of how we can get there,  and particularly on avoiding the bottom left quadrant.\n\nWe will have a particular focus on two aspects: measurement and scale.\n\nThere is a famous saying, “You can’t improve what you don’t measure.” In AI, we often encounter the converse as well; time and again, we have found that once we can measure an objective, we can also improve upon it. Alignment and safety often make the measurement task more complex: the phenomena we deal with could involve worst-case behavior, complex interactions of multiple components (both human and AI), behaviors such as “cheating” that are not always easy to define. Hence, measurements and evaluations will play a significant part in this course.\n\nThe other component is scale. The fundamental property of current AI systems is that they are not static – they constantly grow in the resources they use (data, compute), their capabilities, and their scope of implementation and influence. For every type of safety concern, we need to ask ourselves, is this a problem that would get better or worse with scale. Similarly, for every safety intervention we need to ask whether this is a method that would work better or worse with scale.\n\nTopics\n\nA list of questions that we may* consider in this course includes:\n\n\n  What are the potential risks and benefits of AI?\n  What potential capabilities of AI could lead to catastrophic risks? For which ones do we think that AI can also be used to help defend against the risk?\n  What lessons can we learn from other fields, including aviation and transportation safety, computer security, and others.\n  Is there a tension between capabilities and safety? Which current safety methods become better as capabilities improve, and which ones become worse?\n  How can we obtain “leading indicators” to measure potential for catastrophic risk before it happens?\n  What aspects of AI training process can lead to increased risk? This includes phenomena such as reward hacking, scheming, alignment faking, etc..\n  When AI behaves in “bad” ways, can we always trace it back to either their dataset or the objectives they trained on?\n  How do we even define precisely notions such as “scheming”, “sandbagging”, “reward hacking”, “unfaithfulness”?\n  What is the goal for alignment – AI following instructions by humans? AI having good values? Something else?\n  What are the ways to evaluate AIs for safety?\n  Can we make AI models robust to adversaries who can modify their inputs? Are there fundamental limitations to this? Does making models adversarially robust requires making them less capable on non-adversarial inputs?\n  What are the unique safety aspects that arise when AI is being used to build future versions of itself?\n  What are ways to understand the reasoning of why models provide certain outputs – white box, black box, and intermediate (e.g., access to privileged outputs such as “chain of thought”) methods? Are there ways that only white-box methods can achieve and not black-box ones?\n  What is the role of “model organisms” – specific examples designed to exhibit specific behavior.\n  How will AI impact individual freedoms?  mass surveillance, etc..\n  How will AI impact warfare?  international stability.\n  How can we do “unlearning” for either safety or privacy.\n  As AI tools become more capable, how does this translate into an increase in need for model weight security?\n  What are prompt injection attacks and how can we defend against them.\n\n\n* We will likely not get to many of those, and we will see what we cover as we go along.\n\nHomework Zero\n\nIn order to maintain the ability for effective discussion, as well as due to compute limitations, we will cap the number of students in the course. If you are a Harvard or MIT student and are interested in the course, you will need to submit the following “homework zero” to apply to join. Submitting homework zero does not guarantee you a place in the course, but hopefully, you will find doing it interesting and rewarding regardless.  You will be reimbursed up to $40 for compute expenses in doing this project.\n\nThe homework will be to replicate a variant of the “emergent misalignment” paper by Betley et al., specifically following the work of Turner et al.\n\nIf you are a Harvard or MIT student that. have filled out the course interest form then you will get an invite to the repository with code and instructions for submissions.. Please sign up to it with the same email you use for registering to courses (your Harvard key email address). The homework will be due on 11:59pm eastern Monday August 4 2025.\n\n\n\nAppendix: o3’s summary of predictions\n\nFollowing is o3’s summary of AI forecasters predictions. (I’ve used multiple prompts/conversations to get it in the right format, which makes it less convenient to share the conversation. Hence I just copy pasted here the bottom line and some links that o3 came up with)\n\n• AI Stagnation (“New AI Winter / Plateau”)\n\n\n  Predictors &amp; docs – Centre for Future Generations Plateau scenario; FT “bear‑case for AI” analysis.Centre for Future Generations Financial Times\n  GDP (% y/y) 2  2  2  2  1.8  1.8  1.7  1.7  1.6  1.6 → +19.8 % cum “AI capabilities hit a hard ceiling … throwing more resources at them yields sharply diminishing returns.” Centre for Future Generations\n  Life‑expectancy (yr) +0.10 each year → +1.0 yr\n  Employment (% of global jobs) little net change; automation plateaus (&lt;0.3 % loss p.a.).\n  Deaths by violence (2036‑‑45) ≈ 3 M, unchanged from 2010s average (no major AI wars).\n  Other QoL Incremental health/ed tech; freedoms unchanged.\n\n\n\n\n• AI Utopia (“Machines of Loving Grace”)\n\n\n  Predictors &amp; docs – Dario Amodei essay; Goldman Sachs research (+1.5 pp prod. boost); Ray Kurzweil longevity claims.darioamodei.com Goldman Sachs Fortune\n  GDP (% y/y) 4.5 ×10 → +55 % cum (baseline 34 % +21 pp)\n“Generative AI could lift productivity growth by 1.5 percentage‑points over a decade.” Goldman Sachs\n  Life‑expectancy (yr) +0.80 each yr → +8 yr Kurzweil: “by the end of the 2030s we will largely overcome diseases and the aging process.” Fortune\n  Employment creative expansion; net +0.5 % jobs p.a. (WEF “Jobs of Tomorrow” on trainer/explainer roles).World Economic Forum\n  Violent deaths &lt; 1 M / decade (AI‑enabled early‑warning &amp; mediation).\n  Other QoL Universal AI tutors &amp; doctors, near‑zero cost goods, high civil liberties.\n\n\n\n\n• AI Catastrophe (“Unaligned Power‑Seeker”)\n\n\n  Predictors &amp; docs – Geoffrey Hinton extinction warnings; Carlsmith existential‑risk report.The Guardian arXiv\n  GDP +3 % first 3 yrs then ‑20 %, ‑10 %, ‑2 % … ⇒ ‑30 % cum (global collapse).\n  Life‑expectancy ‑3 yr p.a. from year‑4 ⇒ ‑30 yr.\n  Employment Irrelevant after takeover; human economic agency ≈ 0.\n  Deaths Up to 7 Bn (existential level).\nHinton: “10–20 % chance AI could wipe out humanity within 30 years.” The Guardian\n  Other QoL Human rights &amp; freedom → zero.\n\n\n\n\n• Technofeudal Oligarchy\n\n\n  Predictors &amp; docs – Scott Alexander et al. “AI 2027” technofeudal path; Stiefenhofer 2025 paper on AGI &amp; inequality.Astral Codex Ten arXiv\n  GDP 6 % p.a. → +79 % cum\n  Life‑expectancy +0.50 yr p.a. → +5 yr (but unequal access).\n  Employment ‑3 % p.a. (‑26 % cum); wealth captured by &lt;0.1 % elite.\n  Deaths &lt; 2 M (stable order, high surveillance).\n  Other QoL Top‑tier healthcare and education for elites; mass population under tight algorithmic control, low civil liberties.\n\n\n\n\n• AI Arms Race &amp; Hot Conflict\n\n\n  Predictors &amp; docs – CFG Arms race narrative; European‑Parliament brief on “AI war lab” in Ukraine; New Yorker war‑games piece.Centre for Future Generations European Parliament The New Yorker\n  GDP (% y/y) 3  3  3  0  ‑2  ‑2  1  1  2  2 → +11 % cum\n  Life‑expectancy flat then ‑0.2 yr in war yrs ⇒ ‑1 yr.\n  Employment initial militarised boom (+1 %) then ‑4 % per war year; net ‑6 % decade.\n  Deaths Major‑power war: 30–50 M combat &amp; civilian casualties (RAND/ICRC autonomy escalation warnings).RAND Corporation\n  Other QoL Civil liberties curtailed; R&amp;D diverted from health/education to defence.\n\n\n\n\n• Global Co‑operation on Safe AI\n\n\n  Predictors &amp; docs – CFG Diplomacy scenario; OECD foresight note; 2024 Council‑of‑Europe AI Treaty.Centre for Future Generations OECD Illinois Law Review\n  GDP 4 % p.a. → +48 %\n  Life‑expectancy +0.60 yr p.a. → +6 yr (shared breakthroughs).\n  Employment managed transition; net ‑0.5 % first half, +0.5 % later ⇒ flat overall.\n  Deaths &lt; 1.5 M (arms‑control lowers risks).\n  Other QoL Robust human‑rights guard‑rails, broad access to AI medicine &amp; education.\n\n\n\n\n• Mass Automation Shock\n\n\n  Predictors &amp; docs – McKinsey 400‑800 M displacement; WEF April 2025 entry‑level job concerns.McKinsey &amp; Company World Economic Forum\n  GDP 4 % p.a. → +48 % (higher prod.)\n  Life‑expectancy +0.30 yr p.a. → +3 yr (cheap AI health, but stress/inequality).\n  Employment ‑2.3 % p.a. ⇒ ‑21 % decade (roughly 600 M net jobs lost).\n  Deaths 2–4 M from unrest &amp; indirect effects.\n  Other QoL Sharp inequality spike; possible UBI debates; mental‑health strains.\n\n\n\n\n• Digital Authoritarianism\n\n\n  Predictors &amp; docs – Lawfare “Authoritarian risks of AI surveillance”; Bulletin piece on erosion of democracy; Euro‑Parl study on AI repression.Lawfare Bulletin of the Atomic Scientists European Parliament\n  GDP 4 % p.a. → +48 % (tech‑driven growth)\n  Life‑expectancy +0.35 yr p.a. → +3.5 yr\n  Employment ‑0.5 % p.a. (state‑run economy, limited labour voice).\n  Deaths State violence + AI policing ≈ 5 M over decade.\n  Other QoL Pervasive facial‑recog &amp; social‑credit; freedoms very low despite material gains.\n\n\n\n\n• AI Chaos &amp; Decentralised Disruption\n\n\n  Predictors &amp; docs – IBM on open‑source risks; DHS report on adversarial Gen‑AI; ENISA 2030 cyber threat foresight; Tom’s‑Hardware malware demo.IBM U.S. Department of Homeland Security ENISA Tom’s Hardware\n  GDP 3  3  2.5  2  1.5  1  1  1.5  2  2 → +22 %\n  Life‑expectancy +0.25 yr p.a. minus 0.5 yr lost to crises ⇒ +(-0.8) yr net\n  Employment volatile; cyber‑crime &amp; trust collapses cost 10 % of jobs by 2035.\n  Deaths 10–15 M from scattered AI‑aided terror, bio‑incidents &amp; infrastructure failures.\n  Other QoL Fragmented internet, high misinformation; governments swing between over‑regulation and impotence.\n\n\nBy Boaz Barak\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Weighted Matching in a Poly-Streaming Model",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-weighted-matching-in-a-poly-streaming-model/",
      "content": "Authors: Ahammed Ullah, S. M. Ferdous, Alex Pothen\n\nWe introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\nWe design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon &gt; 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon &gt; 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\nWe evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Treedepth Inapproximability and Exponential ETH Lower Bound",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-treedepth-inapproximability-and-exponential-eth-lower-bound/",
      "content": "Authors: Édouard Bonnet, Daniel Neuen, Marek Sokołowski\n\nTreedepth is a central parameter to algorithmic graph theory. The current\nstate-of-the-art in computing and approximating treedepth consists of a\n$2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\\text{OPT}\n\\log^{3/2} \\text{OPT})$-approximation algorithm, where the former algorithm\nreturns an elimination forest of height $k$ (witnessing that treedepth is at\nmost $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has\ntreedepth larger than $k$, and $\\text{OPT}$ is the actual value of the\ntreedepth. On the complexity side, exactly computing treedepth is NP-complete,\nbut the known reductions do not rule out a polynomial-time approximation scheme\n(PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running\ntime of $2^{o(\\sqrt n)}$ for exact algorithms.\nWe show that 1.0003-approximating treedepth is NP-hard, and that exactly\ncomputing the treedepth of an $n$-vertex graph requires time $2^{\\Omega(n)}$,\nunless the ETH fails. We further derive that there exist absolute constants\n$\\delta, c &gt; 0$ such that any $(1+\\delta)$-approximation algorithm requires\ntime $2^{\\Omega(n / \\log^c n)}$. We do so via a simple direct reduction from\nSatisfiability to Treedepth, inspired by a reduction recently designed for\nTreewidth [STOC ‘25].\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Tight Bounds for Answering Adaptively Chosen Concentrated Queries",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-tight-bounds-for-answering-adaptively-chosen-concentrated-queries/",
      "content": "Authors: Emma Rapoport, Edith Cohen, Uri Stemmer\n\nMost work on adaptive data analysis assumes that samples in the dataset are\nindependent. When correlations are allowed, even the non-adaptive setting can\nbecome intractable, unless some structural constraints are imposed. To address\nthis, Bassily and Freund [2016] introduced the elegant framework of\nconcentrated queries, which requires the analyst to restrict itself to queries\nthat are concentrated around their expected value. While this assumption makes\nthe problem trivial in the non-adaptive setting, in the adaptive setting it\nremains quite challenging. In fact, all known algorithms in this framework\nsupport significantly fewer queries than in the independent case: At most\n$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the\nindependent setting.\nIn this work, we prove that this utility gap is inherent under the current\nformulation of the concentrated queries framework, assuming some natural\nconditions on the algorithm. Additionally, we present a simplified version of\nthe best-known algorithms that match our impossibility result.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Strassen 2times2 Matrix Multiplication from a 3-dimensional Volume",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-strassen-2times2-matrix-multiplication-from-a-3-dimensional-volume/",
      "content": "Authors: Benoit Jacob\n\nThe Strassen $2\\times2$ matrix multiplication algorithm arises from the\nvolume form on the 3-dimensional quotient space of the $2\\times 2$ matrices by\nthe multiples of identity.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-sparse-navigable-graphs-for-nearest-neighbor-search-algorithms-and/",
      "content": "Authors: Sanjeev Khanna, Ashwin Padaki, Erik Waingarten\n\nWe initiate the study of approximation algorithms and computational barriers\nfor constructing sparse $\\alpha$-navigable graphs [IX23, DGM+24], a core\nprimitive underlying recent advances in graph-based nearest neighbor search.\nGiven an $n$-point dataset $P$ with an associated metric $\\mathsf{d}$ and a\nparameter $\\alpha \\geq 1$, the goal is to efficiently build the sparsest graph\n$G=(P, E)$ that is $\\alpha$-navigable: for every distinct $s, t \\in P$, there\nexists an edge $(s, u) \\in E$ with $\\mathsf{d}(u, t) &lt; \\mathsf{d}(s,\nt)/\\alpha$. We consider two natural sparsity objectives: minimizing the maximum\nout-degree and minimizing the total size.\nWe first show a strong negative result: the slow-preprocessing version of\nDiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose\nsparsity is $\\widetilde{\\Omega}(n)$ times larger than optimal, even on\nEuclidean instances. We then show a tight approximation-preserving equivalence\nbetween the Sparsest Navigable Graph problem and the classic Set Cover problem,\nobtaining an $O(n^3)$-time $(\\ln n + 1)$-approximation algorithm, as well as\nestablishing NP-hardness of achieving an $o(\\ln n)$-approximation. Building on\nthis equivalence, we develop faster $O(\\ln n)$-approximation algorithms. The\nfirst runs in $\\widetilde{O}(n \\cdot \\mathrm{OPT})$ time and is thus much\nfaster when the optimal solution is sparse. The second, based on fast matrix\nmultiplication, is a bicriteria algorithm that computes an $O(\\ln\nn)$-approximation to the sparsest $2\\alpha$-navigable graph, running in\n$\\widetilde{O}(n^{\\omega})$ time.\nFinally, we complement our upper bounds with a query complexity lower bound,\nshowing that any $o(n)$-approximation requires examining $\\Omega(n^2)$\ndistances. This result shows that in the regime where $\\mathrm{OPT} =\n\\widetilde{O}(n)$, our $\\widetilde{O}(n \\cdot \\mathrm{OPT})$-time algorithm is\nessentially best possible.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum Pattern Matching with Wildcards",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-quantum-pattern-matching-with-wildcards/",
      "content": "Authors: Masoud Seddighin, Saeed Seddighin\n\nPattern matching is one of the fundamental problems in Computer Science. Both\nthe classic version of the problem as well as the more sophisticated version\nwhere wildcards can also appear in the input can be solved in almost linear\ntime $\\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,\nrespectively. In 2000, Ramesh and Vinay~\\cite{ramesh2003string} give a quantum\nalgorithm that solves classic pattern matching in sublinear time and asked\nwhether the wildcard problem can also be solved in sublinear time? In this\nwork, we give a quantum algorithm for pattern matching with wildcards that runs\nin time $\\tilde O(\\sqrt{n}\\sqrt{k})$ when the number of wildcards is bounded by\n$k$ for $k \\geq \\sqrt{n}$. This leads to an algorithm that runs in sublinear\ntime as long as the number of wildcards is sublinear.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Optimal antimatroid sorting",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-optimal-antimatroid-sorting/",
      "content": "Authors: Benjamin Aram Berendsohn\n\nThe classical comparison-based sorting problem asks us to find the underlying\ntotal order of a given set of elements, where we can only access the elements\nvia comparisons. In this paper, we study a restricted version, where, as a\nhint, a set $T$ of possible total orders is given, usually in some compressed\nform.\nRecently, an algorithm called topological heapsort with optimal running time\nwas found for the case where $T$ is the set of topological orderings of a given\ndirected acyclic graph, or, equivalently, $T$ is the set of linear extensions\nof a given partial order [Haeupler et al. 2024]. We show that a simple\ngeneralization of topological heapsort is applicable to a much broader class of\nrestricted sorting problems, where $T$ corresponds to a given antimatroid.\nAs a consequence, we obtain optimal algorithms for the following restricted\nsorting problems, where the allowed total orders are restricted by: a given set\nof monotone precedence formulas; the perfect elimination orders of a given\nchordal graph; or the possible vertex search orders of a given connected rooted\ngraph.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved girth approximation in weighted undirected graphs",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-improved-girth-approximation-in-weighted-undirected-graphs/",
      "content": "Authors: Avi Kadria, Liam Roditty, Aaron Sidford, Virginia Vassilevska Williams, Uri Zwick\n\nLet $G = (V,E,\\ell)$ be a $n$-node $m$-edge weighted undirected graph, where\n$\\ell: E \\rightarrow (0,\\infty)$ is a real \\emph{length} function defined on\nits edges, and let $g$ denote the girth of $G$, i.e., the length of its\nshortest cycle. We present an algorithm that, for any input, integer $k \\geq\n1$, in $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ expected time finds a cycle of\nlength at most $\\frac{4k}{3}g$. This algorithm nearly matches a\n$O(n^{1+1/k}\\log{n})$-time algorithm of \\cite{KadriaRSWZ22} which applied to\nunweighted graphs of girth $3$. For weighted graphs, this result also improves\nupon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\\log n+m)\\log\n(nM))$ time, where $\\ell: E \\rightarrow [1, M]$ is an integral length function,\nfinds a cycle of length at most $2kg$~\\cite{KadriaRSWZ22}. For $k=1$ this\nresult improves upon the result of Roditty and Tov~\\cite{RodittyT13}.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Multi-Source Reachability and Approximate Distances via",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-faster-multi-source-reachability-and-approximate-distances-via/",
      "content": "Authors: Michael Elkin, Chhaya Trehan\n\nGiven an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$’s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min { 2 + \\sigma, \\omega}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min {2 + \\sigma, \\omega }$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 &lt; \\tilde \\sigma &lt; 0.3336$ is a universal\nconstant.\nIn a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho &lt; 1$, requiring polylogarithmic time\nand work $n^{\\max {\\omega \\rho, 2\\rho + \\sigma } + o(1)}$. We significantly\nimprove, extend, and generalize Cohen’s result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen’s in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho &lt; 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Combinatorics of Palindromes",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-combinatorics-of-palindromes/",
      "content": "Authors: Michael Itzhaki\n\nWe investigate the structure and reconstruction complexity of Manacher\narrays. First, we establish a combinatorial lower bound, proving that the\nnumber of rooted tandem repeat trees with $n+1$ genes exceeds the number of\ndistinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic\nframework that associates a graph to each Manacher array, where every proper\nvertex coloring yields a string consistent with the array. Finally, we analyze\na reconstruction algorithm by I et al. (SPIRE 2010), showing that it\nsimultaneously achieves a globally minimal alphabet size, uses at most\n$\\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce\nreconstructions over arbitrary alphabets when possible. Our results also\nresolve an open problem posed by the original authors. Together, these findings\nadvance the combinatorial understanding of Manacher arrays and open new\ndirections for string reconstruction under structural constraints.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Efficient Massively Parallel Constant-Factor Approximation Algorithm",
      "url": "/cstheoryrss/2025/07/21/arxiv-data-structures-and-algorithms-an-efficient-massively-parallel-constant-factor-approximation-algorithm/",
      "content": "Authors: Vincent Cohen-Addad, Fabian Kuhn, Zahra Parsaeian\n\nIn this paper, we present an efficient massively parallel approximation\nalgorithm for the $k$-means problem. Specifically, we provide an MPC algorithm\nthat computes a constant-factor approximation to an arbitrary $k$-means\ninstance in $O(\\log\\log n \\cdot \\log\\log\\log n)$ rounds. The algorithm uses\n$O(n^\\sigma)$ bits of memory per machine, where $\\sigma &gt; 0$ is a constant that\ncan be made arbitrarily small. The global memory usage is\n$O(n^{1+\\varepsilon})$ bits for an arbitrarily small constant $\\varepsilon &gt;\n0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,\nKrauthgamer, and Vesel'{y} showed that a constant-factor bicriteria\napproximation can be computed in $O(1)$ rounds in the MPC model. However, our\nalgorithm is the first constant-factor approximation for the general $k$-means\nproblem that runs in $o(\\log n)$ rounds in the MPC model.\nOur approach builds upon the foundational framework of Jain and Vazirani. The\ncore component of our algorithm is a constant-factor approximation for the\nrelated facility location problem. While such an approximation was already\nachieved in constant time in the work of Czumaj et al.\\ mentioned above, our\nversion additionally satisfies the so-called Lagrangian Multiplier Preserving\n(LMP) property. This property enables the transformation of a facility location\napproximation into a comparably good $k$-means approximation.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Isotropic Remeshing with Inter-Angle Optimization",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-geometry-isotropic-remeshing-with-inter-angle-optimization/",
      "content": "Authors: Hanbing Zheng, Chenlei Lv\n\nAs an important metric for mesh quality evaluation, the isotropy property\nholds significant value for applications such as texture UV-mapping, physical\nsimulation, and discrete geometric analysis. Classical isotropy remeshing\nmethods adjust vertices and edge lengths, which exhibit certain limitations in\nterms of input data sensitivity, geometric consistency control, and convergence\nspeed. In this paper, we propose an improved isotropy remeshing solution with\ninter-angle optimization during mesh editing to enhance shape control\ncapability and accelerate convergence. The advantage of the solution lies in\nits ability to predict the impact of edge length adjustments on subsequent\noptimization by monitoring angle transformations. It avoids inefficient editing\nthat may cause performance fluctuations, thereby improving efficiency.\nExperiments demonstrate that the proposed method effectively improves the\noverall efficiency of mesh optimization.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Generalized cluster algorithms for Potts lattice gauge theory",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-geometry-generalized-cluster-algorithms-for-potts-lattice-gauge-theory/",
      "content": "Authors: Anthony E. Pizzimenti, Paul Duncan, Benjamin Schweinhart\n\nMonte Carlo algorithms, like the Swendsen-Wang and invaded-cluster, sample\nthe Ising and Potts models asymptotically faster than single-spin Glauber\ndynamics do. Here, we generalize both algorithms to sample Potts lattice gauge\ntheory by way of a $2$-dimensional cellular representation called the plaquette\nrandom-cluster model. The invaded-cluster algorithm targets Potts lattice gauge\ntheory at criticality by implementing a stopping condition defined in terms of\nhomological percolation, the emergence of spanning surfaces on the torus.\nSimulations for $\\mathbb Z_2$ and $\\mathbb Z_3$ lattice gauge theories on the\ncubical $4$-dimensional torus indicate that both generalized algorithms exhibit\nmuch faster autocorrelation decay than single-spin dynamics and allow for\nefficient sampling on $4$-dimensional tori of linear scale at least $40$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Proceedings of the 15th International Workshop on Non-Classical Models",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-complexity-proceedings-of-the-15th-international-workshop-on-non-classical-models/",
      "content": "Authors: Nelma Moreira, Luca Prigioniero\n\nThe Fifteenth International Workshop on Non-Classical Models of Automata and\nApplications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,\norganized by the Department of Computer Science at Loughborough University and\nco-located with the 26th International Conference on Descriptional Complexity\nof Formal Systems (DCFS 2025, 22-24 July).\nThe NCMA workshop series was established in 2009 as an annual event for\nresearchers working on non-classical and classical models of automata, grammars\nor related devices. Such models are investigated both as theoretical models and\nas formal models for applications from various points of view. The goal of the\nNCMA workshop series is to exchange and develop novel ideas in order to gain\ndeeper and interdisciplinary coverage of this particular area that may foster\nnew insights and substantial progress.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Fast computational deep thermalization",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-complexity-fast-computational-deep-thermalization/",
      "content": "Authors: Shantanav Chakraborty, Soonwon Choi, Soumik Ghosh, Tudor Giurgică-Tiron\n\nDeep thermalization refers to the emergence of Haar-like randomness from\nquantum systems upon partial measurements. As a generalization of quantum\nthermalization, it is often associated with high complexity and entanglement.\nHere, we introduce computational deep thermalization and construct the fastest\npossible dynamics exhibiting it at infinite effective temperature. Our circuit\ndynamics produce quantum states with low entanglement in polylogarithmic depth\nthat are indistinguishable from Haar random states to any computationally\nbounded observer. Importantly, the observer is allowed to request many copies\nof the same residual state obtained from partial projective measurements on the\nstate – this condition is beyond the standard settings of quantum\npseudorandomness, but natural for deep thermalization. In cryptographic terms,\nthese states are pseudorandom, pseudoentangled, and crucially, retain these\nproperties under local measurements. Our results demonstrate a new form of\ncomputational thermalization, where thermal-like behavior arises from\nstructured quantum states endowed with cryptographic properties, instead of\nfrom highly unstructured ensembles. The low resource complexity of preparing\nthese states suggests scalable simulations of deep thermalization using quantum\ncomputers. Our work also motivates the study of computational quantum\npseudorandomness beyond BQP observers.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Exact versus Approximate Representations of Boolean Functions in the De",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-complexity-exact-versus-approximate-representations-of-boolean-functions-in-the-de/",
      "content": "Authors: Arkadev Chattopadhyay, Yogesh Dahiya, Shachar Lovett\n\nA seminal result of Nisan and Szegedy (STOC, 1992) shows that for any total\nBoolean function, the degree of the real polynomial that computes the function,\nand the minimal degree of a real polynomial that point-wise approximates the\nfunction, are at most polynomially separated. Extending this result from degree\nto other complexity measures like sparsity of the polynomial representation, or\ntotal weight of the coefficients, remains poorly understood.\nIn this work, we consider this problem in the De Morgan basis, and prove an\nanalogous result for the sparsity of the polynomials at a logarithmic scale.\nOur result further implies that the exact $\\ell_1$ norm and its approximate\nvariant are also similarly related to each other at a log scale. This is in\ncontrast to the Fourier basis, where the analog of our results are known to be\nfalse.\nOur proof is based on a novel random restriction method. Unlike most existing\nrandom restriction methods used in complexity theory, our random restriction\nprocess is adaptive and is based on how various complexity measures simplify\nduring the restriction process.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Characterizing p-Simulation Between Theories",
      "url": "/cstheoryrss/2025/07/21/arxiv-computational-complexity-characterizing-p-simulation-between-theories/",
      "content": "Authors: Hunter Monroe\n\nThis paper characterizes when one axiomatic theory, as a proof system for\ntautologies, $p$-simulates another, by showing: (i)~if c.e. theory\n$\\mathcal{S}$ efficiently interprets $\\mathcal{S}{+}\\phi$, then $\\mathcal{S}$\n$p$-simulates $\\mathcal{S}{+}\\phi$ (Je\\v{r}'abek in Pudl'ak17 proved\nsimulation), since the interpretation maps an $\\mathcal{S}{+}\\phi$-proof whose\nlines are all theorems into an $\\mathcal{S}$-proof; (ii)~$\\mathcal{S}$ proves\n$\\mathcal{S}$ efficiently interprets $\\mathcal{S}{+}\\phi$'' iff $\\mathcal{S}$\nproves$\\mathcal{S}$ $p$-simulates $\\mathcal{S}{+}\\phi$’’ (if so,\n$\\mathcal{S}$ already proves the $\\Pi_1$ theorems of $\\mathcal{S}{+}\\phi$); and\n(iii)~no $\\mathcal{S}$ $p$-simulates all theories. Result (iii) implies\n$\\textbf{P}{\\neq}\\textbf{NP}{\\neq}\\textbf{coNP}$, using the nonrelativizing\nfact no c.e. theory interprets all c.e. theories'' (false for $\\mathcal{S}$\nwith predicate for true sentences). To explore whether this framework resolves\nother open questions, the paper formulates conjectures stronger thanno\noptimal proof system exists’’ that imply Feige’s Hypothesis, the existence of\none-way functions, and circuit lower bounds.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: A Prez Question: Can AI do it? Can you? Can I?",
      "url": "/cstheoryrss/2025/07/20/computational-complexity-a-prez-question-can-ai-do-it-can-you-can-i/",
      "content": " I am curious how AI or humans can do on the following question.\n\nI have listed out the nominees for Prez and VP (Vice Prez) since 1976 and put them in two categories.\n\nWhat criteria did I use?\n\nThe criteria is about their lives. So it’s not going to be something like\n\nThe ones in GROUP ONE have last names with at most 3 vowels.\n\nA few notes before the lists:\n\n1) You may come up with  criteria I didn’t come up with.  It may even be outside of my rules- for example about vowels. Fine- I will be curious if some criteria like that happen to be equivalent to my criteria.\n\n2) You can use whatever you want- Wikipedia, ChatGPT, your friend who knows a lot about presidents.\n\n3) Leave comments with your proposed answer AND HOW YOU GOT IT, though be warned to NOT go to the comments if you want to work on it yourself, since the right answer might be there.\n\n4) There are people who were the nominees for Prez or VP several times.\nI want the list to be in chronological order. I list everyone only once.\nWhat to do about (say) the fact\nthat Bob Dole ran for VP in 1976 and for Prez in 1996?\nI list people in order of the FIRST time they were the nominee.\nSo I have:\n\nVP 1976. Prez-1996\nBob Dole\n\n5) I added some misc information for fun. That information is NOT relevant to the solution. \n\n\n\nGROUP ONE:\n\nVP-1976 and 1980. Prez-1984\nWalter Mondale\n\nPrez-1976\nGerald Ford\n\nVP-1976. Prez-1996\nBob Dole\n\nVP-1984\nGeraldine Ferraro\n\nPrez-1988\nMichael Dukakis\n\nVP-1988\nLloyd Bentson\n\nVP-1988 and 1992\nDan Quayle\n\nPrez-1992 and 1996\nBill Clinton\n\nVP-1992 and  1996. Prez-2000\nAl Gore\n\nVP-2000\nJoe Lieberman\n\nPrez-2004\nJohn Kerry\n\nVP-2004\nJohn Edwards\n\nPrez-2008 and 2012\nBarack Obama\n\nPrez-2012\nMitt Romney\n\nVP-2008 and 2012. Prez-2020\nJoe Biden\n\nPrez-2016\nHillary Clinton\n\nVP-2016\nTom Kaine\n\nVP-2016 and 2020\nMike Pence\n\nVP-2020. Prez-2024\nKamala Harris\n\nVP-2024\nJ.D Vance\n\n(The only names that were flagged for being misspelled are Dukakis, Bentson, Kamala.)\n\n\nGROUP TWO\n\nPrez-1976 and 1980\nJimmy Carter\n\nPrez-1980 and 1984\nRonald Reagan\n\nVP-1980 and 1984, Prez-1988 and 1992.\nGeorge H.W. Bush\n(Not counting the early elections which had different rules,\nI think the only other person who got the nomination twice for VP\nand twice for president is Richard Nixon. If I am wrong, let me know.)\n\nVP-1996\nJack Kemp\n\nPrez-2000 and 2004\nGeorge W Bush\n\nVP-2000 and 2004\nDick Cheney\n\nPrez-2008\nJohn McCain\n\nPrez-2008\nSarah Palin\n\nVP-2012\nPaul Ryan\n\nPrez-2016 and 2020 and 2024\nDonald Trump\n\nVP-2024\nTim Walz\n\n(The only name that was flagged for being misspelled was Walz.) \n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-101 | Exact versus Approximate Representations of Boolean Functions in the De Morgan Basis |",
      "url": "/cstheoryrss/2025/07/20/eccc-papers-tr25-101-exact-versus-approximate-representations-of-boolean-functions-in-the-de-morgan-basis/",
      "content": "A seminal result of Nisan and Szegedy (STOC, 1992) shows that for any total Boolean function, the degree of the real polynomial that computes the function, and the minimal degree of a real polynomial that point-wise approximates the function, are at most polynomially separated. Extending this result from degree to other complexity measures like sparsity of the polynomial representation, or total weight of the coefficients, remains poorly understood.\nIn this work, we consider this problem in the De Morgan basis, and prove an analogous result for the sparsity of the polynomials at a logarithmic scale. Our result further implies that the exact $\\ell_1$ norm and its approximate variant are also similarly related to each other at a log scale. This is in contrast to the Fourier basis, where the analog of our results are known to be false.\nOur proof is based on a novel random restriction method. Unlike most existing random restriction methods used in complexity theory, our random restriction process is adaptive and is based on how various complexity measures simplify during the restriction process.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-100 | Equality is Far Weaker Than Constant-Cost Communication |",
      "url": "/cstheoryrss/2025/07/20/eccc-papers-tr25-100-equality-is-far-weaker-than-constant-cost-communication/",
      "content": "We exhibit an $n$-bit communication problem with a constant-cost randomized protocol but which requires $n^{\\Omega(1)}$ deterministic (or even non-deterministic) queries to an Equality oracle. Therefore, even constant-cost randomized protocols cannot be efficiently “derandomized” using Equality oracles. This improves on several recent results and answers a question from the survey of Hatami and Hatami (SIGACT News 2024). It also gives a significantly simpler and quantitatively superior proof of the main result of Fang, Göös, Harms, and Hatami (STOC 2025), that constant-cost communication does not reduce to the $k$-Hamming Distance hierarchy.\n\nRead original post\n"
    },
    
    {
      "title": "David Eppstein: Twenty years of blogging",
      "url": "/cstheoryrss/2025/07/20/david-eppstein-twenty-years-of-blogging/",
      "content": "I made my first post to this blog twenty years ago, on July 20, 2005.\n\nInitially, it was on LiveJournal, and consisted of a mix of longer-form postings with the sort of brief commentary on web links that, today, I would post as a Mastodon toot. The (lack of) focus has always been roughly the same: technical and arty stuff that interests me, research notes too small or preliminary to publish as a proper paper, open problems, announcements of new publications, conference reports, personal updates, and academic and technical politics. I started cross-posting to Google+ in 2011, stopped again soon after that over a new policy forbidding pseudonymous users, and returned in 2014 after this policy was rescinded. At that point I moved the brief links to Google+, shifting to a format where the blog itself contained only the longer posts and roundups of the links.\n\nLiveJournal was sold to a Russian company in 2007, and for many years after that it operated much as it had before, but gradually became more annoying about showing ads even to readers of my (paid and supposedly ad-free) account. In 2017 they imposed new terms of service with Russian legal restrictions (in particular, against LBGTQ+ advocacy) that I found unacceptable and refused to sign. Instead, I deleted my account and moved to GitHub Pages, including my old posts, almost all of which I had backed up before that became impossible. Under GitHub, everything is in a git repository that I keep local copies of, so it should be much easier to move again should I need to. The old posts were in html format and the posts after the move are in markdown format but fortunately it all works with the mix of formats. Later I slowly went through the old posts cleaning up some dubious markup, migrating image files to GitHub, and using vector graphic files when I still had them; that process is still not entirely complete.\n\nUsing GitHub meant static content and no discussion threads, and I was already using Google+ for the shorter link posts, so I started using it to host discussion links for my posts as well. By the time Google cancelled Google+ in 2019, my posts included many links to Google+, most of which I was able to replace with copies on archive.org. Needing a new host for short posts and discussion links, I chose Mastodon and mathstodon.xyz. For once, my habit of choosing a technically better solution over a more popular solution paid off: I have never used Twitter, so I haven’t had to move again after recent events. And here I am now.\n\nAnyway, I thought at this anniversary it would be appropriate to make a roundup of twenty of my old posts that I found particularly memorable and maybe worth revisiting. Here they are, in chronological order:\n\n\n  Updated Python library: Repetitivity, Sudoku, July 20, 2005. My first post. It’s more telegraphic than I would write now, but I think otherwise it stands up well. It describes an open-source command-line Sudoku solver that I wrote, aimed at mimicking human deduction rather than doing what would be much easier for a computer, backtracking search, and an efficient algorithm for one of its deduction rules, based on finding the edges of a bipartite graph that cannot take part in a perfect matching.\n  Periodic coloring of tilings, September 11, 2006. For any periodic tiling of the plane (or, if you prefer, a periodic planar graph), you can 4-color the tiles or the vertices, by a combination of the 4-color theorem for finite graphs and the De Bruijn–Erdős theorem on coloring infinite graphs. But the coloring might not itself be periodic. If you ask for a periodic coloring with the same period as the original tiling, then it’s the same as coloring a graph on the torus and you might need six colors. But I still don’t know how many colors you need if you require periodicity but allow a bigger fundamental region.\n  The range-restricted Hamming problem, March 18, 2007. How to quickly solve a problem from ancient Mesopotamia: listing all ({2,3,5})-smooth numbers in the range ([60^k,60^{k+1}]). With a diagram of these numbers closely related to the Tonnetz of music theory.\n  Was sind und was sollen die Pseudogeraden?, August 3, 2007. Pretentious title aside, this is on choosing among multiple incompatible definitions for pseudolines, with more in a follow-up post. I think it continues to be relevant: as of this posting the Wikipedia pseudoline article still fails to adequately define a single pseudoline: it uses a definition that has the intended meaning only for arrangements of more than one pseudoline.\n  The many faces of the Nauru graph, December 12, 2007. This roundup of different drawing styles for the 24-vertex cubic symmetric graph gave it a name which has since caught on: Google Scholar now lists 80 publications containing the “Nauru graph” phrase. Follow-ups: a 3d ray-trace of its genus-four symmetric embedding and another drawing with lots of unnecessary crossings.\n  Parts assembly and the burr puzzle antimatroid, December 2, 2008. In how many orders can you take apart a six-piece burr puzzle? This is not the first post I made about antimatroids, but I think it is the first to make a point I have repeated multiple times since then. Despite the scary name, antimatroids formalize a simple and intuitive concept, that you are doing some things one at a time and that once a thing becomes available for you to do it stays available until you do it. In this case, the things you are doing are removing pieces from the puzzle. Later posts applied the same idea to rhyme schemes, course prerequisites, deductions in logic puzzles, quadtree mesh generation, and introductory computer programming.\n  Flat equilateral tori?, February 3, 2009. An easy-to-state unsolved problem: can you make a torus out of equilateral triangles meeting six to a vertex? Usually I draw vector graphics illustrations for my geometry posts but for this one I used photographs of snap-together plastic triangles.\n  Visualizing BFS as a spiral, May 16, 2009. When applied to the Calkin–Wilf tree this produces a sequence containing all positive rational numbers exactly once, with a simple formula for determining each successive number from the previous one that behaves the same everywhere in the spiral, regardless of jumps in level in the breadth-first search tree.\n  A mathematical model of conference acceptance rates, July 18, 2011. If program committees base their decisions on some combination of strength, fashion, and random factors, but the outcome you want is to accept all of the strongest papers, then you’re probably going to need higher acceptance rates and more acceptances of weaker papers than you might expect. But the “mathematical model” here is very unsophisticated and can probably be made much more realistic.\n  Stack-based graph traversal ≠ depth first search, December 17, 2013. A surprisingly common mistake in algorithm texts. It is possible to start with a form of BFS, replace the queue by a stack, and get DFS, but you have to be careful or you’ll get something else instead. See also xkcd on depth and breadth.\n  MathML considered harmful, August 4, 2015. Or, how the pursuit of an unrealistic ideal has harmed and continues to harm the legibility and editability of mathematical formulas on Wikipedia.\n  The shape of the Kresge Auditorium, April 30, 2016. A study of the geometry of MIT’s Kresge Auditorium, a curved triangle formed by projecting onto the plane an eighth of a sphere, comparing it with the Reuleaux triangle, a similar-looking but different curved triangle. This was the first of what became a series of posts on curved triangles that other people had called Reuleaux triangles, but that were not actually Reuleaux triangles. The latest full-length post in the series, on the shapes of triangular pencils, has links to the rest; I also made brief posts on the subject here and here.\n  Half a dimension short, October 21, 2017. Or, why 3d views of some bridges in Google Maps look so strange.\n  #MeToo in theoretical computer science, February 14, 2018. Guest post; trigger warning: rape. I recently joined the board of the Computational Geometry Society, one of whose main roles is to provide a legal framework to keep proven predators away from our conferences. This was one of multiple incidents (the others less public) convincing me that this role is still necessary and important.\n  One thousand women of STEM!, September 22, 2019. Since I started in 2005, I’ve spent a lot of time editing Wikipedia. Since 2008, one of the things I have been doing there has been creating biographies of women in STEM. By my rough estimate there were 1000 by this date and by my even rougher estimate it’s likely to be over 3000 by now. If I had to choose who I most want others to know about, it would be the first one listed in this post: Pandrosion of Alexandria, the first female mathematician that we know by name.\n  Gilbert tessellations from a cellular automaton, November 2, 2021. Long ago Stephen Wolfram described a four-way subdivision of the typical behaviors of cellular automata on random initial fields: they can die out, quickly form small stable or periodic structures, stay chaotic, or exhibit complex behaviors. This post points to an intermediate possibility: they can build walls that extend across space until they are blocked by other walls. Similar wall-building behavior was studied by Gilbert in the 1950s as a model of crack formation, and has appeared in some of my computational geometry papers under the heading of “motorcycle graphs”, named for the Tron light-cycle wall-building game.\n  Midsphere facts and fallacies, July 27, 2022. A midsphere is a sphere tangent to all edges of a polyhedron. All polyhedra have a combinatorially equivalent form with a midsphere. But contrary to what multiple sources state, the midsphere does not always touch the midpoints of the edges. It is not true that only the Platonic solids have all three of an insphere, midsphere, and circumsphere. When a polyhedron has all three, they might not be concentric nor even nested. The midsphere might not be the smallest sphere touching all the edges. I don’t know whether (when both exist) the inradius is always smaller than the midradius, or whether the midradius is always smaller than the circumradius.\n  Coloring the plane for generic norms, May 13, 2023. Many of my posts attempt to provide a more-accessible explanation of research from my own papers. This one is similar, but for a paper that is not mine, by Noga Alon, Matija Bucić and Lisa Sauermann on the problem of coloring the unit distance graph of the plane. For Euclidean distances the number of colors you need is 5, 6, or 7, but it remains a big open problem which one. Alon et al prove that for generic convex distance functions, the number of colors is exactly four, but finding a natural strictly-convex distance function for which this is true is another open problem.\n  Random perfection, May 8, 2024. Another Wikipedia editor asked me: how likely is it that a random graph is a perfect graph? It depends on the density of the graph, with two phase transitions between densities for which it is very likely and densities for which it is very unlikely, less sharp than the phase transitions for many other properties. My longest recent post, and maybe one of my most technical.\n  The ancient Greek mathematics of distorted airplane propeller photos, March 22, 2025. One of the things I particularly enjoy about Wikipedia editing, when it happens, is discovering unexpected connections between things I didn’t know were related. This one is on a connection between the distortions caused by rolling shutters and ancient Greek work on trisecting angles and squaring the circle.\n\n\n(Discuss on Mastodon)\n\nBy David Eppstein\n\nRead original post\n"
    },
    
    {
      "title": "Nisheeth Vishnoi: What is Intelligence? Architecture, Divergence, and Fiction",
      "url": "/cstheoryrss/2025/07/19/nisheeth-vishnoi-what-is-intelligence-architecture-divergence-and-fiction/",
      "content": "A computational anatomy of intelligence. How faculties interact, architectures diverge, and coherence emerges through self-constructed fictions\n\n\n\n\n  “There is no single path into the forest.” — Yoruba proverb\n\n\nYo-Yo Ma and the Single Note\n\nIt was the winter of 2018 and the NeurIPS conference—one of the world’s premier gatherings on artificial intelligence—had descended on a snow-laced Montreal. Thousands of researchers, engineers, and students crisscrossed the vast convention center, sharing ideas about optimization tricks, new models, and the future of AI. Posters lined the walls of rooms steeped in the aroma of coffee, while outside, the city lay wrapped in cold, crisp silence.\n\nAt one of the marquee panels, a senior executive from a major tech company presented their latest AI music generator—an advanced system trained on thousands of classical works, capable of composing coherent classical music in real time.\n\nThe melodies were elegant and the timing precise.\n\nThen Yo-Yo Ma was invited to respond.\n\nHe didn’t speak. He turned his chair, lifted his cello, and played a single note. Then he played it again. And again. Each time, the same note emerged differently—tentative, bold, grieving, serene. Each time, his breath shifted and his eyes drifted into a different world.\n\nThe AI had captured form. But Yo-Yo Ma, infusing his music with intention and feeling, captured the room.\n\nThat moment didn’t just expose AI’s limitations. It revealed a deeper truth:\n\nIntelligence isn’t precision—it’s relation.\n\nIt does not reside in outputs alone, but in how systems tune themselves to the world: shaped by context, memory, attention, and intent.\n\nIt is a dynamic interplay between perception and action, between internal models and external pressures. It arises wherever systems engage their constraints creatively: whether through mycelial networks, migrating birds, musical phrases, or planetary motion.\n\nIn the previous essay, we traced how intelligence emerges in nature: not as a fixed trait, but as a layered process—optimization in physics, adaptation in evolution, collective sensing in life before neurons.\n\nThis second essay turns inward—from emergence to architecture. If the first asked where intelligence comes from, this one asks: what is it made of?\n\nWe begin by identifying a set of core faculties: sensing, responding, memory, learning, attention, valuation, modeling, and reflection.\n\nThese faculties take many forms. Sensing may be chemical, tactile, social, or symbolic. Memory may be episodic, spatial, or associative. Valuation may be shaped by prediction error, pain, or narrative.\n\nAnd how they are configured—what is emphasized, suppressed, amplified, or ignored—depends not just on design, but on history: evolutionary, developmental, experiential.\n\nFrom these components and their interrelations, intelligence emerges—not as a single thread, but as a weave: recursive, plural, and at times, fictional.\n\nThis part of the essay unfolds in three movements:\n\n\n  Composition: How core faculties combine to produce reasoning, language, and creativity—not through accumulation, but through tension, feedback, and reprogramming.\n  Divergence: Why there is no single blueprint for intelligence. We examine human cognitive diversity to understand the space of architectural variation.\n  Fiction: How intelligent systems—especially human ones—construct internal narratives to manage complexity, maintain coherence, and navigate meaning.\n\n\nThis is not a final theory. It is a trace—a computational lens on intelligence as it curves inward, reshapes itself, and constructs meaning under pressure. For those exploring AI not as an isolated artifact, but as part of a broader landscape of intelligence, this lens may offer new ways to rethink design and augmentation.\n\nAnd like a forest, this inquiry offers no fixed path—only branching terrain shaped by tension, memory, and choice.\n\nRead the full essay by subscribing (for free) toThe Intelligence Loop.\n\nBy nisheethvishnoi\n\nRead original post\n"
    },
    
    {
      "title": "CCI: jobs: Postdoctoral fellow position at University of Houston apply by September 30, 2025",
      "url": "/cstheoryrss/2025/07/18/cci-jobs-postdoctoral-fellow-position-at-university-of-houston-apply-by-september-30-2025/",
      "content": "A postdoc is available in distributed and scalable machine learning, security, and fault tolerance in distributed computing at the CS department, Univ. of Houston. Prior publications in top conferences such as NeurIPS, ICML, SODA, FOCS, STOC, and PODC are desired. Candidates should send their CV, a research statement, and (request referees to forward) 3 letters to Prof. Gopal Pandurangan.\n\nWebsite: https://www2.cs.uh.edu/~gopal\nEmail: gopalpandurangan@gmail.com\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-099 | The Algebraic Cost of a Boolean Sum |",
      "url": "/cstheoryrss/2025/07/18/eccc-papers-tr25-099-the-algebraic-cost-of-a-boolean-sum/",
      "content": "It is a well-known fact that the permanent polynomial is complete for the complexity class VNP, and it is largely suspected that the determinant does not share this property, despite its similar expression.\nWe study the question of why the VNP-completeness proof of the permanent fails for the determinant.\nWe isolate three fundamental properties that are sufficient to prove a polynomial sequence is VNP-hard, of which two are shared by both the permanent and the determinant.\nWe proceed to show that the permanent satisfies the third property, which we refer to as the ``cost of a boolean sum,” while the determinant does not, showcasing the fundamental difference between the polynomial families.\nWe further note that this differentiation also applies in the border complexity setting and that our results apply for counting complexity.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-099 | The Algebraic Cost of a Boolean Sum |",
      "url": "/cstheoryrss/2025/07/18/eccc-papers-tr25-099-the-algebraic-cost-of-a-boolean-sum-ian-orzel-srikanth-srinivasan-s-bastien-tavenas-amir-yehudayoff/",
      "content": "It is a well-known fact that the permanent polynomial is complete for the complexity class VNP, and it is largely suspected that the determinant does not share this property, despite its similar expression.\nWe study the question of why the VNP-completeness proof of the permanent fails for the determinant.\nWe isolate three fundamental properties that are sufficient to prove a polynomial sequence is VNP-hard, of which two are shared by both the permanent and the determinant.\nWe proceed to show that the permanent satisfies the third property, which we refer to as the ``cost of a boolean sum,” while the determinant does not, showcasing the fundamental difference between the polynomial families.\nWe further note that this differentiation also applies in the border complexity setting and that our results apply for counting complexity.\n\nRead original post\n"
    },
    
    {
      "title": "Francis Bach: Revisiting scaling laws via the z-transform",
      "url": "/cstheoryrss/2025/07/18/francis-bach-revisiting-scaling-laws-via-the-z-transform/",
      "content": "In the last few years, we have seen a surge of empirical and theoretical works about “scaling laws”, whose goals are to characterize the performance of learning methods based on various problem parameters (e.g., number of observations and parameters, or amount of compute). From a theoretical point of view, this marks a renewed interest in asymptotic equivalents—something the machine learning community had mostly moved away from (and, let’s be honest, kind of looked down on) in favor of non-asymptotic bounds. The two types of bounds have their own pros and cons, and I value both of them, but on a personal note, after having spent close to twenty years in proving (sometimes tedious) non-asymptotic results, proving asymptotic results is particularly rewarding, especially when you experience that “aha!” moment where the empirical behavior aligns perfectly with the derived expression (see some examples below).\n\nScaling laws for quadratic optimization require aggregating the effects of all eigenvalues of the Hessian matrix and not considering only the worst one. This was done with Laplace’s method in an earlier post for gradient descent and partially for Nesterov acceleration. This blog post explores similar asymptotic scaling laws and will consider stochastic algorithms, but there is more to it.\n\nI will use a classical tool from applied mathematics, electrical engineering, and computer science: the z-transform (a.k.a. generating function) of a discrete sequence. My goal in this blog post is to present the essentials of the method. For more details, see my recent preprint [1], with lots of potential follow-ups. Note that the z-transform has already been used in the context of stochastic gradient descent for stability analysis [15, 20] and for deriving convergence rates with constant momentum [22].\n\nz-transform method and final value theorem\n\nFrom Abel’s theorem to the finite value theorem. Given a sequence ((b_k)_{k \\geqslant 0}), its z-transform is the function (B) defined for a complex argument (z \\in \\mathbb{C}), as (B(z) = \\sum_{k=0}^\\infty b_k z^k) (note the change of convention where (z^{-1}) is replaced by (z)). The behavior of the series defined by ((b_k)_{k \\geqslant 0}) can be characterized by the behavior of (B(z)) for (z) tending to (1) while remaining in ([0,1)). This is the classical Abel’s theorem: when the series defined by ((b_k)_{k \\geqslant 0}) is convergent, then \\(\\sum\\_{k=0}^{+\\infty} b\\_k = \\lim\\_{z \\to 1^-} B(z).\\)\n\nWhen applied to (b_k = a_k\\, – a_{k-1}) for (k \\geqslant 1), with (b_0 = a_0), then we have (\\sum_{\\ell=1}^k b_\\ell = a_k), and (B(z) = (1\\, – z) A(z)) where (A) is the z-transfom of ((a_k)_{k \\geqslant 0}). We then obtain the final value theorem, which states \\(\\lim\\_{z \\to 1^-} \\ ( 1 \\, – z) A(z) = \\lim\\_{k \\to +\\infty} a\\_k.\\)\n\nFrom limits to asymptotic equivalents. In order to obtain equivalents of the sequence ((a_k)_{k \\geqslant 0}) (and not simply its limit), we can use two additional properties:\n\n\n  the z-transform of (((k+1) a_{k+1})_{k \\geqslant 0}) is (A’(z)), leading to \\(\\lim\\_{z \\to 1^-} \\ ( 1 \\, – z) A'(z)= \\lim\\_{k \\to +\\infty} k a\\_k.\\)\n  To treat non-integer powers, we have the following identity, valid for any real (\\nu &gt; 0), \\(\\lim\\_{z \\to 1^-} \\ ( 1 \\,- z)^{\\nu} A(z) = \\Gamma(\\nu) \\cdot \\lim\\_{k \\to +\\infty} k^{1-\\nu} a\\_k,\\) where (\\Gamma) is the Gamma function. A classical example is (a_k = \\frac{1}{k!} \\nu(\\nu+1) \\cdots (\\nu+k-1) = \\frac{ \\Gamma(k+\\nu)}{\\Gamma(\\nu)\\Gamma(k+1)} \\sim \\frac{k^{\\nu-1}}{\\Gamma(\\nu)}), for which (A(z) = (1-z)^{-\\nu}).\n\n\nCombining the last two properties (with an extension to higher-order derivatives), when the two limits exist, we have: \\(\\lim\\_{z \\to 1^-} \\ ( 1 \\, – z)^{\\nu} A^{(\\mu)}(z) = \\Gamma(\\nu)\\cdot \\lim\\_{k \\to +\\infty} k^{1+\\mu-\\nu} a\\_k.\\) Therefore, the z-transform method consists in deriving asymptotics of the z-transform or its derivatives around (z = 1^-). Before showing why this is a simplification, some words on sufficient conditions for the equivalence to hold, through a sequence of so-called “Tauberian” theorems.\n\nTauberian theory. In order to show that limits and asymptotic equivalents exist, several options are available. When only considering real-valued arguments for the z-transforms, various sufficient conditions have been derived from the work of Hardy and Littlewood [2] (the book from Jacob Korevaar [3] is a great source of detailed results). In a nutshell, oscillating sequences such as (a_k = (-1)^k) are the ones where the limits are not equal (or may not exist), and a classical sufficient condition is that there exists a constant (c) such that for all (k \\geqslant 1), (a_k \\, – a_{k-1} \\leqslant c / k^{2+\\mu – \\nu}) (in particular, with (c = 0), being decreasing is a sufficient condition). Alternative frameworks can also be considered using complex analysis, which only depends on property of the z-transform (A(z)) for complex (z) [4, 5].\n\nProperties of the z-transform. What makes the z-transform so versatile is a suite of properties that link modifications of the sequence ((a_k)_{k \\geqslant 0}) to its z-transform (A(z)) (see more details in [1, 6]). The most important ones are:\n\n\n  Shift: If (A(z)) is the z-transform of the sequence ((a_k)_{k \\geqslant 0}), then (z A(z)) is the z-transform of the sequence ((0,a_0,a_1,\\dots)), that is, shifted by 1. This implies that sequences that satisfy a linear difference equation lead to rational z-transforms.\n  Multiplication by a polynomial: If (A) is the z-transform of ((a_k)_{k \\geqslant 0}), then (z \\mapsto z A’(z)) is the (z)-transform of ((k a_k)_{k \\geqslant 0}). Thus, when we have a difference equation with rational coefficients (in (k)), this leads to an ordinary differential equation for the z-transform.\n\n\nClassical use of the z-transform method to derive asymptotic equivalents. The z-transform method is a classical tool, with already many applications, e.g., in combinatorics, analysis of recurrence relations, queuing theory, signal processing, and control (see [6, 7]). In this blog post, I will focus on optimization of quadratic functions.\n\nGradient descent and spectral dimension\n\nLike in an earlier post, we consider an idealized quadratic optimization problem in infinite dimension, which can be rewritten as the minimization of \\(F(\\eta) = \\frac{1}{2} \\langle \\eta-\\eta\\_\\ast, H ( \\eta-\\eta\\_\\ast)\\rangle,\\) where (\\eta_\\ast) is a global optimum of (F) and (H) the positive semi-definite Hessian operator. Gradient descent leads to the recursion \\(\\eta\\_k = \\eta\\_{k-1} \\, – \\gamma F'(\\eta\\_{k-1}) = \\eta\\_{k-1} \\, – \\gamma H ( \\eta\\_{k-1} \\, – \\eta\\_\\ast),\\) where (\\gamma &gt; 0) is a step-size which we choose so that the operator norm of (\\gamma H) is less than one (e.g., (\\gamma \\leqslant 1/L), where (L) is the largest eigenvalue of the operator (H)). With (\\theta_k = \\eta_k \\, – \\eta_\\ast), this leads to the following linear iteration \\(\\theta\\_k = (I \\, – \\gamma H) \\theta\\_{k-1} = ( I \\, – \\gamma H)^k \\delta,\\) where (\\delta = \\theta_0 = \\eta_0\\, – \\eta_\\ast).\n\nThus, given a spectral decomposition (\\gamma H = \\sum_{i=1}^{+\\infty} \\lambda_i u_i \\otimes u_i) with eigenvalues ((\\lambda_i)_{i \\geqslant 1}) in ([0,1]) and eigenvectors ((u_i)_{i \\geqslant 1}), we get the following performance criterion \\(a\\_k = \\frac{1}{2\\gamma} \\sum\\_{i=1}^{+\\infty} \\lambda\\_i (1 \\, – \\lambda\\_i)^{2k} \\langle u\\_i,\\delta \\rangle^2 = \\int\\_{0}^1 (1 \\, – \\lambda)^{2k} d\\sigma(\\lambda),\\) where \\(d\\sigma(\\lambda) = \\frac{1}{2\\gamma} \\sum\\_{i=1}^{+\\infty} \\lambda\\_i \\langle u\\_i,\\delta \\rangle^2 {\\rm Dirac}(\\lambda|\\lambda\\_i)\\)\nis a weighted spectral measure, as defined in [8] in the gossip context (see this earlier post), with a z-transform equal to \\(A(z) = \\sum\\_{k=0}^{+\\infty} z^k \\int\\_0^{1 } (1-\\lambda)^{2k} d\\sigma(\\lambda)  \n= \\int\\_0^{1 } \\frac{1}{1 \\, – z (1-\\lambda)^{2}} d\\sigma(\\lambda),\\) which is a rational function in (z) and (\\lambda). It can thus be re-written as, using a partial function decomposition in the variable (\\lambda), as \\(A(z) = \\frac{1}{2 \\sqrt{z} } \\int\\_0^{1 } \\frac{d\\sigma(\\lambda) }{ \\lambda + z^{-1/2} \\, – 1 } – \\frac{1}{2\\sqrt{z}} \\int\\_0^{1 } \\frac{d\\sigma(\\lambda) }{ \\lambda\\, – z^{-1/2} – 1 }.\\) We thus get \\(A(z) = \\frac{1}{2 \\sqrt{z} } S( z^{-1/2}-1 ) – \\frac{1}{2 \\sqrt{z}}S ( – z^{-1/2}-1) ,\\)\nwhere (\\displaystyle S(u) = \\int_0^1 ! \\frac{d\\sigma(\\lambda)}{\\lambda + u}) is the Stieltjes transform of the measure (\\sigma) (see Chapter 8 of [10]), a classical tool in random matrix theory. We see above that what matters in the equivalent of (S(u)) around (u=0) (since the value at (-2) is bounded).\n\nThe spectral dimension defined by [8] corresponds to a measure whose behavior around zero has density (c \\lambda^{\\omega \\, – 1}), or in almost equivalent terms so that (S(u) \\sim c \\Gamma(\\omega) \\Gamma(1-\\omega) u^{\\omega\\, -1}) around (u=0), with a similar expansion for derivatives. This leads directly to a an explicit scaling law in ({1}/{k^\\omega}) which exactly recovers an earlier post (which was using Laplace method) with a different proof.\n\nThe spectral dimension depends explicitly on problem parameters:\n\n\n  For least-squares regression, as described in an earlier post and in many papers, this corresponds to (\\lambda_i \\sim L / i^\\alpha) (“capacity” conditions) and (\\langle \\delta, u_i \\rangle \\sim \\Delta / i^{\\beta/2}) (“source” conditions), leading to (\\omega = \\frac{\\beta-1}{\\alpha} + 1 ) assumed to be positive, and (c = \\frac{L \\Delta^2 }{2 \\alpha (\\gamma L)^{\\frac{\\beta-1}{\\alpha}+1}}). The equivalent is then \\(a\\_ k \\sim c \\frac{\\Gamma(\\omega)}{(2k)^{\\omega}},\\) with nice connections with non-asymptotic bounds for the same problem.\n  For gossip, as shown in [8], we get that (\\omega) is the underlying dimension of the set on which local messages are sent.\n\n\nSummary. Linear iterations lead to rational z-transforms along all eigenvectors, and then asymptotics of the Stieltjes transform (based on the spectral dimension) can be used after partial function decomposition. For gradient descent (a simple linear iteration with constant coefficients), this can be easily achieved in other ways. However, for time-dependent coefficients (Nesterov acceleration) and for stochastic iterations, it will provide a new direct way that avoids lengthy computations.\n\nNesterov acceleration vs. heavy-ball\n\nA classical way to accelerate the convergence of the gradient iteration is to use an extrapolation step due to Nesterov [11]. This can be formulated with two sequences (and a first-order recursion) as:\n\\(\\begin{array}{rcl} \\eta\\_{k+1} &amp; = &amp; \\zeta\\_{k} \\, – \\gamma F'(\\zeta\\_{k}) \\\\ \\zeta\\_{k+1} &amp; = &amp; \\eta\\_{k+1} + ( 1 \\, – \\tau\\_{k+1}) ( \\eta\\_{k+1} \\, – \\eta\\_k), \\end{array}\\) and with a single sequence (and a second-order recursion) as \\(\\eta\\_{k+1} = \\eta\\_{k} + ( 1 \\, – \\tau\\_{k}) ( \\eta\\_{k}\\, – \\eta\\_{k-1})\\, – \\gamma F’ \\big[ \\eta\\_{k} + ( 1 \\,- \\tau\\_{k}) ( \\eta\\_{k} \\, – \\eta\\_{k-1})\\big].\\)\n\nIn the original formulation with convex functions, (\\tau_k) is chosen asymptotically proportional to (2\\rho/(k+1)) with (\\rho = 3/2). For quadratic functions, [9] argues that the choice (\\rho = 1) is more natural as it leads to a simple rescaled reformulation, and [12, 13] consider a general (\\rho). We now show that the z-transform allows us to analyze all integers (\\rho), with a conjecture that is empirically valid for all (\\rho &gt;0).\n\nWith (\\theta_k = \\eta_k\\, – \\eta_\\ast), we obtain the following recursion for quadratic functions \\(\\theta\\_{k+1} = ( I- \\gamma H) \\bigg[ \\theta\\_{k} + \\Big( 1\\, – \\frac{ 2\\rho }{k+2\\rho-1} \\Big) ( \\theta\\_{k} \\, – \\theta\\_{k-1}) \\bigg].\\) I show in [1] how the performance measure leads to an explicit rational function in ((z,\\lambda)) of order (2 \\rho), obtained through differentiations of the z-transform (to take into account the rational depence of (\\tau_k)). For (\\rho=1), we can easily get by hand a partial function decomposition, while for larger integer (\\rho), this can be readily done by symbolic computation tools such as Mathematica. Overall, the final equivalents for (a_k = \\frac{1}{2} \\langle \\eta_k \\, – \\eta_\\ast, H ( \\eta_k \\, – \\eta_\\ast) \\rangle) are essentially (up to logarithmic terms) proportional to ({1}/{k^{\\min{2\\omega, \\omega + \\rho}}}). More precisely we get totally explicit equivalents:\n\n\n  (\\displaystyle a_k \\sim c \\frac{\\Gamma(2 \\rho)^2}{\\Gamma(\\rho)^2} \\cdot \\frac{\\Gamma(\\rho-\\omega) \\Gamma(\\omega)}{\\Gamma(4\\rho-1-2\\omega)} \\frac{\\Gamma(2\\rho-1/2-\\omega)}{\\Gamma(\\rho+1/2-\\omega)} \\frac{2^{2\\rho-1}}{4^\\omega } \\cdot \\frac{1}{k^{ 2\\omega}}) for (\\omega \\in (0,\\rho)).\n  (\\displaystyle a_k \\sim c \\frac{\\Gamma(2 \\rho)^2}{\\Gamma(\\rho)^2} \\cdot\\frac{1}{2^{2\\rho-1}} \\cdot \\frac{ \\log k}{k^{2\\rho}}) for (\\omega = \\rho).\n  (\\displaystyle a_k \\sim c \\frac{\\Gamma(2 \\rho)^2}{\\Gamma(\\rho)^2} \\cdot \\frac{1}{2^{2\\rho-1}} \\Gamma(\\omega-\\rho)\\cdot \\frac{1}{k^{\\omega+\\rho}}) for (\\omega &gt; \\rho).\n\n\nAnd amazingly, they do match in our experiments even beyond integer (\\rho), as shown below.\n\n\n\nNesterov acceleration for (\\omega = 1) and several (\\rho)’s. Note the classical vanishing oscillations for small (\\rho). Moreover, the best performance is achieved around (\\rho \\approx \\omega).\n\nWhat about heavy-ball? The heavy-ball method is very similar to Nesterov acceleration, with the following iteration \\(\\eta\\_{k+1} = \\eta\\_{k} \\, – \\gamma F'(\\eta\\_k) + (1-\\tau\\_{k+1}) ( \\eta\\_k \\,- \\eta\\_{k-1}),\\) leading to, with the same notations, to \\(\\theta\\_{k+1} = \\Big( I- \\frac{k}{k+2\\rho-1} \\gamma H\\Big) \\theta\\_{k} + \\Big( 1 \\, – \\frac{ 2\\rho }{k+2\\rho-1} \\Big) ( \\theta\\_{k} \\, – \\theta\\_{k-1}).\\) The associated z-transform is also the integral with respect to the spectral measure of a rational function, leading to an asymptotic equivalent around (z=1^-). Then, one can plot the actual performance and compare to the equivalent, as shown below.\n\n\n\nHeavy-ball method with (\\rho=1) for two values of the spectral dimension (\\omega). Top: performance (a_k) vs. equivalent (\\bar{a}_k), bottom: ratio.\n\nWhat’s happening? The two do not match for (\\omega) large enough (right plot above). It turns out that oscillations do not vanish, and the sufficient Tauberian conditions are not satisfied. What can then be shown in terms of asymptotic equivalents remains open.\n\nStochastic gradient descent (a.k.a. least-mean-squares algorithm)\n\nWe now consider minimizing the expexted risk for a linear predictor with square loss: \\(F(\\eta) = \\frac{1}{2}\\mathbb{E} \\big[ ( y \\, – \\langle x, \\eta \\rangle )^2 \\big]\\) (keeping in mind that we can use a feature vector). Single-pass stochastic gradient descent (SGD) leads to the iteration \\(\\eta\\_k = \\eta\\_{k-1}\\, – \\gamma ( \\langle x\\_k,\\eta\\_{k-1} \\rangle \\,- y\\_k) x\\_k,\\) with ((x_k,y_k)) an independent sample from the distribution defining (F). We can write it using a minimizer (\\eta_\\ast) of (F) as \\(\\eta\\_k -\\eta\\_\\ast =( I \\, – \\gamma x\\_k \\otimes x\\_k) (\\eta\\_{k-1} \\, – \\eta\\_\\ast) + \\gamma \\varepsilon\\_k x\\_k,\\) where (\\varepsilon_k = y_k \\, – \\langle x_k, \\eta_\\ast \\rangle) is the optimal residual. We denote (\\theta_k = \\eta_k \\, – \\eta_\\ast). In this context, SGD is referred to as the least-mean-squares (LMS) algorithm [14, 15, 16, 17].\n\nThe simplest but incomplete analysis uses that (\\mathbb{E} [ \\varepsilon_k x_k ] =0) (which is the optimality condition characterizing (\\varepsilon_k)), to get: \\(\\mathbb{E}[\\theta\\_k] = ( I \\, – \\gamma H) \\mathbb{E}[\\theta\\_{k-1}],\\) leading to the classical linear iteration of gradient descent. However, it does not lead to any result on the performance measure (\\frac{1}{2} \\mathbb{E} [ \\langle \\theta_k, H \\theta_k \\rangle] = \\mathbb{E} [ F(\\eta_k)\\, – F(\\eta_\\ast) ]).\n\n\n  \n    \n      Traditionally, there are two terms in the analysis: “bias” and “variance” (see a thorough discussion in [27]). For simplicity, let’s assume that (\\varepsilon_k) is independent of (x_k), with (\\mathbb{E} [ \\varepsilon_k]=0) and (\\mathbb{E} [ \\varepsilon_k^2]=\\sigma^2) (not to be confused with the notation for the spectral measure defined above). We then consider the operator \\(\\Theta\\_k = (\\eta\\_k \\, – \\eta\\_\\ast)\\otimes (\\eta\\_k \\,- \\eta\\_\\ast) = \\theta\\_k \\otimes \\theta\\_k,\\) for which we have \\(F(\\eta\\_k) \\,- F(\\eta\\_\\ast) = \\frac{1}{2} \\langle \\Theta\\_k,H \\rangle = \\frac{1}{2}{\\rm tr}( \\Theta\\_k H),\\) and $$ \\mathbb{E} [ \\Theta_k\n      \\Theta_{k-1}] = \\mathbb{E} \\big[ ( I \\, – \\gamma x_k \\otimes x_k) \\otimes ( I \\, – \\gamma x_k \\otimes x_k) \\big] \\Theta_{k-1} + \\gamma^2 \\sigma^2 H,\\(leading to:\\) \\mathbb{E} [ \\Theta_k ] = \\big( I\\, – \\gamma H \\otimes I \\, – \\gamma I \\otimes H\\, + \\gamma^2 \\mathbb{E} [ x \\otimes x \\otimes x \\otimes x] \\big) \\mathbb{E} [ \\Theta_{k-1} ] \\, + \\gamma^2 \\sigma^2 H.$$\n    \n  \n\n\nWe consider the operator (defined on self-adjoint operators) \\(T = H \\otimes I \\, + I \\otimes H \\, -\\, \\gamma \\mathbb{E} [ x \\otimes x \\otimes x \\otimes x],\\) so that \\(\\tag{1} \\mathbb{E} [ \\Theta\\_k ] = \\big( I\\, – \\gamma T \\big) \\mathbb{E} [ \\Theta\\_{k-1} ] \\, + \\gamma^2 \\sigma^2 H,\\) leading to, after summation of the geometric series (see an earlier post): \\(\\mathbb{E} [ \\Theta\\_k ] = \\big( I\\, – \\gamma T \\big)^k \\Theta\\_{0} \\, + \\gamma \\sigma^2 \\big[ I- \\big( I- \\gamma T \\big)^k \\big] T^{-1} H .\\)\n\nA sufficient condition for convergence is that the operator (I\\, – \\gamma T) (as an operator on symmetric operators) has eigenvalues in ([-1,1]). In [17], we define and characterize the largest step-size with few assumptions. We consider instead specific models for asymptotic computations.\n\nSimplest model. In order to obtain simpler formulas, several models have been proposed that are compatible with the Hessian operator (H) having eigenvalues ((\\lambda_i)_{i \\geqslant 1}) and eigenvectors ((u_i)_{i \\geqslant 1}). The simplest model [18] is (x = r u_j) with (r \\in \\mathbb{R}) and (i \\in \\mathbb{N}^\\ast) random and independent, with (\\mathbb{E}[r^2] = \\sum_{i \\geqslant 1} h_i = {\\rm tr}(H)), and (\\mathbb{P}(j = i) = h_i / {\\rm tr}(H)). What makes this model special is that, like in the deterministic case, there are no interactions between eigensubspaces. While this includes one-hot encoded discrete data as recently used in [19], this remains limited compared to the model below (which includes Gaussian data and is often used in random matrix theory).\n\nSimplified high-dimensional model. We consider \\(x= \\sum\\_{i = 1}^{+\\infty} h\\_i^{1/2} z\\_i u\\_i,\\) where the variables (z_i \\in \\mathbb{R}), (i \\geqslant 1), are independent (and not merely un-correlated), and have zero mean and unit variance. The only parameter that we will need to characterize the operator (T) is the fourth-order moment, (\\mathbb{E} [ z_i^2] = 3 + \\kappa), where (\\kappa) is the excess kurtosis.\n\nThe Gaussian model [15] where all (z_i) are Gaussians corresponds to (\\kappa=0), while the Rademacher model where (z_i \\in {-1,1}) are Rademacher random variables corresponds to the smallest possible value (\\kappa=-2). Other models could also be considered, particularly when using kernels [25].\n\nWith this simplified model, as already shown in the 1980’s in the Gaussian context [20, 15], in the basis of eigenvectors of (H), the operator (T) has a simple block-diagonal structure: the off-diagonal elements of (\\mathbb{E} \\big[ \\Theta_k ] ) evolve independently (and converge to zero linearly), while the diagonal elements that are needed to compute the performance measure evolve according to a linear iteration with a matrix that is the sum of a diagonal and a rank-one matrix. More precisely, assuming without loss of generality that the operator (H) is diagonal equal to ({\\rm Diag}(h)), Eq. ((1)) projected on diagonal elements becomes \\({\\rm diag}( \\mathbb{E}[ \\Theta\\_k]) = ( I\\, – \\gamma V) {\\rm diag}( \\mathbb{E}[ \\Theta\\_k]) + \\gamma^2 \\sigma^2 h,\\) with \\(V = {\\rm Diag}\\big( 2 h \\, – \\gamma(\\kappa+2) h \\circ h\\big) – \\gamma h \\otimes h .\\)\n\nThe performance (a_k = \\mathbb{E} [ F(\\eta_k) ] – F(\\eta_\\ast)) is thus \\(a\\_k = \\frac{1}{2}\\langle \\delta \\circ \\delta, ( I \\, – \\gamma V )^k h \\rangle + \\gamma \\sigma^2 \\langle h, \\big(I\\, – ( I \\, – \\gamma V )^k \\big) V^{-1} h \\rangle.\\) In order to study convergence, we could look at an eigenvalue decomposition of the matrix (V) using “secular” equations [21]. Instead, we will use the z-transform method, which avoids explicit computations of eigenvalues.\n\nFor simplicity, we consider here only the interpolation regime where (\\sigma^2=0) (i.e., there is no noise on top of optimal predictions, see [1] for all details). Then, the z-transform is equal to \\(A(z) = \\sum\\_{k=0}^{+\\infty} a\\_k z^k = \\frac{1}{2}\\langle \\delta \\circ \\delta, ( (1-z) I \\, + z \\gamma V )^{-1} h \\rangle.\\) The matrix ((1-z) I \\, + z \\gamma V) that needs to be inverted has a “diagonal + rank-one” structure, and can thus be inverted using the matrix inversion lemma, leading to an explicit rational function in (z), that can be directly analyzed around (z = 1) (see [1]).\n\nAsymptotic equivalent. Following this post and the gradient descent analysis above, we consider (h_i = {L}/{i^\\alpha}) and (\\delta_i = {\\Delta}/{i^{\\beta/2}}). If we assume (\\kappa = -2) (Rademacher case, which leads to the simplest formulas), the largest step-size is (\\gamma = 2/ {\\rm tr}(H)) (which can be significantly smaller than (2 / \\lambda_\\max(H)) when (\\alpha) is close to 1), and we get the asymptotic equivalent \\(a\\_k \\sim \\frac{L \\Delta^2}{2 \\alpha} \\frac{1}{1-\\gamma {\\rm tr}(H)/2 } \\frac{\\Gamma(\\omega)}{(2 \\gamma L k)^{\\omega}},\\) with (\\omega= (\\beta-1)/\\alpha + 1), and under the condition (\\omega = (0, 2- 1/\\alpha)) (see [1] for a result for all cases). Up to constants, this leads to the same equivalent as for gradient descent. See below for an illustration.\n\n\n\nComparison of asymptotic equivalent and performance of SGD in the interpolation regime for several replications for (\\omega=1).\n\nWe recover the results from [22] with a simpler and more direct proof, thereby obtaining asymptotic results that complement the non-asymptotic results from [23]. This is also a subcase of results from [24] with a simpler proof. Various extensions are possible, e.g., using averaging of iterates, or computing estimates of the variance of the performance (and not only its expectation); see [1] for details.\n\nConclusion\n\nIn this blog post, I have shown how the z-transform can be used to derive asymptotic equivalents of sequences that naturally appear in the optimization of quadratic forms, with classical tools such as acceleration and stochastic approximation. In all cases, the z-transform method allows simple computations of asymptotic equivalents (e.g., scaling laws) through the expansion of rational functions.\n\nSince quadratic functions are at the heart of optimization, many recent developments can be considered as candidates for the z-transform method, such as Richardson extrapolation, non-linear iterations for generic convex functions, time-varying coefficients beyond rational functions, mixing momentum techniques and SGD [26, 26], primal-dual algorithms, variance reduced methods, or sampling techniques. Many situations where the z-transform can prove useful!\n\nWhere does the “z” come from? For those questioning the naming of the z-transform, the wikipedia page has some interesting historical notes. The idea of using generating functions to study sequences dates back at least to De Moivre around 1730, while its first use in discrete engineering systems was done by Witold Hurewicz in 1947 using the letter “z” (to make it different from the letter “s” used for the Laplace transform (its continuous-time counterpart). The name z-transform was later coined in 1952 by John R. Ragazzini and Lofti Zadeh. As confirmed by a personal communication from Lofti Zadeh to Murat Arcak, It has nothing to do with the first letter of Loftis Zadeh’s name (“I used the letter z not because of my name but because in the mathematical literature on difference equations, z was the symbol that was used”). However, I didn’t find any formal confirmation that Zorro had nothing to do with it.\n\nAcknowledgements. I thank Adrien Taylor, Ayoub Melliti, Nicolas Flammarion, Baptiste Goujaud, and Raphaël Berthier for insightful discussions related to this work.\n\n\n\nReferences\n\n[1] Francis Bach. On the effectiveness of the z-transform method in quadratic optimization. Technical report, arXiv:2507.03404, 2025.\n[2] Godfrey H. Hardy and John E. Littlewood. Abel’s theorem and its converse. Proceedings of the London Mathematical Society, 2(1):205–235, 1920.\n[3] Jacob Korevaar. Tauberian Theory: A Century of Developments. Springer, 2004.\n[4] Philippe Flajolet and Andrew Odlyzko. Singularity analysis of generating functions. SIAM Journal on Discrete Mathematics, 3(2):216–240, 1990.\n[5] Edward A. Bender. Asymptotic methods in enumeration. SIAM Review, 16(4):485–515, 1974.\n[6] Eliahu Ibrahim Jury. Theory and Application of the z-Transform Method. Robert E. Krieger Publishing Company, 1964.\n[7] Herbert S. Wilf. Generatingfunctionology. CRC Press, 2005.\n[8] Raphaël Berthier, Francis Bach, and Pierre Gaillard. Accelerated gossip in networks of given dimension using Jacobi polynomial iterations. SIAM Journal on Mathematics of Data Science, 2(1):24–47, 2020.\n[9] Nicolas Flammarion and Francis Bach. From averaging to acceleration, there is only a step-size. Conference on Learning Theory, 2015.\n[10] David Vernon Widder. Laplace Transform. Princeton University Press, 1942.\n[11] Yurii Nesterov. A method for solving a convex programming problem with rate of convergence (O(1/k^2)). Soviet Mathematics. Doklady, 269(3):543–547, 1983.\n[12] Antonin Chambolle and Charles Dossal. On the convergence of the iterates of the “fast iterative shrinkage/thresholding algorithm”. Journal of Optimization theory and Applications, 166:968–982, 2015.\n[13] Jean-François Aujol, Charles Dossal, Hippolyte Labarrière, and Aude Rondepierre. Strong convergence of FISTA iterates under Hölderian and quadratic growth conditions. Technical Report 2407.17063, arXiv, 2024.\n[14] Neil Bershad. Analysis of the normalized LMS algorithm with Gaussian inputs. IEEE Transactions on Acoustics, Speech, and Signal Processing, 34(4):793–806, 1986.\n[15] Arie Feuer and Ehud Weinstein. Convergence analysis of LMS filters with uncorrelated Gaussian data. IEEE Transactions on Acoustics, Speech, and Signal Processing, 33(1):222–230, 2003.\n[16] Francis Bach and Eric Moulines. Non-strongly-convex smooth stochastic approximation with convergence rate (O(1/n)). Advances in Neural Information Processing Systems, 2013.\n[17] Alexandre Défossez and Francis Bach. Averaged least-mean-squares: Bias-variance trade-offs and optimal sampling distributions. International Conference on Artificial Intelligence and Statistics, 2015\n[18] Dirk T. M. Slock. On the convergence behavior of the LMS and the normalized LMS algorithms. IEEE Transactions on Signal Processing, 41(9):2811–2825, 1993.\n[19] Frederik Kunstner, Francis Bach. Scaling laws for gradient descent and sign descent for linear bigram models under Zipf’s law. Technical report, arXiv:2505.19227, 2025.\n[20] Larry L. Horowitz and Kenneth D. Senne. Performance advantage of complex LMS for controlling narrow-band adaptive arrays. IEEE Transactions on Circuits and Systems, 28(6):562–576, 1981.\n[21] Gene H. Golub. Some modified matrix eigenvalue problems. SIAM Review, 15(2):318–334, 1973.\n[22] Maksim Velikanov, Denis Kuznedelev, and Dmitry Yarotsky. A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions, benefit from negative momenta. International Conference on Learning Representations, 2023.\n[23] Raphaël Berthier, Francis Bach, and Pierre Gaillard. Tight nonparametric convergence rates for stochastic gradient descent under the noiseless linear model. Advances in Neural Information Processing Systems, 2020b.\n[24] Elliot Paquette, Courtney Paquette, Lechao Xiao, and Jeffrey Pennington. 4+3 phases of compute-optimal neural scaling laws. Advances in Neural Information Processing Systems, 2024.\n[25] Aditya Varre and Nicolas Flammarion. Accelerated SGD for non-strongly-convex least squares. In Conference on Learning Theory, 2022.\n[26] Damien Ferbach, Katie Everett, Gauthier Gidel, Elliot Paquette, and Courtney Paquette. Dimension-adapted momentum outscales SGD. Technical Report 2505.16098, arXiv, 2025.\n[27] Aymeric Dieuleveut, Nicolas Flammarion, Francis Bach. Harder, better, faster, stronger convergence rates for least-squares regression. Journal of Machine Learning Research, 18(101):1-51, 2017.\n\nBy Francis Bach\n\nRead original post\n"
    },
    
    {
      "title": "Decentralized Thoughts: 2-round BFT in Simplex style",
      "url": "/cstheoryrss/2025/07/18/decentralized-thoughts-2-round-bft-in-simplex-style/",
      "content": "Simplex is a recent partially synchronous Byzantine Fault Tolerant (BFT) protocol that is gaining popularity. We take this opportunity to rehash several classic results in the Simplex style. The first post explained the key difference between Simplex and Tendermint. This second post is on 2-round BFT. The next post will…\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Waiting is worth it and can be improved with predictions",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-waiting-is-worth-it-and-can-be-improved-with-predictions/",
      "content": "Authors: Ya-Chun Liang, Meng-Hsi Li, Chung-Shou Liao, Clifford Stein\n\nWe revisit the well-known online traveling salesman problem (OLTSP) and its\nextension, the online dial-a-ride problem (OLDARP). A server starting at a\ndesignated origin in a metric space, is required to serve online requests, and\nreturn to the origin such that the completion time is minimized. The SmartStart\nalgorithm, introduced by Ascheuer et al., incorporates a waiting approach into\nan online schedule-based algorithm and attains the optimal upper bound of 2 for\nthe OLTSP and the OLDARP if each schedule is optimal. Using the Christofides’\nheuristic to approximate each schedule leads to the currently best upper bound\nof (7 + sqrt(13)) / 4 approximately 2.6514 in polynomial time.\nIn this study, we investigate how an online algorithm with predictions, a\nrecent popular framework (i.e. the so-called learning-augmented algorithms),\ncan be used to improve the best competitive ratio in polynomial time. In\nparticular, we develop a waiting strategy with online predictions, each of\nwhich is only a binary decision-making for every schedule in a whole route,\nrather than forecasting an entire set of requests in the beginning (i.e.\noffline predictions). That is, it does not require knowing the number of\nrequests in advance. The proposed online schedule-based algorithm can achieve\n1.1514 * lambda + 1.5-consistency and 1.5 + 1.5 / (2.3028 * lambda -\n1)-robustness in polynomial time, where lambda lies in the interval (1/theta,\n1] and theta is set to (1 + sqrt(13)) / 2 approximately 2.3028. The best\nconsistency tends to approach to 2 when lambda is close to 1/theta. Meanwhile,\nwe show any online schedule-based algorithms cannot derive a competitive ratio\nof less than 2 even with perfect online predictions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The Price of Diversity of the Traveling Salesman Problem",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-the-price-of-diversity-of-the-traveling-salesman-problem/",
      "content": "Authors: Mark de Berg, Andrés López Martínez, Frits Spieksma\n\nThis paper introduces the concept of the “Price of Diversity” (PoD) in\ndiscrete optimization problems, quantifying the trade-off between solution\ndiversity and cost. For a minimization problem, the PoD is defined as the\nworst-case ratio, over all instances, of the minimum achievable cost of a\ndiverse set of $k$ solutions to the cost of a single optimal solution for the\nsame instance. Here, the cost of a $k$-solution set is determined by the most\nexpensive solution within the set. Focusing on the Traveling Salesman Problem\n(TSP) as a key example, we study the PoD in the setting where $k$ edge-disjoint\ntours are required. We establish that, asymptotically, the PoD of finding two\nedge-disjoint tours is $\\frac{8}{5}$ in a special one-dimensional case and 2 in\na general metric space. We obtain these results from analyzing a related\nfundamental problem: the Shortest Hamiltonian Path problem (SHP), for which we\nestablish similar results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Splittable Spanning Trees and Balanced Forests in Dense Random Graphs",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-splittable-spanning-trees-and-balanced-forests-in-dense-random-graphs/",
      "content": "Authors: David Gillman, Jacob Platnick, Dana Randall\n\nWeighted equitable partitioning of a graph has been of interest lately due to\nseveral applications, including redistricting, network algorithms, and image\ndecomposition. Weighting a partition according to the spanning-tree metric has\nbeen of mathematical and practical interest because it typically favors\npartitions with more compact pieces. An appealing algorithm suggested by\nCharikar et al. is to sample a random spanning tree and remove k-1 edges,\nproducing a random forest. If the components of the forest form a balanced\npartition, the partition is equitable under an easily computed acceptance\nprobability. Cannon et al. recently showed that spanning trees on grid graphs\nand grid-like graphs on $n$ vertices are splittable into $k$ equal sized pieces\nwith probability at least $n^{-2k}$, leading to the first rigorous sampling\nalgorithm for a class of graphs. We present complementary results showing that\nspanning trees on dense random graphs also have inverse polynomial probability\nof being splittable, giving another class of graphs where equitable partitions\ncan be efficiently sampled exactly. These proofs also guarantee fast\nalmost-uniform sampling for the up-down walk on forests, giving another\nprovably efficient randomized method for generating equitable partitions.\nFurther, we show that problems with the well-studied ReCom algorithm for\nequitable partitioning are more extensive than previously known, even in\nspecial cases that were believed to be more promising. We present a family of\ngraphs where the Markov chain fails to be irreducible when it must keep the\ncomponents perfectly equitable; yet when the chain is allowed an imbalance of\njust one vertex between components, the rejection sampling step may take\nexponential time. This is true even when the graph satisfies desirable\nproperties that have been conjectured to be sufficient for fast sampling.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Rounding for Set Cover under Subset Arrivals",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-online-rounding-for-set-cover-under-subset-arrivals/",
      "content": "Authors: Jarosław Byrka, Yongho Shin\n\nA rounding scheme for set cover has served as an important component in\ndesign of approximation algorithms for the problem, and there exists an\nH_s-approximate rounding scheme, where s denotes the maximum subset size,\ndirectly implying an approximation algorithm with the same approximation\nguarantee. A rounding scheme has also been considered under some online models,\nand in particular, under the element arrival model used as a crucial subroutine\nin algorithms for online set cover, an O(log s)-competitive rounding scheme is\nknown [Buchbinder, Chen, and Naor, SODA 2014]. On the other hand, under a more\ngeneral model, called the subset arrival model, only a simple O(log\nn)-competitive rounding scheme is known, where n denotes the number of elements\nin the ground set.\nIn this paper, we present an O(log^2 s)-competitive rounding scheme under the\nsubset arrival model, with one mild assumption that s is known upfront. Using\nour rounding scheme, we immediately obtain an O(log^2 s)-approximation\nalgorithm for multi-stage stochastic set cover, improving upon the existing\nalgorithms [Swamy and Shmoys, SICOMP 2012; Byrka and Srinivasan, SIDMA 2018]\nwhen s is small enough compared to the number of stages and the number of\nelements. Lastly, for set cover with s = 2, also known as edge cover, we\npresent a 1.8-competitive rounding scheme under the edge arrival model.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Max-Cut with Multiple Cardinality Constraints",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-max-cut-with-multiple-cardinality-constraints/",
      "content": "Authors: Yury Makarychev, Madhusudhan Reddy Pittu, Ali Vakilian\n\nWe study the classic Max-Cut problem under multiple cardinality constraints,\nwhich we refer to as the Constrained Max-Cut problem. Given a graph $G=(V, E)$,\na partition of the vertices into $c$ disjoint parts $V_1, \\ldots, V_c$, and\ncardinality parameters $k_1, \\ldots, k_c$, the goal is to select a set $S\n\\subseteq V$ such that $|S \\cap V_i| = k_i$ for each $i \\in [c]$, maximizing\nthe total weight of edges crossing $S$ (i.e., edges with exactly one endpoint\nin $S$).\nBy designing an approximate kernel for Constrained Max-Cut and building on\nthe correlation rounding technique of Raghavendra and Tan (2012), we present a\n$(0.858 - \\varepsilon)$-approximation algorithm for the problem when $c =\nO(1)$. The algorithm runs in time $O\\left(\\min{k/\\varepsilon,\nn}^{\\poly(c/\\varepsilon)} + \\poly(n)\\right)$, where $k = \\sum_{i \\in [c]} k_i$\nand $n=|V|$. This improves upon the $(\\frac{1}{2} +\n\\varepsilon_0)$-approximation of Feige and Langberg (2001) for $\\maxcut_k$ (the\nspecial case when $c=1, k_1 = k$), and generalizes the $(0.858 -\n\\varepsilon)$-approximation of Raghavendra and Tan (2012), which only applies\nwhen $\\min{k,n-k}=\\Omega(n)$ and does not handle multiple constraints.\nWe also establish that, for general values of $c$, it is NP-hard to determine\nwhether a feasible solution exists that cuts all edges. Finally, we present a\n$1/2$-approximation algorithm for Max-Cut under an arbitrary matroid\nconstraint.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Maintaining Routing Structures under Deletions via Self-Pruning",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-maintaining-routing-structures-under-deletions-via-self-pruning/",
      "content": "Authors: Bernhard Haeupler, Antti Roeyskoe\n\nExpanders are powerful algorithmic structures with two key properties: they\nare\na) routable: for any multi-commodity flow unit demand, there exists a routing\nwith low congestion over short paths, where a demand is unit if the amount of\ndemand sent / received by any vertex is at most the number of edges adjacent to\nit.\nb) stable / prunable: for any (sequence of) edge failures, there exists a\nproportionally small subset of vertices that can be disabled, such that the\ngraph induced on the remaining vertices is an expander.\nTwo natural algorithmic problems correspond to these two existential\nguarantees: expander routing, i.e. computing a low-congestion routing for a\nunit multi-commodity demand on an expander, and expander pruning, i.e.,\nmaintaining the subset of disabled vertices under a sequence of edge failures.\nThis paper considers the combination of the two problems: maintaining a\nrouting for a unit multi-commodity demand under pruning steps. This is done\nthrough the introduction of a family of expander graphs that, like hypercubes,\nare easy to route in, and are self-pruning: for an online sequence of edge\ndeletions, a simple self-contained algorithm can find a few vertices to prune\nwith each edge deletion, such that the remaining graph always remains an\neasy-to-route-in expander in the family.\nNotably, and with considerable technical work, this self-pruning can be made\nworst-case, i.e., such that every single adversarial deletion only causes a\nsmall number of additional deletions. Our results also allow tight\nconstant-factor control over the length of routing paths (with the usual\ntrade-offs in congestion and pruning ratio) and therefore extend to\nconstant-hop and length-constrained expanders in which routing over constant\nlength paths is crucial.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Kernelization for H-Coloring",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-kernelization-for-h-coloring/",
      "content": "Authors: Yael Berkman, Ishay Haviv\n\nFor a fixed graph $H$, the $H$-Coloring problem asks whether a given graph\nadmits an edge-preserving function from its vertex set to that of $H$. A\nseminal theorem of Hell and Ne\\v{s}et\\v{r}il asserts that the $H$-Coloring\nproblem is NP-hard whenever $H$ is loopless and non-bipartite. A result of\nJansen and Pieterse implies that for every graph $H$, the $H$-Coloring problem\nparameterized by the vertex cover number $k$ admits a kernel with\n$O(k^{\\Delta(H)})$ vertices and bit-size bounded by $O(k^{\\Delta(H)} \\cdot \\log\nk)$, where $\\Delta(H)$ denotes the maximum degree in $H$. For the case where\n$H$ is a complete graph on at least three vertices, this kernel size nearly\nmatches conditional lower bounds established by Jansen and Kratsch and by\nJansen and Pieterse.\nThis paper presents new upper and lower bounds on the kernel size of\n$H$-Coloring problems parameterized by the vertex cover number. The upper\nbounds arise from two kernelization algorithms. The first is purely\ncombinatorial, and its size is governed by a structural quantity of the graph\n$H$, called the non-adjacency witness number. As applications, we obtain\nkernels whose size is bounded by a fixed polynomial for natural classes of\ngraphs $H$ with unbounded maximum degree. More strikingly, we show that for\nalmost every graph $H$, the degree of the polynomial that bounds the size of\nour combinatorial kernel grows only logarithmically in $\\Delta(H)$. Our second\nkernel leverages linear-algebraic tools and involves the notion of faithful\nindependent representations of graphs. It strengthens the general bound from\nprior work and, among other applications, yields near-optimal kernels for\nproblems concerning the dimension of orthogonal graph representations over\nfinite fields. We complement these results with conditional lower bounds,\nthereby nearly settling the kernel complexity of the problem for various target\ngraphs $H$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fast Approximate Rank Determination and Selection with Group Testing",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-fast-approximate-rank-determination-and-selection-with-group-testing/",
      "content": "Authors: Adiesha Liyanage, Braeden Sopp, Brendan Mumey\n\nSuppose that a group test operation is available for checking order relations\nin a set, can this speed up problems like finding the minimum/maximum element,\nrank determination and selection? We consider a one-sided group test to be\navailable, where queries are of the form $u \\le_Q V$ or $V \\le_Q u$, and the\nanswer is `yes’ if and only if there is some $v \\in V$ such that $u \\le v$ or\n$v \\le u$, respectively. We restrict attention to total orders and focus on\nquery-complexity; for min or max finding, we give a Las Vegas algorithm that\nmakes $\\mathcal{O}(\\log^2 n)$ expected queries. We also give randomized\napproximate algorithms for rank determination and selection; we allow a\nrelative error of $1 \\pm \\delta$ for $\\delta &gt; 0$ in the estimated rank or\nselected element. In this case, we give a Monte Carlo algorithm for approximate\nrank determination with expected query complexity\n$\\tilde{\\mathcal{O}}(1/\\delta^2 - \\log \\epsilon)$, where $1-\\epsilon$ is the\nprobability that the algorithm succeeds. We also give a Monte Carlo algorithm\nfor approximate selection that has expected query complexity\n$\\tilde{\\mathcal{O}}(-\\log( \\epsilon \\delta^2) / \\delta^4)$; it has probability\nat least $\\frac{1}{2}$ to output an element $x$, and if so, $x$ has the desired\napproximate rank with probability $1-\\epsilon$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Efficiently Constructing Sparse Navigable Graphs",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-efficiently-constructing-sparse-navigable-graphs/",
      "content": "Authors: Alex Conway, Laxman Dhulipala, Martin Farach-Colton, Rob Johnson, Ben Landrum, Christopher Musco, Yarin Shechter, Torsten Suel, Richard Wen\n\nGraph-based nearest neighbor search methods have seen a surge of popularity\nin recent years, offering state-of-the-art performance across a wide variety of\napplications. Central to these methods is the task of constructing a sparse\nnavigable search graph for a given dataset endowed with a distance function.\nUnfortunately, doing so is computationally expensive, so heuristics are\nuniversally used in practice.\nIn this work, we initiate the study of fast algorithms with provable\nguarantees for search graph construction. For a dataset with $n$ data points,\nthe problem of constructing an optimally sparse navigable graph can be framed\nas $n$ separate but highly correlated minimum set cover instances. This yields\na naive $O(n^3)$ time greedy algorithm that returns a navigable graph whose\nsparsity is at most $O(\\log n)$ higher than optimal. We improve significantly\non this baseline, taking advantage of correlation between the set cover\ninstances to leverage techniques from streaming and sublinear-time set cover\nalgorithms. Combined with problem-specific pre-processing techniques, we\npresent an $\\tilde{O}(n^2)$ time algorithm for constructing an $O(\\log\nn)$-approximate sparsest navigable graph under any distance function.\nThe runtime of our method is optimal up to logarithmic factors under the\nStrong Exponential Time Hypothesis via a reduction from Monochromatic Closest\nPair. Moreover, we prove that, as with general set cover, obtaining better than\nan $O(\\log n)$-approximation is NP-hard, despite the significant additional\nstructure present in the navigable graph problem. Finally, we show that our\ntechniques can also beat cubic time for the closely related and practically\nimportant problems of constructing $\\alpha$-shortcut reachable and\n$\\tau$-monotonic graphs, which are also used for nearest neighbor search. For\nsuch graphs, we obtain $\\tilde{O}(n^{2.5})$ time or better algorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Efficient Semi-External Breadth-First Search",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-efficient-semi-external-breadth-first-search/",
      "content": "Authors: Xiaolong Wan, Xixian Han\n\nBreadth-first search (BFS) is known as a basic search strategy for learning\ngraph properties. As the scales of graph databases have increased tremendously\nin recent years, large-scale graphs G are often disk-resident. Obtaining the\nBFS results of G in semi-external memory model is inevitable, because the\nin-memory BFS algorithm has to maintain the entire G in the main memory, and\nexternal BFS algorithms consume high computational costs. As a good trade-off\nbetween the internal and external memory models, semi-external memory model\nassumes that the main memory can at least reside a spanning tree of G.\nNevertheless, the semi-external BFS problem is still an open issue due to its\ndifficulty. Therefore, this paper presents a comprehensive study for processing\nBFS in semi-external memory model. After discussing the naive solutions based\non the basic framework of semi-external graph algorithms, this paper presents\nan efficient algorithm, named EP-BFS, with a small minimum memory space\nrequirement, which is an important factor for evaluating semi-external\nalgorithms. Extensive experiments are conducted on both real and synthetic\nlarge-scale graphs, where graph WDC-2014 contains over 1.7 billion nodes, and\ngraph eu-2015 has over 91 billion edges. Experimental results confirm that\nEP-BFS can achieve up to 10 times faster.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-cut-matching-games-for-bipartiteness-ratio-of-undirected-graphs/",
      "content": "Authors: Tasuku Soma, Mingquan Ye, Yuichi Yoshida\n\nWe propose an $O(\\log n)$-approximation algorithm for the bipartiteness ratio\nfor undirected graphs introduced by Trevisan (SIAM Journal on Computing, vol.\n41, no. 6, 2012), where $n$ is the number of vertices. Our approach extends the\ncut-matching game framework for sparsest cut to the bipartiteness ratio. Our\nalgorithm requires only $\\mathrm{poly}\\log n$ many single-commodity undirected\nmaximum flow computations. Therefore, with the current fastest undirected\nmax-flow algorithms, it runs in nearly linear time. Along the way, we introduce\nthe concept of well-linkedness for skew-symmetric graphs and prove a novel\ncharacterization of bipartitness ratio in terms of well-linkedness in an\nauxiliary skew-symmetric graph, which may be of independent interest.\nAs an application, we devise an $\\tilde{O}(mn)$-time algorithm that given a\ngraph whose maximum cut deletes a $1-\\eta$ fraction of edges, finds a cut that\ndeletes a $1 - O(\\log n \\log(1/\\eta)) \\cdot \\eta$ fraction of edges, where $m$\nis the number of edges.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Computing and Bounding Equilibrium Concentrations in Athermic Chemical",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computing-and-bounding-equilibrium-concentrations-in-athermic-chemical/",
      "content": "Authors: Hamidreza Akef, Minki Hhan, David Soloveichik\n\nComputing equilibrium concentrations of molecular complexes is generally\nanalytically intractable and requires numerical approaches. In this work we\nfocus on the polymer-monomer level, where indivisible molecules (monomers)\ncombine to form complexes (polymers). Rather than employing free-energy\nparameters for each polymer, we focus on the athermic setting where all\ninteractions preserve enthalpy. This setting aligns with the strongly bonded\n(domain-based) regime in DNA nanotechnology when strands can bind in different\nways, but always with maximum overall bonding – and is consistent with the\nsaturated configurations in the Thermodynamic Binding Networks (TBNs) model.\nWithin this context, we develop an iterative algorithm for assigning polymer\nconcentrations to satisfy detailed-balance, where on-target (desired) polymers\nare in high concentrations and off-target (undesired) polymers are in low. Even\nif not directly executed, our algorithm provides effective insights into upper\nbounds on concentration of off-target polymers, connecting combinatorial\narguments about discrete configurations such as those in the TBN model to\nreal-valued concentrations. We conclude with an application of our method to\ndecreasing leak in DNA logic and signal propagation. Our results offer a new\nframework for design and verification of equilibrium concentrations when\nconfigurations are distinguished by entropic forces.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Computing and Bounding Equilibrium Concentrations in Athermic Chemical",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computing-and-bounding-equilibrium-concentrations-in-athermic-chemical-systems/",
      "content": "Authors: Hamidreza Akef, Minki Hhan, David Soloveichik\n\nComputing equilibrium concentrations of molecular complexes is generally\nanalytically intractable and requires numerical approaches. In this work we\nfocus on the polymer-monomer level, where indivisible molecules (monomers)\ncombine to form complexes (polymers). Rather than employing free-energy\nparameters for each polymer, we focus on the athermic setting where all\ninteractions preserve enthalpy. This setting aligns with the strongly bonded\n(domain-based) regime in DNA nanotechnology when strands can bind in different\nways, but always with maximum overall bonding – and is consistent with the\nsaturated configurations in the Thermodynamic Binding Networks (TBNs) model.\nWithin this context, we develop an iterative algorithm for assigning polymer\nconcentrations to satisfy detailed-balance, where on-target (desired) polymers\nare in high concentrations and off-target (undesired) polymers are in low. Even\nif not directly executed, our algorithm provides effective insights into upper\nbounds on concentration of off-target polymers, connecting combinatorial\narguments about discrete configurations such as those in the TBN model to\nreal-valued concentrations. We conclude with an application of our method to\ndecreasing leak in DNA logic and signal propagation. Our results offer a new\nframework for design and verification of equilibrium concentrations when\nconfigurations are distinguished by entropic forces.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Computational-Statistical Tradeoffs from NP-hardness",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-computational-statistical-tradeoffs-from-np-hardness/",
      "content": "Authors: Guy Blanc, Caleb Koch, Carmen Strassle, Li-Yang Tan\n\nA central question in computer science and statistics is whether efficient\nalgorithms can achieve the information-theoretic limits of statistical\nproblems. Many computational-statistical tradeoffs have been shown under\naverage-case assumptions, but since statistical problems are average-case in\nnature, it has been a challenge to base them on standard worst-case\nassumptions.\nIn PAC learning where such tradeoffs were first studied, the question is\nwhether computational efficiency can come at the cost of using more samples\nthan information-theoretically necessary. We base such tradeoffs on\n$\\mathsf{NP}$-hardness and obtain:\n$\\circ$ Sharp computational-statistical tradeoffs assuming $\\mathsf{NP}$\nrequires exponential time: For every polynomial $p(n)$, there is an $n$-variate\nclass $C$ with VC dimension $1$ such that the sample complexity of\ntime-efficiently learning $C$ is $\\Theta(p(n))$.\n$\\circ$ A characterization of $\\mathsf{RP}$ vs. $\\mathsf{NP}$ in terms of\nlearning: $\\mathsf{RP} = \\mathsf{NP}$ iff every $\\mathsf{NP}$-enumerable class\nis learnable with $O(\\mathrm{VCdim}(C))$ samples in polynomial time. The\nforward implication has been known since (Pitt and Valiant, 1988); we prove the\nreverse implication.\nNotably, all our lower bounds hold against improper learners. These are the\nfirst $\\mathsf{NP}$-hardness results for improperly learning a subclass of\npolynomial-size circuits, circumventing formal barriers of Applebaum, Barak,\nand Xiao (2008).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Analysis of Langevin midpoint methods using an anticipative Girsanov",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-analysis-of-langevin-midpoint-methods-using-an-anticipative-girsanov/",
      "content": "Authors: Matthew S. Zhang\n\nWe introduce a new method for analyzing midpoint discretizations of\nstochastic differential equations (SDEs), which are frequently used in Markov\nchain Monte Carlo (MCMC) methods for sampling from a target measure $\\pi\n\\propto \\exp(-V)$. Borrowing techniques from Malliavin calculus, we compute\nestimates for the Radon-Nikodym derivative for processes on $L^2([0, T);\n\\mathbb{R}^d)$ which may anticipate the Brownian motion, in the sense that they\nmay not be adapted to the filtration at the same time. Applying these to\nvarious popular midpoint discretizations, we are able to improve the regularity\nand cross-regularity results in the literature on sampling methods. We also\nobtain a query complexity bound of $\\widetilde{O}(\\frac{\\kappa^{5/4}\nd^{1/4}}{\\varepsilon^{1/2}})$ for obtaining a $\\varepsilon^2$-accurate sample\nin $\\mathsf{KL}$ divergence, under log-concavity and strong smoothness\nassumptions for $\\nabla^2 V$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Analysis of Langevin midpoint methods using an anticipative Girsanov",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-analysis-of-langevin-midpoint-methods-using-an-anticipative-girsanov-theorem/",
      "content": "Authors: Matthew S. Zhang\n\nWe introduce a new method for analyzing midpoint discretizations of\nstochastic differential equations (SDEs), which are frequently used in Markov\nchain Monte Carlo (MCMC) methods for sampling from a target measure $\\pi\n\\propto \\exp(-V)$. Borrowing techniques from Malliavin calculus, we compute\nestimates for the Radon-Nikodym derivative for processes on $L^2([0, T);\n\\mathbb{R}^d)$ which may anticipate the Brownian motion, in the sense that they\nmay not be adapted to the filtration at the same time. Applying these to\nvarious popular midpoint discretizations, we are able to improve the regularity\nand cross-regularity results in the literature on sampling methods. We also\nobtain a query complexity bound of $\\widetilde{O}(\\frac{\\kappa^{5/4}\nd^{1/4}}{\\varepsilon^{1/2}})$ for obtaining a $\\varepsilon^2$-accurate sample\nin $\\mathsf{KL}$ divergence, under log-concavity and strong smoothness\nassumptions for $\\nabla^2 V$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An EPTAS for multiprocessor scheduling with rejection under a machine",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-an-eptas-for-multiprocessor-scheduling-with-rejection-under-a-machine/",
      "content": "Authors: Mingyang Gong, Brendan Mumey\n\nWe study the multiprocessor scheduling with rejection problem under a machine\ncost constraint. In this problem, each job is either rejected with a rejection\npenalty or; accepted and scheduled on one of the machines for processing. The\nmachine cost is proportional to the total processing time of the jobs scheduled\non it. The problem aims to minimize the makespan of accepted jobs plus the\ntotal rejection penalty of rejected jobs while the total machine cost does not\nexceed a given upper bound. We present a simple $2$-approximation algorithm for\nthe problem and we achieve an EPTAS when the number $m$ of machines is a fixed\nconstant.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An EPTAS for multiprocessor scheduling with rejection under a machine",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-an-eptas-for-multiprocessor-scheduling-with-rejection-under-a-machine-cost-constraint/",
      "content": "Authors: Mingyang Gong, Brendan Mumey\n\nWe study the multiprocessor scheduling with rejection problem under a machine\ncost constraint. In this problem, each job is either rejected with a rejection\npenalty or; accepted and scheduled on one of the machines for processing. The\nmachine cost is proportional to the total processing time of the jobs scheduled\non it. The problem aims to minimize the makespan of accepted jobs plus the\ntotal rejection penalty of rejected jobs while the total machine cost does not\nexceed a given upper bound. We present a simple $2$-approximation algorithm for\nthe problem and we achieve an EPTAS when the number $m$ of machines is a fixed\nconstant.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A 1/2-Approximation for Budgeted k-Submodular Maximization",
      "url": "/cstheoryrss/2025/07/18/arxiv-data-structures-and-algorithms-a-1-2-approximation-for-budgeted-k-submodular-maximization/",
      "content": "Authors: Chenhao Wang\n\nA $k$-submodular function naturally generalizes submodular functions by\ntaking as input $k$ disjoint subsets, rather than a single subset. Unlike\nstandard submodular maximization, which only requires selecting elements for\nthe solution, $k$-submodular maximization adds the challenge of determining the\nsubset to which each selected element belongs. Prior research has shown that\nthe greedy algorithm is a 1/2-approximation for the monotone $k$-submodular\nmaximization problem under cardinality or matroid constraints. However, whether\na firm 1/2-approximation exists for the budgeted version (i.e., with a knapsack\nconstraint) has remained open for several years. We resolve this question\naffirmatively by proving that the 1-Guess Greedy algorithm, which first guesses\nan appropriate element from an optimal solution before proceeding with the\ngreedy algorithm, achieves a 1/2-approximation. This result is asymptotically\ntight as $((k+1)/(2k)+\\epsilon)$-approximation requires exponentially many\nvalue oracle queries even without constraints (Iwata et al., SODA 2016). We\nfurther show that 1-Guess Greedy is 1/3-approximation for the non-monotone\nproblem. This algorithm is both simple and parallelizable, making it\nwell-suited for practical applications. Using the thresholding technique from\n(Badanidiyuru and Vondrak, SODA 2014), it runs in nearly $\\tilde O(n^2k^2)$\ntime.\nThe proof idea is simple: we introduce a novel continuous transformation from\nan optimal solution to a greedy solution, using the multilinear extension to\nevaluate every fractional solution during the transformation. This continuous\nanalysis approach yields two key extensions. First, it enables improved\napproximation ratios of various existing algorithms. Second, our method\nnaturally extends to $k$-submodular maximization problems under broader\nconstraints, offering a more flexible and unified analysis framework.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Discrete Analog of Tutte's Barycentric Embeddings on Surfaces",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-geometry-a-discrete-analog-of-tutte-s-barycentric-embeddings-on-surfaces/",
      "content": "Authors: Éric Colin de Verdière, Vincent Despré, Loïc Dubois\n\nTutte’s celebrated barycentric embedding theorem describes a natural way to\nbuild straight-line embeddings (crossing-free drawings) of a (3-connected)\nplanar graph: map the vertices of the outer face to the vertices of a convex\npolygon, and ensure that each remaining vertex is in convex position, namely, a\nbarycenter with positive coefficients of its neighbors. Actually computing an\nembedding then boils down to solving a system of linear equations. A\nparticularly appealing feature of this method is the flexibility given by the\nchoice of the barycentric weights. Generalizations of Tutte’s theorem to\nsurfaces of nonpositive curvature are known, but due to their inherently\ncontinuous nature, they do not lead to an algorithm.\nIn this paper, we propose a purely discrete analog of Tutte’s theorem for\nsurfaces (with or without boundary) of nonpositive curvature, based on the\nrecently introduced notion of reducing triangulations. We prove a Tutte theorem\nin this setting: every drawing homotopic to an embedding such that each vertex\nis harmonious (a discrete analog of being in convex position) is a weak\nembedding (arbitrarily close to an embedding). We also provide a\npolynomial-time algorithm to make an input drawing harmonious without\nincreasing the length of any edge, in a similar way as a drawing can be put in\nconvex position without increasing the edge lengths.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: The Serial Scaling Hypothesis",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-complexity-the-serial-scaling-hypothesis/",
      "content": "Authors: Yuxi Liu, Konpat Preechakul, Kananart Kuwaranancharoen, Yutong Bai\n\nWhile machine learning has advanced through massive parallelization, we\nidentify a critical blind spot: some problems are fundamentally sequential.\nThese “inherently serial” problems-from mathematical reasoning to physical\nsimulations to sequential decision-making-require dependent computational steps\nthat cannot be parallelized. Drawing from complexity theory, we formalize this\ndistinction and demonstrate that current parallel-centric architectures face\nfundamental limitations on such tasks. We argue that recognizing the serial\nnature of computation holds profound implications on machine learning, model\ndesign, hardware development. As AI tackles increasingly complex reasoning,\ndeliberately scaling serial computation-not just parallel computation-is\nessential for continued progress.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Ranking Vectors Clustering: Theory and Applications",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-complexity-ranking-vectors-clustering-theory-and-applications/",
      "content": "Authors: Ali Fattahi, Ali Eshragh, Babak Aslani, Meysam Rabiee\n\nWe study the problem of clustering ranking vectors, where each vector\nrepresents preferences as an ordered list of distinct integers. Specifically,\nwe focus on the k-centroids ranking vectors clustering problem (KRC), which\naims to partition a set of ranking vectors into k clusters and identify the\ncentroid of each cluster. Unlike classical k-means clustering (KMC), KRC\nconstrains both the observations and centroids to be ranking vectors. We\nestablish the NP-hardness of KRC and characterize its feasible set. For the\nsingle-cluster case, we derive a closed-form analytical solution for the\noptimal centroid, which can be computed in linear time. To address the\ncomputational challenges of KRC, we develop an efficient approximation\nalgorithm, KRCA, which iteratively refines initial solutions from KMC, referred\nto as the baseline solution. Additionally, we introduce a branch-and-bound\n(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a\ndecision tree framework to reduce computational time while incorporating a\ncontrolling parameter to balance solution quality and efficiency. We establish\ntheoretical error bounds for KRCA and BnB. Through extensive numerical\nexperiments on synthetic and real-world datasets, we demonstrate that KRCA\nconsistently outperforms baseline solutions, delivering significant\nimprovements in solution quality with fast computational times. This work\nhighlights the practical significance of KRC for personalization and\nlarge-scale decision making, offering methodological advancements and insights\nthat can be built upon in future studies.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-complexity-formulaone-measuring-the-depth-of-algorithmic-reasoning-beyond/",
      "content": "Authors: Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua\n\nFrontier AI models demonstrate formidable breadth of knowledge. But how close\nare they to true human – or superhuman – expertise? Genuine experts can\ntackle the hardest problems and push the boundaries of scientific\nunderstanding. To illuminate the limits of frontier model capabilities, we turn\naway from contrived competitive programming puzzles, and instead focus on\nreal-life research problems.\nWe construct FormulaOne, a benchmark that lies at the intersection of graph\ntheory, logic, and algorithms, all well within the training distribution of\nfrontier models. Our problems are incredibly demanding, requiring an array of\nreasoning steps. The dataset has three key properties. First, it is of\ncommercial interest and relates to practical large-scale optimisation problems,\nsuch as those arising in routing, scheduling, and network design. Second, it is\ngenerated from the highly expressive framework of Monadic Second-Order (MSO)\nlogic on graphs, paving the way toward automatic problem generation at scale;\nideal for building RL environments. Third, many of our problems are intimately\nrelated to the frontier of theoretical computer science, and to central\nconjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As\nsuch, any significant algorithmic progress on our dataset, beyond known\nresults, could carry profound theoretical implications.\nRemarkably, state-of-the-art models like OpenAI’s o3 fail entirely on\nFormulaOne, solving less than 1% of the questions, even when given 10 attempts\nand explanatory fewshot examples – highlighting how far they remain from\nexpert-level understanding in some domains. To support further research, we\nadditionally curate FormulaOne-Warmup, offering a set of simpler tasks, from\nthe same distribution. We release the full corpus along with a comprehensive\nevaluation framework.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-complexity-formulaone-measuring-the-depth-of-algorithmic-reasoning-beyond-competitive-programming/",
      "content": "Authors: Gal Beniamini, Yuval Dor, Alon Vinnikov, Shir Granot Peled, Or Weinstein, Or Sharir, Noam Wies, Tomer Nussbaum, Ido Ben Shaul, Tomer Zekharya, Yoav Levine, Shai Shalev-Shwartz, Amnon Shashua\n\nFrontier AI models demonstrate formidable breadth of knowledge. But how close\nare they to true human – or superhuman – expertise? Genuine experts can\ntackle the hardest problems and push the boundaries of scientific\nunderstanding. To illuminate the limits of frontier model capabilities, we turn\naway from contrived competitive programming puzzles, and instead focus on\nreal-life research problems.\nWe construct FormulaOne, a benchmark that lies at the intersection of graph\ntheory, logic, and algorithms, all well within the training distribution of\nfrontier models. Our problems are incredibly demanding, requiring an array of\nreasoning steps. The dataset has three key properties. First, it is of\ncommercial interest and relates to practical large-scale optimisation problems,\nsuch as those arising in routing, scheduling, and network design. Second, it is\ngenerated from the highly expressive framework of Monadic Second-Order (MSO)\nlogic on graphs, paving the way toward automatic problem generation at scale;\nideal for building RL environments. Third, many of our problems are intimately\nrelated to the frontier of theoretical computer science, and to central\nconjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As\nsuch, any significant algorithmic progress on our dataset, beyond known\nresults, could carry profound theoretical implications.\nRemarkably, state-of-the-art models like OpenAI’s o3 fail entirely on\nFormulaOne, solving less than 1% of the questions, even when given 10 attempts\nand explanatory fewshot examples – highlighting how far they remain from\nexpert-level understanding in some domains. To support further research, we\nadditionally curate FormulaOne-Warmup, offering a set of simpler tasks, from\nthe same distribution. We release the full corpus along with a comprehensive\nevaluation framework.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Computational-Statistical Tradeoffs from NP-hardness",
      "url": "/cstheoryrss/2025/07/18/arxiv-computational-complexity-computational-statistical-tradeoffs-from-np-hardness/",
      "content": "Authors: Guy Blanc, Caleb Koch, Carmen Strassle, Li-Yang Tan\n\nA central question in computer science and statistics is whether efficient\nalgorithms can achieve the information-theoretic limits of statistical\nproblems. Many computational-statistical tradeoffs have been shown under\naverage-case assumptions, but since statistical problems are average-case in\nnature, it has been a challenge to base them on standard worst-case\nassumptions.\nIn PAC learning where such tradeoffs were first studied, the question is\nwhether computational efficiency can come at the cost of using more samples\nthan information-theoretically necessary. We base such tradeoffs on\n$\\mathsf{NP}$-hardness and obtain:\n$\\circ$ Sharp computational-statistical tradeoffs assuming $\\mathsf{NP}$\nrequires exponential time: For every polynomial $p(n)$, there is an $n$-variate\nclass $C$ with VC dimension $1$ such that the sample complexity of\ntime-efficiently learning $C$ is $\\Theta(p(n))$.\n$\\circ$ A characterization of $\\mathsf{RP}$ vs. $\\mathsf{NP}$ in terms of\nlearning: $\\mathsf{RP} = \\mathsf{NP}$ iff every $\\mathsf{NP}$-enumerable class\nis learnable with $O(\\mathrm{VCdim}(C))$ samples in polynomial time. The\nforward implication has been known since (Pitt and Valiant, 1988); we prove the\nreverse implication.\nNotably, all our lower bounds hold against improper learners. These are the\nfirst $\\mathsf{NP}$-hardness results for improperly learning a subclass of\npolynomial-size circuits, circumventing formal barriers of Applebaum, Barak,\nand Xiao (2008).\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: The unpredictability conundrum",
      "url": "/cstheoryrss/2025/07/17/ben-recht-the-unpredictability-conundrum/",
      "content": "\n\nScrolling through the deluge of people advertising their ICML papers on social media, I found myself bedeviled by a philosophical question about the logical reconstruction of machine learning. In the most famous machine learning papers, the central claims take the form:\n\nY is predictable from X, and method M demonstrates a particular accuracy on this prediction problem.\n\nThe AlexNet paper showed that ImageNet image classes were predictable from images, and a convolutional neural network achieved high accuracy. The GPT3 paper achieved high accuracy on a variety of natural language processing prediction problems with one-shot learning and transformer-based large language models. The Support Vector Network paper showed that support vector machines could recognize handwritten digits with high accuracy.\n\nIn these descriptions, I am being vague today about what precisely “X” and “Y” are. “X” could be streams of text, images, or electronic health records. “Y” could be translations, image classes, or cancer diagnoses. How papers build up these constructs and concepts also bugs me, but I will leave a full logical reconstruction of machine learning for another blog post.1\n\nToday, I am interested in understanding the papers that argue the negative claim and whether they ever provide useful evidence. That is, the papers that assert:\n\nY is not predictable from X.\n\nI call claims of this form “unpredictability arguments.” Papers making unpredictability arguments can get a lot of temporary traction in machine learning discourse. They give fuel to the petty battles inside the community. In our current landscape, they give ammunition for lay critiques of industry. They can even help bring on AI Winters if people take them seriously enough. The problem is they are much harder to justify as stated.\n\nUnpredictability arguments can be purely theoretical. These might say something like “under this list of assumptions about how data is generated and this list of assumptions about how you build the prediction function, Y is not predictable from X.” Such arguments can be helpful for conceptualization, but they are too strongly tied to their assumptions. Yes, simple linear perceptrons can’t build an XOR of input bits. But simple multilayer perceptrons can. Moreover, if your prediction function is allowed to include simple numerical transformations of the input data, all of a sudden XOR is predictable by linear functions (that is, just add XOR as a feature.).\n\nTheory bounds are weak because practitioners (and theorists for that matter) can simply change the rules. Yes, you can tell me that under some very contrived scenario, I can’t build a particular computer program. But machine learning practice is the apotheosis of computer science, fully embracing a Feyerabendian zeal for anything goes. I can always disagree with your assessment of how data is collected, generated, and processed. And there are an infinite number of computer programs I can write in PyTorch to disprove your unpredictability assertion.\n\nMinsky and Papert’s arguments that I’m alluding to above—about whether perceptrons can compute parity—are a notable exception that proves the rule. No one really understands their arguments, and if you believed them without really digging into the details or trying some simple alternative prediction programs, you would have abandoned supervised learning for decades (oh wait, that’s actually what happened).\n\nNow, what about experimental bounds? If someone writes a paper saying, “I did procedure P and found transformers were really bad at predicting Y from X,” what does this tell us? I’ve seen a lot of papers make such claims concerning LLMs and transformers. You’ll have people saying, “See, LLMs are stochastic parrots,” or “See, LLMs just learn epicycles.” In these papers, the predictability of the Y value is supposed to be obvious to the reader, and we’re supposed to be shocked that some machine learning model can’t predict it.\n\nSure, people can say all they want. As someone who wants better critiques of predictions, I’m never convinced by these papers, no matter how frequently they capture a viral zeitgeist. In the spirit of a Lakatosian offense, I can always counter by tweeting “your procedure is pretty arbitrary, my friend,” or “i don’t think that baseline is fair,” or “skill issue.” There is no reason to believe that the code shared in such papers is the only way for a method to predict Y from X. There is an infinite regress of hyperparameters, optimization variants, and so on. You only have so many forking paths you can explore in the garden before the conference deadline.\n\nMost people would find competitions to be more compelling evidence. Machine learning is built upon competitive testing, leading to breakthroughs in proving Y predictable from X. Everyone loves the ImageNet competition. Benchmark scores are a central part of how companies showcase their latest language models. Can competitive testing “prove” Y is unpredictable?\n\nWhat do we conclude when machine learning competitions fail? A notable example of failure is the Future of Families Challenge (formerly known as the Fragile Families Challenge). The goal here was to predict certain socioeconomic outcomes from complex, unstructured data recorded about a large birth cohort. After hundreds of researchers tried to predict the outcomes, the study concluded that the best predictions were not very accurate and were only slightly better than those from a simple benchmark model.”\n\nWhat should we conclude from this competition? We could conclude that the Ys in this paper (including “material hardship,” GPA, “grit,” and eviction) are not predictable from the Xs. I could also conclude that poor predictability arises because the data is far worse than advertised (e.g., there is a lot of missing data in the dataset). I could conclude that the targets studied have poor construct validity. There’s a long line of objections that I can string together even when a competitive test fails to find predictability.\n\nIn any event, I don’t have good answers for how to think about this aspect of the philosophy of machine learning yet. I’m very much thinking out loud today! But I’m posting because I’d love to hear your thoughts on what would constitute compelling evidence to prove the impossibility of prediction.\n\nSubscribe now\n\n1\n\nReally, it should be a paper. Let me know if you are soliciting invitations for special issues on the philosophy of engineering.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-098 | IPS Lower Bounds for Formulas and Sum of1 ROABPs |",
      "url": "/cstheoryrss/2025/07/17/eccc-papers-tr25-098-ips-lower-bounds-for-formulas-and-sum-of1-roabps/",
      "content": "We give new lower bounds for the fragments of the Ideal Proof System (IPS) introduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is a central topic in algebraic proof complexity developed in the context of Nullstellensatz refutation (Beame, Impagliazzo, Krajicek, Pitassi, Pudlak, FOCS 1994) and simulates Extended Frege efficiently. Our main results are as follows.\n\n  mult-IPS_{Lin’}: We prove nearly quadratic-size formula lower bound for multilinear refutation (over the Boolean hypercube) of a variant of the subset-sum axiom polynomial. Extending this, we obtain a nearly matching qualitative statement for a constant degree target polynomial.\n  IPS_{Lin’}: Over the fields of characteristic zero, we prove exponential-size sum-of-ROABPs lower bound for the refutation of a variant of the subset-sum axiom polynomial. The result also extends over the fields of positive characteristics when the target polynomial is suitably modified. The modification is inspired by the recent results (Hakoniemi, Limaye, Tzameret, STOC 2024 and Behera, Limaye, Ramanathan, Srinivasan, ICALP 2025).\nThe mult-IPS_{Lin’} lower bound result is obtained by combining the quadratic-size formula lower bound technique of Kalorkoti (SICOMP 1985) with some additional ideas. The proof technique of IPS_{Lin’} lower bound result is inspired by the recent lower bound result of Chatterjee, Kush, Saraf and Shpilka (CCC 2024).\n\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-098 | IPS Lower Bounds for Formulas and Sum of1 ROABPs |",
      "url": "/cstheoryrss/2025/07/17/eccc-papers-tr25-098-ips-lower-bounds-for-formulas-and-sum-of1-roabps-utsab-ghosal-prerona-chatterjee-partha-mukhopadhyay-amit-sinhababu/",
      "content": "We give new lower bounds for the fragments of the Ideal Proof System (IPS) introduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is a central topic in algebraic proof complexity developed in the context of Nullstellensatz refutation (Beame, Impagliazzo, Krajicek, Pitassi, Pudlak, FOCS 1994) and simulates Extended Frege efficiently. Our main results are as follows.\n\n  mult-IPS_{Lin’}: We prove nearly quadratic-size formula lower bound for multilinear refutation (over the Boolean hypercube) of a variant of the subset-sum axiom polynomial. Extending this, we obtain a nearly matching qualitative statement for a constant degree target polynomial.\n  IPS_{Lin’}: Over the fields of characteristic zero, we prove exponential-size sum-of-ROABPs lower bound for the refutation of a variant of the subset-sum axiom polynomial. The result also extends over the fields of positive characteristics when the target polynomial is suitably modified. The modification is inspired by the recent results (Hakoniemi, Limaye, Tzameret, STOC 2024 and Behera, Limaye, Ramanathan, Srinivasan, ICALP 2025).\nThe mult-IPS_{Lin’} lower bound result is obtained by combining the quadratic-size formula lower bound technique of Kalorkoti (SICOMP 1985) with some additional ideas. The proof technique of IPS_{Lin’} lower bound result is inspired by the recent lower bound result of Chatterjee, Kush, Saraf and Shpilka (CCC 2024).\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Weighted k-Server Admits an Exponentially Competitive Algorithm",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-weighted-k-server-admits-an-exponentially-competitive-algorithm/",
      "content": "Authors: Adithya Bijoy, Ankit Mondal, Ashish Chiplunkar\n\nThe weighted $k$-server is a variant of the $k$-server problem, where the\ncost of moving a server is the server’s weight times the distance through which\nit moves. The problem is famous for its intriguing properties and for evading\nstandard techniques for designing and analyzing online algorithms. Even on\nuniform metric spaces with sufficiently many points, the deterministic\ncompetitive ratio of weighted $k$-server is known to increase doubly\nexponentially with respect to $k$, while the behavior of its randomized\ncompetitive ratio is not fully understood. Specifically, no upper bound better\nthan doubly exponential is known, while the best known lower bound is singly\nexponential in $k$. In this paper, we close the exponential gap between these\nbounds by giving an $\\exp(O(k^2))$-competitive randomized online algorithm for\nthe weighted $k$-server problem on uniform metrics, thus breaking the doubly\nexponential barrier for deterministic algorithms for the first time. This is\nachieved by a recursively defined notion of a phase which, on the one hand,\nforces a lower bound on the cost of any offline solution, while, on the other\nhand, also admits a randomized online algorithm with bounded expected cost. The\nalgorithm is also recursive; it involves running several algorithms virtually\nand in parallel and following the decisions of one of them in a random order.\nWe also show that our techniques can be lifted to construct an\n$\\exp(O(k^2))$-competitive randomized online algorithm for the generalized\n$k$-server problem on weighted uniform metrics.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Pathfinding in Self-Deleting Graphs",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-pathfinding-in-self-deleting-graphs/",
      "content": "Authors: Michal Dvořák, Dušan Knop, Michal Opler, Jan Pokorný, Ondřej Suchý, Krisztina Szilágyi\n\nIn this paper, we study the problem of pathfinding on traversal-dependent\ngraphs, i.e., graphs whose edges change depending on the previously visited\nvertices. In particular, we study \\emph{self-deleting graphs}, introduced by\nCarmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich,\nand Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson\nproblems with traversal-dependent edge deletion. J. Comput. Sci.), which\nconsist of a graph $G=(V, E)$ and a function $f\\colon V\\rightarrow 2^E$, where\n$f(v)$ is the set of edges that will be deleted after visiting the vertex $v$.\nIn the \\textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a\nself-deleting graph and its vertices $s$ and $t$, and we are asked to find a\n(shortest) path from $s$ to $t$, such that it does not traverse an edge in\n$f(v)$ after visiting $v$ for any vertex $v$.\nWe prove that \\textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the\ngiven graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$\nand $|f(v)|\\leq 1$ for each vertex $v$. We show that \\textsc{Shortest\nSelf-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the\nsought path and that \\textsc{Self-Deleting $s$-$t$-path} is \\W{1}-complete\nparameterized by the vertex cover number, feedback vertex set number and\ntreedepth. We also show that the problem becomes FPT when we parameterize by\nthe maximum size of $f(v)$ and several structural parameters. Lastly, we show\nthat the problem does not admit a polynomial kernel even for parameterization\nby the vertex cover number and the maximum size of $f(v)$ combined already on\n2-outerplanar graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Block Packing",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-online-block-packing/",
      "content": "Authors: Ariel Ben Eliezer, Noam Nisan\n\nWe consider the algorithmic challenge that is faced by blockchains that have\nmultidimensional block constraints and serve quasi-patient bidders. We provide\nonline approximation algorithms for this problem, thus solving open problems\nleft by [Babaioff and Nisan, EC 2025].\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Kernelization for list H-coloring for graphs with small vertex cover",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-kernelization-for-list-h-coloring-for-graphs-with-small-vertex-cover/",
      "content": "Authors: Marta Piecyk, Astrid Pieterse, Paweł Rzążewski, Magnus Wahlström\n\nFor a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph\n$G$ along with list $L(v) \\subseteq V(H)$ for every $v \\in V(G)$, and we have\nto determine if there exists a list homomorphism $\\varphi$ from $(G,L)$ to $H$,\ni.e., an edge preserving mapping $\\varphi: V(G)\\to V(H)$ that satisfies\n$\\varphi(v)\\in L(v)$ for every $v\\in V(G)$. Note that if $H$ is the complete\ngraph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We\ninvestigate the kernelization properties of List $H$-Coloring parameterized by\nthe vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of\n$G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G’,L’)$ of\nList $H$-Coloring where the size of $G’$ is bounded by a low-degree polynomial\n$p(k)$ in $k$? This question has been investigated previously by Jansen and\nPieterse [Algorithmica 2019], who provided an upper bound, which turns out to\nbe optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result\nwas one of the first applications of the method of kernelization via\nbounded-degree polynomials. We define two new integral graph invariants,\n$c^*(H)$ and $d^*(H)$, with $d^*(H) \\leq c^*(H) \\leq d^*(H)+1$, and show that\nfor every graph $H$, List $H$-Coloring\n– has a kernel with $\\mathcal{O}(k^{c^*(H)})$ vertices,\n– admits no kernel of size $\\mathcal{O}(k^{d^*(H)-\\varepsilon})$ for any\n$\\varepsilon &gt; 0$, unless the polynomial hierarchy collapses.\n– Furthermore, if $c^*(H) &gt; d^*(H)$, then there is a kernel with\n$\\mathcal{O}(k^{c^*(H)-\\varepsilon})$ vertices where $\\varepsilon \\geq\n2^{1-c^*(H)}$.\nAdditionally, we show that for some classes of graphs, including powers of\ncycles and graphs $H$ where $\\Delta(H) \\leq c^*(H)$ (which in particular\nincludes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We\nconjecture that this holds in general.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Finite Pinwheel Scheduling: the k-Visits Problem",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-finite-pinwheel-scheduling-the-k-visits-problem/",
      "content": "Authors: Sotiris Kanellopoulos, Christos Pergaminelis, Maria Kokkou, Euripides Markou, Aris Pagourtzis\n\nPinwheel Scheduling is a fundamental scheduling problem, in which each task\n$i$ is associated with a positive integer $d_i$, and the objective is to\nschedule one task per time slot, ensuring each task perpetually appears at\nleast once in every $d_i$ time slots. Although conjectured to be\nPSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless\na compact input encoding is used) or even contained in NP.\nWe introduce k-Visits, a finite version of Pinwheel Scheduling, where given n\ndeadlines, the goal is to schedule each task exactly k times. While we observe\nthat the 1-Visit problem is trivial, we prove that 2-Visits is strongly\nNP-complete through a surprising reduction from Numerical 3-Dimensional\nMatching (N3DM). As intermediate steps in the reduction, we define NP-complete\nvariants of N3DM which may be of independent interest. We further extend our\nstrong NP-hardness result to a generalization of k-Visits $k\\geq 2$ in which\nthe deadline of each task may vary throughout the schedule, as well as to a\nsimilar generalization of Pinwheel Scheduling, thus making progress towards\nsettling the complexity of Pinwheel Scheduling.\nAdditionally, we prove that 2-Visits can be solved in linear time if all\ndeadlines are distinct, rendering it one of the rare natural problems which\nexhibit the interesting dichotomy of being in P if their input is a set and\nNP-complete if the input is a multiset. We achieve this through a Turing\nreduction from 2-Visits to a variation of N3DM, which we call Position\nMatching. Based on this reduction, we also show an FPT algorithm for 2-Visits\nparameterized by a value related to how close the input deadlines are to each\nother, as well as a linear-time algorithm for instances with up to two distinct\ndeadlines.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: FastReChain: Highly Responsive and Low-Overhead Centralized Route",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-fastrechain-highly-responsive-and-low-overhead-centralized-route-scheduling-in-clos-datacenter-networks/",
      "content": "Authors: Zihan Zhu, Dongchao Wu, Zhanbang Zhang, Jian Yang\n\nEver since Clos topologies were used in datacenter networks (DCNs), a\npractical centralized scheduling algorithm that supports dynamic scheduling has\nbeen absent. The introduction of optical switches in DCNs as a future-proof\nsolution exacerbates this problem due to several properties of optical\nswitches, such as the fact that they are generally bufferless and therefore\nrely on centralized scheduling, and that they have long switching times and\ntherefore require the number of rearrangements to be minimized.\nIn this paper, we propose a centralized scheduling algorithm that achieves\ntheoretical maximum throughput even in one-rate bidirectional Clos networks,\nwhile producing schemes with near-minimal numbers of rearrangements. It is the\nonly algorithm that directly supports bidirectional Clos networks and has a\ntime efficiency high enough to support dynamic scheduling to date. For static\nminimal rewiring, its running time ranges from a fraction to a few hundredths\nof other algorithms, and the number of rearrangements has also been steadily\nimproved, allowing for more frequent adjustments and less impact on ongoing\ncommunications. In addition, the algorithm is very flexible and can support\nvarious functional requirements in real-world environments. We achieve this\nresult through the replacement chain concept and bitset optimization.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Approaching Optimality for Solving Dense Linear Systems with Low-Rank",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-approaching-optimality-for-solving-dense-linear-systems-with-low-rank-structure/",
      "content": "Authors: Michał Dereziński, Aaron Sidford\n\nWe provide new high-accuracy randomized algorithms for solving linear systems\nand regression problems that are well-conditioned except for $k$ large singular\nvalues. For solving such $d \\times d$ positive definite system our algorithms\nsucceed whp. and run in time $\\tilde O(d^2 + k^\\omega)$. For solving such\nregression problems in a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ our\nmethods succeed whp. and run in time $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 +\nk^\\omega)$ where $\\omega$ is the matrix multiplication exponent and\n$\\mathrm{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. Our\nmethods nearly-match a natural complexity limit under dense inputs for these\nproblems and improve upon a trade-off in prior approaches that obtain running\ntimes of either $\\tilde O(d^{2.065}+k^\\omega)$ or $\\tilde O(d^2 +\ndk^{\\omega-1})$ for $d\\times d$ systems. Moreover, we show how to obtain these\nrunning times even under the weaker assumption that all but $k$ of the singular\nvalues have a suitably bounded generalized mean. Consequently, we give the\nfirst nearly-linear time algorithm for computing a multiplicative approximation\nto the nuclear norm of an arbitrary dense matrix. Our algorithms are built on\nthree general recursive preconditioning frameworks, where matrix sketching and\nlow-rank update formulas are carefully tailored to the problems’ structure.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A near-complete resolution of the exponential-time complexity of k-opt",
      "url": "/cstheoryrss/2025/07/17/arxiv-data-structures-and-algorithms-a-near-complete-resolution-of-the-exponential-time-complexity-of-k-opt-for-the-traveling-salesman-problem/",
      "content": "Authors: Sophia Heimann, Hung P. Hoang, Stefan Hougardy\n\nThe $k$-opt algorithm is one of the simplest and most widely used heuristics\nfor solving the traveling salesman problem. Starting from an arbitrary tour,\nthe $k$-opt algorithm improves the current tour in each iteration by exchanging\nup to $k$ edges. The algorithm continues until no further improvement of this\nkind is possible. For a long time, it remained an open question how many\niterations the $k$-opt algorithm might require for small values of $k$,\nassuming the use of an optimal pivot rule. In this paper, we resolve this\nquestion for the cases $k = 3$ and $k = 4$ by proving that in both these cases\nan exponential number of iterations may be needed even if an optimal pivot rule\nis used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP\n2024), this provides a complete answer for all $k \\geq 3$ regarding the number\nof iterations the $k$-opt algorithm may require under an optimal pivot rule. In\naddition we establish an analogous exponential lower bound for the 2.5-opt\nalgorithm, a variant that generalizes 2-opt and is a restricted version of\n3-opt. All our results hold for both the general and the metric traveling\nsalesman problem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Which graph motif parameters count?",
      "url": "/cstheoryrss/2025/07/17/arxiv-computational-complexity-which-graph-motif-parameters-count/",
      "content": "Authors: Markus Bläser, Radu Curticapean, Julian Dörfler, Christian Ikenmeyer\n\nFor a fixed graph H, the function #IndSub(H,*) maps graphs G to the count of\ninduced H-copies in G; this function obviously “counts something” in that it\nhas a combinatorial interpretation. Linear combinations of such functions are\ncalled graph motif parameters and have recently received significant attention\nin counting complexity after a seminal paper by Curticapean, Dell and Marx\n(STOC’17). We show that, among linear combinations of functions #IndSub(H,*)\ninvolving only graphs H without isolated vertices, precisely those with\npositive integer coefficients maintain a combinatorial interpretation. It is\nimportant to note that graph motif parameters can be nonnegative for all inputs\nG, even when some coefficients are negative.\nFormally, we show that evaluating any graph motif parameter with a negative\ncoefficient is impossible in an oracle variant of #P, where an implicit graph\nis accessed by oracle queries. Our proof follows the classification of the\nrelativizing closure properties of #P by Hertrampf, Vollmer, and Wagner\n(SCT’95) and the framework developed by Ikenmeyer and Pak (STOC’22), but our\napplication of the required Ramsey theorem turns out to be more subtle, as\ngraphs do not have the required Ramsey property.\nOur techniques generalize from graphs to relational structures, including\ncolored graphs. Vastly generalizing this, we introduce motif parameters over\ncategories that count occurrences of sub-objects in the category. We then prove\na general dichotomy theorem that characterizes which such parameters have a\ncombinatorial interpretation. Using known results in Ramsey theory for\ncategories, we obtain a dichotomy for motif parameters of finite vector spaces\nas well as parameter sets.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Searching for Falsified Clause in Random (log n)-CNFs is Hard for",
      "url": "/cstheoryrss/2025/07/17/arxiv-computational-complexity-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for/",
      "content": "Authors: Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov, Weiqiang Yuan\n\nWe show that for a randomly sampled unsatisfiable $O(\\log n)$-CNF over $n$\nvariables the randomized two-party communication cost of finding a clause\nfalsified by the given variable assignment is linear in $n$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Searching for Falsified Clause in Random log n-CNFs is Hard for",
      "url": "/cstheoryrss/2025/07/17/arxiv-computational-complexity-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for-randomized-communication/",
      "content": "Authors: Artur Riazanov, Anastasia Sofronova, Dmitry Sokolov, Weiqiang Yuan\n\nWe show that for a randomly sampled unsatisfiable $O(\\log n)$-CNF over $n$\nvariables the randomized two-party communication cost of finding a clause\nfalsified by the given variable assignment is linear in $n$.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-097 | On the Limits of Computationally Sound IPPs in the Isolated Model |",
      "url": "/cstheoryrss/2025/07/16/eccc-papers-tr25-097-on-the-limits-of-computationally-sound-ipps-in-the-isolated-model-hadar-strauss/",
      "content": "Interactive proofs of proximity (IPPs) are a relaxation of interactive proofs, analogous to property testing, in which soundness is required to hold only for inputs that are far from the property being verified. In such proof systems, the verifier has oracle access to the input, and it engages in two types of activities before making its decision: querying the input oracle and communicating with the prover. The main objective is to achieve protocols where both the query and communication complexities are extremely low.\nOf particular interest are IPPs in which the querying and the interacting activities are performed independently, with no information flow from one activity to the other. Such IPPs were systematically studied by Goldreich, Rothblum, and Skverer (ITCS 2023), who introduced two variants: the pre-coordinated model, where the querying and interacting activities may use a common source of randomness, and the isolated model, where the two activities are fully independent, each operating with a separate source of randomness.\nWe focus on what is possible under these models when soundness is relaxed to computational soundness. Our previous work (ECCC, TR24-131) showed that the pre-coordinated model becomes significantly more powerful under this relaxation. In this work, we consider the isolated model under the same relaxation and show a separation between the two models. We consider a property that, by our previous work, has a computationally sound IPP in the pre-coordinated model with poly-logarithmic complexities (assuming the existence of collision-resistant hashing functions), and show that any computationally sound IPP in the isolated model for this property must have either query complexity or communication complexity that is $n^{\\Omega(1)}$, where $n$ is the length of the input.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: Turing, Wagner, Ruth",
      "url": "/cstheoryrss/2025/07/16/computational-complexity-turing-wagner-ruth/",
      "content": "Douglas Hofstadter first published Gödel, Escher, Bach: an Eternal Golden Braid in 1979 and my then high school self tried, and failed, to read though the entire book. It focused on the contradictions, with Kurt Gödel’s incompleteness theorems, M. C. Escher’s Drawing Hands and Johann Sebastian Bach’s Canon a 2 per tonos, a piece that keeps rising until it ends a whole tone higher than it started.\n\nI’d prefer to focus less on the paradoxes and self-reference to the true beauty and complexity of computation. So now having had a long career in the field, who would I call on to capture the power and beauty of computing?\n\nIt has to start with Alan Turing. His seminal paper On Computable Numbers, with an Application to the Entscheidungsproblem gives a clean model for computation and still the best argument (Section 9) for why this simple model captures everything computable. The Entscheidungsproblem, that you can’t mechanize all of mathematics, comes as a consequence, not as a goal of the paper. In a much later paper, The Chemical Basis of Morphogenesis, he shows how the beauty of nature can emerge naturally from computation, which of course we now know much better arises from discrete DNA sequences.\n\nFor music, instead of Bach’s abstract works, I prefer to focus on the emotional power of music that still arises from a musical score that is not unlike a computer program in the way it lays out the composition. Take for example Richard Wagner’s Prelude and Liebestod (the beginning and the end of his opera Tristan and Isolde). It captures the tension of the two lovers from the very first notes and keeps that tension going until it resolves at the very end.\n\nWhile soccer and basketball have mostly continuous play, I prefer that great American game of baseball that after each pitch has a very discrete state space that stadiums would capture with a few light bulbs (strikes, balls, outs), and yet could keep the excitement and tension on every one of those pitches. No one dominated the game more in his time than George Herman “Babe” Ruth, who I might have admittedly also chose to keep the same syllable cadence as Hofstadter.\n\nSo let’s thank Turing, Wagner, Ruth, and the many others that showed we can show how incredible complexity and beauty can arise in the simplicity of computation. So many stories to tell.\n\nBy Lance Fortnow\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-096 | Searching for Falsified Clause in Random log{n}-CNFs is Hard for Randomized Communication |",
      "url": "/cstheoryrss/2025/07/16/eccc-papers-tr25-096-searching-for-falsified-clause-in-random-log-n-cnfs-is-hard-for-randomized-communication-artur-riazanov-anastasia-sofronova-dmitry-sokolov-weiqiang-yuan/",
      "content": "We show that for a randomly sampled unsatisfiable $O(\\log n)$-CNF over $n$ variables the randomized two-party communication cost of finding a clause falsified by the given variable assignment is linear in $n$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Solving Random Planted CSPs below the n{k/2} Threshold",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-solving-random-planted-csps-below-the-n-k-2-threshold/",
      "content": "Authors: Arpon Basu, Jun-Ting Hsieh, Andrew D. Lin, Peter Manohar\n\nWe present a family of algorithms to solve random planted instances of any\n$k$-ary Boolean constraint satisfaction problem (CSP). A randomly planted\ninstance of a Boolean CSP is generated by (1) choosing an arbitrary planted\nassignment $x^*$, and then (2) sampling constraints from a particular “planting\ndistribution” designed so that $x^*$ will satisfy every constraint. Given an\n$n$ variable instance of a $k$-ary Boolean CSP with $m$ constraints, our\nalgorithm runs in time $n^{O(\\ell)}$ for a choice of a parameter $\\ell$, and\nsucceeds in outputting a satisfying assignment if $m \\geq O(n) \\cdot\n(n/\\ell)^{\\frac{k}{2} - 1} \\log n$. This generalizes the\n$\\mathrm{poly}(n)$-time algorithm of [FPV15], the case of $\\ell = O(1)$, to\nlarger runtimes, and matches the constraint number vs.\\ runtime trade-off\nestablished for refuting random CSPs by [RRS17].\nOur algorithm is conceptually different from the recent algorithm of\n[GHKM23], which gave a $\\mathrm{poly}(n)$-time algorithm to solve semirandom\nCSPs with $m \\geq \\tilde{O}(n^{\\frac{k}{2}})$ constraints by exploiting\nconditions that allow a basic SDP to recover the planted assignment $x^*$\nexactly. Instead, we forego certificates of uniqueness and recover $x^*$ in two\nsteps: we first use a degree-$O(\\ell)$ Sum-of-Squares SDP to find some\n$\\hat{x}$ that is $o(1)$-close to $x^*$, and then we use a second rounding\nprocedure to recover $x^*$ from $\\hat{x}$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Solving Linear Programs with Differential Privacy",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-solving-linear-programs-with-differential-privacy/",
      "content": "Authors: Alina Ene, Huy Le Nguyen, Ta Duy Nguyen, Adrian Vladu\n\nWe study the problem of solving linear programs of the form $Ax\\le b$,\n$x\\ge0$ with differential privacy. For homogeneous LPs $Ax\\ge0$, we give an\nefficient $(\\epsilon,\\delta)$-differentially private algorithm which with\nprobability at least $1-\\beta$ finds in polynomial time a solution that\nsatisfies all but\n$O(\\frac{d^{2}}{\\epsilon}\\log^{2}\\frac{d}{\\delta\\beta}\\sqrt{\\log\\frac{1}{\\rho_{0}}})$\nconstraints, for problems with margin $\\rho_{0}&gt;0$. This improves the bound of\n$O(\\frac{d^{5}}{\\epsilon}\\log^{1.5}\\frac{1}{\\rho_{0}}\\mathrm{poly}\\log(d,\\frac{1}{\\delta},\\frac{1}{\\beta}))$\nby [Kaplan-Mansour-Moran-Stemmer-Tur, STOC ‘25]. For general LPs $Ax\\le b$,\n$x\\ge0$ with potentially zero margin, we give an efficient\n$(\\epsilon,\\delta)$-differentially private algorithm that w.h.p drops\n$O(\\frac{d^{4}}{\\epsilon}\\log^{2.5}\\frac{d}{\\delta}\\sqrt{\\log dU})$\nconstraints, where $U$ is an upper bound for the entries of $A$ and $b$ in\nabsolute value. This improves the result by Kaplan et al. by at least a factor\nof $d^{5}$. Our techniques build upon privatizing a rescaling perceptron\nalgorithm by [Hoberg-Rothvoss, IPCO ‘17] and a more refined iterative procedure\nfor identifying equality constraints by Kaplan et al.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Scheduling on Identical Machines with Setup Time and Unknown Execution",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-scheduling-on-identical-machines-with-setup-time-and-unknown-execution-time/",
      "content": "Authors: Yasushi Kawase, Kazuhisa Makino, Vinh Long Phan, Hanna Sumita\n\nIn this study, we investigate a scheduling problem on identical machines in\nwhich jobs require initial setup before execution. We assume that an algorithm\ncan dynamically form a batch (i.e., a collection of jobs to be processed\ntogether) from the remaining jobs. The setup time is modeled as a known\nmonotone function of the set of jobs within a batch, while the execution time\nof each job remains unknown until completion. This uncertainty poses\nsignificant challenges for minimizing the makespan. We address these challenges\nby considering two scenarios: each job batch must be assigned to a single\nmachine, or a batch may be distributed across multiple machines. For both\nscenarios, we analyze settings with and without preemption. Across these four\nsettings, we design online algorithms that achieve asymptotically optimal\ncompetitive ratios with respect to both the number of jobs and the number of\nmachines.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Rapid Mixing of Glauber Dynamics for Monotone Systems via Entropic",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-rapid-mixing-of-glauber-dynamics-for-monotone-systems-via-entropic-independence/",
      "content": "Authors: Weiming Feng, Minji Yang\n\nWe study the mixing time of Glauber dynamics on monotone systems. For\nmonotone systems satisfying the entropic independence condition, we prove a new\nmixing time comparison result for Glauber dynamics. For concrete applications,\nwe obtain $\\tilde{O}(n)$ mixing time for the random cluster model induced by\nthe ferromagnetic Ising model with consistently biased external fields, and\n$\\tilde{O}(n^2)$ mixing time for the bipartite hardcore model under the\none-sided uniqueness condition, where $n$ is the number of variables in\ncorresponding models, improving the best known results in [Chen and Zhang,\nSODA’23] and [Chen, Liu, and Yin, FOCS’23], respectively.\nOur proof combines ideas from the stochastic dominance argument in the\nclassical censoring inequality and the recently developed high-dimensional\nexpanders. The key step in the proof is a novel comparison result between the\nGlauber dynamics and the field dynamics for monotone systems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Permutation patterns in streams",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-permutation-patterns-in-streams/",
      "content": "Authors: Benjamin Aram Berendsohn\n\nPermutation patterns and pattern avoidance are central, well-studied concepts\nin combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$,\nthe pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This\nproblem arises in various contexts in computer science and statistics and has\nbeen studied extensively in exact-, parameterized-, approximate-,\nproperty-testing- and other formulations.\nIn this paper, we study pattern matching in a \\emph{streaming setting}, when\nthe input $\\tau$ is revealed sequentially, one element at a time. There is\nextensive work on the space complexity of various statistics in streams of\nintegers. The novelty of our setting is that the input stream is \\emph{a\npermutation}, which allows inferring some information about future inputs. Our\nalgorithms crucially take advantage of this fact, while existing lower bound\ntechniques become difficult to apply.\nWe show that the complexity of the problem changes dramatically depending on\nthe pattern~$\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the\nmonotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$\nfor $\\pi \\in {312,132}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in {231,213}$, and\n$\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary\nsequence of integers (not necessary a permutation), we show that the complexity\nis $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On Tight Robust Coresets for k-Medians Clustering",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-on-tight-robust-coresets-for-k-medians-clustering/",
      "content": "Authors: Lingxiao Huang, Zhenyu Jiang, Yi Li, Xuan Wu\n\nThis paper considers coresets for the robust $k$-medians problem with $m$\noutliers, and new constructions in various metric spaces are obtained.\nSpecifically, for metric spaces with a bounded VC or doubling dimension $d$,\nthe coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up\nto logarithmic factors. For Euclidean spaces, the coreset size is\n$O(m\\varepsilon^{-1}) +\n\\tilde{O}(\\min{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}})$, improving upon a\nrecent result by Jiang and Lou (ICALP 2025). These results also extend to\nrobust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset\nsize of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear\ndependence on $m$. This extended result improves upon the earlier work of Huang\net al. (SODA 2025). The techniques introduce novel dataset decompositions,\nenabling chaining arguments to be applied jointly across multiple components.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Multipass Linear Sketches for Geometric LP-Type Problems",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-multipass-linear-sketches-for-geometric-lp-type-problems/",
      "content": "Authors: N. Efe Çekirge, William Gay, David P. Woodruff\n\nLP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support\nVector Machine (SVM), Linear Programming (LP), and Semidefinite Programming\n(SDP) are fundamental combinatorial optimization problems, with many important\napplications in machine learning applications such as classification,\nbioinformatics, and noisy learning. We study LP-type problems in several\nstreaming and distributed big data models, giving $\\varepsilon$-approximation\nlinear sketching algorithms with a focus on the high accuracy regime with low\ndimensionality $d$, that is, when ${d &lt; (1/\\varepsilon)^{0.999}}$. Our main\nresult is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s})\n\\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for\nany parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve\n$\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC\ndimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space\ncomplexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting\nexponential improvements in $1/\\varepsilon$ over current algorithms. We\ncomplement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$\nfor any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB\nand linear SVM problems, further motivating our multi-pass approach.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved sampling algorithms and Poincar inequalities for",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-improved-sampling-algorithms-and-poincar-inequalities-for-non-log-concave-distributions/",
      "content": "Authors: Yuchen He, Zhehan Lei, Jianan Shao, Chihao Zhang\n\nWe study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n(1) The potential function $V$ is $L$-smooth.\n(2) The second moment $\\mathbf{E}_{X\\sim \\mu}[|X|^2]\\leq M$.\nRecently, He and Zhang (COLT’25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar'e constant can be\narbitrarily large.\nMeanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR’23))\nstrengthens the smoothness condition (1) to the following:\n(1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\nWe show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT’24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\nMoreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $|X|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar'e\nconstant for mixture of Gaussians with the same covariance.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fully Dynamic Euclidean k-Means",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-fully-dynamic-euclidean-k-means/",
      "content": "Authors: Sayan Bhattacharya, Martín Costa, Ermiya Farokhnejad, Shaofeng H. -C. Jiang, Yaonan Jin, Jianing Lou\n\nWe consider the fundamental Euclidean $k$-means clustering problem in a\ndynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time\nvia a sequence of point insertions/deletions. We have to explicitly maintain a\nsolution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these\nupdates, while minimizing the approximation ratio, the update time (time taken\nto handle a point insertion/deletion) and the recourse (number of changes made\nto the solution $S$) of the algorithm.\nWe present a dynamic algorithm for this problem with\n$\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update\ntime and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension\n$d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal\nguarantees across all these three parameters. Indeed, improving our update time\nor approximation ratio would imply beating the state-of-the-art static\nalgorithm for this problem (which is widely believed to be the best possible),\nand the recourse of any dynamic algorithm must be $\\Omega(1)$.\nWe obtain our result by building on top of the recent work of [Bhattacharya,\nCosta, Farokhnejad; STOC’25], which gave a near-optimal dynamic algorithm for\n$k$-means in general metric spaces (as opposed to in the Euclidean setting).\nAlong the way, we design several novel geometric data structures that are of\nindependent interest. Specifically, one of our main contributions is designing\nthe first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel'y,\nYang; FOCS’22] that achieves $\\text{poly}(d)$ running time per point evaluation\nwith competitive parameters.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: FPT Parameterisations of Fractional and Generalised Hypertree Width",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-fpt-parameterisations-of-fractional-and-generalised-hypertree-width/",
      "content": "Authors: Matthias Lanzinger, Igor Razgon, Daniel Unterberger\n\nWe present the first fixed-parameter tractable (fpt) algorithms for precisely\ndetermining several central hypergraph decomposition parameters, including\ngeneralized hypertree width, fractional hypertree width, and adaptive width.\nDespite the recognized importance of these measures in complexity theory,\ndatabases, and constraint satisfaction, no exact fpt algorithms for any of them\nhad previously been known. Our results are obtained for hypergraph classes of\nbounded rank and bounded degree.\nOur approach extends a recent algorithm for treewidth (Boja'ncyk &amp;\nPilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions.\nLeveraging this framework, we overcome the significant technical hurdles\npresented by hypergraphs, whose structural decompositions are technically much\nmore intricate than their graph counterparts.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Finding Order-Preserving Subgraphs",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-finding-order-preserving-subgraphs/",
      "content": "Authors: Haruya Imamura, Yasuaki Kobayashi, Yota Otachi, Toshiki Saitoh, Keita Sato, Asahi Takaoka, Ryo Yoshinaka\n\n(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are\nfundamental problems in graph pattern matching and similarity computation. In\ngraphs derived from time-series data or protein structures, a natural total\nordering of vertices often arises from their underlying structure, such as\ntemporal sequences or amino acid sequences. This motivates the study of problem\nvariants that respect this inherent ordering. This paper addresses Ordered\n(Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common\nOrdered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms\nthat preserve the vertex orderings of two given ordered graphs. Our main\ncontributions are threefold: (1) We prove that these problems remain\nNP-complete even when restricted to small graph classes, such as trees of depth\n2 and threshold graphs. (2) We establish a gap in computational complexity\nbetween OSI and OISI on certain graph classes. For instance, OSI is\npolynomial-time solvable for interval graphs with their interval orderings,\nwhereas OISI remains NP-complete under the same setting. (3) We demonstrate\nthat the tractability of these problems can depend on the vertex ordering. For\nexample, while OISI is NP-complete on threshold graphs, its generalization,\nMCOIS, can be solved in polynomial time if the specific vertex orderings that\ncharacterize the threshold graphs are provided.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster algorithms for k-Orthogonal Vectors in low dimension",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-faster-algorithms-for-k-orthogonal-vectors-in-low-dimension/",
      "content": "Authors: Anita Dürr, Evangelos Kipouridis, Karol Węgrzycki\n\nIn the Orthogonal Vectors problem (OV), we are given two families $A, B$ of\nsubsets of ${1,\\ldots,d}$, each of size $n$, and the task is to decide\nwhether there exists a pair $a \\in A$ and $b \\in B$ such that $a \\cap b =\n\\emptyset$. Straightforward algorithms for this problem run in $\\mathcal{O}(n^2\n\\cdot d)$ or $\\mathcal{O}(2^d \\cdot n)$ time, and assuming SETH, there is no\n$2^{o(d)}\\cdot n^{2-\\varepsilon}$ time algorithm that solves this problem for\nany constant $\\varepsilon &gt; 0$.\nWilliams (FOCS 2024) presented a $\\tilde{\\mathcal{O}}(1.35^d \\cdot n)$-time\nalgorithm for the problem, based on the succinct equality-rank decomposition of\nthe disjointness matrix. In this paper, we present a combinatorial algorithm\nthat runs in randomized time $\\tilde{\\mathcal{O}}(1.25^d n)$. This can be\nimproved to $\\mathcal{O}(1.16^d \\cdot n)$ using computer-aided evaluations.\nWe generalize our result to the $k$-Orthogonal Vectors problem, where given\n$k$ families $A_1,\\ldots,A_k$ of subsets of ${1,\\ldots,d}$, each of size $n$,\nthe task is to find elements $a_i \\in A_i$ for every $i \\in {1,\\ldots,k}$\nsuch that $a_1 \\cap a_2 \\cap \\ldots \\cap a_k = \\emptyset$. We show that for\nevery fixed $k \\ge 2$, there exists $\\varepsilon_k &gt; 0$ such that the $k$-OV\nproblem can be solved in time $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot\nn)$. We also show that, asymptotically, this is the best we can hope for: for\nany $\\varepsilon &gt; 0$ there exists a $k \\ge 2$ such that $2^{(1 -\n\\varepsilon)\\cdot d} \\cdot n^{\\mathcal{O}(1)}$ time algorithm for\n$k$-Orthogonal Vectors would contradict the Set Cover Conjecture.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Efficient Branch-and-Bound for Submodular Function Maximization under",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-efficient-branch-and-bound-for-submodular-function-maximization-under-knapsack-constraint/",
      "content": "Authors: Yimin Hao, Yi Zhou, Chao Xu, Zhang-Hua Fu\n\nThe submodular knapsack problem (SKP), which seeks to maximize a submodular\nset function by selecting a subset of elements within a given budget, is an\nimportant discrete optimization problem. The majority of existing approaches to\nsolving the SKP are approximation algorithms. However, in domains such as\nhealth-care facility location and risk management, the need for optimal\nsolutions is still critical, necessitating the use of exact algorithms over\napproximation methods. In this paper, we present an optimal branch-and-bound\napproach, featuring a novel upper bound with a worst-case tightness guarantee\nand an efficient dual branching method to minimize repeat computations.\nExperiments in applications such as facility location, weighted coverage,\ninfluence maximization, and so on show that the algorithms that implement the\nnew ideas are far more efficient than conventional methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Distributionally Robust Optimization with Adversarial Data Contamination",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-distributionally-robust-optimization-with-adversarial-data-contamination/",
      "content": "Authors: Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas\n\nDistributionally Robust Optimization (DRO) provides a framework for\ndecision-making under distributional uncertainty, yet its effectiveness can be\ncompromised by outliers in the training data. This paper introduces a\nprincipled approach to simultaneously address both challenges. We focus on\noptimizing Wasserstein-1 DRO objectives for generalized linear models with\nconvex Lipschitz loss functions, where an $\\epsilon$-fraction of the training\ndata is adversarially corrupted. Our primary contribution lies in a novel\nmodeling framework that integrates robustness against training data\ncontamination with robustness against distributional shifts, alongside an\nefficient algorithm inspired by robust statistics to solve the resulting\noptimization problem. We prove that our method achieves an estimation error of\n$O(\\sqrt{\\epsilon})$ for the true DRO objective value using only the\ncontaminated data under the bounded covariance assumption. This work\nestablishes the first rigorous guarantees, supported by efficient computation,\nfor learning under the dual challenges of data contamination and distributional\nshifts.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Deterministic Lower Bounds for k-Edge Connectivity in the Distributed",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-deterministic-lower-bounds-for-k-edge-connectivity-in-the-distributed-sketching-model/",
      "content": "Authors: Peter Robinson, Ming Ming Tan\n\nWe study the $k$-edge connectivity problem on undirected graphs in the\ndistributed sketching model, where we have $n$ nodes and a referee. Each node\nsends a single message to the referee based on its 1-hop neighborhood in the\ngraph, and the referee must decide whether the graph is $k$-edge connected by\ntaking into account the received messages.\nWe present the first lower bound for deciding a graph connectivity problem in\nthis model with a deterministic algorithm. Concretely, we show that the worst\ncase message length is $\\Omega( k )$ bits for $k$-edge connectivity, for any\nsuper-constant $k = O(\\sqrt{n})$. Previously, only a lower bound of $\\Omega(\n\\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021).\nIn fact, our result is the first super-polylogarithmic lower bound for a\nconnectivity decision problem in the distributed graph sketching model.\nTo obtain our result, we introduce a new lower bound graph construction, as\nwell as a new 3-party communication complexity problem that we call\nUniqueOverlap. As this problem does not appear to be amenable to reductions to\nexisting hard problems such as set disjointness or indexing due to correlations\nbetween the inputs of the three players, we leverage results from\ncross-intersecting set families to prove the hardness of UniqueOverlap for\ndeterministic algorithms. Finally, we obtain the sought lower bound for\ndeciding $k$-edge connectivity via a novel simulation argument that, in\ncontrast to previous works, does not introduce any probability of error and\nthus works for deterministic algorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Compressed data structures for Heegaard splittings",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-compressed-data-structures-for-heegaard-splittings/",
      "content": "Authors: Henrique Ennes, Clément Maria\n\nHeegaard splittings provide a natural representation of closed 3-manifolds by\ngluing handlebodies along a common surface. These splittings can be\nequivalently given by two finite sets of meridians lying in the surface, which\ndefine a Heegaard diagram. We present a data structure to effectively represent\nHeegaard diagrams as normal curves with respect to triangulations of a surface\nof complexity measured by the space required to express the normal coordinates’\nvectors in binary. This structure can be significantly more compressed than\ntriangulations of 3-manifolds, given exponential gains for some families. Even\nwith this succinct definition of complexity, we establish polynomial time\nalgorithms for comparing and manipulating diagrams, performing stabilizations,\ndetecting trivial stabilizations and reductions, and computing topological\ninvariants of the underlying manifolds, such as their fundamental and first\nhomology groups. We also contrast early implementations of our techniques with\nstandard software programs for 3-manifolds, achieving better precision and\nfaster algorithms for the average cases and exponential gains in speed for some\nparticular presentations of the inputs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Access Control for Information-Theoretically Secure Key-Document Stores",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-access-control-for-information-theoretically-secure-key-document-stores/",
      "content": "Authors: Yin Li, Sharad Mehrota, Shantanu Sharma, Komal Kumari\n\nThis paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir’s\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access – it takes 231.5ms over 5,000 keywords across 500,000 files.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Fast Coloring Oracle for Average Case Hypergraphs",
      "url": "/cstheoryrss/2025/07/16/arxiv-data-structures-and-algorithms-a-fast-coloring-oracle-for-average-case-hypergraphs/",
      "content": "Authors: Cassandra Marcussen, Edward Pyne, Ronitt Rubinfeld, Asaf Shapira, Shlomo Tauber\n\nHypergraph $2$-colorability is one of the classical NP-hard problems. Person\nand Schacht [SODA’09] designed a deterministic algorithm whose expected running\ntime is polynomial over a uniformly chosen $2$-colorable $3$-uniform\nhypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform\nhypergraphs for all $k\\geq 3$. Both papers relied heavily on the regularity\nlemma, hence their analysis was involved and their running time hid tower-type\nconstants.\nOur first result in this paper is a new simple and elementary deterministic\n$2$-coloring algorithm that reproves the theorems of Person-Schacht and\nLee-Molla-Nagle while avoiding the use of the regularity lemma. We also show\nhow to turn our new algorithm into a randomized one with average expected\nrunning time of only $O(n)$.\nOur second and main result gives what we consider to be the ultimate evidence\nof just how easy it is to find a $2$-coloring of an average $2$-colorable\nhypergraph. We define a coloring oracle to be an algorithm which, given vertex\n$v$, assigns color red/blue to $v$ while inspecting as few edges as possible,\nso that the answers to any sequence of queries to the oracle are consistent\nwith a single legal $2$-coloring of the input. Surprisingly, we show that there\nis a coloring oracle that, on average, can answer every vertex query in time\n$O(1)$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Tileable Surfaces",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-geometry-tileable-surfaces/",
      "content": "Authors: David Brander, Jens Gravesen\n\nWe define a class of $C^k$-regular surfaces, $k \\geq 1$, \\emph{tileable\nsurfaces}, that admit geometric tilings by a finite number of congruence\nclasses of tiles. We show how to construct many examples, and examine the\nrelationship with the well known tilings of the plane and sphere, as well as\nmonohedral polyhedral surfaces.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: On Tight Robust Coresets for k-Medians Clustering",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-geometry-on-tight-robust-coresets-for-k-medians-clustering/",
      "content": "Authors: Lingxiao Huang, Zhenyu Jiang, Yi Li, Xuan Wu\n\nThis paper considers coresets for the robust $k$-medians problem with $m$\noutliers, and new constructions in various metric spaces are obtained.\nSpecifically, for metric spaces with a bounded VC or doubling dimension $d$,\nthe coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up\nto logarithmic factors. For Euclidean spaces, the coreset size is\n$O(m\\varepsilon^{-1}) +\n\\tilde{O}(\\min{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}})$, improving upon a\nrecent result by Jiang and Lou (ICALP 2025). These results also extend to\nrobust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset\nsize of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear\ndependence on $m$. This extended result improves upon the earlier work of Huang\net al. (SODA 2025). The techniques introduce novel dataset decompositions,\nenabling chaining arguments to be applied jointly across multiple components.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Compressed data structures for Heegaard splittings",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-geometry-compressed-data-structures-for-heegaard-splittings/",
      "content": "Authors: Henrique Ennes, Clément Maria\n\nHeegaard splittings provide a natural representation of closed 3-manifolds by\ngluing handlebodies along a common surface. These splittings can be\nequivalently given by two finite sets of meridians lying in the surface, which\ndefine a Heegaard diagram. We present a data structure to effectively represent\nHeegaard diagrams as normal curves with respect to triangulations of a surface\nof complexity measured by the space required to express the normal coordinates’\nvectors in binary. This structure can be significantly more compressed than\ntriangulations of 3-manifolds, given exponential gains for some families. Even\nwith this succinct definition of complexity, we establish polynomial time\nalgorithms for comparing and manipulating diagrams, performing stabilizations,\ndetecting trivial stabilizations and reductions, and computing topological\ninvariants of the underlying manifolds, such as their fundamental and first\nhomology groups. We also contrast early implementations of our techniques with\nstandard software programs for 3-manifolds, achieving better precision and\nfaster algorithms for the average cases and exponential gains in speed for some\nparticular presentations of the inputs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Bicriteria Polygon Aggregation with Arbitrary Shapes",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-geometry-bicriteria-polygon-aggregation-with-arbitrary-shapes/",
      "content": "Authors: Lotte Blank, David Eppstein, Jan-Henrik Haunert, Herman Haverkort, Benedikt Kolbe, Philip Mayer, Petra Mutzel, Alexander Naumann, Jonas Sauer\n\nWe study the problem of aggregating polygons by covering them with disjoint\nrepresentative regions, thereby inducing a clustering of the polygons. Our\nobjective is to minimize a weighted sum of the total area and the total\nperimeter of the regions. This problem has applications in cartographic map\ngeneralization and urban analytics. Here, the polygons represent building\nfootprints and the clusters may represent urban areas. Previous approaches\nforced the boundaries of the regions to come from a fixed subdivision of the\nplane, which allows the optimal solution (restricted in this way) to be found\nfrom a minimum cut in a dual graph. It is natural to ask whether the problem\ncan still be solved efficiently if this restriction is removed, allowing output\nregions to be bounded by arbitrary curves. We provide a positive answer in the\nform of a polynomial-time algorithm. Additionally, we fully characterize the\noptimal solutions by showing that their boundaries are composed of input\npolygon edges and circular arcs of constant radius. Since some applications\nfavor straight edges, we also study two problem variants in which the output\nregions must be polygons, but are not restricted to have boundaries from a\nfixed subdivision. In the first variant, region vertices must lie on the\nboundaries of the input polygons. The second variant requires them to be\nvertices of the input polygons. We show that both variants can be approximated\nup to a constant factor in polynomial time by altering an optimal solution for\nthe unrestricted problem. Our experimental evaluation on real-world building\nfootprints demonstrates that these approximate solutions are visually similar\nto the optimal unrestricted ones and achieve near-optimal objective values.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Complexity of the Skolem Problem at Low Orders",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-on-the-complexity-of-the-skolem-problem-at-low-orders/",
      "content": "Authors: Piotr Bacik, Joël Ouaknine, James Worrell\n\nThe Skolem Problem asks to determine whether a given linear recurrence\nsequence (LRS) $\\langle u_n \\rangle_{n=0}^\\infty$ over the integers has a zero\nterm, that is, whether there exists $n$ such that $u_n = 0$. Decidability of\nthe problem is open in general, with the most notable positive result being a\ndecision procedure for LRS of order at most 4.\nIn this paper we consider a bounded version of the Skolem Problem, in which\nthe input consists of an LRS $\\langle u_n \\rangle_{n=0}^\\infty$ and a bound $N\n\\in \\mathbb N$ (with all integers written in binary), and the task is to\ndetermine whether there exists $n\\in{0,\\ldots,N}$ such that $u_n=0$. We give\na randomised algorithm for this problem that, for all $d\\in \\mathbb N$, runs in\npolynomial time on the class of LRS of order at most $d$. As a corollary we\nshow that the (unrestricted) Skolem Problem for LRS of order at most 4 lies in\n$\\mathsf{coRP}$, improving the best previous upper bound of\n$\\mathsf{NP}^{\\mathsf{RP}}$.\nThe running time of our algorithm is exponential in the order of the LRS – a\ndependence that appears necessary in view of the $\\mathsf{NP}$-hardness of the\nBounded Skolem Problem. However, even for LRS of a fixed order, the problem\ninvolves detecting zeros within an exponentially large range. For this, our\nalgorithm relies on results from $p$-adic analysis to isolate polynomially many\ncandidate zeros and then test in randomised polynomial time whether each\ncandidate is an actual zero by reduction to arithmetic-circuit identity\ntesting.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Complexity of the Optimal Correlated Equilibria in Extensive-Form",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-on-the-complexity-of-the-optimal-correlated-equilibria-in-extensive-form-games/",
      "content": "Authors: Vincent Cheval, Florian Horn, Soumyajit Paul, Mahsa Shirmohammadi\n\nA major open question in algorithmic game theory is whether normal-form\ncorrelated equilibria (NFCE) can be computed efficiently in succinct games such\nas extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this\nquestion, we study the associated Threshold problem: deciding whether there\nexists a correlated equilibrium whose value exceeds a given threshold. We prove\nthat this problem is PSPACE-hard for NFCE in multiplayer extensive-form games\nwith perfect recall, even for fixed thresholds. To contextualize this result,\nwe also establish the complexity of the Threshold problem for Nash equilibria\nin this setting, showing it is ER-complete. These results uncover a surprising\ncomplexity reversal: while optimal correlated equilibria are computationally\nsimpler than optimal Nash in normal-form games, the opposite holds in\nextensive-form games, where computing optimal correlated equilibria is provably\nharder. Building on this line of inquiry, we also address a related question by\n[VSF08], who introduced the notions of extensive-form correlated equilibrium\n(EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult\nthe Threshold problem is for AFCE; we answer this question by proving that it\nis NP-hard, even in two-player games without chance nodes. Complementing our\nhardness results, we establish tight complexity classifications for the\nThreshold problem across several correlated equilibrium concepts - including\nEFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse\ncorrelated equilibria. For each of these solution concepts in multiplayer\nstochastic extensive-form games with perfect recall, we prove NP-completeness\nby providing matching NP upper bounds to the previously known hardness results.\nTogether, our results provide the most complete landscape to date for the\ncomplexity of optimal equilibrium computation in extensive-form games.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: FPT Parameterisations of Fractional and Generalised Hypertree Width",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-fpt-parameterisations-of-fractional-and-generalised-hypertree-width/",
      "content": "Authors: Matthias Lanzinger, Igor Razgon, Daniel Unterberger\n\nWe present the first fixed-parameter tractable (fpt) algorithms for precisely\ndetermining several central hypergraph decomposition parameters, including\ngeneralized hypertree width, fractional hypertree width, and adaptive width.\nDespite the recognized importance of these measures in complexity theory,\ndatabases, and constraint satisfaction, no exact fpt algorithms for any of them\nhad previously been known. Our results are obtained for hypergraph classes of\nbounded rank and bounded degree.\nOur approach extends a recent algorithm for treewidth (Boja'ncyk &amp;\nPilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions.\nLeveraging this framework, we overcome the significant technical hurdles\npresented by hypergraphs, whose structural decompositions are technically much\nmore intricate than their graph counterparts.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Equality is Far Weaker than Constant-Cost Communication",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-equality-is-far-weaker-than-constant-cost-communication/",
      "content": "Authors: Mika Göös, Nathaniel Harms, Artur Riazanov\n\nWe exhibit an $n$-bit communication problem with a constant-cost randomized\nprotocol but which requires $n^{\\Omega(1)}$ deterministic (or even\nnon-deterministic) queries to an Equality oracle. Therefore, even constant-cost\nrandomized protocols cannot be efficiently “derandomized” using Equality\noracles. This improves on several recent results and answers a question from\nthe survey of Hatami and Hatami (SIGACT News 2024). It also gives a\nsignificantly simpler and quantitatively superior proof of the main result of\nFang, G\"o\"os, Harms, and Hatami ( STOC 2025), that constant-cost\ncommunication does not reduce to the $k$-Hamming Distance hierarchy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Eigenvalue Bounds for Symmetric Markov Chains on Multislices With",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-eigenvalue-bounds-for-symmetric-markov-chains-on-multislices-with-applications/",
      "content": "Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan\n\nWe consider random walks on balanced multislices'' of anygrid’’ that\nrespects the ``symmetries’’ of the grid, and show that a broad class of such\nwalks are good spectral expanders. (A grid is a set of points of the form\n$\\mathcal{S}^n$ for finite $\\mathcal{S}$, and a balanced multi-slice is the\nsubset that contains an equal number of coordinates taking every value in\n$\\mathcal{S}$. A walk respects symmetries if the probability of going from $u =\n(u_1,\\ldots,u_n)$ to $v = (v_1,\\ldots,v_n)$ is invariant under simultaneous\npermutations of the coordinates of $u$ and $v$.) Our main theorem shows that,\nunder some technical conditions, every such walk where a single step leads to\nan almost $\\mathcal{O}(1)$-wise independent distribution on the next state,\nconditioned on the previous state, satisfies a non-trivially small singular\nvalue bound.\nWe give two applications of our theorem to error-correcting codes: (1) We\ngive an analog of the Ore-DeMillo-Lipton-Schwartz-Zippel lemma for polynomials,\nand junta-sums, over balanced multislices. (2) We also give a local\nlist-correction algorithm for $d$-junta-sums mapping an arbitrary grid\n$\\mathcal{S}^n$ to an Abelian group, correcting from a near-optimal\n$(\\frac{1}{|\\mathcal{S}|^{d}} - \\varepsilon)$ fraction of errors for every\n$\\varepsilon &gt; 0$, where a $d$-junta-sum is a sum of (arbitrarily many)\n$d$-juntas (and a $d$-junta is a function that depends on only $d$ of the $n$\nvariables).\nOur proofs are obtained by exploring the representation theory of the\nsymmetric group and merging it with some careful spectral analysis.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: A Fast Coloring Oracle for Average Case Hypergraphs",
      "url": "/cstheoryrss/2025/07/16/arxiv-computational-complexity-a-fast-coloring-oracle-for-average-case-hypergraphs/",
      "content": "Authors: Cassandra Marcussen, Edward Pyne, Ronitt Rubinfeld, Asaf Shapira, Shlomo Tauber\n\nHypergraph $2$-colorability is one of the classical NP-hard problems. Person\nand Schacht [SODA’09] designed a deterministic algorithm whose expected running\ntime is polynomial over a uniformly chosen $2$-colorable $3$-uniform\nhypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform\nhypergraphs for all $k\\geq 3$. Both papers relied heavily on the regularity\nlemma, hence their analysis was involved and their running time hid tower-type\nconstants.\nOur first result in this paper is a new simple and elementary deterministic\n$2$-coloring algorithm that reproves the theorems of Person-Schacht and\nLee-Molla-Nagle while avoiding the use of the regularity lemma. We also show\nhow to turn our new algorithm into a randomized one with average expected\nrunning time of only $O(n)$.\nOur second and main result gives what we consider to be the ultimate evidence\nof just how easy it is to find a $2$-coloring of an average $2$-colorable\nhypergraph. We define a coloring oracle to be an algorithm which, given vertex\n$v$, assigns color red/blue to $v$ while inspecting as few edges as possible,\nso that the answers to any sequence of queries to the oracle are consistent\nwith a single legal $2$-coloring of the input. Surprisingly, we show that there\nis a coloring oracle that, on average, can answer every vertex query in time\n$O(1)$.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-095 | Godel in Cryptography: Effectively Zero-Knowledge Proofs for NP with No Interaction, No Setup, and Perfect Soundness |",
      "url": "/cstheoryrss/2025/07/15/eccc-papers-tr25-095-godel-in-cryptography-effectively-zero-knowledge-proofs-for-np-with-no-interaction-no-setup-and-perfect-soundness-rahul-ilango/",
      "content": "A zero-knowledge proof demonstrates that a fact (like that a Sudoku puzzle has a solution) is true while, counterintuitively, revealing nothing else (like what the solution actually is). This remarkable guarantee is extremely useful in cryptographic applications, but it comes at a cost. A classical impossibility result by Goldreich and Oren [J. Cryptol. ‘94] shows that zero-knowledge proofs must necessarily sacrifice basic properties of traditional mathematical proofs — namely perfect soundness (that no proof of a false statement exists) and non-interactivity (that a proof can be transmitted in a single message).\nContrary to this impossibility, we show that zero-knowledge with perfect soundness and no interaction is effectively possible. We do so by defining and constructing a powerful new relaxation of zero-knowledge. Intuitively, while the classical zero-knowledge definition requires that an object called a simulator actually exists, our new definition only requires that one cannot rule out that a simulator exists (in a particular logical sense). Using this, we show that **every falsifiable security property of (classical) zero-knowledge can be achieved with no interaction, no setup, and perfect soundness.** This enables us to remove interaction and setup from (classical) zero-knowledge in essentially all of its applications in the literature, at the relatively mild cost that such applications now have security that is “game-based” instead of “simulation-based.”\nOur construction builds on the work of Kuykendall and Zhandry [TCC ‘20] and relies on two central, longstanding, and well-studied assumptions that we show are also necessary. The first is the existence of non-interactive witness indistinguishable proofs, which follows from standard assumptions in cryptography. The second is Krajícek and Pudlak’s 1989 conjecture that no optimal proof system exists. This is one of the main conjectures in the field of proof complexity and is the natural finitistic analogue of the impossibility of Hilbert’s second problem (and, hence, also Gödel’s incompleteness theorem). Our high-level idea is to use these assumptions to construct a prover and verifier where no simulator exists, but the non-existence of a simulator is independent (in the logical sense of unprovability) of an arbitrarily strong logical system. One such logical system is the standard axioms of mathematics: ZFC.\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Jorams seminar 2025: Hypercontractivity, Groups and Representations",
      "url": "/cstheoryrss/2025/07/15/gil-kalai-joram-s-seminar-2025-hypercontractivity-groups-and-representations/",
      "content": "Joram’s seminar 2025\n\nHere is my summary of the recent Joram’s seminar that took place on July 9 and 10 in Jerusalem. Much of the seminar was about the the paper Product Mixing in Compact Lie Groups by David Ellis, Guy Kindler, Noam Lifshitz, and Dor Minzer.\n\nLecture I: Noam Lifshitz\n\n\n\nNoam Lifshitz (HUJI): Product mixing in groups (Special Colloquium)\n\nAbstract: Let  be subsets of the special unitary group  of Haar measure . Then . In fact, the product  of random elements  is equidistributed in  This makes progress on a question that was posed independently by Gowers studying nonabelian variants of questions from additive combinatorics and settles a conjecture of physicists studying quantum communication complexity. To prove our results we introduce a tool known as ‘hypercontractivity’ to the study of high rank compact Lie groups. We then show that it synergies with their representation theory to obtain our result.\n\nMy summary\n\nThe Babai–Sós Problem\n\nIn 1985, László Babai and Vera Sós posed the following question: What is the largest possible size of a product-free subset of a finite group ?\n\nFor abelian groups, one can always find a sum-free set of positive density. However, the situation in the non-commutative case is quite different—and turns out to be very interesting.\n\nGowers’ Work and the Sarnak–Xue–Gowers Lemma\n\nIn his 2008 paper quasirandom groups, Tim Gowers proved that if the dimension of the smallest non-trivial representation of a finite group is , then any product-free subset has density at most  for some constant . \nGowers also obtained an analogous result for compact Lie groups, showing that the Haar measure of a product-free set is similarly bounded. For example, for the group , any product-free set has measure at most .\n\nGowers’ argument relies (among other things) on ideas reminiscent of a 1991 result by Sarnak and Xue, which established a beautiful connection between spectral gaps and the dimensions of irreducible representations.\n\n“Gowers’s enemies are low dimensional representation”\n\nImproving on Gowers’ bound requires a more refined analysis of characteristic functions of sets, made possible by hypercontractive estimates. Hypercontractivity enables one to strengthen the upper bound for product-free sets from  to . Further improvements might still be achievable—an intriguing open direction. However, for the stronger statement concerning the equidistribution of products, this new bound is sharp.\n\nOne Clean Qubit Suffices\n\nNoam also described a related problem in quantum communication complexity, which was resolved using similar methods. This result appears in the paper One Clean Qubit Suffices for Quantum Communication Advantage by Srinivasan Arunachalam, Uma Girish, and Noam Lifshitz.\n\nHypercontractivity\n\nNoam concluded his talk by highlighting hypercontractivity—the key new ingredient in this line of work—and the associated -level inequalities. The proof of the main theorem, to be developed over four additional lectures, combines representation theory for  with the establishment and use of hypercontractive estimates.\n\n\n\nLecture II: Dor Minzer\n\nDor Minzer (MIT): On CSPs, Inverse Theorems and Friends\n\nAbstract: Constraint satisfaction problems (CSPs in short) are among the most important computational problems studied in Theoretical Computer Science. In this talk we will discuss a recent line of study addressing the complexity of approximating satisfiable instances of CSPs.\nWe will focus on connections to analytic inverse-type theorems for correlations that generalize the -Gowers norm, and show how these results can be used in other areas, such as property testing and extremal combinatorics.\n\nBased mostly on joint works with Amey Bhangale, Subhash Khot and Yang P. Liu.\n\nMy summary:\n\nCSPs and the difference between 3LIN and 3SAT\n\nIt is NP-hard to find a satisfying assignment for a 3-SAT instance—and even to satisfy a large fraction of clauses when a perfect assignment exists. The case of 3-LIN (systems of linear equations mod 2 with three variables per equation) is very different: here it is easy to find a satisfying assignment, but hard to find an assignment that satisfies many equations.\n\nBoth problems fall under the general framework of constraint satisfaction problems (CSPs). Understanding the source of this difference is a deep and challenging question in computational complexity.\n\nAmey Bhangale, Subhash Khot, and Dor Minzer (recently joined by Yang P. Liu) have written a remarkable series of (so far) seven papers developing a theory to address this question; Here is a link to On Approximability of Satisfiable k-CSPs:VII.  As it turns out, combinatorial objects like combinatorial lines are special cases of a much broader family of structures arising from CSPs. This connection works both ways:\n\n\n  The general theory applies to long-standing problems in additive combinatorics.\n  At the same time, advances in additive combinatorics—via more sophisticated mathematical tools—feed back into the general CSP theory.\n\n\nBetter Bounds for Density Hales–Jewett\n\nDor highlighted a striking application of this theory (we already mentioned it in this post):\n\nReasonable Bounds for Combinatorial Lines of Length Three, by Amey Bhangale, Subhash Khot, Yang P. Liu, Dor Minzer\n\n\n  \n    \n      The paper proves that any subset  with ![3^{-n}\n      A\n      \\ge (\\log \\log \\log \\log n)^{-c}](https://s0.wp.com/latex.php?latex=3%5E%7B-n%7D%7CA%7C+%5Cge+%28%5Clog+%5Clog+%5Clog+%5Clog+n%29%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002)  contains a combinatorial line of length 3. This dramatically improves on the previous best bound of ![3^{-n}\n      A\n      \\ge \\Omega ((\\log ^*n)^{-1/2})](https://s0.wp.com/latex.php?latex=3%5E%7B-n%7D%7CA%7C%5Cge+%5COmega+%28%28%5Clog+%5E%2An%29%5E%7B-1%2F2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002)  of [D.H.J. Polymath, Ann. of Math. 2012] (DHJ[3] was the goal of the first polymath project.)\n    \n  \n\n\nDor also mentioned general algebraic norms in this theory, reminiscent of Gowers norms, as well as inverse theorems for these new norms.\n\n\n\nLecture III: Nathan Keller\n\nNathan Keller (BIU): Intersection theorems and improved covering results for the symmetric group, via hypercontractivity\n\nIn this talk we describe two seemingly unrelated results on the symmetric group .\nA family  of permutations is called t-intersecting if any two permutations in F agree on at least t values. In 1977, Deza and Frankl conjectured that for all  , the maximal size of a t-intersecting subfamily of S_n is (n-t)!. Ellis, Friedgut and Pilpel (JAMS, 2011) proved the conjecture for all  n&gt;exp(exp(t)) and conjectured that it holds for all n&gt;2t. We prove that the conjecture holds for all n&gt;ct for some constant c.\n\nA well-known problem asks for characterizing subsets A of  whose square  contains (=”covers”) the alternating group . We show that if A is a union of conjugacy classes of density at least  then  covers  This extends a seminal result of Larsen and Shalev (Inventiones Math., 2008) who obtained the same with 1/4 in the double exponent.\n\nThe two results boil down to the understanding of independent sets in certain Cayley graphs, and turn out to be related. We shall focus on the main new tool we use in the proof of both results – hypercontractive inequalities for global functions, developed by Keevash, Lifshitz, Long and Minzer (JAMS, 2024).\n\nThe talk was based on joint works with Noam Lifshitz, Dor Minzer, and Ohad Sheinfeld.\n\nNathan’s talk is based on these two papers:\n\nImproved covering results for conjugacy classes of symmetric groups via hypercontractivity, by Nathan Keller, Noam Lifshitz, and Ohad Sheinfeld\n\nOn t-intersecting families of permutations by Nathan Keller, Noam Lifshitz, and Ohad Sheinfeld\n\nNathan explained how Erdős–Ko–Rado-type problems about permutations in combinatorics and problems about products of conjugacy classes in group theory can both be formulated in terms of combinatorial properties of Cayley graphs of normal subsets (unions of conjugacy classes) in groups. (This explanation was quite stunning for me.) He then outlined how hypercontractive inequalities for global functions— (that we mentioned here and here) yield major advances in both of these areas.  We discussed Ellis, Friedgut and Pilpel’s Erdős–Ko–Rado result for permutations in this 2009 post.\n\n##\n\nLectures IV,V,VI,VII: Guy Kindler and Noam Lifshitz\n\nHypercontractivity and product mixing in compact Lie groups (Four lectures)  Guy Kindler (HUJI) and Noam Lifshitz (HUJI)\n\nAbstract: The study of geometric properties of Cayley graphs associated with non-abelian groups is a rich area of research with wide ranging applications. Here, key questions concern properties such as expansion, mixing, diameter, etc. While remarkable progress was made in this area by applying deep results in character theory, such methods seem to be limited to the case of normal Cayley graphs (those generated by unions of conjugacy classes).\n\nIn this mini-course we explore a recent approach which seems to sidestep such limitations. Inspired by techniques originally introduced in the study of the (abelian) Boolean Cube, we use a synergy between hypercontractive inequalities and dimensional lower bounds from representation theory to make progress on various problems. In particular, we will present a significant improvement of a bound of Gowers on the measure of product-free subsets in the unitary group SU(n).\n\nMy comments: I will not give a detailed summary of the lectures by Guy and Noam. They described a subtle coupling method to prove hypercontractivity  for  and mentioned another method based on curvature. They got quite deeply into the representation theory of SU(n) and mentioned notions of “degree” (analogous to “Juntas” for Boolean functions) that plays a role. Related notions appeared in works of Shamgar Gurevich and  Roger Howe (e.g. this paper) and of Bob Guralnik, Michael Larsen, and Pham Huu Tiep (e.g., this paper). The proof presented by Noam for bounding the eigenvalues was actually a simplification discovered right before the lecture!\n\nMore\n\n\n\nOn Joram\n\nElon Lindenstrauss shared a few moving words about his father, emphasizing Joram’s deep commitment to the Israeli mathematical community. The format of Joram’s seminar—aiming not only to present high-level ideas but also to dive into the gory details of major mathematical advances—was something he greatly valued.\n\nI vividly recall a seminar Joram organized back in 1981 on the newly published book by Gromov, Structures métriques pour les variétés riemanniennes.\n\n(See also this post about Joram Lindenstrauss. Here is a link to previous seminars in the series.)\n\n\n\nDavid Ellis\n\nThe fourth author of the paper, our dear friend David Ellis, visited Jerusalem in May.\n\nVideoes\n\nVideoes for the lectures are Lecture 1, lecture 2, lecture 3, lecture 4, lecture 5, lecture 6, lecture 7. (The links may not be stable).\n\nKazhdan’s seminar on hypercontractivity – Spring 2026\n\nBack in 2003–2004, David Kazhdan and I ran a seminar on polytopes, toric varieties, and related topics in combinatorics and algebra. (Much has happened since then—Karim Adiprasito even organized another Kazhdan seminar on a related theme in 2018.)\n\nIn 2012, David and I thought it might be time to run a similar event in 2014 and perhaps start a tradition of a decennial joint seminar. This plan materialized only in 2019 when Leonid Polterovich, Dorit Aharonov, Guy Kindler, Michael Ben-Or, and I dedicated one of David’s Sunday seminars to computation, quantumness, symplectic geometry, and information.\n\nNow, we’re planning a Kazhdan seminar on hypercontractivity for Spring 2026. Since many of Kazhdan’s seminars focus on representation theory, the new connections between hypercontractivity and representations make this an especially natural fit.\n\nPlans for my blog\n\nI have plenty of material I’d love to share—from the Combinatorial Colloquium in London, the events of the Czech Learned Society in Prague, and several lectures and meetings in Israel. This summary of the very recent Joram seminar does not mean I’ve abandoned plans to write about earlier events. Stay tuned!\n\nHigh-degree representations and physics.\n\nIt is an interesting (meta) question why representations that occur in particle physics are (very) low dimensional. Is the Sarnak-Xue lemma related to this phenomenon?\n\nBy Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "David Eppstein: Linkage",
      "url": "/cstheoryrss/2025/07/15/david-eppstein-linkage/",
      "content": "\n  Dozens of the world’s most cited scientists stop falsely claiming to work in Saudi Arabia ((\\mathbb{M})). Perhaps relatedly, Clarivate has tightened its checks for fraudulent citation practices and removed a greatly expanded number of researchers from its highly cited researcher lists.\n  After learning about the existence of plesiohedra, Jim Propp wants to know about stegohedra, ankylohedra, and icthyohedra. One possibility for stegohedra: a polyhedron with triangular faces each of which has exactly one concave and two convex dihedrals.\n  A photograph of George Green? A case study in historical misconception ((\\mathbb{M})). Peter Rowlett does some sleuthing and discovers that a purported photo of the British mathematician is really of an American wagon maker and civil war soldier.\n  Research papers containing hidden prompts directing artificial intelligence tools to give them good reviews ((\\mathbb{M}), via). The prompts were “concealed from human readers using tricks such as white text or extremely small font sizes”. The link gives no explicit examples but some can be found in the comment thread.\n  Interpreting hat color puzzle states as orientations of hypercube graphs.\n  The most useless data visualisation ever ((\\mathbb{M})): a bar chart of US GDP by year that shows a single bar of a fixed size, with only the scale markings changing if you use a slider to view different years.\n  Hexagonal box (not actually hexagonal).\n  Measuring the impact of early-2025 AI on experienced open-source developer productivity ((\\mathbb{M})). METR ran a controlled experiment with 16 experienced open-source developers on 246 programming tasks. The developers predicted that the use of AI would speed up their work by 25%, and after the experiment judged that it had sped it up by 20%. But when actually measured, the use of AI slowed down their work by 19%.\n  Record lattice sphere packings discovered ((\\mathbb{M})). The proof “utilizes a stochastically evolving ellipsoid that accumulates lattice points on its boundary, while containing no lattice points in its interior”, reviving an old but abandonded idea of Minkowski.\n  BusyBeaver(6) is really quite large ((\\mathbb{M}), see also). The previous bound of roughly (10\\uparrow\\uparrow 15) is improved to at least (2\\uparrow\\uparrow2\\uparrow\\uparrow2\\uparrow\\uparrow9&gt;2\\uparrow\\uparrow\\uparrow 5), while (BB(7)&gt;2\\uparrow^{11}2\\uparrow^{11}3), as expressed in Knuth’s up-arrow notation. Meanwhile the smallest (n) for which ZFC cannot determine (BB(n)) has been reduced from 643 to 588, but there’s a lot more room for improvement.\n  Carleson’s theorem formalized in Lean ((\\mathbb{M})). This is the one about pointwise almost everywhere convergence of Fourier series of (L^2) functions, for which Wikipedia states “there are still no easy proofs”.\n  The vigorous and long-running academic debate about precisely what shape the polyhedron depicted in Dürer’s Melencolia I is ((\\mathbb{M})). For another one sort of like this, see the debate on whether the sphere in Da Vinci’s Salvator Mundi is hollow or solid, and what it is made of.\n  The new diamond open access journal Annals of Formalized Mathematics publishes its first issue ((\\mathbb{M})). I’m particularly interested in Karayel’s “Derandomization with pseudorandomness”. It looks like it will be an interesting journal.\n\n\nBy David Eppstein\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Metascience of pull requests",
      "url": "/cstheoryrss/2025/07/15/ben-recht-metascience-of-pull-requests/",
      "content": "\n\nLast week, I wrote two posts on a related theme, but didn’t fully connect them to my earlier thoughts on the topic. I have a particular drum I’ve been beating consistently on this blog since I moved to Substack (and I have even older posts on it, too):\n\n\n  Though machine learning is statistical prediction, classical inferential statistics has nothing interesting to say about the field.\n  In fact, lessons from classical inferential statistics have historically provided poor, misleading guidance for machine learning practice.\n  A culture of frictionless reproducibility has been the primary driver of machine learning progress.\n\n\nI use the term classical inferential statistics loosely here, and Siva Balakrishnan is going to get mad at me about it. He and I cannot agree on a term to describe the narrow statistical subfield that I want to call out: frequentist claims about out-of-sample behavior derived from laws of large numbers and the union bound. This includes statistical significance, null hypothesis significance testing, and error bars.1\n\nI’ve decided to try out “classical” because Jessica Hullman used it in her blog post advocating for more statistics in machine learning. I always find Jessica thought-provoking, and she links to me and asks at the end of the post.\n\n\n  “But others refer to attempts to incentivize more thorough reporting of uncertainty in ML evaluation as “a weird obsession with statistics. What’s up with that, I wonder?”\n\n\nI’ll reply here, though most of what I wanted to say was already written in the comments under Jessica’s post by frequent stat modeling interlocutor Anoneuoid:\n\n\n  Mandating null hypothesis significance testing and related ideas is a fast way to stifle progress.\n  Systematic errors are more important than sampling errors.\n  Since everyone started deep learning, machine learning papers have been reduced to advertisements of pull requests.\n  You don’t need 90 pages of robustness checks or proofs, since you can simply try the code and decide for yourself whether to accept it.\n\n\nI swear I am not Anoneuoid. We just happen to strongly agree about everything.\n\nBut yes, I have made the same arguments on the blog many times. If the machine learning community had listened to the guidelines from classical inferential statistics, nothing would have ever gotten built. Machine learning was largely developed without the use of classical inferential statistics. In fact, the influence has gone in the opposite direction: since 1960, statistically minded researchers have been trying to bootstrap a “statistical learning theory” by chasing practice.\n\nThe problem is that theories derived by shoe-horning practice into classical statistical footwear haven’t been productive. Every time this narrow view of classical statistics is applied, it gives the wrong advice! It’s been actively harmful to the field. It makes incorrect predictions and obsesses about the wrong type of error.\n\nThe part of practice that most resembles classical statistics is the train-test paradigm.2 Statistics doesn’t explain why this is successful at all! If anything, this has polarized me against other conclusions drawn from statistical theory. Indeed, it makes me believe that claims about the scientific detriment of p-hacking and uncorrected multiple hypothesis testing are wildly overstated.\n\nAnother post critiquing statistics is all well and good, but I have a more important point to make here about what we might consider doing instead. Jessica writes to Anoneuoid:\n\n\n  “But I guess part of what I find confusing about dismissing attempts to hold people accountable for what they are claiming (like the crazy long NeurIPS checklist that the linked post complains about) is that in the absence of suggesting an alternative way to better align the claims and the evidence, it reads as though we’re saying all is ok as is and uncertainty can continue to be an afterthought when presenting evaluation results.”\n\n\nI often feel like the solutionist burden placed on critics is an easy way to wave off critique. But on this issue, I am actually proposing an alternative! Open models, open data, and open code are a clear, feasible alternative requirement. These are not major asks. As I said in a previous post, the only reason we don’t require these is that there are still a lot of corporate interests at the big machine learning conferences, and these places always have some argument for why they can’t release code and data. David Pfau noted on Twitter that this is rapidly changing with the LLM arms race, with the companies moving towards abandoning publishing altogether. He might be right, but that doesn’t mean we have to encourage their nefarious behavior by embracing their move to proprietary secrecy.\n\nJessica admits the problem herself in her review of Weijie Su’s argument for more statistics in machine learning research.\n\n\n  “Something a bit cringey that becomes clearer when you see the various statistical challenges laid out like this is that sometimes they arise not just because LLMs are too complex for us to understand, but also because they are proprietary objects.”\n\n\nThe frustration with most modern published LLM papers is industrial closedness reduces open research to ephemeral flailing. If you are taking a proprietary, closed model and doing some prompt engineering to elicit funny answers, you are doing HCI research on proprietary software. If you train a transformer model from scratch on the orbits of planets and don’t use all of the language on the internet, your result says nothing about LLMs. Even if you are fine-tuning an open weights model, there’s only so much we can learn because you have no idea what the training corpus is.\n\nMachine learning has thrived in its embrace of frictionless reproducibility— Open, shareable data. The ability to re-execute code. Competitive Testing. These are powerful tools to mitigate uncertainty. I’ve written some thoughts about why this is, drawing analogies to distributed optimization. I still think this is an excellent direction for meta-scientific study. But for whatever reason, many in the orbit of machine learning seem more interested in developing more statistical tests than in understanding why exactly this practice works so well.\n\nLet me close with quoting Andrew Gelman, who replied to Jessica,\n\n\n  “On the other side, Recht presents a very reasonable engineering perspective that is anti-bureaucratic: we’ve already made a lot of progress and continue to do so, so don’t tell us what to do. Or, to put it more carefully, you can tell us what to do for safety or public policy reasons, but it seems like a mistake to try to restrict researchers’ freedom in the belief that this will improve research progress. This general position makes sense to me, and it is similar to many things I’ve said and written regarding science reform: I don’t want to tell people what to do, and I also don’t want criticism to be suppressed. That doesn’t mean that science-reform proposals are necessarily bad. For example, I find preregistration to be valuable (for the science, not the p-values), but I wouldn’t want it to be a requirement.”\n\n\nI agree strongly here with Andrew. Our mandates should be few and far between. I advocate for only one: stronger norms about openness in code, data, and models.\n\nSubscribe now\n\n1\n\nI’ll leave the Bayesians alone today because no one is yet proposing LDA to be on the NeurIPS checklist yet.\n\n2\n\nThough the train test paradigm was invented by practice, not by a careful application of statistics.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Simultaneous Network Design with Restricted Link Usage",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-simultaneous-network-design-with-restricted-link-usage/",
      "content": "Authors: Naonori Kakimura, Péter Madarasi, Jannik Matuschke, Kitti Varga\n\nGiven a digraph with two terminal vertices $s$ and $t$ as well as a\nconservative cost function and several not necessarily disjoint color classes\non its arc set, our goal is to find a minimum-cost subset of the arcs such that\nits intersection with each color class contains an $s$-$t$ dipath. Problems of\nthis type arise naturally in multi-commodity network design settings where each\ncommodity is restricted to use links of its own color only.\nWe study several variants of the problem, deriving strong hardness results\neven for restricted cases, but we also identify cases that can be solved in\npolynomial time. The latter ones include the cases where the color classes form\na laminar family, or where the underlying digraph is acyclic and the number of\ncolor classes is constant. We also present an FPT algorithm for the general\ncase parameterized by the number of multi-colored arcs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Phase transition of the Sinkhorn-Knopp algorithm",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-phase-transition-of-the-sinkhorn-knopp-algorithm/",
      "content": "Authors: Kun He\n\nThe matrix scaling problem, particularly the Sinkhorn-Knopp algorithm, has\nbeen studied for over 60 years. In practice, the algorithm often yields\nhigh-quality approximations within just a few iterations. Theoretically,\nhowever, the best-known upper bound places it in the class of\npseudopolynomial-time approximation algorithms. Meanwhile, the lower-bound\nlandscape remains largely unexplored. Two fundamental questions persist: what\naccounts for the algorithm’s strong empirical performance, and can a tight\nbound on its iteration count be established?\nFor an $n\\times n$ matrix, its normalized version is obtained by dividing\neach entry by its largest entry. We say that a normalized matrix has a density\n$\\gamma$ if there exists a constant $\\rho &gt; 0$ such that one row or column has\nexactly $\\lceil \\gamma n \\rceil$ entries with values at least $\\rho$, and every\nother row and column has at least $\\lceil \\gamma n \\rceil$ such entries.\nFor the upper bound, we show that the Sinkhorn-Knopp algorithm produces a\nnearly doubly stochastic matrix in $O(\\log n - \\log \\varepsilon)$ iterations\nand $\\widetilde{O}(n^2)$ time for all nonnegative square matrices whose\nnormalized version has a density $\\gamma &gt; 1/2$. Such matrices cover both the\nalgorithm’s principal practical inputs and its typical theoretical regime, and\nthe $\\widetilde{O}(n^2)$ runtime is optimal.\nFor the lower bound, we establish a tight bound of\n$\\widetilde{\\Omega}\\left(n^{1/2}/\\varepsilon\\right)$ iterations for positive\nmatrices under the $\\ell_2$-norm error measure. Moreover, for every $\\gamma &lt;\n1/2$, there exists a matrix with density $\\gamma$ for which the algorithm\nrequires $\\Omega\\left(n^{1/2}/\\varepsilon\\right)$ iterations.\nIn summary, our results reveal a sharp phase transition in the Sinkhorn-Knopp\nalgorithm at the density threshold $\\gamma = 1/2$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Paths and Intersections: Exact Emulators for Planar Graphs",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-paths-and-intersections-exact-emulators-for-planar-graphs/",
      "content": "Authors: George Z. Li, Zihan Tan, Tianyi Zhang\n\nWe study vertex sparsification for preserving distances in planar graphs.\nGiven an edge-weighted planar graph with $k$ terminals, the goal is to\nconstruct an emulator, which is a smaller edge-weighted planar graph that\ncontains the terminals and exactly preserves the pairwise distances between\nthem. We construct exact planar emulators of size $O(f^2k^2)$ in the setting\nwhere terminals lie on $f$ faces in the planar embedding of the input graph.\nOur result generalizes and interpolates between the previous results of Chang\nand Ophelders and Goranci, Henzinger, and Peng which is an $O(k^2)$ bound in\nthe setting where all terminals lie on a single face (i.e., $f=1$), and the\nresult of Krauthgamer, Nguyen, and Zondiner, which is an $O(k^4)$ bound for the\ngeneral case (i.e., $f=k$).\nOur construction follows a recent new way of analyzing graph structures, by\nviewing graphs as paths and their intersections, which we believe is of\nindependent interest.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Nearly Tight Sample Complexity for Matroid Online Contention Resolution",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-nearly-tight-sample-complexity-for-matroid-online-contention-resolution/",
      "content": "Authors: Moran Feldman, Ola Svensson, Rico Zenklusen\n\nDue to their numerous applications, in particular in Mechanism Design,\nProphet Inequalities have experienced a surge of interest. They describe\ncompetitive ratios for basic stopping time problems where random variables get\nrevealed sequentially. A key drawback in the classical setting is the\nassumption of full distributional knowledge of the involved random variables,\nwhich is often unrealistic. A natural way to address this is via sample-based\napproaches, where only a limited number of samples from the distribution of\neach random variable is available. Recently, Fu, Lu, Gavin Tang, Wu, Wu, and\nZhang (2024) showed that sample-based Online Contention Resolution Schemes\n(OCRS) are a powerful tool to obtain sample-based Prophet Inequalities. They\npresented the first sample-based OCRS for matroid constraints, which is a\nheavily studied constraint family in this context, as it captures many\ninteresting settings. This allowed them to get the first sample-based Matroid\nProphet Inequality, using $O(\\log^4 n)$ many samples (per random variable),\nwhere $n$ is the number of random variables, while obtaining a constant\ncompetitiveness of $\\frac{1}{4}-\\varepsilon$.\nWe present a nearly optimal sample-based OCRS for matroid constraints, which\nuses only $O(\\log \\rho \\cdot \\log^2\\log\\rho)$ many samples, almost matching a\nknown lower bound of $\\Omega(\\log \\rho)$, where $\\rho \\leq n$ is the rank of\nthe matroid. Through the above-mentioned connection to Prophet Inequalities,\nthis yields a sample-based Matroid Prophet Inequality using only $O(\\log n +\n\\log\\rho \\cdot \\log^2\\log\\rho)$ many samples, and matching the competitiveness\nof $\\frac{1}{4}-\\varepsilon$, which is the best known competitiveness for the\nconsidered almighty adversary setting even when the distributions are fully\nknown.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Minimum-Peak-Cost Flows Over Time",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-minimum-peak-cost-flows-over-time/",
      "content": "Authors: Mariia Anapolska, Emma Ahrens, Christina Büsing, Felix Engelhardt, Timo Gersing, Corinna Mathwieser, Sabrian Schmitz, Sophia Wrede\n\nWhen planning transportation whose operation requires non-consumable\nresources, the peak demand for allocated resources is often of higher interest\nthan the duration of resource usage. For instance, it is more cost-effective to\ndeliver parcels with a single truck over eight hours than to use two trucks for\nfour hours, as long as the time suffices. To model such scenarios, we introduce\nthe novel minimum peak cost flow over time problem, whose objective is to\nminimise the maximum cost at all points in time rather than minimising the\nintegral of costs. We focus on minimising peak costs of temporally repeated\nflows. These are desirable for practical applications due to their simple\nstructure. This yields the minimum-peak-cost Temporally Repeated flow problem\n(MPC-TRF).\nWe show that the simple structure of temporally repeated flows comes with the\ndrawback of arbitrarily bad approximation ratios compared to general flows over\ntime. Furthermore, our complexity analysis shows the integral version of\nMPC-TRF is strongly NP-hard, even under strong restrictions. On the positive\nside, we identify two benign special cases: unit-cost series-parallel networks\nand networks with time horizon at least twice as long as the longest path in\nthe network (with respect to the transit time). In both cases, we show that\nintegral optimal flows if the desired flow value equals the maximum flow value\nand fractional optimal flows for arbitrary flow values can be found in\npolynomial time. For each of these cases, we provide an explicit algorithm that\nconstructs an optimal solution.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: m-Eternal Domination and Variants on Some Classes of Finite and Infinite",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-m-eternal-domination-and-variants-on-some-classes-of-finite-and-infinite-graphs/",
      "content": "Authors: Tiziana Calamoneri, Federico Corò, Neeldhara Misra, Saraswati G. Nanoti, Giacomo Paesani\n\nWe study the m-Eternal Domination problem, which is the following two-player\ngame between a defender and an attacker on a graph: initially, the defender\npositions k guards on vertices of the graph; the game then proceeds in turns\nbetween the defender and the attacker, with the attacker selecting a vertex and\nthe defender responding to the attack by moving a guard to the attacked vertex.\nThe defender may move more than one guard on their turn, but guards can only\nmove to neighboring vertices. The defender wins a game on a graph G with k\nguards if the defender has a strategy such that at every point of the game the\nvertices occupied by guards form a dominating set of G and the attacker wins\notherwise. The m-eternal domination number of a graph G is the smallest value\nof k for which (G,k) is a defender win.\nWe show that m-Eternal Domination is NP-hard, as well as some of its\nvariants, even on special classes of graphs. We also show structural results\nfor the Domination and m-Eternal Domination problems in the context of four\ntypes of infinite regular grids: square, octagonal, hexagonal, and triangular,\nestablishing tight bounds.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved Directed Expander Decompositions",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-improved-directed-expander-decompositions/",
      "content": "Authors: Henry Fleischmann, George Z. Li, Jason Li\n\nWe obtain faster expander decomposition algorithms for directed graphs,\nmatching the guarantees of Saranurak and Wang (SODA 2019) for expander\ndecomposition on undirected graphs. Our algorithms are faster than prior work\nand also generalize almost losslessly to capacitated graphs. In particular, we\nobtain the first directed expander decomposition algorithm for capacitated\ngraphs in near-linear time with optimal dependence on $\\phi$.\nTo obtain our result, we provide the first implementation and analysis of the\nnon-stop cut-matching game for directed, capacitated graphs. All existing\ndirected expander decomposition algorithms instead temporarily add ‘‘fake\nedges’’ before pruning them away in a final cleanup step. Our result shows that\nthe natural undirected approach applies even to directed graphs. The difficulty\nis in its analysis, which is technical and requires significant modifications\nfrom the original setting of undirected graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved bicriteria approximation for k-edge-connectivity",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-improved-bicriteria-approximation-for-k-edge-connectivity/",
      "content": "Authors: Zeev Nutov\n\nIn the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a\n(multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost\n$k$-edge-connected spanning subgraph of $G$. The problem admits a\n$2$-approximation algorithm and no better approximation ratio is\nknown.Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria\n$(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected\nspanning subgraph of cost at most the optimal value of a standard Cut-LP for\n$k$-ECSS. This LP bicriteria approximation was recently improved by Cohen and\nNutov [ESA 25] to $(1,k-4)$, where also was given a bicriteria approximation\n$(3/2,k-2)$. In this paper we improve the bicriteria approximation to $(1,k-2)$\nfor $k$ even and to $\\left(1-\\frac{1}{k},k-3\\right)$ for $k$ is odd, and also\ngive another bicriteria approximation $(3/2,k-1)$.\nThe $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost\nthe same as $k$-ECSS, except that any edge can be selected multiple times at\nthe same cost. The previous best approximation ratio for $k$-ECSM was $1+4/k$.\nOur result improves this to $1+\\frac{2}{k}$ for $k$ even and to $1+\\frac{3}{k}$\nfor $k$ odd, where for $k$ odd the computed subgraph is in fact\n$(k+1)$-edge-connected.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Explicit Bounds and Parallel Algorithms for Counting Multiply Gleeful",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-explicit-bounds-and-parallel-algorithms-for-counting-multiply-gleeful-numbers/",
      "content": "Authors: Sara Moore, Jonathan P. Sorenson\n\nLet $k\\ge 1$ be an integer. A positive integer $n$ is $k$-\\textit{gleeful} if\n$n$ can be represented as the sum of $k$th powers of consecutive primes. For\nexample, $35=2^3+3^3$ is a $3$-gleeful number, and $195=5^2+7^2+11^2$ is\n$2$-gleeful. In this paper, we present some new results on $k$-gleeful numbers\nfor $k&gt;1$.\nFirst, we extend previous analytical work. For given values of $x$ and $k$,\nwe give explicit upper and lower bounds on the number of $k$-gleeful\nrepresentations of integers $n\\le x$.\nSecond, we describe and analyze two new, efficient parallel algorithms, one\ntheoretical and one practical, to generate all $k$-gleeful representations up\nto a bound $x$.\nThird, we study integers that are multiply gleeful, that is, integers with\nmore than one representation as a sum of powers of consecutive primes,\nincluding both the same or different values of $k$. We give a simple heuristic\nmodel for estimating the density of multiply-gleeful numbers, we present\nempirical data in support of our heuristics, and offer some new conjectures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Covering a Few Submodular Constraints and Applications",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-covering-a-few-submodular-constraints-and-applications/",
      "content": "Authors: Tanvi Bajpai, Chandra Chekuri, Pooja Kulkarni\n\nWe consider the problem of covering multiple submodular constraints. Given a\nfinite ground set $N$, a cost function $c: N \\rightarrow \\mathbb{R}_+$, $r$\nmonotone submodular functions $f_1,f_2,\\ldots,f_r$ over $N$ and requirements\n$b_1,b_2,\\ldots,b_r$ the goal is to find a minimum cost subset $S \\subseteq N$\nsuch that $f_i(S) \\ge b_i$ for $1 \\le i \\le r$. When $r=1$ this is the\nwell-known Submodular Set Cover problem. Previous work\n\\cite{chekuri2022covering} considered the setting when $r$ is large and\ndeveloped bi-criteria approximation algorithms, and approximation algorithms\nfor the important special case when each $f_i$ is a weighted coverage function.\nThese are fairly general models and capture several concrete and interesting\nproblems as special cases. The approximation ratios for these problem are at\nleast $\\Omega(\\log r)$ which is unavoidable when $r$ is part of the input. In\nthis paper, motivated by some recent applications, we consider the problem when\n$r$ is a \\emph{fixed constant} and obtain two main results. For covering\nmultiple submodular constraints we obtain a randomized bi-criteria\napproximation algorithm that for any given integer $\\alpha \\ge 1$ outputs a set\n$S$ such that $f_i(S) \\ge$ $(1-1/e^\\alpha -\\epsilon)b_i$ for each $i \\in [r]$\nand $\\mathbb{E}[c(S)] \\le (1+\\epsilon)\\alpha \\cdot \\sf{OPT}$. Second, when the\n$f_i$ are weighted coverage functions from a deletion-closed set system we\nobtain a $(1+\\epsilon)$ $(\\frac{e}{e-1})$ $(1+\\beta)$-approximation where\n$\\beta$ is the approximation ratio for the underlying set cover instances via\nthe natural LP. These results show that one can obtain nearly as good an\napproximation for any fixed $r$ as what one would achieve for $r=1$. We mention\nsome applications that follow easily from these general results and anticipate\nmore in the future.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Computing the probability of intersection",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-computing-the-probability-of-intersection/",
      "content": "Authors: Alexander Barvinok\n\nLet $\\Omega_1, \\ldots, \\Omega_m$ be probability spaces, let $\\Omega=\\Omega_1\n\\times \\cdots \\times \\Omega_m$ be their product and let $A_1, \\ldots, A_n\n\\subset \\Omega$ be events. Suppose that each event $A_i$ depends on $r_i$\ncoordinates of a point $x \\in \\Omega$, $x=\\left(\\xi_1, \\ldots, \\xi_m\\right)$,\nand that for each event $A_i$ there are $\\Delta_i$ of other events $A_j$ that\ndepend on some of the coordinates that $A_i$ depends on. Let $\\Delta=\\max{5,\n\\Delta_i: i=1, \\ldots, n}$ and let $\\mu_i=\\min{r_i,\\ \\Delta_i+1}$ for $i=1,\n\\ldots, n$. We prove that if $P(A_i) &lt; (3\\Delta)^{-3\\mu_i}$ for all $I$, then\nfor any $0 &lt; \\epsilon &lt; 1$, the probability $P\\left( \\bigcap_{i=1}^n\n\\overline{A}_i\\right)$ of the intersection of the complements of all $A_i$ can\nbe computed within relative error $\\epsilon$ in polynomial time from the\nprobabilities $P\\left(A_{i_1} \\cap \\ldots \\cap A_{i_k}\\right)$ of $k$-wise\nintersections of the events $A_i$ for $k = e^{O(\\Delta)} \\ln (n/\\epsilon)$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Colorful Minors",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-colorful-minors/",
      "content": "Authors: Evangelos Protopapas, Dimitrios M. Thilikos, Sebastian Wiederrecht\n\nWe introduce the notion of colorful minors, which generalizes the classical\nconcept of rooted minors in graphs. $q$-colorful graph is defined as a pair\n$(G, \\chi),$ where $G$ is a graph and $\\chi$ assigns to each vertex a (possibly\nempty) subset of at most $q$ colors. The colorful minor relation enhances the\nclassical minor relation by merging color sets at contracted edges and allowing\nthe removal of colors from vertices. This framework naturally models\nalgorithmic problems involving graphs with (possibly overlapping) annotated\nvertex sets. We develop a structural theory for colorful minors by establishing\nseveral theorems characterizing $\\mathcal{H}$-colorful minor-free graphs, where\n$\\mathcal{H}$ consists either of a clique or a grid with all vertices assigned\nall colors, or of grids with colors segregated and ordered on the outer face.\nLeveraging our structural insights, we provide a complete classification -\nparameterized by the number $q$ of colors - of all colorful graphs that exhibit\nthe Erd\\H{o}s-P'osa property with respect to colorful minors. On the\nalgorithmic side, we provide a fixed-parameter tractable algorithm for colorful\nminor testing and a variant of the $k$-disjoint paths problem. Together with\nthe fact that the colorful minor relation forms a well-quasi-order, this\nimplies that every colorful minor-monotone parameter on colorful graphs admits\na fixed-parameter algorithm. Furthermore, we derive two algorithmic\nmeta-theorems (AMTs) whose structural conditions are linked to extensions of\ntreewidth and Hadwiger number on colorful graphs. Our results suggest how known\nAMTs can be extended to incorporate not only the structure of the input graph\nbut also the way the colored vertices are distributed in it.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bicriteria Submodular Maximization",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-bicriteria-submodular-maximization/",
      "content": "Authors: Moran Feldman, Alan Kuhnle\n\nSubmodular functions and their optimization have found applications in\ndiverse settings ranging from machine learning and data mining to game theory\nand economics. In this work, we consider the constrained maximization of a\nsubmodular function, for which we conduct a principled study of bicriteria\napproximation algorithms – algorithms which can violate the constraint, but\nonly up to a bounded factor. Bicrteria optimization allows constrained\nsubmodular maximization to capture additional important settings, such as the\nwell-studied submodular cover problem and optimization under soft constraints.\nWe provide results that span both multiple types of constraints (cardinality,\nknapsack, matroid and convex set) and multiple classes of submodular functions\n(monotone, symmetric and general). For many of the cases considered, we provide\noptimal results. In other cases, our results improve over the state-of-the-art,\nsometimes even over the state-of-the-art for the special case of\nsingle-criterion (standard) optimization. Results of the last kind demonstrate\nthat relaxing the feasibility constraint may give a perspective about the\nproblem that is useful even if one only desires feasible solutions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Average Sensitivity of Hierarchical k-Median Clustering",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-average-sensitivity-of-hierarchical-k-median-clustering/",
      "content": "Authors: Shijie Li, Weiqiang He, Ruobing Bai, Pan Peng\n\nHierarchical clustering is a widely used method for unsupervised learning\nwith numerous applications. However, in the application of modern algorithms,\nthe datasets studied are usually large and dynamic. If the hierarchical\nclustering is sensitive to small perturbations of the dataset, the usability of\nthe algorithm will be greatly reduced. In this paper, we focus on the\nhierarchical $k$ -median clustering problem, which bridges hierarchical and\ncentroid-based clustering while offering theoretical appeal, practical utility,\nand improved interpretability. We analyze the average sensitivity of algorithms\nfor this problem by measuring the expected change in the output when a random\ndata point is deleted. We propose an efficient algorithm for hierarchical\n$k$-median clustering and theoretically prove its low average sensitivity and\nhigh clustering quality. Additionally, we show that single linkage clustering\nand a deterministic variant of the CLNSS algorithm exhibit high average\nsensitivity, making them less stable. Finally, we validate the robustness and\neffectiveness of our algorithm through experiments.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Approximating Maximum Cut on Interval Graphs and Split Graphs beyond",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-approximating-maximum-cut-on-interval-graphs-and-split-graphs-beyond-goemans-williamson/",
      "content": "Authors: Jungho Ahn, Ian DeHaan, Eun Jung Kim, Euiwoong Lee\n\nWe present a polynomial-time $(\\alpha_{GW} + \\varepsilon)$-approximation\nalgorithm for the Maximum Cut problem on interval graphs and split graphs,\nwhere $\\alpha_{GW} \\approx 0.878$ is the approximation guarantee of the\nGoemans-Williamson algorithm and $\\varepsilon &gt; 10^{-34}$ is a fixed constant.\nTo attain this, we give an improved analysis of a slight modification of the\nGoemans-Williamson algorithm for graphs in which triangles can be packed into a\nconstant fraction of their edges. We then pair this analysis with structural\nresults showing that both interval graphs and split graphs either have such a\ntriangle packing or have maximum cut close to their number of edges. We also\nshow that, subject to the Small Set Expansion Hypothesis, there exists a\nconstant $c &gt; 0$ such that there is no polyomial-time $(1 - c)$-approximation\nfor Maximum Cut on split graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Fixed Parameter Tractable Approach for Solving the Vertex Cover",
      "url": "/cstheoryrss/2025/07/15/arxiv-data-structures-and-algorithms-a-fixed-parameter-tractable-approach-for-solving-the-vertex-cover-problem-in-polynomial-time-complexity/",
      "content": "Authors: Mumuksh Tayal\n\nThe Minimum Vertex Cover problem, a classical NP-complete problem, presents\nsignificant challenges for exact solution on large graphs. Fixed-Parameter\nTractability (FPT) offers a powerful paradigm to address such problems by\nexploiting a parameter of the input, typically related to the size of the\ndesired solution. This paper presents an implementation and empirical\nevaluation of an FPT algorithm for the Minimum Vertex Cover problem\nparameterized by the size of the vertex cover, $k$. The algorithm utilizes a\nbranching strategy based on selecting adjacent vertices and recursively solving\nsubproblems on a reduced graph. We describe the algorithmic approach,\nimplementation details in Python, and present experimental results comparing\nits performance against the SageMath computational system. The results\ndemonstrate that the FPT implementation achieves significant performance\nimprovements for instances with large numbers of vertices ($n$) but relatively\nsmall values of the parameter ($k$), aligning with theoretical FPT complexity\nguarantees. We also discuss potential optimizations that could further improve\nthe algorithm’s performance, particularly concerning the branching factor.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: The Network Satisfaction Problem for Relation Algebras with at most 4",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-the-network-satisfaction-problem-for-relation-algebras-with-at-most-4-atoms/",
      "content": "Authors: Manuel Bodirsky, Moritz Jahn, Matěj Konečný, Simon Knäuer, Paul Winkler\n\nAndr'eka and Maddux classified the relation algebras with at most 3 atoms,\nand in particular they showed that all of them are representable. Hirsch and\nCristiani showed that the network satisfaction problem (NSP) for each of these\nalgebras is in P or NP-hard. There are relation algebras with 4 atoms that are\nnot representable, and there are many results in the literature about\nrepresentations and non-representability of relation algebras with at most 4\natoms. We extend the result of Hirsch and Cristiani to relation algebras with\nat most 4 atoms: the NSP is always either in P or NP-hard. To this end, we\nconstruct universal, fully universal, or even normal representations for these\nalgebras, whenever possible.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Simultaneous Network Design with Restricted Link Usage",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-simultaneous-network-design-with-restricted-link-usage/",
      "content": "Authors: Naonori Kakimura, Péter Madarasi, Jannik Matuschke, Kitti Varga\n\nGiven a digraph with two terminal vertices $s$ and $t$ as well as a\nconservative cost function and several not necessarily disjoint color classes\non its arc set, our goal is to find a minimum-cost subset of the arcs such that\nits intersection with each color class contains an $s$-$t$ dipath. Problems of\nthis type arise naturally in multi-commodity network design settings where each\ncommodity is restricted to use links of its own color only.\nWe study several variants of the problem, deriving strong hardness results\neven for restricted cases, but we also identify cases that can be solved in\npolynomial time. The latter ones include the cases where the color classes form\na laminar family, or where the underlying digraph is acyclic and the number of\ncolor classes is constant. We also present an FPT algorithm for the general\ncase parameterized by the number of multi-colored arcs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: m-Eternal Domination and Variants on Some Classes of Finite and Infinite",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-m-eternal-domination-and-variants-on-some-classes-of-finite-and-infinite-graphs/",
      "content": "Authors: Tiziana Calamoneri, Federico Corò, Neeldhara Misra, Saraswati G. Nanoti, Giacomo Paesani\n\nWe study the m-Eternal Domination problem, which is the following two-player\ngame between a defender and an attacker on a graph: initially, the defender\npositions k guards on vertices of the graph; the game then proceeds in turns\nbetween the defender and the attacker, with the attacker selecting a vertex and\nthe defender responding to the attack by moving a guard to the attacked vertex.\nThe defender may move more than one guard on their turn, but guards can only\nmove to neighboring vertices. The defender wins a game on a graph G with k\nguards if the defender has a strategy such that at every point of the game the\nvertices occupied by guards form a dominating set of G and the attacker wins\notherwise. The m-eternal domination number of a graph G is the smallest value\nof k for which (G,k) is a defender win.\nWe show that m-Eternal Domination is NP-hard, as well as some of its\nvariants, even on special classes of graphs. We also show structural results\nfor the Domination and m-Eternal Domination problems in the context of four\ntypes of infinite regular grids: square, octagonal, hexagonal, and triangular,\nestablishing tight bounds.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: IPS Lower Bounds for Formulas and Sum of ROABPs",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-ips-lower-bounds-for-formulas-and-sum-of-roabps/",
      "content": "Authors: Prerona Chatterjee, Utsab Ghosal, Partha Mukhopadhyay, Amit Sinhababu\n\nWe give new lower bounds for the fragments of the Ideal Proof System (IPS)\nintroduced by Grochow and Pitassi (JACM 2018). The Ideal Proof System is a\ncentral topic in algebraic proof complexity developed in the context of\nNullstellensatz refutation (Beame, Impagliazzo, Krajicek, Pitassi, Pudlak, FOCS\n1994) and simulates Extended Frege efficiently. Our main results are as\nfollows.\n\n  mult-IPS_{Lin’}: We prove nearly quadratic-size formula lower bound for\nmultilinear refutation (over the Boolean hypercube) of a variant of the\nsubset-sum axiom polynomial. Extending this, we obtain a nearly matching\nqualitative statement for a constant degree target polynomial.\n  IPS_{Lin’}: Over the fields of characteristic zero, we prove\nexponential-size sum-of-ROABPs lower bound for the refutation of a variant of\nthe subset-sum axiom polynomial. The result also extends over the fields of\npositive characteristics when the target polynomial is suitably modified. The\nmodification is inspired by the recent results (Hakoniemi, Limaye, Tzameret,\nSTOC 2024 and Behera, Limaye, Ramanathan, Srinivasan, ICALP 2025).\nThe mult-IPS_{Lin’} lower bound result is obtained by combining the\nquadratic-size formula lower bound technique of Kalorkoti (SICOMP 1985) with\nsome additional ideas. The proof technique of IPS_{Lin’} lower bound result is\ninspired by the recent lower bound result of Chatterjee, Kush, Saraf and\nShpilka (CCC 2024).\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Directed disjoint paths remains W[1]-hard on acyclic digraphs without",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-directed-disjoint-paths-remains-w-1-hard-on-acyclic-digraphs-without-large-grid-minors/",
      "content": "Authors: Ken-ichi Kawarabayashi, Nicola Lorenz, Marcelo Garlet Milani, Jacob Stegemann\n\nIn the Vertex Disjoint Paths with Congestion problem, the input consists of a\ndigraph $D$, an integer $c$ and $k$ pairs of vertices $(s_i, t_i)$, and the\ntask is to find a set of paths connecting each $s_i$ to its corresponding\n$t_i$, whereas each vertex of $D$ appears in at most $c$ many paths. The case\nwhere $c = 1$ is known to be NP-complete even if $k = 2$ [Fortune, Hopcroft and\nWyllie, 1980] on general digraphs and is W[1]-hard with respect to $k$\n(excluding the possibility of an $f(k)n^{O(1)}$-time algorithm under standard\nassumptions) on acyclic digraphs [Slivkins, 2010]. The proof of [Slivkins,\n2010] can also be adapted to show W[1]-hardness with respect to $k$ for every\ncongestion $c \\geq 1$.\nWe strengthen the existing hardness result by showing that the problem\nremains W[1]-hard for every congestion $c \\geq 1$ even if:\n\n  the input digraph $D$ is acyclic,\n  $D$ does not contain an acyclic $(5, 5)$-grid as a butterfly minor,\n  $D$ does not contain an acyclic tournament on 9 vertices as a butterfly\nminor, and\n  $D$ has ear-anonymity at most 5.\nFurther, we also show that the edge-congestion variant of the problem remains\nW[1]-hard for every congestion $c \\geq 1$ even if:\n  the input digraph $D$ is acyclic,\n  $D$ has maximum undirected degree 3,\n  $D$ does not contain an acyclic $(7, 7)$-wall as a weak immersion and\n  $D$ has ear-anonymity at most 5.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Consensus, Inconsistency, Emergence: what's paraconsistency got to do",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-consensus-inconsistency-emergence-what-s-paraconsistency-got-to-do-with-it/",
      "content": "Authors: Gabriel Rocha\n\nThe consensus problem, briefly stated, consists of having processes in an\nasynchronous distributed system agree on a value. It is widely known that the\nconsensus problem does not have a deterministic solution that ensures both\ntermination and consistency, if there is at least one faulty process in the\nsystem. This result, known as the FLP impossibility theorem, led to several\ngeneralizations and developments in theoretical distributed computing. This\npaper argues that the FLP impossibility theorem holds even under a generalized\ndefinition of computation through oracles. Furthermore, using a theoretical\nmachinery from complex systems, this paper also posits that inconsistency may\nbe an emergent feature of consensus over distributed systems by examining how a\nsystem transitions phases. Under the same complex systems framework, this paper\nexamines paraconsistent logics, arguing that while inconsistency is not an\nemergent feature for these logics, triviality may be. Lastly, some attention is\ngiven to the possibility of developing consensus algorithms capable of\nparaconsistent reasoning.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Communication Complexity is NP-hard",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-communication-complexity-is-np-hard/",
      "content": "Authors: Shuichi Hirahara, Rahul Ilango, Bruno Loff\n\nIn the paper where he first defined Communication Complexity, Yao asks:\n\\emph{Is computing $CC(f)$ (the 2-way communication complexity of a given\nfunction $f$) NP-complete?} The problem of deciding whether $CC(f) \\le k$, when\ngiven the communication matrix for $f$ and a number $k$, is easily seen to be\nin NP. Kushilevitz and Weinreb have shown that this problem is\ncryptographically hard. Here we show it is NP-hard.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: A Critique of Deng's P=NP",
      "url": "/cstheoryrss/2025/07/15/arxiv-computational-complexity-a-critique-of-deng-s-p-np/",
      "content": "Authors: Isabel Humphreys, Matthew Iceland, Harry Liuson, Dylan McKellips, Leo Sciortino\n\nIn this paper, we critically examine Deng’s “P=NP” [Den24]. The paper claims\nthat there is a polynomial-time algorithm that decides 3-coloring for graphs\nwith vertices of degree at most 4, which is known to be an NP-complete problem.\nDeng presents a semidefinite program with an objective function that is\nunboundedly negative if the graph is not 3-colorable, and a minimum of 0 if the\ngraph is 3-colorable. Through detailed analysis, we find that Deng conflates\nsubgraphs with induced subgraphs, leading to a critical error which thereby\ninvalidates Deng’s proof that $\\text{P}=\\text{NP}$.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-094 | Communication Complexity is NP-hard |",
      "url": "/cstheoryrss/2025/07/14/eccc-papers-tr25-094-communication-complexity-is-np-hard-shuichi-hirahara-rahul-ilango-bruno-loff/",
      "content": "In the paper where he first defined Communication Complexity, Yao asks: \\emph{Is computing $CC(f)$ (the 2-way communication complexity of a given function $f$) NP-complete?} The problem of deciding whether $CC(f) \\le k$, when given the communication matrix for $f$ and a number $k$, is easily seen to be in NP. Kushilevitz and Weinreb have shown that this problem is cryptographically hard. Here we show it is NP-hard.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-093 | Eigenvalue Bounds for Symmetric Markov Chains on Multislices With Applications |",
      "url": "/cstheoryrss/2025/07/14/eccc-papers-tr25-093-eigenvalue-bounds-for-symmetric-markov-chains-on-multislices-with-applications-prashanth-amireddy-amik-raj-behera-srikanth-srinivasan-madhu-sudan/",
      "content": "We consider random walks on “balanced multislices”\nof any “grid” that respects the “symmetries” of the grid, and show that a broad class of such walks are good spectral expanders. (A grid is a set of points of the form $\\mathcal{S}^n$ for finite $\\mathcal{S}$, and a balanced multi-slice is the subset that contains an equal number of coordinates taking every value in $\\mathcal{S}$. A walk respects symmetries if the probability of going from $u = (u_1,\\ldots,u_n)$ to $v = (v_1,\\ldots,v_n)$ is invariant under simultaneous permutations of the coordinates of $u$ and $v$.) Our main theorem shows that, under some technical conditions, every such walk where a single step leads to an almost $\\mathcal{O}(1)$-wise independent distribution on the next state, conditioned on the previous state, satisfies a non-trivially small singular value bound.\nWe give two applications of our theorem to error-correcting codes: (1) We give an analog of the Ore-DeMillo-Lipton-Schwartz-Zippel lemma for polynomials, and junta-sums, over balanced multislices. (2) We also give a local list-correction algorithm for $d$-junta-sums mapping an arbitrary grid $\\mathcal{S}^n$ to an Abelian group, correcting from a near-optimal $(\\frac{1}{|\\mathcal{S}|^{d}} - \\varepsilon)$ fraction of errors for every $\\varepsilon &gt; 0$, where a $d$-junta-sum is a sum of (arbitrarily many) $d$-juntas (and a $d$-junta is a function that depends on only $d$ of the $n$ variables).\nOur proofs are obtained by exploring the representation theory of the symmetric group and merging it with some careful spectral analysis.\n\nRead original post\n"
    },
    
    {
      "title": "Property Testing Review: News for June 2025",
      "url": "/cstheoryrss/2025/07/14/property-testing-review-news-for-june-2025/",
      "content": "Another (sigh) delayed post. A moderately busy month, with 4 papers with sublinear graph algorithms and, of course, distribution testing.\n\nA 0.51-Approximation of Maximum Matching in Sublinear (n^{1.5}) Time by Sepideh Mahabadi, Mohammad Roghani, and Jakub Tarnawski (arXiv). The title says it all. This paper gives a 0.51-approximation for the maximum matching in, well, (O(n^{1.5})) time. Here’s the back story. There are two kinds of sublinear maximum matching algorithms. The first kind (achieved after a long line of impressive results) get ((1- \\varepsilon))-approximations in time (O(n^{2 – \\Omega_{\\varepsilon}(1)})). This means that that in sublinear (o(n^2)) time, one can get arbitrarily good approximations. The second kind beats the simple (0.5)-approximation (obtained from maximal matchings), but tries for closer to (O(n)) time. Behnezhad–Roghani–Rubinstein–Saberi gave a ((0.5+\\varepsilon))-approximation algorithm running in (n^{1+\\varepsilon}) time. But the largest value of (\\varepsilon) possible in these results is tiny. Can one get a “significant” improvement over 0.5-approximations in time “significantly less” than (n^2)? The answer is yes, as the title explains.\n\n\n  \n    \n      Testing (Conditional) Mutual Information by Jan Seyfried, Sayantan Sen, and Marco Tomamichel (arXiv, ECCC). Consider a distribution over pairs ((A, B)). The mutual information (I(A,B)) of (A) and (B) is the minimum KL-divergence between the original distribution and any product distribution over the support of (A) and (B). So the mutual information is zero iff ((A,B)) is a product distribution, or equivalently (A) and (B) are independent. A natural distribution testing question is to distinguish (A) and (B) being independent from (I(A,B) &gt; \\varepsilon). One can take this problem a step further. Suppose the distribution is over triples ((A,B,C)). Then can one distinguish conditional independence ((I(A, B\n      C) = 0)) from sufficient conditional dependence, so (I(A, B\n      C) &gt; \\varepsilon)? This problem was studied by (including our very own) Canonne-Diakonikolas-Kane-Stewart, and is known that (O(d^{7/4})) samples suffice. Here, (d) denotes the maximum alphabet size for each coordinate, so the overall domain size is (d^3). This paper gives a much more nuanced complexity, that depends separately on the support sizes for each coordinate. It is interesting that each coordinate plays a different role in the final complexity.\n    \n  \n\n\nTight simulation of a distribution using conditional samples by Tomer Adar (arXiv). Consider a distribution of ({0,1}^n). Many distribution testing results would not yield useful algorithms for this setting, since the domain is exponentially large. Inspired by this setting, the subcube conditional model was introduced by Bhattacharyya-Chakraborty. In this setting, we can generate samples conditioned on any subcube. The aim of this paper goes beyond property testing. Can we actually estimate specific values of the distribution with a few queries? Can we simulate the distribution, which means to “locally compute” a distribution that is close to the input? Specifically, given domain point (x), we want to compute a value (\\mu(x)) such that (\\mu) represents a distribution close to the input. This paper gives such a result, where each (\\mu(x)) can be computed in (O(n^2/\\varepsilon^2)) queries. The final distribution has KL-divergence (\\varepsilon^2) from the original.\n\n\n  \n    \n      Sampling and Identity-Testing Without Approximate Tensorization of Entropy by William Gay, William He, Nicholas Kocurek, and Ryan O’Donnell (arXiv). Again, consider a distribution (D) over a large product domain (\\Sigma^n). Our aim is identity testing, so we wish to determine if ({D} = {D}’) or (\n      {D} – {D}’\n      &gt; \\varepsilon), where ({D}’) is some explicitly known distribution. The model is much weaker than subcube condition access. Essentially, we can only get samples from subcubes of dimension (at least) (n-1). Blanca-Chen-Štefankovič-Vigoda studied identity testing where ({D}) satisfies a condition called “approximate tensorization of entropy” (ATE). By Jensen’s inequality, if ({D}) is a product distribution, the entropy of ({D}) is at most the sum of entropies of the marginal distributions. If the entropy of ({D}) is (say) at most a constant factor of this sum, we say it satisfies the ATE. Blanca-Chen-Štefankovič-Vigoda proves that (\\widetilde{O}(n/\\varepsilon)) suffices for identity testing. This paper studies input distributions that are mixtures of (say, a constant number of) distributions satisfying ATE. Interestingly, these mixtures do not satisfy the ATE. But this paper shows that one can still get (\\widetilde{O}(n/\\varepsilon)) query identity testers.\n    \n  \n\n\nBy Seshadhri\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: To buy or not to buy: deterministic rent-or-buy problems on",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-to-buy-or-not-to-buy-deterministic-rent-or-buy-problems-on-node-weighted-graphs/",
      "content": "Authors: Sander Borst, Moritz Venzin\n\nWe study the rent-or-buy variant of the online Steiner forest problem on\nnode- and edge-weighted graphs. For $n$-node graphs with at most $\\bar{n}$\nnon-zero node-weights, and at most $\\tilde{k}$ different arriving terminal\npairs, we obtain a deterministic, $O(\\log n \\log \\bar{n})$-competitive\nalgorithm. This improves on the previous best, $O(\\log^4 n)$-competitive\nalgorithm obtained by the black-box reduction from (Bartal et al. 2021)\ncombined with the previously best deterministic algorithms for the simpler\n‘buy-only’ setting. We also obtain a deterministic, $O(\\bar{n}\\log\n\\tilde{k})$-competitive algorithm. This generalizes the $O(\\log\n\\tilde{k})$-competitive algorithm for the purely edge-weighted setting from\n(Umboh 2015). We also obtain a randomized, $O(\\log \\tilde{k} \\log\n\\bar{n})$-competitive algorithm. All previous approaches were based on the\nrandomized, black-box reduction from~\\cite{AwerbuchAzarBartal96} that achieves\na $O(\\log \\tilde{k} \\log n)$-competitive ratio when combined with an algorithm\nfor the ‘buy-only’ setting. Our key technical ingredient is a novel charging\nscheme to an instance of \\emph{online prize-collecting set cover}. This allows\nus to extend the witness-technique of (Umboh 2015) to the node-weighted setting\nand obtain refined guarantees with respect to $\\bar{n}$, already in the much\nsimpler ‘buy-only’ setting.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Parallel Complexity of Finding a Matroid Basis",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-the-parallel-complexity-of-finding-a-matroid-basis/",
      "content": "Authors: Sanjeev Khanna, Aaron Putterman, Junkai Song\n\nA fundamental question in parallel computation, posed by Karp, Upfal, and\nWigderson (FOCS 1985, JCSS 1988), asks: \\emph{given only independence-oracle\naccess to a matroid on $n$ elements, how many rounds are required to find a\nbasis using only polynomially many queries?} This question generalizes, among\nothers, the complexity of finding bases of linear spaces, partition matroids,\nand spanning forests in graphs. In their work, they established an upper bound\nof $O(\\sqrt{n})$ rounds and a lower bound of $\\widetilde{\\Omega}(n^{1/3})$\nrounds for this problem, and these bounds have remained unimproved since then.\nIn this work, we make the first progress in narrowing this gap by designing a\nparallel algorithm that finds a basis of an arbitrary matroid in\n$\\tilde{O}(n^{7/15})$ rounds (using polynomially many independence queries per\nround) with high probability, surpassing the long-standing $O(\\sqrt{n})$\nbarrier. Our approach introduces a novel matroid decomposition technique and\nother structural insights that not only yield this general result but also lead\nto a much improved new algorithm for the class of \\emph{partition matroids}\n(which underlies the $\\widetilde\\Omega(n^{1/3})$ lower bound of Karp, Upfal,\nand Wigderson). Specifically, we develop an $\\tilde{O}(n^{1/3})$-round\nalgorithm, thereby settling the round complexity of finding a basis in\npartition matroids.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Constant-Factor Approximability of Minimum Cost Constraint",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-the-constant-factor-approximability-of-minimum-cost-constraint-satisfaction-problems/",
      "content": "Authors: Ian DeHaan, Neng Huang, Euiwoong Lee\n\nWe study minimum cost constraint satisfaction problems (MinCostCSP) through\nthe algebraic lens. We show that for any constraint language $\\Gamma$ which has\nthe dual discriminator operation as a polymorphism, there exists a\n$|D|$-approximation algorithm for MinCostCSP$(\\Gamma)$ where $D$ is the domain.\nComplementing our algorithmic result, we show that any constraint language\n$\\Gamma$ where MinCostCSP$(\\Gamma)$ admits a constant-factor approximation must\nhave a \\emph{near-unanimity} (NU) polymorphism unless P = NP, extending a\nsimilar result by Dalmau et al. on MinCSPs. These results imply a dichotomy of\nconstant-factor approximability for constraint languages that contain all\npermutation relations (a natural generalization for Boolean CSPs that allow\nvariable negation): either MinCostCSP$(\\Gamma)$ has an NU polymorphism and is\n$|D|$-approximable, or it does not have any NU polymorphism and is NP-hard to\napproximate within any constant factor. Finally, we present a constraint\nlanguage which has a majority polymorphism, but is nonetheless NP-hard to\napproximate within any constant factor assuming the Unique Games Conjecture,\nshowing that the condition of having an NU polymorphism is in general not\nsufficient unless UGC fails.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On Fair Epsilon Net and Geometric Hitting Set",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-on-fair-epsilon-net-and-geometric-hitting-set/",
      "content": "Authors: Mohsen Dehghankar, Stavros Sintos, Abolfazl Asudeh\n\nFairness has emerged as a formidable challenge in data-driven decisions. Many\nof the data problems, such as creating compact data summaries for approximate\nquery processing, can be effectively tackled using concepts from computational\ngeometry, such as $\\varepsilon$-nets. However, these powerful tools have yet to\nbe examined from the perspective of fairness. To fill this research gap, we add\nfairness to classical geometric approximation problems of $\\varepsilon$-net,\n$\\varepsilon$-sample, and geometric hitting set. We introduce and address two\nnotions of group fairness: demographic parity, which requires preserving group\nproportions from the input distribution, and custom-ratios fairness, which\ndemands satisfying arbitrary target ratios. We develop two algorithms to\nenforce fairness: one based on sampling and another on discrepancy theory. The\nsampling-based algorithm is faster and computes a fair $\\varepsilon$-net of\nsize which is only larger by a $\\log(k)$ factor compared to the standard\n(unfair) $\\varepsilon$-net, where $k$ is the number of demographic groups. The\ndiscrepancy-based algorithm is slightly slower (for bounded VC dimension), but\nit computes a smaller fair $\\varepsilon$-net. Notably, we reduce the fair\ngeometric hitting set problem to finding fair $\\varepsilon$-nets. This results\nin a $O(\\log \\mathsf{OPT} \\times \\log k)$ approximation of a fair geometric\nhitting set. Additionally, we show that under certain input distributions,\nconstructing fair $\\varepsilon$-samples can be infeasible, highlighting\nlimitations in fair sampling. Beyond the theoretical guarantees, our\nexperimental results validate the practical effectiveness of the proposed\nalgorithms. In particular, we achieve zero unfairness with only a modest\nincrease in output size compared to the unfair setting.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Mallows Model with Learned Distance Metrics: Sampling and Maximum",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-mallows-model-with-learned-distance-metrics-sampling-and-maximum-likelihood-estimation/",
      "content": "Authors: Yeganeh Alimohammadi, Kiana Asgari\n\n\\textit{Mallows model} is a widely-used probabilistic framework for learning\nfrom ranking data, with applications ranging from recommendation systems and\nvoting to aligning language models with human\npreferences~\\cite{chen2024mallows, kleinberg2021algorithmic,\nrafailov2024direct}. Under this model, observed rankings are noisy\nperturbations of a central ranking $\\sigma$, with likelihood decaying\nexponentially in distance from $\\sigma$, i.e, $P (\\pi) \\propto \\exp\\big(-\\beta\n\\cdot d(\\pi, \\sigma)\\big),$ where $\\beta &gt; 0$ controls dispersion and $d$ is a\ndistance function.\nExisting methods mainly focus on fixed distances (such as Kendall’s $\\tau$\ndistance), with no principled approach to learning the distance metric directly\nfrom data. In practice, however, rankings naturally vary by context; for\ninstance, in some sports we regularly see long-range swaps (a low-rank team\nbeating a high-rank one), while in others such events are rare. Motivated by\nthis, we propose a generalization of Mallows model that learns the distance\nmetric directly from data. Specifically, we focus on $L_\\alpha$ distances:\n$d_\\alpha(\\pi,\\sigma):=\\sum_{i=1} |\\pi(i)-\\sigma(i)|^\\alpha$.\nFor any $\\alpha\\geq 1$ and $\\beta&gt;0$, we develop a Fully Polynomial-Time\nApproximation Scheme (FPTAS) to efficiently generate samples that are\n$\\epsilon$- close (in total variation distance) to the true distribution. Even\nin the special cases of $L_1$ and $L_2$, this generalizes prior results that\nrequired vanishing dispersion ($\\beta\\to0$). Using this sampling algorithm, we\npropose an efficient Maximum Likelihood Estimation (MLE) algorithm that jointly\nestimates the central ranking, the dispersion parameter, and the optimal\ndistance metric. We prove strong consistency results for our estimators (for\nany values of $\\alpha$ and $\\beta$), and we validate our approach empirically\nusing datasets from sports rankings.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: H-Planarity and Parametric Extensions: when Modulators Act Globally",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-h-planarity-and-parametric-extensions-when-modulators-act-globally/",
      "content": "Authors: Fedor V. Fomin, Petr A. Golovach, Laure Morelle, Dimitrios M. Thilikos\n\nWe introduce a series of graph decompositions based on the modulator/target\nscheme of modification problems that enable several algorithmic applications\nthat parametrically extend the algorithmic potential of planarity. In the core\nof our approach is a polynomial time algorithm for computing planar\nH-modulators. Given a graph class H, a planar H-modulator of a graph G is a set\nX \\subseteq V(G) such that the ``torso’’ of X is planar and all connected\ncomponents of G - X belong to H. Here, the torso of X is obtained from G[X] if,\nfor every connected component of G-X, we form a clique out of its neighborhood\non G[X]. We introduce H-Planarity as the problem of deciding whether a graph G\nhas a planar H-modulator. We prove that, if H is hereditary, CMSO-definable,\nand decidable in polynomial time, then H-Planarity is solvable in polynomial\ntime. Further, we introduce two parametric extensions of H-Planarity by\ndefining the notions of H-planar treedepth and H-planar treewidth, which\ngeneralize the concepts of elimination distance and tree decompositions to the\nclass H. Combining this result with existing FPT algorithms for various\nH-modulator problems, we thereby obtain FPT algorithms parameterized by\nH-planar treedepth and H-planar treewidth for numerous graph classes H. By\ncombining the well-known algorithmic properties of planar graphs and graphs of\nbounded treewidth, our methods for computing H-planar treedepth and H-planar\ntreewidth lead to a variety of algorithmic applications. For instance, once we\nknow that a given graph has bounded H-planar treedepth or bounded H-planar\ntreewidth, we can derive additive approximation algorithms for graph coloring\nand polynomial-time algorithms for counting (weighted) perfect matchings.\nFurthermore, we design Efficient Polynomial-Time Approximation Schemes\n(EPTAS-es) for several problems, including Maximum Independent Set.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Finding a solution to the Erds-Ginzburg-Ziv theorem in",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-finding-a-solution-to-the-erd-s-ginzburg-ziv-theorem-in-o-n-log-log-log-n-time/",
      "content": "Authors: Yui Hin Arvin Leung\n\nThe Erd\\H{o}s-Ginzburg-Ziv theorem states that for any sequence of $2n-1$\nintegers, there exists a subsequence of $n$ elements whose sum is divisible by\n$n$. In this article, we provide a simple, practical $O(n\\log\\log n)$ algorithm\nand a theoretical $O(n\\log\\log\\log n)$ algorithm, both of which improve upon\nthe best previously known $O(n\\log n)$ approach. This shows that a specific\nvariant of boolean convolution can be implemented in time faster than the usual\n$O(n\\log n)$ expected from FFT-based methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Fast and Efficient Merge of Sorted Input Lists in Hardware Using List",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-fast-and-efficient-merge-of-sorted-input-lists-in-hardware-using-list-offset-merge-sorters/",
      "content": "Authors: Robert B. Kent, Marios S. Pattichis\n\nA new set of hardware merge sort devices are introduced here, which merge\nmultiple sorted input lists into a single sorted output list in a fast and\nefficient manner. In each merge sorter, the values from the sorted input lists\nare arranged in an input 2-D setup array, but with the order of each sorted\ninput list offset from the order of each of the other sorted input lists. In\nthese new devices, called List Offset Merge Sorters (LOMS), a minimal set of\ncolumn sort stages alternating with row sort stages process the input setup\narray into a final output array, now in the defined sorted order. LOMS 2-way\nsorters, which merge 2 sorted input lists, require only 2 merge stages and are\nsignificantly faster than Kenneth Batcher’s previous state-of-the-art 2-way\nmerge devices, Bitonic Merge Sorters and Odd-Even Merge Sorters. LOMS 2-way\nsorters utilize the recently-introduced Single-Stage 2-way Merge Sorters (S2MS)\nin their first stage. Both LOMS and S2MS devices can merge any mixture of input\nlist sizes, while Batcher’s merge sorters are difficult to design unless the 2\ninput lists are equal, and a power-of-2. By themselves, S2MS devices are the\nfastest 2-way merge sorters when implemented in this study’s target FPGA\ndevices, but they tend to use a large number of LUT resources. LOMS 2-way\ndevices use fewer resources than comparable S2MS devices, enabling some large\nLOMS devices to be implemented in a given FPGA when comparable S2MS devices\ncannot fit in that FPGA. A List Offset 2-way sorter merges 2 lists, each with\n32 values, into a sorted output list of those 64 values in 2.24 nS, a speedup\nof 2.63 versus a comparable Batcher device. A LOMS 3-way merge sorter, merging\n3 sorted input lists with 7 values, fully merges the 21 values in 3.4 nS, a\nspeedup of 1.36 versus the comparable state-of-the-art 3-way merge device.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Beer Path Problems in Temporal Graphs",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-beer-path-problems-in-temporal-graphs/",
      "content": "Authors: Andrea D’Ascenzo, Giuseppe F. Italiano, Sotiris Kanellopoulos, Anna Mpanti, Aris Pagourtzis, Christos Pergaminelis\n\nComputing paths in graph structures is a fundamental operation in a wide\nrange of applications, from transportation networks to data analysis. The beer\npath problem, which captures the option of visiting points of interest, such as\ngas stations or convenience stops, prior to reaching the final destination, has\nbeen recently introduced and extensively studied in static graphs. However,\nexisting approaches do not account for temporal information, which is often\ncrucial in real-world scenarios. For instance, transit services may follow\nfixed schedules, and shops may only be accessible during certain hours.\nIn this work, we introduce the notion of beer paths in temporal graphs, where\nedges are time-dependent and certain vertices (beer vertices) are active only\nat specific time instances. We formally define the problems of computing\nearliest-arrival, latest-departure, fastest, and shortest temporal beer paths\nand propose efficient algorithms for these problems under both edge stream and\nadjacency list representations. The time complexity of each of our algorithms\nis aligned with that of corresponding temporal pathfinding algorithms, thus\npreserving efficiency.\nAdditionally, we present preprocessing techniques that enable efficient query\nanswering under dynamic conditions, for example new openings or closings of\nshops. We achieve this through appropriate precomputation of selected paths or\nby transforming a temporal graph into an equivalent static graph.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Approximation Algorithms for the Cumulative Vehicle Routing Problem with",
      "url": "/cstheoryrss/2025/07/14/arxiv-data-structures-and-algorithms-approximation-algorithms-for-the-cumulative-vehicle-routing-problem-with-stochastic-demands/",
      "content": "Authors: Jingyang Zhao, Mingyu Xiao\n\nIn the Cumulative Vehicle Routing Problem (Cu-VRP), we need to find a\nfeasible itinerary for a capacitated vehicle located at the depot to satisfy\ncustomers’ demand, as in the well-known Vehicle Routing Problem (VRP), but the\ngoal is to minimize the cumulative cost of the vehicle, which is based on the\nvehicle’s load throughout the itinerary. If the demand of each customer is\nunknown until the vehicle visits it, the problem is called Cu-VRP with\nStochastic Demands (Cu-VRPSD). Assume that the approximation ratio of metric\nTSP is $1.5$. In this paper, we propose a randomized $3.456$-approximation\nalgorithm for Cu-VRPSD, improving the best-known approximation ratio of $6$\n(Discret. Appl. Math. 2020). Since VRP with Stochastic Demands (VRPSD) is a\nspecial case of Cu-VRPSD, as a corollary, we also obtain a randomized\n$3.25$-approximation algorithm for VRPSD, improving the best-known\napproximation ratio of $3.5$ (Oper. Res. 2012). For Cu-VRP, we give a\nrandomized $3.194$-approximation algorithm, improving the best-known\napproximation ratio of $4$ (Oper. Res. Lett. 2013). Moreover, if each customer\nis allowed to be satisfied by using multiple tours, we obtain further\nimprovements for Cu-VRPSD and Cu-VRP.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Flexible arrangement of two Bennett tubes",
      "url": "/cstheoryrss/2025/07/14/arxiv-computational-geometry-flexible-arrangement-of-two-bennett-tubes/",
      "content": "Authors: Georg Nawratil\n\nIn analogy to flexible bipyramids, also known as Bricard octahedra, we study\nflexible couplings of two Bennett mechanisms. The resulting flexible bi-Bennett\nstructures can be used as building blocks of flexible tubes with quadrilateral\ncross-section that possess skew faces. We present three 4-dimensional families\nof flexible arranged Bennett tubes and discuss some of their properties as well\nas their relation to flexible bipyramids and biprisms, respectively.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Computing optimal trajectories for a tethered pursuer",
      "url": "/cstheoryrss/2025/07/14/arxiv-computational-geometry-computing-optimal-trajectories-for-a-tethered-pursuer/",
      "content": "Authors: Aurelio Barrera-Vicent, José Miguel Díaz-Báñez, Fabio Rodríguez, Vanesa Sánchez-Canales\n\nIn this paper, we introduce a trajectory planning problem for a marsupial\nrobotics system consisting of a ground robot, a drone, and a taut tether of\nbounded length connecting the two robots. This problem can be framed within the\ncontext of a pursuit-evasion game. Using a geometric modeling approach, we\npresent an optimal algorithm to compute a minimum-link path for the pursuer\n(ground robot), given the known path of the evader (drone). Furthermore, we\naddress and solve three related geometric optimization problems, leveraging the\nintrinsic connections between them.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Robust Approach to Detect Intersections between Triangles with",
      "url": "/cstheoryrss/2025/07/14/arxiv-computational-geometry-a-robust-approach-to-detect-intersections-between-triangles-with-different-numerical-representations/",
      "content": "Authors: Luca Garau, Gianmarco Cherchi\n\nThe detection and classification of intersections between triangles are\ncrucial tasks in a wide range of applications within Computer Graphics and\nGeometry Processing, including mesh Arrangements, mesh Booleans, and generic\nmesh processing and fixing tasks. Existing methods are hard-coded and deeply\nintegrated into specific algorithms, and significant efforts are usually\nrequired to integrate them into new pipelines or to extend them to different\nnumerical representations. This paper presents a versatile and exhaustive\nalgorithm to identify and classify intersections between triangles with either\nfloating points, rational numbers, or implicit representations. The proposed\ntool is implemented as a C++ templated and header-only code that is generic and\neasy to integrate into further algorithms requiring the triangle-triangle\nintersection detection step. The developed tool has been tested and compared\nwith a state-of-the-art approach, and it is shared with the Geometry Processing\ncommunity with an Open Source license.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Constant-Factor Approximability of Minimum Cost Constraint",
      "url": "/cstheoryrss/2025/07/14/arxiv-computational-complexity-on-the-constant-factor-approximability-of-minimum-cost-constraint-satisfaction-problems/",
      "content": "Authors: Ian DeHaan, Neng Huang, Euiwoong Lee\n\nWe study minimum cost constraint satisfaction problems (MinCostCSP) through\nthe algebraic lens. We show that for any constraint language $\\Gamma$ which has\nthe dual discriminator operation as a polymorphism, there exists a\n$|D|$-approximation algorithm for MinCostCSP$(\\Gamma)$ where $D$ is the domain.\nComplementing our algorithmic result, we show that any constraint language\n$\\Gamma$ where MinCostCSP$(\\Gamma)$ admits a constant-factor approximation must\nhave a \\emph{near-unanimity} (NU) polymorphism unless P = NP, extending a\nsimilar result by Dalmau et al. on MinCSPs. These results imply a dichotomy of\nconstant-factor approximability for constraint languages that contain all\npermutation relations (a natural generalization for Boolean CSPs that allow\nvariable negation): either MinCostCSP$(\\Gamma)$ has an NU polymorphism and is\n$|D|$-approximable, or it does not have any NU polymorphism and is NP-hard to\napproximate within any constant factor. Finally, we present a constraint\nlanguage which has a majority polymorphism, but is nonetheless NP-hard to\napproximate within any constant factor assuming the Unique Games Conjecture,\nshowing that the condition of having an NU polymorphism is in general not\nsufficient unless UGC fails.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Communication complexity of pointer chasing via the fixed-set lemma",
      "url": "/cstheoryrss/2025/07/14/arxiv-computational-complexity-communication-complexity-of-pointer-chasing-via-the-fixed-set-lemma/",
      "content": "Authors: Emanuele Viola\n\nI give a very simple, apparently new proof of a tight communication lower\nbound for pointer chasing.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: How much money did Francis Scott Key give to have a building named after him?",
      "url": "/cstheoryrss/2025/07/13/computational-complexity-how-much-money-did-francis-scott-key-give-to-have-a-building-named-after-him/",
      "content": "UMCP has a building named\n\nThe Francis Scott Key Building\n\nSTUDENT: How much money did Francis Scott Key give to have a building named after him?\n\nBILL: He didn’t give money. He wrote The Star Spangled Banner.\n\nSTUDENT: I get it! He left the royalties! That would be a lot since Major League Baseball plays that song before every game!\n\nBILL: The song is in the public domain.\n\nSTUDENT: That’s too bad. Well, at least UMCP got some money out of it before it was in the public domain.\n\nBILL: Francis Scott Key did not give UMCP the royalties from his song.\n\nSTUDENT: Well then what did he give UMCP?\n\nBILL: He didn’t give UMCP anything. He died in 1843 and UMCP was founded in 1856.\n\nSTUDENT: Oh. So his descendants gave money to have a building named after him.\n\nBILL: No, that didn’t happen either.\n\nSTUDENT: Then why is there a building named after him?\n\nBILL: To honor him.\n\nSTUDENT: What does that mean? The only reason to name a building after someone is if they give money to the school. The notion of “honoring someone” sounds so odd–in fact I honestly don’t know what it means. OH, I get it, they are just using that name as a placeholder until they find someone who gives the school money for a building.\n\nBILL: I doubt that. Once a building is named to honor someone, it won’t change the name for money. That’s just too crass.\n\nLANCE: Don’t be so sure. When I started undergrad at Cornell in 1981, Benjamin Franklin hall, the site of the country’s first Electrical Engineering Department, was just renamed to Olive Tjaden hall. One of my professors made fun of the change, “Why should we name it after Ben Franklin—he never donated to Cornell”.\n\nDuring an alumni weekend, we had a visit from a former alum and his wife, Olive Tjaden, to my fraternity, Kappa Delta Rho (Yes, I was a frat boy in college). She was not shy about bragging that the building was named after her. For some reason Mr. Franklin never showed up to defend the old name.\n\nCornell still has a Lincoln Hall named after the former president.\n\nBILL: Does any campus name buildings to honor people anymore?\n\nLANCE: At this point I wouldn’t be surprised if some university names a building “Donald J Trump Hall” as part of a settlement.\n\nBut really, these days, you need money to build buildings, so they get named after donors—or after someone the donor wants to honor. Even if a building is built on state funds, it’s usually given a generic name to leave open a naming opportunity later.\n\nBILL: What happens if you name a building after someone because they gave money but later if they found out that they are an X (you can fill it in with some type of person you would not want to honor)? If you had named the building to honor them, you can change the name. If you named it because they gave money you may have a contractual obligation to keep the name. (This was almost a problem with Enron Field, see here).\n\nLANCE: In 2017, Yale renamed Calhoun College, named for a white supremacist, to honor Grace Murray Hopper.\n\nBILL: I hope they got all the bugs out first.\n\nI conjecture very few (any?) colleges name buildings anymore to honor people. It is purely transactional.\n\n1) Am I right?\n\n2) If so, is this a bad thing?\n\n3) And when will Grace Murray Hopper College be renamed again after a donor?\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-092 | Complexity-Theoretic Inductive Inference |",
      "url": "/cstheoryrss/2025/07/12/eccc-papers-tr25-092-complexity-theoretic-inductive-inference-shuichi-hirahara-mikito-nanashima/",
      "content": "Inductive inference, introduced by Solomonoff (Information and Control, 1964), is a foundational concept in knowledge acquisition, formulated as the task of extrapolating a sequence of symbols. In his seminal work, Solomonoff established a fundamental theorem for recursion-theoretic universal inductive inference, applicable to sequences generated by all Turing machines, based on the (uncomputable) task of computing Kolmogorov complexity.\nIn this work, we present a complexity-theoretic counterpart to Solomonoff’s theorem: we construct an efficient universal inductive inference algorithm, applicable to sequences efficiently generated by all randomized Turing machines, assuming that time-bounded Kolmogorov complexity can be efficiently approximated. This assumption is known to follow from the average-csae easiness of NP. As corollaries, we obtain various worst-case learning algorithms, such as distributional learning and learning adaptively changing distributions, under the assumption that NP is easy on average.\nOur inductive inference algorithm and its analysis build on techniques developed in meta-complexity theory. At a high level, the algorithm divides a given sequence of symbols into two parts, “advice” and “context”, and extrapolates the next symbol of the context according to the time-bounded universal distribution given the advice. We prove that this algorithm avoids computationally deep strings, which are hard instances for every average-case algorithm.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Are developers finally out of a job?",
      "url": "/cstheoryrss/2025/07/11/ben-recht-are-developers-finally-out-of-a-job/",
      "content": "\n\nYesterday, METR, one of the many budding nonprofit “AI Safety” institutes in Berkeley, released a study purportedly showing that AI tools slowed down expert developers. Here’s the plot they led with in their announcement:\n\n\n\nBecause METR, like all AI Safety Institutes, is run by devout rationalists, the first four bars here are the values of predictions. Everyone asked said AI would speed up development time. The final bar is the observed result. Ackshually, AI slows down development time.\n\nThis result inevitably broke the internet. The reaction on Twitter was “Bro, that’s clearly wrong.” The reaction on Bluesky was “See, I told you so.” I didn’t check LinkedIn. I wonder if METR’s cross-posting was itself part of an ethnographic study of confirmation bias.\n\nOn Bluesky, Akhil Rao smartly pointed out that the error bar on the speedup is very close to zero and hence must be fragile. It’s a good rule of thumb. But he didn’t want to be “the seminar standard errors guy.”\n\nLong-time readers know that horrible standard errors guy is me. I was ranting about AI papers and error bars last week. I wrote a whole paper about inferential error bars being a silly exercise unless we are using them as part of a clear regulatory rulebook. And hey, if everyone is freaking out about a study “proving” something with frequentist statistics, I’m going to be the sicko who goes and reads the appendix. You will not be surprised that I think the error bars are made up, even if there’s some interesting ethnography we can take away from METR’s work here.\n\nHere’s a summary of how the study worked:\n\n\n  METR recruited 16 developers\n  All 16 brought approximately 16 coding tasks to the study that they wanted to complete.\n  METR assigned each task to one of two conditions at random. Condition 0 is “you can’t use AI.” Condition 1 is “you can use AI.”\n  The developers completed their tasks in whichever order they desired. METR recorded the completion time for each task\n\n\nFirst, I don’t like calling this study an “RCT.” There is no control group! There are 16 people and they receive both treatments. We’re supposed to believe that the “treated units” here are the coding assignments. We’ll see in a second that this characterization isn’t so simple.\n\nAs experimenters, our goal is to figure out how the times in Condition 0 compare to those in Condition 1. There are a couple of ways to think about how to study this. If I were to take my guide from the “potential outcomes” school, I’d say something like the following.\n\nThere is an intrinsic amount of time each task takes in each condition. Unfortunately, I can only see one condition for each task. I can’t complete the tasks both with AI and without AI. I thus have a missing data problem. I can only see half of the times I care about in each condition. Perhaps I can use some clever math to estimate the actual average time in each condition had I seen everything. And I can use even more clever math to estimate the uncertainty in my estimate. You know, error bars.\n\nThis isn’t that crazy if you can sample uniformly at random. Let’s say you have a bunch of playing cards face down on the table in front of you. You want to estimate the proportion of the cards that are red. If you flip half of them uniformly at random, the proportion of red cards in your sample is a reasonable estimate of the proportion of red cars in the sample you didn’t see.\n\nThe problem in this study is that there are a bunch of steps required to go from randomizing the tasks to completing the tasks that cloud the estimation problem. These intermediary steps bias your estimation problem. The developers get to choose the order in which they complete the tasks. Task completion order can affect the amount of time it takes you to complete the task. For instance, if you’re an expert developer and asked to use a new tool, you’ll become faster with it after using it 8 times. Similarly, you can imagine that if you do a bunch of tasks in sequence, your time on task 4 is going to be sluggish because you are tired. There are lots of stories I can tell. There are undoubtedly many conditions that affect the time measurement other than their random assignment.\n\nThese other effects are called spillover or interference effects. In randomized trials, experimentalists work their tails off to remove these effects to ensure they are isolating the effect of the intervention. The ideal experiment satisfies SUTVA, the Stable Unit Treatment Value Assumption, which asserts that the only thing that affects a measured outcome is the assignment to the treatment group or the control group. This is a rather strong modeling assumption, but you perhaps could convince yourself that it is close to true in a carefully controlled, blinded study comparing a drug to a placebo.\n\nUnfortunately, SUTVA does not hold in the METR study. And that means we have to bring out the econometrics to tell the difference between the groups. Here’s where we get to wrestle in the mud with statistics. If you go to the appendix of the paper, you can bore yourself to death with regression models and robustness checks. The main model that they use to make the widely circulated plot (from Appendix D on page 27) is this one:\n\n\n\nThis model more or less says the following: each developer estimates how long a task will take. The median time for each task without AI is a constant times this estimate. The median time with AI is a different constant times the developer estimate. The observed time is the predicted time multiplied by the speedup time for the condition, multiplied by a fudge factor, which is a random variable. The fudge factor is independent of the AI condition, the person’s time estimate, and all of the other fudge factors. The expected value of the fudge factor is one for all tasks. The variance of the fudge factor is the same for all tasks.\n\nThat is, if you’d prefer something that looks like code,\n\ntime(task) = speedup(AI_condition) * est_time(task) * fudge_factor(task)\n\n\nIs that a reasonable model? The AI condition was assigned at random, so it should be independent of the estimated time. But the model assumes everyone experiences the same speed-up/slow-down with the AI tools. Since the fudge factor now includes the developers’ choices for the order in which they perform the tasks, they can’t be probabilistically independent.\n\nOK, so the model is not literally true, but perhaps you can convince me that it’s predictive? All models are wrong, amirite? The authors will now provide a bunch of “robustness checks” to convince you that it is close enough. Now we’re spending pages analyzing normal approximations when maybe we should accept that a precise estimate of “speedup” is impossible to measure with this experiment’s design.\n\nAfter thinking about this for a day, the only data summary I’m happy with would be the following simple analysis: “there are 256 coding tasks, each has an intrinsic time inside of it, when we flip coins we get to see 128 of the times in Condition 1 and 128 of the times in Condition 2. Here are the means and standard deviations of these times.” We could then all move on. I mean, rather than boring us with these robustness checks, METR could just release a CSV with three columns (developer ID, task condition, time). Then the seminar guys can run whatever dumb check they want.1\n\nLet me be clear here, I don’t think METR’s analysis is better or worse than any random quantitative social science study. Measurement in quantitative social sciences is always fraught with an infinite regress of doubt. That doesn’t mean we can’t tell reasonable qualitative stories with quantitative data. What we can glean from this study is that even expert developers aren’t great at predicting how long tasks will take. And despite the new coding tools being incredibly useful, people are certainly far too optimistic about the dramatic gains in productivity they will bring.\n\nThanks to ‪Sam Anthony, Tilman Bayer‬, ‪Isaiah Bishop‬, ‪Robin Blythe‬, Kevin Chen, ‪Greg Faletto, Apoorva Lal‬, Jordan Nafa, Akhil Rao, Anton Strezhnev, and Stephen Wild for hashing these thoughts out on Bluesky last night.\n\nSubscribe now\n\n1\n\nMETR, if you are reading this, please do it.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "CCI: jobs: Postdoc in Complexity Theory at University of Warwick apply by July 31, 2025",
      "url": "/cstheoryrss/2025/07/11/cci-jobs-postdoc-in-complexity-theory-at-university-of-warwick-apply-by-july-31-2025/",
      "content": "A postdoctoral position is available in the research group of Igor Carboni Oliveira at the University of Warwick. Candidates interested in computational complexity theory and/or related areas such as mathematical logic and computational learning theory are encouraged to apply.\n\nWebsite: https://www.dcs.warwick.ac.uk/~igorcarb/position.html\nEmail: igorcarb@gmail.com\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Complexity of Hyperpath and Minimal Separator Enumeration in",
      "url": "/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-on-the-complexity-of-hyperpath-and-minimal-separator-enumeration-in-directed-hypergraphs/",
      "content": "Authors: Kazuhiro Kurita, Kevin Mann\n\nIn this paper, we address the enumeration of (induced) $s$-$t$ paths and\nminimal $s$-$t$ separators. These problems are some of the most famous\nclassical enumeration problems that can be solved in polynomial delay by simple\nbacktracking for a (un)directed graph. As a generalization of these problems,\nwe consider the (induced) $s$-$t$ hyperpath and minimal $s$-$t$ separator\nenumeration in a \\emph{directed hypergraph}. We show that extending these\nclassical enumeration problems to directed hypergraphs drastically changes\ntheir complexity. More precisely, there are no output-polynomial time\nalgorithms for the enumeration of induced $s$-$t$ hyperpaths and minimal\n$s$-$t$ separators unless $P = NP$, and if there is an output-polynomial time\nalgorithm for the $s$-$t$ hyperpath enumeration, then the minimal transversal\nenumeration can be solved in output polynomial time even if a directed\nhypergraph is $BF$-hypergraph. Since the existence of an output-polynomial time\nalgorithm for the minimal transversal enumeration has remained an open problem\nfor over 45 years, it indicates that the $s$-$t$ hyperpath enumeration for a\n$BF$-hypergraph is not an easy problem. As a positive result, the $s$-$t$\nhyperpath enumeration for a $B$-hypergraph can be solved in polynomial delay by\nbacktracking.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Finding sparse induced subgraphs on graphs of bounded induced matching",
      "url": "/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-finding-sparse-induced-subgraphs-on-graphs-of-bounded-induced-matching-treewidth/",
      "content": "Authors: Hans L. Bodlaender, Fedor V. Fomin, Tuukka Korhonen\n\nThe induced matching width of a tree decomposition of a graph $G$ is the\ncardinality of a largest induced matching $M$ of $G$, such that there exists a\nbag that intersects every edge in $M$. The induced matching treewidth of a\ngraph $G$, denoted by $\\mathsf{tree-}\\mu(G)$, is the minimum induced matching\nwidth of a tree decomposition of $G$. The parameter $\\mathsf{tree-}\\mu$ was\nintroduced by Yolov [SODA ‘18], who showed that, for example, Maximum-Weight\nIndependent Set can be solved in polynomial-time on graphs of bounded\n$\\mathsf{tree-}\\mu$. Lima, Milani\\v{c}, Mur\\v{s}i\\v{c}, Okrasa,\nRz\\k{a}.zewski, and \\v{S}torgel [ESA ‘24] conjectured that this algorithm can\nbe generalized to a meta-problem called Maximum-Weight Induced Subgraph of\nBounded Treewidth, where we are given a vertex-weighted graph $G$, an integer\n$w$, and a $\\mathsf{CMSO}_2$-sentence $\\Phi$, and are asked to find a\nmaximum-weight set $X \\subseteq V(G)$ so that $G[X]$ has treewidth at most $w$\nand satisfies $\\Phi$. They proved the conjecture for some special cases, such\nas for the problem Maximum-Weight Induced Forest.\nIn this paper, we prove the general case of the conjecture. In particular, we\nshow that Maximum-Weight Induced Subgraph of Bounded Treewidth is\npolynomial-time solvable when $\\mathsf{tree-}\\mu(G)$, $w$, and $|\\Phi|$ are\nbounded. The running time of our algorithm for $n$-vertex graphs $G$ with\n$\\mathsf{tree} - \\mu(G) \\le k$ is $f(k, w, |\\Phi|) \\cdot n^{O(k w^2)}$ for a\ncomputable function $f$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Finding One Local Optimum Is Easy -- But What about Two?",
      "url": "/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-finding-one-local-optimum-is-easy-but-what-about-two/",
      "content": "Authors: Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi\n\nThe class PLS (Polynomial Local Search) captures the complexity of finding a\nsolution that is locally optimal and has proven to be an important concept in\nthe theory of local search. It has been shown that local search versions of\nvarious combinatorial optimization problems, such as Maximum Independent Set\nand Max Cut, are complete for this class. Such computational intractability\ntypically arises in local search problems allowing arbitrary weights; in\ncontrast, for unweighted problems, locally optimal solutions can be found in\npolynomial time under standard settings. In this paper, we pursue the\ncomplexity of local search problems from a different angle: We show that\ncomputing two locally optimal solutions is NP-hard for various natural\nunweighted local search problems, including Maximum Independent Set, Minimum\nDominating Set, Max SAT, and Max Cut. We also discuss several tractable cases\nfor finding two (or more) local optimal solutions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Efficient and Adaptive Estimation of Local Triadic Coefficients",
      "url": "/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-efficient-and-adaptive-estimation-of-local-triadic-coefficients/",
      "content": "Authors: Ilie Sarpe, Aristides Gionis\n\nCharacterizing graph properties is fundamental to the analysis and to our\nunderstanding of real-world networked systems. The local clustering\ncoefficient, and the more recently introduced, local closure coefficient,\ncapture powerful properties that are essential in a large number of\napplications, ranging from graph embeddings to graph partitioning. Such\ncoefficients capture the local density of the neighborhood of each node,\nconsidering incident triadic structures and paths of length two. For this\nreason, we refer to these coefficients collectively as local triadic\ncoefficients.\nIn this work, we consider the novel problem of computing efficiently the\naverage of local triadic coefficients, over a given partition of the nodes of\nthe input graph into a set of disjoint buckets. The average local triadic\ncoefficients of the nodes in each bucket provide a better insight into the\ninterplay of graph structure and the properties of the nodes associated to each\nbucket. Unfortunately, exact computation, which requires listing all triangles\nin a graph, is infeasible for large networks. Hence, we focus on obtaining\nhighly-accurate probabilistic estimates.\nWe develop Triad, an adaptive algorithm based on sampling, which can be used\nto estimate the average local triadic coefficients for a partition of the nodes\ninto buckets. Triad is based on a new class of unbiased estimators, and\nnon-trivial bounds on its sample complexity, enabling the efficient computation\nof highly accurate estimates. Finally, we show how Triad can be efficiently\nused in practice on large networks, and we present a case study showing that\naverage local triadic coefficients can capture high-order patterns over\ncollaboration networks.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Randomized Rounding Approach for DAG Edge Deletion",
      "url": "/cstheoryrss/2025/07/11/arxiv-data-structures-and-algorithms-a-randomized-rounding-approach-for-dag-edge-deletion/",
      "content": "Authors: Sina Kalantarzadeh, Nathan Klein, Victor Reis\n\nIn the DAG Edge Deletion problem, we are given an edge-weighted directed\nacyclic graph and a parameter $k$, and the goal is to delete the minimum weight\nset of edges so that the resulting graph has no paths of length $k$. This\nproblem, which has applications to scheduling, was introduced in 2015 by\nKenkre, Pandit, Purohit, and Saket. They gave a $k$-approximation and showed\nthat it is UGC-Hard to approximate better than $\\lfloor 0.5k \\rfloor$ for any\nconstant $k \\ge 4$ using a work of Svensson from 2012. The approximation ratio\nwas improved to $\\frac{2}{3}(k+1)$ by Klein and Wexler in 2016.\nIn this work, we introduce a randomized rounding framework based on\ndistributions over vertex labels in $[0,1]$. The most natural distribution is\nto sample labels independently from the uniform distribution over $[0,1]$. We\nshow this leads to a $(2-\\sqrt{2})(k+1) \\approx 0.585(k+1)$-approximation. By\nusing a modified (but still independent) label distribution, we obtain a\n$0.549(k+1)$-approximation for the problem, as well as show that no independent\ndistribution over labels can improve our analysis to below $0.542(k+1)$.\nFinally, we show a $0.5(k+1)$-approximation for bipartite graphs and for\ninstances with structured LP solutions. Whether this ratio can be obtained in\ngeneral is open.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: The Smooth Power of the Neandertal Method",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-geometry-the-smooth-power-of-the-neandertal-method/",
      "content": "Authors: Aaron Montag, Tim Reinhardt, Jürgen Richter-Gebert\n\nWe describe an algorithmic method to transform a Euclidean wallpaper pattern\ninto a Circle Limit-style picture `a la Escher. The design goals for the\nmethod are to be mathematically sound, aesthetically pleasing and fast to\ncompute. It turns out that a certain class of conformal maps is particularly\nwell-suited for the problem. Moreover, in our specific application, a very\nsimple method, sometimes jokingly called the “Neandertal Method” for its almost\nbrutal simplicity, proves to be highly efficient, as it can easily be\nparallelized to be run on the GPU, unlike many other approaches.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Approximation Depth of Convex Polytopes",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-geometry-approximation-depth-of-convex-polytopes/",
      "content": "Authors: Egor Bakaev, Florestan Brunck, Amir Yehudayoff\n\nWe study approximations of polytopes in the standard model for computing\npolytopes using Minkowski sums and (convex hulls of) unions. Specifically, we\nstudy the ability to approximate a target polytope by polytopes of a given\ndepth. Our main results imply that simplices can only be trivially\napproximated''. On the way, we obtain a characterization of simplices as the\nonlyouter additive’’ convex bodies.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A simple proof of a p,2-theorem for non-piercing regions",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-geometry-a-simple-proof-of-a-p-2-theorem-for-non-piercing-regions/",
      "content": "Authors: Chaya Keller, Shakhar Smorodinsky\n\nA family of sets satisfies the $(p,2)$-property if among any $p$ sets in the\nfamily, some two intersect. Two recent works used elaborate geometric\ntechniques to show that any family of non-piercing regions in the plane that\nsatisfies the $(p,2)$-property can be pierced by $O(p^9)$ points. In this note\nwe show that even in a much more general setting, piercing by $O(p)$ points can\nbe deduced from known results on hypergraphs with a hereditarily linear\nDelaunay graph, which include intersection hypergraphs of non-piercing regions.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Turing complete Navier-Stokes steady states via cosymplectic geometry",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-turing-complete-navier-stokes-steady-states-via-cosymplectic-geometry/",
      "content": "Authors: Søren Dyhr, Ángel González-Prieto, Eva Miranda, Daniel Peralta-Salas\n\nIn this article, we construct stationary solutions to the Navier-Stokes\nequations on certain Riemannian $3$-manifolds that exhibit Turing completeness,\nin the sense that they are capable of performing universal computation. This\nuniversality arises on manifolds admitting nonvanishing harmonic 1-forms, thus\nshowing that computational universality is not obstructed by viscosity,\nprovided the underlying geometry satisfies a mild cohomological condition. The\nproof makes use of a correspondence between nonvanishing harmonic $1$-forms and\ncosymplectic geometry, which extends the classical correspondence between\nBeltrami fields and Reeb flows on contact manifolds.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: The Richness of CSP Non-redundancy",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-the-richness-of-csp-non-redundancy/",
      "content": "Authors: Joshua Brakensiek, Venkatesan Guruswami, Bart M. P. Jansen, Victor Lagerkvist, Magnus Wahlström\n\nIn the field of constraint satisfaction problems (CSP), a clause is called\nredundant if its satisfaction is implied by satisfying all other clauses. An\ninstance of CSP$(P)$ is called non-redundant if it does not contain any\nredundant clause. The non-redundancy (NRD) of a predicate $P$ is the maximum\nnumber of clauses in a non-redundant instance of CSP$(P)$, as a function of the\nnumber of variables $n$. Recent progress has shown that non-redundancy is\ncrucially linked to many other important questions in computer science and\nmathematics including sparsification, kernelization, query complexity,\nuniversal algebra, and extremal combinatorics. Given that non-redundancy is a\nnexus for many of these important problems, the central goal of this paper is\nto more deeply understand non-redundancy.\nOur first main result shows that for every rational number $r \\ge 1$, there\nexists a finite CSP predicate $P$ such that the non-redundancy of $P$ is\n$\\Theta(n^r)$. Our second main result explores the concept of conditional\nnon-redundancy first coined by Brakensiek and Guruswami [STOC 2025]. We\ncompletely classify the conditional non-redundancy of all binary predicates\n(i.e., constraints on two variables) by connecting these non-redundancy\nproblems to the structure of high-girth graphs in extremal combinatorics.\nInspired by these concrete results, we build off the work of Carbonnel [CP\n2022] to develop an algebraic theory of conditional non-redundancy. As an\napplication of this algebraic theory, we revisit the notion of Mal’tsev\nembeddings, which is the most general technique known to date for establishing\nthat a predicate has linear non-redundancy. For example, we provide the first\nexample of predicate with a Mal’tsev embedding that cannot be attributed to the\nstructure of an Abelian group, but rather to the structure of the quantum Pauli\ngroup.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Testing Isomorphism of Boolean Functions over Finite Abelian Groups",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-testing-isomorphism-of-boolean-functions-over-finite-abelian-groups/",
      "content": "Authors: Swarnalipa Datta, Arijit Ghosh, Chandrima Kayal, Manaswi Paraashar, Manmatha Roy\n\nLet $f$ and $g$ be Boolean functions over a finite Abelian group\n$\\mathcal{G}$, where $g$ is fully known, and we have {\\em query access} to $f$,\nthat is, given any $x \\in \\mathcal{G}$ we can get the value $f(x)$. We study\nthe tolerant isomorphism testing problem: given $\\epsilon \\geq 0$ and $\\tau &gt;\n0$, we seek to determine, with minimal queries, whether there exists an\nautomorphism $\\sigma$ of $\\mathcal{G}$ such that the fractional Hamming\ndistance between $f \\circ \\sigma$ and $g$ is at most $\\epsilon$, or whether for\nall automorphisms $\\sigma$, the distance is at least $\\epsilon + \\tau$.\nWe design an efficient tolerant testing algorithm for this problem, with\nquery complexity $\\mathrm{poly}\\left( s, 1/\\tau \\right)$, where $s$ bounds the\nspectral norm of $g$. Additionally, we present an improved algorithm when $g$\nis Fourier sparse.\nOur approach uses key concepts from Abelian group theory and Fourier\nanalysis, including the annihilator of a subgroup, Pontryagin duality, and a\npseudo inner-product for finite Abelian groups. We believe these techniques\nwill find further applications in property testing.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Complexity of Hyperpath and Minimal Separator Enumeration in",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-on-the-complexity-of-hyperpath-and-minimal-separator-enumeration-in-directed-hypergraphs/",
      "content": "Authors: Kazuhiro Kurita, Kevin Mann\n\nIn this paper, we address the enumeration of (induced) $s$-$t$ paths and\nminimal $s$-$t$ separators. These problems are some of the most famous\nclassical enumeration problems that can be solved in polynomial delay by simple\nbacktracking for a (un)directed graph. As a generalization of these problems,\nwe consider the (induced) $s$-$t$ hyperpath and minimal $s$-$t$ separator\nenumeration in a \\emph{directed hypergraph}. We show that extending these\nclassical enumeration problems to directed hypergraphs drastically changes\ntheir complexity. More precisely, there are no output-polynomial time\nalgorithms for the enumeration of induced $s$-$t$ hyperpaths and minimal\n$s$-$t$ separators unless $P = NP$, and if there is an output-polynomial time\nalgorithm for the $s$-$t$ hyperpath enumeration, then the minimal transversal\nenumeration can be solved in output polynomial time even if a directed\nhypergraph is $BF$-hypergraph. Since the existence of an output-polynomial time\nalgorithm for the minimal transversal enumeration has remained an open problem\nfor over 45 years, it indicates that the $s$-$t$ hyperpath enumeration for a\n$BF$-hypergraph is not an easy problem. As a positive result, the $s$-$t$\nhyperpath enumeration for a $B$-hypergraph can be solved in polynomial delay by\nbacktracking.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Nonogram: Complexity of Inference and Phase Transition Behavior",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-nonogram-complexity-of-inference-and-phase-transition-behavior/",
      "content": "Authors: Aaron Foote, Danny Krizanc\n\nNonogram is a popular combinatorial puzzle (similar in nature to Sudoku or\nMinesweeper) in which a puzzle solver must determine if there exists a setting\nof the puzzle parameters that satisfy a given set of constraints. It has long\nbeen known that the problem of deciding if a solution exists is a\ncomputationally difficult problem. Despite this fact, humans still seem to\nenjoy playing it. This work aims to reconcile these seemingly contradictory\nfacts by (1) analyzing the complexity of the inference problem for Nonogram\n(the problem of determining if there exists a puzzle parameter that can be\ninferred from the constraints without guessing) and (2) experimentally\nestablishing the existence of a phase transition behavior for this inference\nproblem. Our results show that the difficulty of the inference problem is\nlargely determined by the density of filled cells (positive parameters) in a\ngiven puzzle. Along the way we implement an efficient encoding of a Nonogram\nboard as a Boolean formula in Conjunctive Normal Form (CNF) through the use of\nregular expressions in order to make our experiments feasible.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Finding One Local Optimum Is Easy -- But What about Two?",
      "url": "/cstheoryrss/2025/07/11/arxiv-computational-complexity-finding-one-local-optimum-is-easy-but-what-about-two/",
      "content": "Authors: Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi\n\nThe class PLS (Polynomial Local Search) captures the complexity of finding a\nsolution that is locally optimal and has proven to be an important concept in\nthe theory of local search. It has been shown that local search versions of\nvarious combinatorial optimization problems, such as Maximum Independent Set\nand Max Cut, are complete for this class. Such computational intractability\ntypically arises in local search problems allowing arbitrary weights; in\ncontrast, for unweighted problems, locally optimal solutions can be found in\npolynomial time under standard settings. In this paper, we pursue the\ncomplexity of local search problems from a different angle: We show that\ncomputing two locally optimal solutions is NP-hard for various natural\nunweighted local search problems, including Maximum Independent Set, Minimum\nDominating Set, Max SAT, and Max Cut. We also discuss several tractable cases\nfor finding two (or more) local optimal solutions.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: An open mindset",
      "url": "/cstheoryrss/2025/07/10/ben-recht-an-open-mindset/",
      "content": "\n\nOver the 4th of July weekend, Nathan Lambert wrote a thoughtful post on “an American Deepseek Project,” posing the challenge of building a fully open, fully performant “frontier model” in the next two years. Deepseek, in case you’ve already forgotten, is a Chinese company that released a highly performing, open-source large language model chatbot in January that could be trained from scratch for under 10 million dollars. Nathan challenges the US research community to produce a similar open artifact.\n\nNathan’s post reminded me of what happened the last time we were told that you needed to be a hyperscaling tech company to do machine learning. In 2014, a year after paying 44 million dollars for Alex Krizhevsky, Ilya Sutskever, and Geoff Hinton, Google won the ILSVRC competition with their “GoogLeNet” model, achieving 93% top-5 accuracy.1 While the authors didn’t release the full details of how to train this model, they asserted they used Google’s internal DistBelief system, a distributed computing framework for wrangling thousands of Google CPUs. However, based on a back of the envelope calculation, they claimed “ the GoogLeNet network could be trained to convergence using few high-end GPUs within a week, the main limitation being the memory usage.”\n\nShortly thereafter, a team at Berkeley sort of reproduced this result, showing that half a day with 128 GPUs could get to 88% top-5 accuracy with the GoogLeNet architecture. I imagine they could have reached 93% had they run for longer. A supercomputer with 128 GPUs was still a serious investment for any academic team, and openly trained ImageNet models still seemed to require infrastructural investments outside the reach of most labs.\n\nIn 2015, a team of researchers at Microsoft Research Asia in Beijing won the ILSVRC competition with their architecture called the ResNet. ResNets were interesting because the principles of architecture were easier to understand. The repeated layers in ResNets made it easy to explore and reimplement the architecture.\n\nSoon thereafter, the Dawn project at Stanford opened a competition, called DawnBench, to see who could train ResNets the fastest. In November 2017, their baseline entry used 8 GPUs for 10.5 days to train a ResNet ImageNet classifier with 93% top-5 accuracy. This cost $1100 using Amazon cloud services. Already, this was getting somewhere, but I don’t think the Dawn team anticipated how quickly competition progress would come. By April 2018, that is, in less than six months, competitors had the training time down to 30 minutes on a single TPU core on Google Cloud. That’s nearly a 500x acceleration in 6 months, and a dramatic cost reduction.\n\nI tell this story because I’m optimistic that Nathan’s challenge is feasible. For two decades, Google and its peers have argued that you need scale to do anything. These claims are marketing. They have been proven wrong several times,2 but it required a significant community commitment to do it. What are those commitments for Nathan’s Deepseek Project?\n\nFirst, it’s elevating old school computational evaluations. During the initial deep learning boom, the machine learning research community decided that worthy common tasks were training time and model accessibility. These evaluations have been missing from the latest “frontier models” arms race. It’s also understandable that the computing for “frontier models” is much larger than it was for ImageNet. The hyperscalers’ only advantage is to find a starting point that’s inaccessible to a researcher without an infinite cloud computing budget. The 6 million dollars needed to train DeepSeek is out of reach for almost any machine learning researcher. This means that the initial work on any fully open LLM will require large-scale collaboration or perhaps an industrial benefactor. On the other hand, a 500x improvement in training time gets these models down to costing under twenty thousand dollars, which is the sort of thing you can add as a line item in a grant proposal.\n\nMore importantly, I want to emphasize that Nathan’s challenge is for something greater than just GPU golf. When he writes “open model,” he really means open. The Deepseek model is “open weights,” which means you can run and tweak it, but you can’t build it from scratch. This is similar to the openness of Meta’s Llama models. Nathan’s vision calls for open data, training code, logs, and decision making too.\n\nI will never get over how the entire machine learning community is writing papers about systems where they don’t know what the training data is. Yes, the artifacts are interesting, but no, we’re not going to learn anything by fine-tuning RL models on top and running hackneyed 1960s psychology experiments on computers. Certainly, open weight models are preferable to closed weight models. But we shouldn’t have to settle.\n\nOpen data poses its own challenges to our community. Though we generally concede that open data has been the primary means of driving machine learning research, parts of the research community are openly hostile to open data. And it’s not exactly who you’d think it would be. Some of the biggest “success stories” of the responsible AI/fairness community are based on finding “dangerous” content in open data sets, resulting in these data sets being removed from the public domain. The Netflix Prize, Tiny Images Dataset, and yes, even ImageNet, have all been either entirely removed, taken down for extended periods, or neutered in some capacity because of highly questionable arguments about “responsibility.”\n\nThis push towards prioritizing academic notions of “privacy,” “safety,” and “fairness” over all else has mostly resulted in academic censorship. And yet, while the hyperscalers love to pay lip service to responsible behavior, they don’t stop using this data! Recent lawsuits have revealed that Anthropic scans millions of books and Facebook trains on LibGen. But academic researchers aren’t allowed to use the Tiny Images Dataset. The hyperscalers do whatever they want, in private, locking out competition and strengthening their oligopoly. They know they will find a favorable ruling in Bill Alsup’s court because they have infinite money for their legal teams.\n\nSo while it’s undeniably essential to raise issues about the societal impacts of machine learning technology, we have to be careful not to do this in a way that solidifies corporate power. If we want fully open and accessible machine learning models, we need to figure out how to build them while accepting that the internet on which they are trained is littered with endlessly horrific and dangerous content. Nathan’s challenge is thus asking the open research community to engage with uncomfortable trade-offs about what open means. This question is as vital as shaking the can to raise money for NVIDIA chips.\n\nSubscribe now\n\n1\n\nFor the purposes of this blog post “top-5 accuracy” is just a number between 0 and 100. Higher is better. Don’t sweat the details of what this means or actually evaluates.\n\n2\n\nNaomi Saphra points me to another example in machine translation.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-091 | Tree PCPs |",
      "url": "/cstheoryrss/2025/07/10/eccc-papers-tr25-091-tree-pcps-tamer-mour-alon-rosen-ron-rothblum/",
      "content": "Probabilistically checkable proofs (PCPs) allow encoding a computation so that it can be quickly verified by only reading a few symbols. Inspired by tree codes (Schulman, STOC’93), we propose tree PCPs; these are PCPs that evolve as the computation progresses so that a proof for time $t$ is obtained by appending a short string to the end of the proof for time $t-1$. At any given time, the tree PCP can be locally queried to verify the entire computation so far.\nWe construct tree PCPs for non-deterministic space-$s$ computation, where at time step $t$, the proof only grows by an additional $poly(s,\\log(t))$ bits, and the number of queries made by the verifier to the overall proof is $poly(s) \\cdot t^\\epsilon$, for an arbitrary constant $\\epsilon &gt; 0$.\nTree PCPs are well-suited to proving correctness of ongoing computation that unfolds over time. They may be thought of as an information-theoretic analog of the cryptographic notion of incrementally verifiable computation (Valiant, TCC’08). In the random oracle model, tree PCPs can be compiled to realize a variant of incrementally verifiable computation where the prover is allowed a small number of queries to a large evolving state. This yields the first construction of (a natural variant of) IVC in the random oracle model.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-090 | Linear Prover IOPs in Log Star Rounds |",
      "url": "/cstheoryrss/2025/07/10/eccc-papers-tr25-090-linear-prover-iops-in-log-star-rounds-ron-rothblum-noor-athamnah-noga-ron-zewi/",
      "content": "Interactive Oracle Proofs (IOPs) form the backbone of some of the most efficient general-purpose cryptographic proof-systems. In an IOP, the prover can interact with the verifier over multiple rounds, where in each round the prover sends a long message, from which the verifier only queries a few symbols.\nState-of-the-art IOPs achieve a linear-size prover and a poly-logarithmic verifier but require a relatively large, logarithmic, number of rounds. While Fiat-Shamir heuristic can be used to eliminate the need for actual interaction, in modern highly-parallelizable computer architectures such as GPUs, the large number of rounds still translates into a major bottleneck for the prover, since it needs to alternate between computing the IOP messages and the Fiat-Shamir hashes. Motivated by this fact, in this work we study the round complexity of linear-prover IOPs.\nOur main result is an IOP for a large class of Boolean circuits, with only $O(\\log^*(S))$ rounds, where $\\log^*$ denotes the iterated logarithm function (and $S$ is the circuit size). The prover has linear size $O(S)$ and the verifier runs in time $\\mathrm{polylog}(S)$ and has query complexity $O(\\log^*(S))$. The protocol is both conceptually simpler, and strictly more efficient, than prior linear prover IOPs for Boolean circuits.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Prediction-Augmented Mechanism Design for Weighted Facility Location",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-prediction-augmented-mechanism-design-for-weighted-facility-location/",
      "content": "Authors: Yangguang Shi, Zhenyu Xue\n\nFacility location is fundamental in operations research, mechanism design,\nand algorithmic game theory, with applications ranging from urban\ninfrastructure planning to distributed systems. Recent research in this area\nhas focused on augmenting classic strategyproof mechanisms with predictions to\nachieve an improved performance guarantee against the uncertainty under the\nstrategic environment. Previous work has been devoted to address the trade-off\nobstacle of balancing the consistency (near-optimality under accurate\npredictions) and robustness (bounded inefficiency under poor predictions)\nprimarily in the unweighted setting, assuming that all agents have the same\nimportance. However, this assumption may not be true in some practical\nscenarios, leading to research of weighted facility location problems.\nThe major contribution of the current work is to provide a prediction\naugmented algorithmic framework for balancing the consistency and robustness\nover strategic agents with non-uniform weights. In particular, through a\nreduction technique that identifies a subset of \\emph{representative} instances\nand maps the other given locations to the representative ones, we prove that\nthere exists a \\emph{strategyproof} mechanism achieving a bounded consistency\nguarantee of $\\frac{\\sqrt{(1+c)^2W^2_{\\min}+(1-c)^2W^2_{\\max}}}{(1+c)W_{\\min}}$\nand a bounded robustness guarantee of\n$\\frac{\\sqrt{(1-c)^2W^2_{\\min}+(1+c)^2W^2_{\\max}}}{(1-c)W_{\\min}}$ in weighted\nsettings, where $c$ can be viewed as a parameter to make a trade-off between\nthe consistency and robustness and $W_{\\min}$ and $W_{\\max}$ denote the minimum\nand maximum agents’ weight. We also proved that there is no strategyproof\ndeterministic mechanism that reach $1$-consistency and $O\\left( n \\cdot\n\\frac{W_{\\max}}{W_{\\min}} \\right)$-robustness in weighted FLP, even with fully\npredictions of all agents.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-parallel-batch-dynamic-coreness-decomposition-with-worst-case-guarantees/",
      "content": "Authors: Mohsen Ghaffari, Jaehyun Koo\n\nWe present the first parallel batch-dynamic algorithm for approximating\ncoreness decomposition with worst-case update times. Given any batch of edge\ninsertions and deletions, our algorithm processes all these updates in $\n\\text{poly}(\\log n)$ depth, using a worst-case work bound of $b\\cdot\n\\text{poly}(\\log n)$ where $b$ denotes the batch size. This means the batch\ngets processed in $\\tilde{O}(b/p)$ time, given $p$ processors, which is optimal\nup to logarithmic factors. Previously, an algorithm with similar guarantees was\nknown by the celebrated work of Liu, Shi, Yu, Dhulipala, and Shun [SPAA’22],\nbut with the caveat of the work bound, and thus the runtime, being only\namortized.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Parallel Batch-Dynamic Algorithms for Spanners, and Extensions",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-parallel-batch-dynamic-algorithms-for-spanners-and-extensions/",
      "content": "Authors: Mohsen Ghaffari, Jaehyun Koo\n\nThis paper presents the first parallel batch-dynamic algorithms for computing\nspanners and sparsifiers. Our algorithms process any batch of edge insertions\nand deletions in an $n$-node undirected graph, in $\\text{poly}(\\log n)$ depth\nand using amortized work near-linear in the batch size. Our concrete results\nare as follows:\n\n  Our base algorithm maintains a spanner with $(2k-1)$ stretch and\n$\\tilde{O}(n^{1+1/k})$ edges, for any $k\\geq 1$.\n  Our first extension maintains a sparse spanner with only $O(n)$ edges, and\n$\\tilde{O}(\\log n)$ stretch.\n  Our second extension maintains a $t$-bundle of spanners – i.e., $t$\nspanners, each of which is the spanner of the graph remaining after removing\nthe previous ones – and allows us to maintain cut/spectral sparsifiers with\n$\\tilde{O}(n)$ edges.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Multi-Queue SSD I/O Modeling & Its Implications for Data Structure",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-multi-queue-ssd-i-o-modeling-its-implications-for-data-structure-design/",
      "content": "Authors: Erin Ransom, Andrew Lim, Michael Mitzenmacher\n\nUnderstanding the performance profiles of storage devices and how best to\nutilize them has always been non-trivial due to factors such as seek times,\ncaching, scheduling, concurrent access, flash wear-out, and garbage collection.\nHowever, analytical frameworks that provide simplified abstractions of storage\nperformance can still be accurate enough to evaluate external memory algorithms\nand data structures at the design stage. For example, the Disk Access Machine\n(DAM) model assumes that a storage device transfers data in fixed-size blocks\nof size B and that all transfers have unit latency. This abstraction is already\nsufficient to explain some of the benefits of data structures such as B-trees\nand Log-Structured Merge trees (LSM trees); however, storage technology\nadvances have significantly reduced current models’ accuracy and utility.\nThis paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new\nstorage abstraction. This model builds upon previous models and aims to more\naccurately represent the performance characteristics of modern storage\nhardware. We identify key performance-critical aspects of modern multi-queue\nsolid-state drives on which we base our model and demonstrate these\ncharacteristics on actual hardware. We then show how our model can be applied\nto LSM-tree-based storage engines to optimize them for modern storage hardware.\nWe highlight that leveraging concurrent access is crucial for fully utilizing\nthe high throughput of multi-queue SSDs, enabling designs that may appear\ncounterintuitive under traditional paradigms We then validate these insights\nthrough experiments using Facebook’s LSM-tree-based key-value store, RocksDB.\nWe conclude that the MQSSD model offers a more accurate abstraction of modern\nhardware than previous models, allowing for greater insight and optimization.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Estimation of the Average Degree of a Graph Using Random Edges",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-faster-estimation-of-the-average-degree-of-a-graph-using-random-edges-and-structural-queries/",
      "content": "Authors: Lorenzo Beretta, Deeparnab Chakrabarty, C. Seshadhri\n\nWe revisit the problem of designing sublinear algorithms for estimating the\naverage degree of an $n$-vertex graph. The standard access model for graphs\nallows for the following queries: sampling a uniform random vertex, the degree\nof a vertex, sampling a uniform random neighbor of a vertex, and pair\nqueries'' which determine if a pair of vertices form an edge. In this model,\noriginal results [Goldreich-Ron, RSA 2008; Eden-Ron-Seshadhri, SIDMA 2019] on\nthis problem prove that the complexity of getting\n$(1+\\varepsilon)$-multiplicative approximations to the average degree, ignoring\n$\\varepsilon$-dependencies, is $\\Theta(\\sqrt{n})$. When random edges can be\nsampled, it is known that the average degree can estimated in\n$\\widetilde{O}(n^{1/3})$ queries, even without pair queries\n[Motwani-Panigrahy-Xu, ICALP 2007; Beretta-Tetek, TALG 2024].\nWe give a nearly optimal algorithm in the standard access model with random\nedge samples. Our algorithm makes $\\widetilde{O}(n^{1/4})$ queries exploiting\nthe power of pair queries. We also analyze thefull neighborhood access”\nmodel wherein the entire adjacency list of a vertex can be obtained with a\nsingle query; this model is relevant in many practical applications. In a\nweaker version of this model, we give an algorithm that makes\n$\\widetilde{O}(n^{1/5})$ queries. Both these results underscore the power of\n{\\em structural queries}, such as pair queries and full neighborhood access\nqueries, for estimating the average degree. We give nearly matching lower\nbounds, ignoring $\\varepsilon$-dependencies, for all our results.\nSo far, almost all algorithms for estimating average degree assume that the\nnumber of vertices, $n$, is known. Inspired by [Beretta-Tetek, TALG 2024], we\nstudy this problem when $n$ is unknown and show that structural queries do not\nhelp in estimating average degree in this setting.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Algorithms for 2k-1-Stretch Distance Oracles",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-faster-algorithms-for-2k-1-stretch-distance-oracles/",
      "content": "Authors: Avi Kadria, Liam Roditty\n\nLet $G=(V, E)$ be an undirected $n$-vertices $m$-edges graph with\nnon-negative edge weights. In this paper, we present three new algorithms for\nconstructing a $(2k-1)$-stretch distance oracle with $O(n^{1+\\frac{1}{k}})$\nspace. The first algorithm runs in $\\Ot(\\max(n^{1+2/k},\nm^{1-\\frac{1}{k-1}}n^{\\frac{2}{k-1}}))$ time, and improves upon the\n$\\Ot(\\min(mn^{\\frac{1}{k}},n^2))$ time of Thorup and Zwick [STOC 2001, JACM\n2005] and Baswana and Kavitha [FOCS 2006, SICOMP 2010], for every $k &gt; 2$ and\n$m=\\Omega(n^{1+\\frac{1}{k}+\\eps})$. This yields the first truly subquadratic\ntime construction for every $2 &lt; k &lt; 6$, and nearly resolves the open problem\nposed by Wulff-Nilsen [SODA 2012] on the existence of such constructions.\nThe two other algorithms have a running time of the form $\\Ot(m+n^{1+f(k)})$,\nwhich is near linear in $m$ if $m=\\Omega(n^{1+f(k)})$, and therefore optimal in\nsuch graphs. One algorithm runs in $\\Ot(m+n^{\\frac32+\\frac{3}{4k-6}})$-time,\nwhich improves upon the $\\Ot(n^2)$-time algorithm of Baswana and Kavitha [FOCS\n2006, SICOMP 2010], for $3 &lt; k &lt; 6$, and upon the\n$\\Ot(m+n^{\\frac{3}{2}+\\frac{2}{k}+O(k^{-2})})$-time algorithm of Wulff-Nilsen\n[SODA 2012], for every $k\\geq 6$. This is the first linear time algorithm for\nconstructing a $7$-stretch distance oracle and a $9$-stretch distance oracle,\nfor graphs with truly subquadratic density.\\footnote{with $m=n^{2-\\eps}$ for\nsome $\\eps &gt; 0$.} The other algorithm runs in\n$\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{2}}{\\sqrt{k}}})$ time, (and hence relevant\nonly for $k\\ge 16$), and improves upon the\n$\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{6}}{\\sqrt{k}}+O(k^{-1})})$ time algorithm of\nWulff-Nilsen [SODA 2012] (which is relevant only for $k\\ge 96$). …\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Designing Parallel Algorithms for Community Detection using Arachne",
      "url": "/cstheoryrss/2025/07/10/arxiv-data-structures-and-algorithms-designing-parallel-algorithms-for-community-detection-using-arachne/",
      "content": "Authors: Fuhuan Li, Zhihui Du, David A. Bader\n\nThe rise of graph data in various fields calls for efficient and scalable\ncommunity detection algorithms. In this paper, we present parallel\nimplementations of two widely used algorithms: Label Propagation and Louvain,\nspecifically designed to leverage the capabilities of Arachne which is a\nPython-accessible, open-source framework for large-scale graph analysis. Our\nimplementations achieve substantial speedups over existing Python-based tools\nlike NetworkX and igraph, which lack efficient parallelization, and are\ncompetitive with parallel frameworks such as NetworKit. Experimental results\nshow that Arachne-based methods outperform these baselines, achieving speedups\nof up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit.\nAdditionally, we analyze the scalability of our implementation under varying\nthread counts, demonstrating how different phases contribute to overall\nperformance gains of the parallel Louvain algorithm. Arachne, including our\ncommunity detection implementation, is open-source and available at\nhttps://github.com/Bears-R-Us/arkouda-njit .\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Topological Machine Learning with Unreduced Persistence Diagrams",
      "url": "/cstheoryrss/2025/07/10/arxiv-computational-geometry-topological-machine-learning-with-unreduced-persistence-diagrams/",
      "content": "Authors: Nicole Abreu, Parker B. Edwards, Francis Motta\n\nSupervised machine learning pipelines trained on features derived from\npersistent homology have been experimentally observed to ignore much of the\ninformation contained in a persistence diagram. Computing persistence diagrams\nis often the most computationally demanding step in such a pipeline, however.\nTo explore this, we introduce several methods to generate topological feature\nvectors from unreduced boundary matrices. We compared the performance of\npipelines trained on vectorizations of unreduced PDs to vectorizations of\nfully-reduced PDs across several data and task types. Our results indicate that\nmodels trained on PDs built from unreduced diagrams can perform on par and even\noutperform those trained on fully-reduced diagrams on some tasks. This\nobservation suggests that machine learning pipelines which incorporate\ntopology-based features may benefit in terms of computational cost and\nperformance by utilizing information contained in unreduced boundary matrices.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: An Improved Bound for Plane Covering Paths",
      "url": "/cstheoryrss/2025/07/10/arxiv-computational-geometry-an-improved-bound-for-plane-covering-paths/",
      "content": "Authors: Hugo A. Akitaya, Greg Aloupis, Ahmad Biniaz, Prosenjit Bose, Jean-Lou De Carufel, Cyril Gavoille, John Iacono, Linda Kleist, Michiel Smid, Diane Souvaine, Leonidas Theocharous\n\nA covering path for a finite set $P$ of points in the plane is a polygonal\npath such that every point of $P$ lies on a segment of the path. The vertices\nof the path need not be at points of $P$. A covering path is plane if its\nsegments do not cross each other. Let $\\pi(n)$ be the minimum number such that\nevery set of $n$ points in the plane admits a plane covering path with at most\n$\\pi(n)$ segments. We prove that $\\pi(n)\\le \\lceil6n/7\\rceil$. This improves\nthe previous best-known upper bound of $\\lceil 21n/22\\rceil$, due to Biniaz\n(SoCG 2023). Our proof is constructive and yields a simple $O(n\\log n)$-time\nalgorithm for computing a plane covering path.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Trainability of Quantum Models Beyond Known Classical Simulability",
      "url": "/cstheoryrss/2025/07/10/arxiv-computational-complexity-trainability-of-quantum-models-beyond-known-classical-simulability/",
      "content": "Authors: Sabri Meyer, Francesco Scala, Francesco Tacchino, Aurelien Lucchi\n\nVariational Quantum Algorithms (VQAs) are promising candidates for near-term\nquantum computing, yet they face scalability challenges due to barren plateaus,\nwhere gradients vanish exponentially in the system size. Recent conjectures\nsuggest that avoiding barren plateaus might inherently lead to classical\nsimulability, thus limiting the opportunities for quantum advantage. In this\nwork, we advance the theoretical understanding of the relationship between the\ntrainability and computational complexity of VQAs, thus directly addressing the\nconjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique\nthat ensures constant-scaling gradient statistics on optimization landscape\nregions that are close to Clifford circuits. Additionally, we leverage\nclassical Taylor surrogates to reveal computational complexity phase\ntransitions from polynomial to super-polynomial as the initialization region\nsize increases. Combining these results, we reveal a deeper link between\ntrainability and computational complexity, and analytically prove that barren\nplateaus can be avoided in regions for which no classical surrogate is known to\nexist. Furthermore, numerical experiments on LCE transformed landscapes confirm\nin practice the existence of a super-polynomially complex ``transition zone’’\nwhere gradients decay polynomially. These findings indicate a plausible path to\npractically relevant, barren plateau-free variational models with potential for\nquantum advantage.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Efficient Algorithms for Quantum Hashing",
      "url": "/cstheoryrss/2025/07/10/arxiv-computational-complexity-efficient-algorithms-for-quantum-hashing/",
      "content": "Authors: Ilnar Zinnatullin, Kamil Khadiev\n\nQuantum hashing is a useful technique that allows us to construct\nmemory-efficient algorithms and secure quantum protocols. First, we present a\ncircuit that implements the phase form of quantum hashing using $2^{n-1}$ CNOT\ngates, where n is the number of control qubits. Our method outperforms existing\napproaches and reduces the circuit depth. Second, we propose an algorithm that\nprovides a trade-off between the number of CNOT gates (and consequently, the\ncircuit depth) and the precision of rotation angles. This is particularly\nimportant in the context of NISQ (Noisy Intermediate-Scale Quantum) devices,\nwhere hardware-imposed angle precision limit remains a critical constraint.\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-089 | Chain Rules for Time-Bounded Kolmogorov Complexity |",
      "url": "/cstheoryrss/2025/07/09/eccc-papers-tr25-089-chain-rules-for-time-bounded-kolmogorov-complexity-valentine-kabanets-antonina-kolokolova/",
      "content": "Time-bounded conditional Kolmogorov complexity of a string $x$ given $y$, $K^t(x\\mid y)$, is the length of a shortest program that, given $y$, prints $x$ within $t$ steps. The Chain Rule for conditional $K^t$ with error $e$ is the following hypothesis: there is a constant $c\\in\\mathbb{N}$ such that, for any strings $y,x_1,\\dots,x_{\\ell}\\in{0,1}^*$, for any $\\ell\\in\\mathbb{N}$, and all sufficiently large time bounds $t$,\n[\nK^t(x_1,\\dots,x_{\\ell}\\mid y) \\geq \\sum_{i=1}^{\\ell} K^{t^{c}}(x_i \\mid y, x_1,\\dots,x_{i-1}) - \\ell\\cdot O(\\log t) -e(N,t),\n]\nwhere $N=\\sum_{i=1}^{\\ell} |x_i|$.\nWe pinpoint the complexity assumptions equivalent to Chain Rules for conditional $K^t$, and the probabilistic variant $pK^t$, where $pK^t(x\\mid y)\\leq s$ iff $K^t(x\\mid y,r)\\leq s$ for at least $2/3$ of random strings $r\\in{0,1}^t$.\n\n  Chain Rule for conditional $K^t$ with error $e(N,t)\\leq o(N)$ is equivalent to the conjunction of the following two statements:\n(a) $E\\not\\subset io SIZE[2^{o(n)}]$, and\n(b) $Gap McK^tP\\in promise\\text{-} P$, where $Gap McK^tP$ is a promise problem to distinguish between inputs $(x,y,1^s)$ with $K^t(x\\mid y)\\leq s$ and those with $K^{poly(t)}(x\\mid y)&gt; s + o(|x|)$.\n  Chain Rule for conditional $pK^t$ with error $e(N,t)\\leq o(N)$ is equivalent to $Gap McpK^tP\\in promise\\text{-} BPP$, for the analog of $Gap McK^tP$ for conditional $pK^t$.\nThese are the first exact complexity characterizations for natural versions of Chain Rules for time-bounded Kolmogorov complexity.\nAssuming $Gap McK^tP$ is $NP$-hard (which is true under cryptographic assumptions [Huang et al., STOC’23]), the equivalence above would simplify to ``the Chain Rule for conditional $K^t$ with error $e(N,t)\\leq o(N)$ holds iff $NP=P$’’. That is, under a plausible $NP$-hardness assumption for $Gap McK^tP$, we would get that proving $P\\neq NP$ is equivalent to disproving the Chain Rule for conditional $K^t$.\nAmong other results, we present a natural $promise\\text{-} BPP$-complete problem based on the problem of approximating $pK^t(x\\mid y)$ for short inputs $x$ with $|x|\\leq \\log t$, and give some algorithmic consequences if $Gap McpK^TP$ were easy.\n\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: The Customers of the Academy",
      "url": "/cstheoryrss/2025/07/09/computational-complexity-the-customers-of-the-academy/",
      "content": "I had an epiphany reading an article in the Trenton Times when I lived in New Jersey at the turn of the century. The article interviewed companies along a certain street lobbying for a new bus route so their employees could more easily get to work. The customers for mass transit are not its riders but the employers who need workers to get to them. Maybe that’s why mass transit trains and buses offer a functional but not particularly comfortable ride.\n\nSo who are the customers for universities? Before I go there, let’s look at newspapers. Until the early 2000s, newspapers were primarily driven by advertising revenue. Readers were the product. While newspapers needed readers to sell, they could get them by offering cheap subscriptions by focusing on quality coverage that focused on news and analysis from a broad range of views. But since then, the few newspapers that thrive now do so mostly on subscription revenue, print and digital, and the readers have become the customers. They also have more competition from other sources like social media. So newspapers now tailor their coverage and their brand for the paying subscriber, and while most still focus on accuracy, they’ll stick to narrower views in their analysis which often overshadows the pure news.\n\nUniversities have a mission beyond just serving students, providing them with knowledge in exchange for tuition. They have a societal mission. The Morrill Land-Grant Act of 1862, which helped establish and grow a number of public universities, wanted to educate students to improve the productivity of American agriculture and industry. The GI Bill in 1944 brought the masses of returning soldiers into higher education. The Higher Education Act of 1965, brought in resources for students through Pell Grants and federally-guaranteed student Loans to further the competitiveness of America through the Cold War. Most universities have non-profit status because of their broader mission.\n\nIn other words, society as a whole was our customer. Our role is to educate and prepare students to help push our society forward. Many universities also have a research mission, also mostly government funded, both to recruit expert professors to educate our students, but also to produce important knowledge to manage the complexities of the world. Students participated willingly for future intellectual and financial gain and our role was to ensure the students got a strong education, for the betterment of not just themselves but the workforce and society they would later join.\n\nOur viewpoint has changed as college costs increased and universities became more dependent on tuition and governmental financial aid. Institutions started treating the students as the customer, to ensure they came to the university and stayed there. More amenities, grade inflation, much more student support and tolerance. The relationship became transactional, a student comes, pays their tuition and their time, gets a degree and gets a job. The focus becomes more on degrees that prepare you for the workplace, a focus more on immediate skill and credential building than producing students who have the critical thinking skills to build a strong career.\n\nAnd now in a time of changing demographics, less government support and AI heading towards performing many of the skills universities teach, how does the story continue? How do universities focus back on producing students who can not just live in our society but improve it? How do they focus on the right customers while ensuring educational quality? Universities need to get it right, or they won’t have customers at all.\n\nBy Lance Fortnow\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Parameterized Restless Temporal Path",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-parameterized-restless-temporal-path/",
      "content": "Authors: Justine Cauvi, Laurent Viennot\n\nRecently, Bumpus and Meeks introduced a purely temporal parameter, called\nvertex-interval-membership-width, which is promising for the design of\nfixed-parameter tractable (FPT) algorithms for vertex reachability problems in\ntemporal graphs. We study this newly introduced parameter for the problem of\nrestless temporal paths, in which the waiting time at each node is restricted.\nIn this article, we prove that, in the interval model, where arcs are present\nfor entire time intervals, finding a restless temporal path is NP-hard even if\nthe vertex-interval-membership-width is equal to three. We exhibit FPT\nalgorithms for the point model, where arcs are present at specific points in\ntime, both with uniform delay one and arbitrary positive delays. In the latter\ncase, this comes with a slight additional computational cost.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Non-Adaptive Evaluation of k-of-n Functions: Tight Gap and a",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-non-adaptive-evaluation-of-k-of-n-functions-tight-gap-and-a-unit-cost-ptas/",
      "content": "Authors: Mads Anker Nielsen, Lars Rohwedder, Kevin Schewior\n\nWe consider the Stochastic Boolean Function Evaluation (SBFE) problem in the\nwell-studied case of $k$-of-$n$ functions: There are independent Boolean random\nvariables $x_1,\\dots,x_n$ where each variable $i$ has a known probability $p_i$\nof taking value $1$, and a known cost $c_i$ that can be paid to find out its\nvalue. The value of the function is $1$ iff there are at least $k$ $1$s among\nthe variables. The goal is to efficiently compute a strategy that, at minimum\nexpected cost, tests the variables until the function value is determined.\nWhile an elegant polynomial-time exact algorithm is known when tests can be\nmade adaptively, we focus on the non-adaptive variant, for which much less is\nknown.\nFirst, we show a clean and tight lower bound of $2$ on the adaptivity gap,\ni.e., the worst-case multiplicative loss in the objective function caused by\ndisallowing adaptivity, of the problem. This improves the tight lower bound of\n$3/2$ for the unit-cost variant.\nSecond, we give a PTAS for computing the best non-adaptive strategy in the\nunit-cost case, the first PTAS for an SBFE problem. At the core, our scheme\nestablishes a novel notion of two-sided dominance (w.r.t. the optimal solution)\nby guessing so-called milestone tests for a set of carefully chosen buckets of\ntests. To turn this technique into a polynomial-time algorithm, we use a\ndecomposition approach paired with a random-shift argument.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Learning-Augmented Online Covering Problems",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-learning-augmented-online-covering-problems/",
      "content": "Authors: Afrouz Jabal Ameli, Laura Sanita, Moritz Venzin\n\nWe give a very general and simple framework to incorporate predictions on\nrequests for online covering problems in a rigorous and black-box manner. Our\nframework turns any online algorithm with competitive ratio $\\rho(k, \\cdot)$\ndepending on $k$, the number of arriving requests, into an algorithm with\ncompetitive ratio of $\\rho(\\eta, \\cdot)$, where $\\eta$ is the prediction error.\nWith accurate enough prediction, the resulting competitive ratio breaks through\nthe corresponding worst-case online lower bounds, and smoothly degrades as the\nprediction error grows. This framework directly applies to a wide range of\nwell-studied online covering problems such as facility location, Steiner\nproblems, set cover, parking permit, etc., and yields improved and novel\nbounds.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Instance-Optimal Quantum State Certification with Entangled Measurements",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-instance-optimal-quantum-state-certification-with-entangled-measurements/",
      "content": "Authors: Ryan O’Donnell, Chirag Wadhwa\n\nWe consider the task of quantum state certification: given a description of a\nhypothesis state $\\sigma$ and multiple copies of an unknown state $\\rho$, a\ntester aims to determine whether the two states are equal or $\\epsilon$-far in\ntrace distance. It is known that $\\Theta(d/\\epsilon^2)$ copies of $\\rho$ are\nnecessary and sufficient for this task, assuming the tester can make entangled\nmeasurements over all copies [CHW07,OW15,BOW19]. However, these bounds are for\na worst-case $\\sigma$, and it is not known what the optimal copy complexity is\nfor this problem on an instance-by-instance basis. While such instance-optimal\nbounds have previously been shown for quantum state certification when the\ntester is limited to measurements unentangled across copies [CLO22,CLHL22],\nthey remained open when testers are unrestricted in the kind of measurements\nthey can perform.\nWe address this open question by proving nearly instance-optimal bounds for\nquantum state certification when the tester can perform fully entangled\nmeasurements. Analogously to the unentangled setting, we show that the optimal\ncopy complexity for certifying $\\sigma$ is given by the worst-case complexity\ntimes the fidelity between $\\sigma$ and the maximally mixed state. We prove our\nlower bounds using a novel quantum analogue of the Ingster-Suslina method,\nwhich is likely to be of independent interest. This method also allows us to\nrecover the $\\Omega(d/\\epsilon^2)$ lower bound for mixedness testing [OW15],\ni.e., certification of the maximally mixed state, with a surprisingly simple\nproof.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-an-optimal-algorithm-for-shortest-paths-in-unweighted-disk-graphs/",
      "content": "Authors: Bruce W. Brewer, Haitao Wang\n\nGiven in the plane a set $S$ of $n$ points and a set of disks centered at\nthese points, the disk graph $G(S)$ induced by these disks has vertex set $S$\nand an edge between two vertices if their disks intersect. Note that the disks\nmay have different radii. We consider the problem of computing shortest paths\nfrom a source point $s\\in S$ to all vertices in $G(S)$ where the length of a\npath in $G(S)$ is defined as the number of edges in the path. The previously\nbest algorithm solves the problem in $O(n\\log^2 n)$ time. A lower bound of\n$\\Omega(n\\log n)$ is also known for this problem under the algebraic decision\ntree model. In this paper, we present an $O(n\\log n)$ time algorithm, which\nmatches the lower bound and thus is optimal. Another virtue of our algorithm is\nthat it is quite simple.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Formal Refutation of the Blockchain Trilemma",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-a-formal-refutation-of-the-blockchain-trilemma/",
      "content": "Authors: Craig Wright\n\nThe so-called blockchain trilemma asserts the impossibility of simultaneously\nachieving scalability, security, and decentralisation within a single\nblockchain protocol. In this paper, we formally refute that proposition.\nEmploying predicate logic, formal automata theory, computational complexity\nanalysis, and graph-theoretic measures of relay topology–specifically Baran’s\nmodel of network path redundancy–we demonstrate that the trilemma constitutes\na category error, conflates distinct analytical domains, and relies upon\nunproven causal assumptions. We further expose its reliance on composition\nfallacies drawn from flawed system implementations. A constructive\ncounterexample is presented: a blockchain protocol exhibiting unbounded\ntransaction throughput, cryptographic security under adversarial load, and\nmultipath decentralised propagation. This example is not hypothetical but\ngrounded in protocol design enabled by compact block relay, SPV verification,\nand IPv6 multicast. The trilemma is revealed not as a law of protocol\narchitecture, but as a heuristic fallacy sustained by imprecision and design\ndefeatism.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: 25 Additional Problems -- Extension to the Book 125 Problems in Text",
      "url": "/cstheoryrss/2025/07/09/arxiv-data-structures-and-algorithms-25-additional-problems-extension-to-the-book-125-problems-in-text-algorithms/",
      "content": "Authors: Maxime Crochemore, Thierry Lecroq, Wojtek Rytter\n\nThis very preliminary text is related to Algorithms on Texts'', also called\nAlgorithmic Stringology’’. It is an extension of the book 125 Problems in\nText Algorithms'' providing, in the same compact style, more problems with\nsolutions. We refer also to the companions toText algorithms’’ available at\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf and at the web page\nhttp://125-problems.univ-mlv.fr, where all 150 problems (including the ones\npresented here) are briefly announced. The selected problems satisfy three\ncriteria: challenging, having short tricky solutions and solvable with only\nvery basic background in stringology. For the basics in stringology we refer to\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: k-means considered harmful: On arbitrary topological changes in Mapper",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-geometry-k-means-considered-harmful-on-arbitrary-topological-changes-in-mapper-complexes/",
      "content": "Authors: Mikael Vejdemo-Johansson\n\nThe Mapper construction is one of the most widespread tools from Topological\nData Analysis. There is an unfortunate trend as the construction has gained\ntraction to use clustering methods with properties that end up distorting any\nanalysis results from the construction. In this paper we will see a few ways in\nwhich widespread choices of clustering algorithms have arbitrarily large\ndistortions of the features visible in the final Mapper complex.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Fast and Accurate Collision Probability Estimation for Autonomous",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-geometry-fast-and-accurate-collision-probability-estimation-for-autonomous-vehicles-using-adaptive-sigma-point-sampling/",
      "content": "Authors: Charles Champagne Cossette, Taylor Scott Clawson, Andrew Feit\n\nA novel algorithm is presented for the estimation of collision probabilities\nbetween dynamic objects with uncertain trajectories, where the trajectories are\ngiven as a sequence of poses with Gaussian distributions. We propose an\nadaptive sigma-point sampling scheme, which ultimately produces a fast, simple\nalgorithm capable of estimating the collision probability with a median error\nof 3.5%, and a median runtime of 0.21ms, when measured on an Intel Xeon Gold\n6226R Processor. Importantly, the algorithm explicitly accounts for the\ncollision probability’s temporal dependence, which is often neglected in prior\nwork and otherwise leads to an overestimation of the collision probability.\nFinally, the method is tested on a diverse set of relevant real-world\nscenarios, consisting of 400 6-second snippets of autonomous vehicle logs,\nwhere the accuracy and latency is rigorously evaluated.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-geometry-an-optimal-algorithm-for-shortest-paths-in-unweighted-disk-graphs/",
      "content": "Authors: Bruce W. Brewer, Haitao Wang\n\nGiven in the plane a set $S$ of $n$ points and a set of disks centered at\nthese points, the disk graph $G(S)$ induced by these disks has vertex set $S$\nand an edge between two vertices if their disks intersect. Note that the disks\nmay have different radii. We consider the problem of computing shortest paths\nfrom a source point $s\\in S$ to all vertices in $G(S)$ where the length of a\npath in $G(S)$ is defined as the number of edges in the path. The previously\nbest algorithm solves the problem in $O(n\\log^2 n)$ time. A lower bound of\n$\\Omega(n\\log n)$ is also known for this problem under the algebraic decision\ntree model. In this paper, we present an $O(n\\log n)$ time algorithm, which\nmatches the lower bound and thus is optimal. Another virtue of our algorithm is\nthat it is quite simple.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Unitary designs in nearly optimal depth",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-unitary-designs-in-nearly-optimal-depth/",
      "content": "Authors: Laura Cui, Thomas Schuster, Fernando Brandao, Hsin-Yuan Huang\n\nWe construct $\\varepsilon$-approximate unitary $k$-designs on $n$ qubits in\ncircuit depth $O(\\log k \\log \\log n k / \\varepsilon)$. The depth is\nexponentially improved over all known results in all three parameters $n$, $k$,\n$\\varepsilon$. We further show that each dependence is optimal up to\nexponentially smaller factors. Our construction uses $\\tilde(nk)$ ancilla\nqubits and ${O}(nk)$ bits of randomness, which are also optimal up to $\\log(n\nk)$ factors. An alternative construction achieves a smaller ancilla count\n$\\tilde(n)$ with circuit depth ${O}(k \\log \\log nk/\\varepsilon)$. To\nachieve these efficient unitary designs, we introduce a highly-structured\nrandom unitary ensemble that leverages long-range two-qubit gates and low-depth\nimplementations of random classical hash functions. We also develop a new\nanalytical framework for bounding errors in quantum experiments involving many\nqueries to random unitaries. As an illustration of this framework’s\nversatility, we provide a succinct alternative proof of the existence of\npseudorandom unitaries.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Parameterized Restless Temporal Path",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-parameterized-restless-temporal-path/",
      "content": "Authors: Justine Cauvi, Laurent Viennot\n\nRecently, Bumpus and Meeks introduced a purely temporal parameter, called\nvertex-interval-membership-width, which is promising for the design of\nfixed-parameter tractable (FPT) algorithms for vertex reachability problems in\ntemporal graphs. We study this newly introduced parameter for the problem of\nrestless temporal paths, in which the waiting time at each node is restricted.\nIn this article, we prove that, in the interval model, where arcs are present\nfor entire time intervals, finding a restless temporal path is NP-hard even if\nthe vertex-interval-membership-width is equal to three. We exhibit FPT\nalgorithms for the point model, where arcs are present at specific points in\ntime, both with uniform delay one and arbitrary positive delays. In the latter\ncase, this comes with a slight additional computational cost.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Complexity of Problems on Graphs Defined on Groups",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-on-the-complexity-of-problems-on-graphs-defined-on-groups/",
      "content": "Authors: Bireswar Das, Dipan Dey, Jinia Ghosh\n\nWe study the complexity of graph problems on graphs defined on groups,\nespecially power graphs. We observe that an isomorphism invariant problem, such\nas Hamiltonian Path, Partition into Cliques, Feedback Vertex Set, Subgraph\nIsomorphism, cannot be NP-complete for power graphs, commuting graphs, enhanced\npower graphs, directed power graphs, and bounded-degree Cayley graphs, assuming\nthe Exponential Time Hypothesis (ETH). An analogous result holds for\nisomorphism invariant group problems: no such problem can be NP-complete unless\nETH is false. We show that the Weighted Max-Cut problem is NP-complete in power\ngraphs. We also show that, unless ETH is false, the Graph Motif problem cannot\nbe solved in quasipolynomial time on power graphs, even for power graphs of\ncyclic groups. We study the recognition problem of power graphs when the\nadjacency matrix or list is given as input and show that for abelian groups and\nsome classes of nilpotent groups, it is solvable in polynomial time.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Lineal Extensions of Kakeya Sets Missing Every ee-Random Point",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-lineal-extensions-of-kakeya-sets-missing-every-ee-random-point/",
      "content": "Authors: Neil Lutz, Spencer Park Martin, Rain White\n\nBy effectivizing a Kakeya set construction, we prove the existence of lines\nin all directions that do not contain any double exponential time random\npoints. This means each point on these lines has an algorithmically predictable\nlocation, to the extent that a gambler in an environment with fair payouts can,\nusing double exponential time computing resources, amass unbounded capital\nplacing bets on increasingly precise estimates of the point’s location. Our\nresult resolves an open question published by Lutz and Lutz (2015).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Generalized and Unified Equivalences between Hardness and Pseudoentropy",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-generalized-and-unified-equivalences-between-hardness-and-pseudoentropy/",
      "content": "Authors: Lunjia Hu, Salil Vadhan\n\nPseudoentropy characterizations provide a quantitatively precise\ndemonstration of the close relationship between computational hardness and\ncomputational randomness. We prove a unified pseudoentropy characterization\nthat generalizes and strengthens previous results for both uniform and\nnon-uniform models of computation. Our characterization holds for a general\nfamily of entropy notions that encompasses the common notions of Shannon\nentropy and min entropy as special cases. Moreover, we show that the\ncharacterizations for different entropy notions can be simultaneously achieved\nby a single, universal function that simultaneously witnesses computational\nhardness and computational randomness. A key technical insight of our work is\nthat the notion of weight-restricted calibration from the recent literature on\nalgorithm fairness, along with standard computational indistinguishability\n(known as multiaccuracy in the fairness literature), suffices for proving\npseudoentropy characterizations for general entropy notions. This demonstrates\nthe power of weight-restricted calibration to enhance the classic\nComplexity-Theoretic Regularity Lemma (Trevisan, Tulsiani, and Vadhan, 2009)\nand Leakage Simulation Lemma (Jetchev and Pietrzak, 2014) and allows us to\nachieve an exponential improvement in the complexity dependency on the alphabet\nsize compared to the pseudoentropy characterizations by Casacuberta, Dwork, and\nVadhan (2024) based on the much stronger notion of multicalibration. We show\nthat the exponential dependency on the alphabet size is inevitable for\nmulticalibration as well as for the weaker notion of calibrated multiaccuracy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Complexity Results of Persuasion",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-complexity-results-of-persuasion/",
      "content": "Authors: Alban Grastien\n\nWe prove that persuasion is an NP-complete problem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: A Formal Refutation of the Blockchain Trilemma",
      "url": "/cstheoryrss/2025/07/09/arxiv-computational-complexity-a-formal-refutation-of-the-blockchain-trilemma/",
      "content": "Authors: Craig Wright\n\nThe so-called blockchain trilemma asserts the impossibility of simultaneously\nachieving scalability, security, and decentralisation within a single\nblockchain protocol. In this paper, we formally refute that proposition.\nEmploying predicate logic, formal automata theory, computational complexity\nanalysis, and graph-theoretic measures of relay topology–specifically Baran’s\nmodel of network path redundancy–we demonstrate that the trilemma constitutes\na category error, conflates distinct analytical domains, and relies upon\nunproven causal assumptions. We further expose its reliance on composition\nfallacies drawn from flawed system implementations. A constructive\ncounterexample is presented: a blockchain protocol exhibiting unbounded\ntransaction throughput, cryptographic security under adversarial load, and\nmultipath decentralised propagation. This example is not hypothetical but\ngrounded in protocol design enabled by compact block relay, SPV verification,\nand IPv6 multicast. The trilemma is revealed not as a law of protocol\narchitecture, but as a heuristic fallacy sustained by imprecision and design\ndefeatism.\n\nRead original post\n"
    },
    
    {
      "title": "Nisheeth Vishnoi: What is Intelligence? Layers of Emergence",
      "url": "/cstheoryrss/2025/07/08/nisheeth-vishnoi-what-is-intelligence-layers-of-emergence/",
      "content": "How Intelligence Arises from Nature, One Layer at a Time\n\n\n\nThe Trouble with Definitions\n\n\n  “The Tao that can be named is not the eternal Tao.” — Lao Tzu\n\n\nAs a mathematician, I’ve long sought clean definitions. Much of my work involves building precise frameworks — starting by defining key concepts, isolating the core of a problem, formalizing it, and tracing its implications to their logical end.\n\nYet over time, I’ve come to see not just the limits of definitions, but their quiet distortions—the way they can flatten nuance in the name of clarity. The richness of a living idea gets traded for the sterile comfort of formal neatness. Sometimes, defining isn’t just clarifying — it’s an act of power: shaping perception, and granting authority to the one who defines.\n\nFew ideas reveal this tension more vividly than intelligence. We talk about it as if we know what it is — a score, a skill, a spark. But what is it, really? And can something so dynamic ever be pinned down?\n\nI think of intelligence not as a fixed trait, but as an experience — not unlike beauty — arising in context, felt through interaction.\n\nSo while we try to define intelligence — because we must — to witness it, to live with it, or to build systems that move with it, we need something else: humility. An attention to context. A willingness to recognize that intelligence, like beauty, is often messy, partial, plural, heuristic, and still astonishingly effective.\n\nBut even our capacity to see intelligence is shaped by history. In The Myth of Superintelligence, I argued that our attempts to define intelligence are never neutral. They reflect what we choose to measure, optimize, and reward. This essay is not a repetition of that critique. It is a step back. A shift in lens. It asks not what intelligence is, but when and how it arises—not as a trait, but as something unfolding across time, scale, and structure.\n\nBecause the power to define has always been the power to exclude. Colonial systems didn’t just extract labor and land—they imposed ways of seeing. In doing so, they dismissed the intelligence embedded in other ways of knowing, reframing rich knowledge traditions as myth or superstition. These distortions still echo in how we define and measure intelligence today. African polyrhythms were labeled primitive. Classical Indian music was exoticized or ignored. Indigenous knowledge systems—deeply attuned to land, season, and cycle—were reduced to folklore. Intelligence was there. But the lens refused to see it.\n\nThis is why any inquiry into intelligence must also be an inquiry into perspective. Definitions don’t just clarify. They constrain. They shape not only what we see, but what we believe intelligence can be.\n\nThis series is an attempt to widen the lens—to trace intelligence not as a fixed trait, but as a dynamic unfolding across layers of complexity. We begin with the silent elegance of physical systems, where matter flows under law, solving problems through coherence and constraint. From there, we enter the domain of evolution, where life adapts through variation and feedback, accumulating structure over time. We then move to the responsive intelligence of behavior—organisms without minds that nonetheless solve, coordinate, and learn through interaction.\n\nBut these are just the foundations. In the second half, we abstract upward: tracing how intelligence evolves the ability to frame problems, to reflect on and revise its own rules, and finally, to orient itself—to choose what matters. This is where intelligence becomes recursive, contextual, and ultimately, meaningful. Not just a solver of problems, but a seeker of value.\n\nRead the full essay by subscribing (for free) toThe Intelligence Loop.\n\nBy nisheethvishnoi\n\nRead original post\n"
    },
    
    {
      "title": "CS Theory Events: Proof Complexity 2025",
      "url": "/cstheoryrss/2025/07/08/cs-theory-events-proof-complexity-2025/",
      "content": "August 11-13, 2025 Oxford, UK https://feasible-math.org/events/PC25/ Proof complexity is a vibrant area in the intersection of computational complexity, algorithms and mathematical logic exploring the inherent difficulty of proving statements in different formal proof systems. This workshop aims to cover both traditional topics and emerging trends in the field, including lower bounds on lengths of proofs, … Continue reading Proof Complexity 2025\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Truthful, Credible, and Optimal Auctions for Matroids via Blockchains",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-truthful-credible-and-optimal-auctions-for-matroids-via-blockchains-and-commitments/",
      "content": "Authors: Aadityan Ganesh, Qianfan Zhang\n\nWe consider a revenue-optimizing auctioneer in single-dimensional\nenvironments with matroid feasibility constraints. Akbarpour and Li (2020)\nargue that any revenue-optimal, truthful, and credible mechanism requires\nunbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et\nal., 2022; Chitra et al., 2024) circumvent their impossibility for the\nsingle-item setting through the use of cryptographic commitments and\nblockchains. We extend their results to matroid feasibility constraints.\nAt a high level, the two-round Deferred-Revelation Auction (DRA) discussed by\nFerreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to\nsubmit a deposit, which is slashed upon presenting verifiable evidence\nindicating a deviation from the behaviour prescribed by the mechanism. We prove\nthat the DRA satisfies truthfulness, credibility and revenue-optimality for all\nmatroid environments when bidders’ values are drawn from $\\alpha$-strongly\nregular distributions for $\\alpha &gt; 0$. Further, we argue that the DRA is not\ncredible for any feasibility constraint beyond matroids and for any smaller\ndeposits than suggested by previous literature even in single-item\nenvironments.\nFinally, we modify the Ascending Deferred-Revelation Auction (ADRA) for\nsingle-item settings proposed by Essaidi et al., (2022) for arbitrary bidder\nvalue distributions. We implement a deferred-revelation variant of the\ndeferred-acceptance auction for matroids due to Bikhchandani et al., (2011),\nwhich requires the same bounded communication as the ADRA.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Tight Guarantees for Cut-Relative Survivable Network Design via a",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-tight-guarantees-for-cut-relative-survivable-network-design-via-a-decomposition-technique/",
      "content": "Authors: Nikhil Kumar, JJ Nan, Chaitanya Swamy\n\nIn the classical \\emph{survivable-network-design problem} (SNDP), we are\ngiven an undirected graph $G = (V, E)$, non-negative edge costs, and some\n$(s_i,t_i,r_i)$ tuples, where $s_i,t_i\\in V$ and $r_i\\in\\mathbb{Z}_+$. We seek\na minimum-cost subset $H \\subseteq E$ such that each $s_i$-$t_i$ pair remains\nconnected even if any $r_i-1$ edges fail. It is well-known that SNDP can be\nequivalently modeled using a weakly-supermodular \\emph{cut-requirement\nfunction} $f$, where we seek a minimum-cost edge-set containing at least $f(S)$\nedges across every cut $S \\subseteq V$.\nRecently, Dinitz et al. proposed a variant of SNDP that enforces a\n\\emph{relative} level of fault tolerance with respect to $G$, where the goal is\nto find a solution $H$ that is at least as fault-tolerant as $G$ itself. They\nformalize this in terms of paths and fault-sets, which gives rise to\n\\emph{path-relative SNDP}. Along these lines, we introduce a new model of\nrelative network design, called \\emph{cut-relative SNDP} (CR-SNDP), where the\ngoal is to select a minimum-cost subset of edges that satisfies the given\n(weakly-supermodular) cut-requirement function to the maximum extent possible,\ni.e., by picking $\\min{f(S),|\\delta_G(S)|}$ edges across every cut\n$S\\subseteq V$.\nUnlike SNDP, the cut-relative and path-relative versions of SNDP are not\nequivalent. The resulting cut-requirement function for CR-SNDP (as also\npath-relative SNDP) is not weakly supermodular, and extreme-point solutions to\nthe natural LP-relaxation need not correspond to a laminar family of tight cut\nconstraints. Consequently, standard techniques cannot be used directly to\ndesign approximation algorithms for this problem. We develop a \\emph{novel\ndecomposition technique} to circumvent this difficulty and use it to give a\n\\emph{tight $2$-approximation algorithm for CR-SNDP}. We also show new hardness\nresults for these relative-SNDP problems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The planar edge-coloring theorem of Vizing in Onlog n time",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-planar-edge-coloring-theorem-of-vizing-in-o-n-log-n-time/",
      "content": "Authors: Patryk Jędrzejczak, Łukasz Kowalik\n\nIn 1965, Vizing [Diskret. Analiz, 1965] showed that every planar graph of\nmaximum degree $\\Delta\\ge 8$ can be edge-colored using $\\Delta$ colors. The\ndirect implementation of the Vizing’s proof gives an algorithm that finds the\ncoloring in $O(n^2)$ time for an $n$-vertex input graph. Chrobak and Nishizeki\n[J. Algorithms, 1990] have shown a more careful algorithm, which improves the\ntime to $O(n\\log n)$ time, though only for $\\Delta\\ge 9$. In this paper, we\nextend their ideas to get an algorithm also for the missing case $\\Delta=8$. To\nthis end, we modify the original recoloring procedure of Vizing. This\ngeneralizes to bounded genus graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The Fair Periodic Assignment Problem",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-fair-periodic-assignment-problem/",
      "content": "Authors: Rolf van Lieshout, Bart van Rossum\n\nWe study the periodic assignment problem, in which a set of periodically\nrepeating tasks must be assigned to workers within a repeating schedule. The\nclassical efficiency objective is to minimize the number of workers required to\noperate the schedule. We propose a O(n log n) algorithm to solve this problem.\nNext, we formalize a notion of fairness among workers, and impose that each\nworker performs the same work over time. We analyze the resulting trade-off\nbetween efficiency and fairness, showing that the price of fairness is at most\none extra worker, and that such a fair solution can always be found using the\nNearest Neighbor heuristic. We characterize all instances that admit a solution\nthat is both fair and efficient, and use this result to develop a O(n log n)\nexact algorithm for the fair periodic assignment problem. Finally, we show that\nallowing aperiodic schedules never reduces the price of fairness.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Recent Advances in Maximum-Entropy Sampling",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-recent-advances-in-maximum-entropy-sampling/",
      "content": "Authors: Marcia Fampa, Jon Lee\n\nIn 2022, we published a book, \\emph{Maximum-Entropy Sampling: Algorithms and\nApplication (Springer)}. Since then, there have been several notable\nadvancements on this topic. In this manuscript, we survey some recent\nhighlights.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum Algorithms for Bandits with Knapsacks with Improved Regret and",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-quantum-algorithms-for-bandits-with-knapsacks-with-improved-regret-and-time-complexities/",
      "content": "Authors: Yuexin Su, Ziyi Yang, Peiyuan Huang, Tongyang Li, Yinyu Ye\n\nBandits with knapsacks (BwK) constitute a fundamental model that combines\naspects of stochastic integer programming with online learning. Classical\nalgorithms for BwK with a time horizon $T$ achieve a problem-independent regret\nbound of ${O}(\\sqrt{T})$ and a problem-dependent bound of ${O}(\\log T)$. In\nthis paper, we initiate the study of the BwK model in the setting of quantum\ncomputing, where both reward and resource consumption can be accessed via\nquantum oracles. We establish both problem-independent and problem-dependent\nregret bounds for quantum BwK algorithms. For the problem-independent case, we\ndemonstrate that a quantum approach can improve the classical regret bound by a\nfactor of $(1+\\sqrt{B/\\mathrm{OPT}_\\mathrm{LP}})$, where $B$ is budget\nconstraint in BwK and $\\mathrm{OPT}_{\\mathrm{LP}}$ denotes the optimal value of\na linear programming relaxation of the BwK problem. For the problem-dependent\nsetting, we develop a quantum algorithm using an inexact quantum linear\nprogramming solver. This algorithm achieves a quadratic improvement in terms of\nthe problem-dependent parameters, as well as a polynomial speedup of time\ncomplexity on problem’s dimensions compared to classical counterparts. Compared\nto previous works on quantum algorithms for multi-armed bandits, our study is\nthe first to consider bandit models with resource constraints and hence shed\nlight on operations research.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Makespan Scheduling under Scenarios",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-makespan-scheduling-under-scenarios/",
      "content": "Authors: Ekin Ergen\n\nWe consider a natural extension of online makespan scheduling on identical\nparallel machines by introducing scenarios. A scenario is a subset of jobs, and\nthe task of our problem is to find a global assignment of the jobs to machines\nso that the maximum makespan under a scenario, i.e., the maximum makespan of\nany schedule restricted to a scenario, is minimized.\nFor varying values of the number of scenarios and machines, we explore the\ncompetitiveness of online algorithms. We prove tight and near-tight bounds,\nseveral of which are achieved through novel constructions. In particular, we\nleverage the interplay between the unit processing time case of our problem and\nthe hypergraph coloring problem both ways: We use hypergraph coloring\ntechniques to steer an adversarial family of instances proving lower bounds,\nwhich in turn leads to lower bounds for several variants of online hypergraph\ncoloring.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Convex Optimization with Switching Cost with Only One Single",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-convex-optimization-with-switching-cost-with-only-one-single-gradient-evaluation/",
      "content": "Authors: Harsh Shah, Purna Chandrasekhar, Rahul Vaze\n\nOnline convex optimization with switching cost is considered under the frugal\ninformation setting where at time $t$, before action $x_t$ is taken, only a\nsingle function evaluation and a single gradient is available at the previously\nchosen action $x_{t-1}$ for either the current cost function $f_t$ or the most\nrecent cost function $f_{t-1}$. When the switching cost is linear, online\nalgorithms with optimal order-wise competitive ratios are derived for the\nfrugal setting. When the gradient information is noisy, an online algorithm\nwhose competitive ratio grows quadratically with the noise magnitude is\nderived.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Maximizing the Margin between Desirable and Undesirable Elements in a",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-maximizing-the-margin-between-desirable-and-undesirable-elements-in-a-covering-problem/",
      "content": "Authors: Sophie Boileau, Andrew Hong, David Liben-Nowell, Alistair Pattison, Anna N. Rafferty, Charlie Roslansky\n\nIn many covering settings, it is natural to consider the simultaneous\npresence of desirable elements (that we seek to include) and undesirable\nelements (that we seek to avoid). This paper introduces a novel combinatorial\nproblem formalizing this tradeoff: from a collection of sets containing both\n“desirable” and “undesirable” items, pick the subcollection that maximizes the\nmargin between the number of desirable and undesirable elements covered. We\ncall this the Target Approximation Problem (TAP) and argue that many real-world\nscenarios are naturally modeled via this objective. We first show that TAP is\nhard, even when restricted to cases where the given sets are small or where\nelements appear in only a small number of sets. In a large subset of these\ncases, we show that TAP is hard to even approximate. We then exhibit exact\npolynomial-time algorithms for other restricted cases and provide an efficient\n0.5-approximation for the case where elements occur at most twice, derived\nthrough a tight connection to the greedy algorithm for Unweighted Set Cover.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Liar's vertex-edge domination in subclasses of chordal graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-liar-s-vertex-edge-domination-in-subclasses-of-chordal-graphs/",
      "content": "Authors: Debojyoti Bhattacharya, Subhabrata Paul\n\nLet $G=(V, E)$ be an undirected graph. The set $N_G[x]={y\\in V|xy\\in E}\\cup\n{x}$ is called the closed neighbourhood of a vertex $x\\in V$ and for an edge\n$e=xy\\in E$, the closed neighbourhood of $e$ is the set $N_G[x]\\cup N_G[y]$,\nwhich is denoted by $N_G[e]$ or $N_G[xy]$. A set $L\\subseteq V$ is called\n\\emph{liar’s vertex-edge dominating set} of a graph $G=(V,E)$ if for every\n$e_i\\in E$, $|N_G[e_i]\\cap L|\\geq 2$ and for every pair of distinct edges\n$e_i,e_j\\in E$, $|(N_G[e_i]\\cup N_G[e_j])\\cap L|\\geq 3$. The notion of liar’s\nvertex-edge domination arises naturally from some applications in communication\nnetworks. Given a graph $G$, the \\textsc{Minimum Liar’s Vertex-Edge Domination\nProblem} (\\textsc{MinLVEDP}) asks to find a liar’s vertex-edge dominating set\nof $G$ of minimum cardinality. In this paper, we study this problem from an\nalgorithmic point of view. We design two linear time algorithms for\n\\textsc{MinLVEDP} in block graphs and proper interval graphs, respectively. On\nthe negative side, we show that the decision version of liar’s vertex-edge\ndomination problem is NP-complete for undirected path graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved Algorithms for Effective Resistance Computation on Graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-improved-algorithms-for-effective-resistance-computation-on-graphs/",
      "content": "Authors: Yichun Yang, Rong-Hua Li, Meihao Liao, Guoren Wang\n\nEffective Resistance (ER) is a fundamental tool in various graph learning\ntasks. In this paper, we address the problem of efficiently approximating ER on\na graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ with $n$ vertices and $m$\nedges. First, we focus on local online-computation algorithms for ER\napproximation, aiming to improve the dependency on the approximation error\nparameter $\\epsilon$. Specifically, for a given vertex pair $(s,t)$, we propose\na local algorithm with a time complexity of $\\tilde{O}(\\sqrt{d}/\\epsilon)$ to\ncompute an $\\epsilon$-approximation of the $s,t$-ER value for expander graphs,\nwhere $d=\\min {d_s,d_t}$. This improves upon the previous state-of-the-art,\nincluding an $\\tilde{O}(1/\\epsilon^2)$ time algorithm based on random walk\nsampling by Andoni et al. (ITCS’19) and Peng et al. (KDD’21). Our method\nachieves this improvement by combining deterministic search with random walk\nsampling to reduce variance. Second, we establish a lower bound for ER\napproximation on expander graphs. We prove that for any $\\epsilon\\in (0,1)$,\nthere exist an expander graph and a vertex pair $(s,t)$ such that any local\nalgorithm requires at least $\\Omega(1/\\epsilon)$ time to compute the\n$\\epsilon$-approximation of the $s,t$-ER value. Finally, we extend our\ntechniques to index-based algorithms for ER computation. We propose an\nalgorithm with $\\tilde{O}(\\min {m+n/\\epsilon^{1.5},\\sqrt{nm}/\\epsilon})$\nprocessing time, $\\tilde{O}(n/\\epsilon)$ space complexity and $O(1)$ query\ncomplexity, which returns an $\\epsilon$-approximation of the $s,t$-ER value for\nany $s,t\\in \\mathcal{V}$ for expander graphs. Our approach improves upon the\nstate-of-the-art $\\tilde{O}(m/\\epsilon)$ processing time by Dwaraknath et al.\n(NeurIPS’24) and the $\\tilde{O}(m+n/\\epsilon^2)$ processing time by Li and\nSachdeva (SODA’23).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-hipermotif-novel-parallel-subgraph-isomorphism-in-large-scale-property-graphs/",
      "content": "Authors: Mohammad Dindoost, Oliver Alvarado Rodriguez, Bartosz Bryg, Ioannis Koutis, David A. Bader\n\nSubgraph isomorphism, essential for pattern detection in large-scale graphs,\nfaces scalability challenges in attribute-rich property graphs used in\nneuroscience, systems biology, and social network analysis. Traditional\nalgorithms explore search spaces vertex-by-vertex from empty mappings, leading\nto extensive early-stage exploration with limited pruning opportunities. We\nintroduce HiPerMotif, a novel hybrid parallel algorithm that fundamentally\nshifts the search initialization strategy. After structurally reordering the\npattern graph to prioritize high-degree vertices, HiPerMotif systematically\nidentifies all possible mappings for the first edge (vertices 0,1) in the\ntarget graph, validates these edge candidates using efficient vertex and edge\nvalidators, and injects the validated partial mappings as states at depth 2.\nThe algorithm then continues with traditional vertex-by-vertex exploration from\nthese pre-validated starting points, effectively pruning the expensive early\nsearch tree branches while enabling natural parallelization over edge\ncandidates. Our contributions include the edge-centric initialization paradigm\nwith state injection, a structural reordering strategy achieving up to 5x\nspeedup, rapid edge and vertex validators for attribute-rich graphs, and\nefficient parallel enumeration over target graph edges. Implemented in the\nopen-source Arachne framework, HiPerMotif achieves up to 66x speedup over\nstate-of-the-art baselines (VF2-PS, VF3P, Glasgow) on diverse datasets where\nbaselines successfully complete execution. Additionally, HiPerMotif\nsuccessfully processes massive datasets such as the H01 connectome with 147\nmillion edges, which existing methods cannot handle due to memory constraints.\nComprehensive evaluation across synthetic and real-world graphs demonstrates\nHiPerMotif’s scalability, enabling advanced analysis in computational\nneuroscience and beyond.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Heights of butterfly trees",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-heights-of-butterfly-trees/",
      "content": "Authors: John Peca-Medlin, Chenyang Zhong\n\nBinary search trees (BSTs) are fundamental data structures whose performance\nis largely governed by tree height. We introduce a block model for constructing\nBSTs by embedding internal BSTs into the nodes of an external BST – a\nstructure motivated by parallel data architectures – corresponding to\ncomposite permutations formed via Kronecker or wreath products. Extending\nDevroye’s result that the height $h_n$ of a random BST satisfies $h_n / \\log n\n\\to c^* \\approx 4.311$, we show that block BSTs with $nm$ nodes and fixed\nexternal size $m$ satisfy $h_{n,m} / \\log n \\to c^* + h_m$ in distribution. We\nthen analyze height growth under iterated products. For simple butterfly trees\n(from iterated Kronecker products of $S_2$), we give a full distributional\ndescription showing polynomial height growth: $\\mathbb{E}\nh_n^{\\operatorname{B}} = \\Theta(N^\\alpha)$ with $\\alpha \\approx 0.58496$. For\nnonsimple butterfly trees (from wreath products), we prove power-law bounds:\n$cN^\\alpha\\cdot (1 + o(1)) \\le \\mathbb{E} h_n^{\\operatorname{B}} \\le\ndN^\\beta\\cdot (1 + o(1))$, with $\\beta \\approx 0.913189$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Greedy Dynamic Matching",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-greedy-dynamic-matching/",
      "content": "Authors: Nick Arnosti, Felipe Simon\n\nWe study a foundational model of dynamic matching market with abandonment.\nThis model has been studied by Collina et al (2020) and Aouad and Saritac\n(2022), and many other papers have considered special cases. We compare the\nperformance of greedy policies – which identify a set of “acceptable” matches\nup front, and perform these matches as soon as possible – to that of an\nomniscient benchmark which knows the full arrival and departure sequence.\nWe use a novel family of linear programs ($LP^{ALG}$) to identify which\ngreedy policy to follow. We show that the value of $LP^ALG$ is a *lower bound*\non the value of the greedy policy that it identifies in two settings of\ninterest:\n-When all types have the same departure rate.\n-The bipartite case where types on the same side of the market have the same\ndeparture rate.\nThe proofs of these results use a new result (Lemma 1), which relates the\n*probability* that at least one agent from a set of types is present in the\nsystem to the expected number of such agents.\nWe also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rate\nearned by the omniscient policy (Proposition 4). Therefore, for both settings\nabove, our greedy policy provably earns at least half of the omniscient reward\nrate. This improves upon the bound of 1/8 from Collina (2020). In both settings\nour competitive ratio of 1/2 is the best possible: no online policy can provide\na better guarantee (Theorem 2).\nTo show these results we introduce a new linear program that upper bounds the\nobjective value of the omniscient policy (Proposition 3). This improves upon\nthe upper bounds presented by Collina et al (2020) and Kessel et al (2022).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Distributed Approximation Algorithms for Minimum Dominating Set in",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-distributed-approximation-algorithms-for-minimum-dominating-set-in-locally-nice-graphs/",
      "content": "Authors: Marthe Bonamy, Cyril Gavoille, Timothé Picavet, Alexandra Wesolek\n\nWe give a new, short proof that graphs embeddable in a given Euler genus-$g$\nsurface admit a simple $f(g)$-round $\\alpha$-approximation distributed\nalgorithm for Minimum Dominating Set (MDS), where the approximation ratio\n$\\alpha \\le 906$. Using tricks from Heydt et al. [European Journal of\nCombinatorics (2025)], we in fact derive that $\\alpha \\le 34 +\\varepsilon$,\ntherefore improving upon the current state of the art of $24g+O(1)$ due to\nAmiri et al. [ACM Transactions on Algorithms (2019)]. It also improves the\napproximation ratio of $91+\\varepsilon$ due to Czygrinow et al. [Theoretical\nComputer Science (2019)] in the particular case of orientable surfaces.\nAll our distributed algorithms work in the deterministic LOCAL model. They do\nnot require any preliminary embedding of the graph and only rely on two things:\na LOCAL algorithm for MDS on planar graphs with uniform'' approximation\nguarantees and the knowledge that graphs embeddable in bounded Euler genus\nsurfaces have asymptotic dimension $2$.\nMore generally, our algorithms work in any graph class of bounded asymptotic\ndimension wheremost vertices’’ are locally in a graph class that admits a\nLOCAL algorithm for MDS with uniform approximation guarantees.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Decremental Greedy Polygons and Polyhedra Without Sharp Angles",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/",
      "content": "Authors: David Eppstein\n\nWe show that the max-min-angle polygon in a planar point set can be found in\ntime $O(n\\log n)$ and a max-min-solid-angle convex polyhedron in a\nthree-dimensional point set can be found in time $O(n^2)$. We also study the\nmaxmin-angle polygonal curve in 3d, which we show to be $\\mathsf{NP}$-hard to\nfind if repetitions are forbidden but can be found in near-cubic time if\nrepeated vertices or line segments are allowed, by reducing the problem to\nfinding a bottleneck cycle in a graph. We formalize a class of problems on\nwhich a decremental greedy algorithm can be guaranteed to find an optimal\nsolution, generalizing our max-min-angle and bottleneck cycle algorithms,\ntogether with a known algorithm for graph degeneracy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Combination generators with optimal cache utilization and communication",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-combination-generators-with-optimal-cache-utilization-and-communication-free-parallel-execution/",
      "content": "Authors: Xi He, Max. A. Little\n\nWe introduce an efficient and elegant combination generator for producing all\ncombinations of size less than or equal to K, designed for exhaustive\ngeneration and combinatorial optimization tasks. This generator can be\nimplemented to achieve what we define as optimal efficiency: constant amortized\ntime, optimal cache utilization, embarrassingly parallel execution, and a\nrecursive structure compatible with pruning-based search. These properties are\ndifficult to satisfy simultaneously in existing generators. For example,\nclassical Gray code or lexicographic generators are typically list-based and\nsequentially defined, making them difficult to vectorized, inefficient in cache\nusage, and inherently hard to parallelize. Generators based on unranking\nmethods, while easy to parallelize, are non-recursive. These limitations reduce\ntheir applicability in our target applications, where both computational\nefficiency and recursion are crucial. We adapt Bird’s algebra of\nprogramming-style calculation to derive our algorithms, a formalism for\ndeveloping correct-by-construction programs from specifications. As a result,\nall generators in this paper are first formulated in their clearest\nspecification, and efficient definitions are derived constructively through\nequational reasoning, resulting in concise and elegant divide-and-conquer\ndefinitions. Beyond presenting a combination generator, we extend our approach\nto construct generators for K-permutations, nested combinations of\ncombinations, and nested permutation-combination structures. To the best of our\nknowledge, the literature has not previously reported generators for these\nnested structures. We also develop sequential variants that produce\nconfigurations in Gray code-compatible orders – such as the revolving door\nordering – which are particularly useful for constructing nested generators.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Color Distance Oracles and Snippets: Separation Between Exact and",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-color-distance-oracles-and-snippets-separation-between-exact-and-approximate-solutions/",
      "content": "Authors: Noam Horowicz, Tsvi Kopelowitz\n\nIn the snippets problem, the goal is to preprocess text $T$ so that given two\npatterns $P_1$ and $P_2$, one can locate the occurrences of the two patterns in\n$T$ that are closest to each other, or report their distance. Kopelowitz and\nKrauthgamer [CPM2016] showed upper bound tradeoffs and conditional lower bounds\ntradeoffs for the snippets problem, by utilizing connections between the\nsnippets problem and the problem of constructing a color distance oracle (CDO),\nwhich is a data structure that preprocess a set of points with associated\ncolors so that given two colors $c$ and $c’$ one can quickly find the (distance\nbetween the) closest pair of points with colors $c$ and $c’$. However, the\nexisting upper bound and lower bound curves are not tight.\nInspired by recent advances by Kopelowitz and Vassilevska-Williams\n[ICALP2020] regarding Set-disjointness data structures, we introduce new\nconditionally optimal algorithms for $(1+\\varepsilon)$ approximation versions\nof the snippets problem and the CDO problem, by applying fast matrix\nmultiplication. For example, for CDO on $n$ points in an array with\npreprocessing time $\\tilde{O}(n^a)$ and query time $\\tilde{O}(n^b)$, assuming\nthat $\\omega=2$ (where $\\omega$ is the exponent of $n$ in the runtime of the\nfastest matrix multiplication algorithm on two squared matrices of size\n$n\\times n$), we show that approximate CDO can be solved with the following\ntradeoff\n\\(a + 2b = 2 \\text{ if } 0 \\leq b \\leq \\frac1 3\\) \\(2a + b = 3 \\text{ if }\n\\frac13\\leq b \\leq 1.\\)\nMoreover, we prove that for exact CDO on points in an array, the algorithm of\nKopelowitz and Krauthgamer [CPM2016], is essentially optimal assuming that the\nstrong APSP hypothesis holds for randomized algorithms. Thus, the exact version\nof CDO is strictly harder than the approximate version.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bicriteria approximation for k-edge-connectivity",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-bicriteria-approximation-for-k-edge-connectivity/",
      "content": "Authors: Zeev Nutov, Reut Cohen\n\nIn the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a\n(multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost\n$k$-edge-connected spanning subgraph of $G$. The problem admits a\n$2$-approximation algorithm and no better approximation ratio is known.\nRecently, Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria\n$(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected\nspanning subgraph of cost at most the optimal value of a standard Cut-LP for\n$k$-ECSS. We improve the bicriteria approximation to $(1,k-4)$, and also give\nanother non-trivial bicriteria approximation $(3/2,k-2)$. The\n$k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost the\nsame as $k$-ECSS, except that any edge can be selected multiple times at the\nsame cost. A $(1,k-p)$ bicriteria approximation for $k$-ECSS w.r.t. Cut-LP\nimplies approximation ratio $1+p/k$ for $k$-ECSM, hence our result also\nimproves the approximation ratio for $k$-ECSM.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Agentic Distributed Computing",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-agentic-distributed-computing/",
      "content": "Authors: Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma\n\nThe most celebrated and extensively studied model of distributed computing is\nthe {\\em message-passing model,} in which each vertex/node of the (distributed\nnetwork) graph corresponds to a static computational device that communicates\nwith other devices through passing messages. In this paper, we consider the\n{\\em agentic model} of distributed computing which extends the message-passing\nmodel in a new direction. In the agentic model, computational devices are\nmodeled as relocatable or mobile computational devices (called agents in this\npaper), i.e., each vertex/node of the graph serves as a container for the\ndevices, and hence communicating with another device requires relocating to the\nsame node. We study two fundamental graph level tasks, leader election, and\nminimum spanning tree, in the agentic model, which will enhance our\nunderstanding of distributed computation across paradigms. The objective is to\nminimize both time and memory complexities. Following the literature, we\nconsider the synchronous setting in which each agent performs its operations\nsynchronously with others, and hence the time complexity can be measured in\nrounds. In this paper, we present two deterministic algorithms for leader\nelection: one for the case of $k\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A simple algorithm for Combinatorial n-fold ILPs using the Steinitz",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-combinatorial-n-fold-ilps-using-the-steinitz-lemma/",
      "content": "Authors: Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi\n\nWe present an algorithm for a class of $n$-fold ILPs: whose existing\nalgorithms in literature typically (1) are based on the \\textit{augmentation\nframework} where one starts with an arbitrary solution and then iteratively\nmoves towards an optimal solution by solving appropriate programs; and (2)\nrequire solving a linear relaxation of the program. Combinatorial $n$-fold ILPs\nis a class introduced and studied by Knop et al. [MP2020] that captures several\nother problems in a variety of domains. We present a simple and direct\nalgorithm that solves Combinatorial $n$-fold ILPs with unbounded non-negative\nvariables via an application of the Steinitz lemma, a classic result regarding\nreordering of vectors. Depending on the structure of the input, we also improve\nupon the existing algorithms in literature in terms of the running time,\nthereby showing an improvement that mirrors the one shown by Rohwedder\n[ICALP2025] contemporaneously and independently.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A note on finding long directed cycles above the minimum degree bound in",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-note-on-finding-long-directed-cycles-above-the-minimum-degree-bound-in-2-connected-digraphs/",
      "content": "Authors: Jadwiga Czyżewska, Marcin Pilipczuk\n\nFor a directed graph $G$, let $\\mathrm{mindeg}(G)$ be the minimum among\nin-degrees and out-degrees of all vertices of $G$. It is easy to see that $G$\ncontains a directed cycle of length at least $\\mathrm{mindeg}(G)+1$. In this\nnote, we show that, even if $G$ is $2$-connected, it is NP-hard to check if $G$\ncontains a cycle of length at least $\\mathrm{mindeg}(G)+3$. This is in contrast\nwith recent algorithmic results of Fomin, Golovach, Sagunov, and Simonov [SODA\n2022] for analogous questions in undirected graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Node-neighbor subnetworks and Hk-core decomposition",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-geometry-node-neighbor-subnetworks-and-hk-core-decomposition/",
      "content": "Authors: Dinghua Shi, Yang Zhao, Guanrong Chen\n\nThe network homology Hk-core decomposition proposed in this article is\nsimilar to the k-core decomposition based on node degrees of the network. The\nC. elegans neural network and the cat cortical network are used as examples to\nreveal the symmetry of the deep structures of such networks. First, based on\nthe concept of neighborhood in mathematics, some new concepts are introduced,\nincluding such as node-neighbor subnetwork and Betti numbers of the neighbor\nsubnetwork, among others. Then, the Betti numbers of the neighbor subnetwork of\neach node are computed, which are used to perform Hk-core decomposition of the\nnetwork homology. The construction process is as follows: the initial network\nis referred to as the H0-core; the H1-core is obtained from the H0-core by\ndeleting some nodes of certain properties; the H2-core is obtained from the\nH1-core by deleting some nodes or edges of certain properties; the H3-core is\nobtained from the H2-core by deleting some nodes of certain properties or by\nretaining the nodes of certain properties, and so on, which will be described\nin detail in the main text. Throughout the process, the index of node involved\nin deleting edge needs to be updated in every step. The Hk-core decomposition\nis easy to implement in parallel. It has a wide range of applications in many\nfields such as network science, data science, computational topology, and\nartificial intelligence. In this article, we also show how to use it to\nsimplify homology calculation, e.g. for the C. elegans neural network, whereas\nthe results of decomposition are the H1-core, the H2-core, and the H3-core.\nThus, the simplexes consisting of four highest-order cavities in the H3-core\nsubnetwork can also be directly obtained.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Input-Sensitive Reconfiguration of Sliding Cubes",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-geometry-input-sensitive-reconfiguration-of-sliding-cubes/",
      "content": "Authors: Hugo Akitaya, Matias Korman, Frederick Stock\n\nA configuration of $n$ unit-cube-shaped \\textit{modules} (or \\textit{robots})\nis a lattice-aligned placement of the $n$ modules so that their union is\nface-connected. The reconfiguration problem aims at finding a sequence of moves\nthat reconfigures the modules from one given configuration to another. The\nsliding cube model (in which modules are allowed to slide over the face or edge\nof neighboring modules) is one of the most studied theoretical models for\nmodular robots.\nIn the sliding cubes model we can reconfigure between any two shapes in\n$O(n^2)$ moves ([Abel \\textit{et al.} SoCG 2024]). If we are interested in a\nreconfiguration algorithm into a \\textit{compact configuration}, the number of\nmoves can be reduced to the sum of coordinates of the input configuration (a\nnumber that ranges from $\\Omega(n^{4/3})$ to $O(n^2)$, [Kostitsyna \\textit{et\nal.} SWAT 2024]). We introduce a new algorithm that combines both universal\nreconfiguration and an input-sensitive bound on the sum of coordinates of both\nconfigurations, with additional advantages, such as $O(1)$ amortized\ncomputation per move.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Decremental Greedy Polygons and Polyhedra Without Sharp Angles",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-geometry-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/",
      "content": "Authors: David Eppstein\n\nWe show that the max-min-angle polygon in a planar point set can be found in\ntime $O(n\\log n)$ and a max-min-solid-angle convex polyhedron in a\nthree-dimensional point set can be found in time $O(n^2)$. We also study the\nmaxmin-angle polygonal curve in 3d, which we show to be $\\mathsf{NP}$-hard to\nfind if repetitions are forbidden but can be found in near-cubic time if\nrepeated vertices or line segments are allowed, by reducing the problem to\nfinding a bottleneck cycle in a graph. We formalize a class of problems on\nwhich a decremental greedy algorithm can be guaranteed to find an optimal\nsolution, generalizing our max-min-angle and bottleneck cycle algorithms,\ntogether with a known algorithm for graph degeneracy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Computing Largest Subsets of Points Whose Convex Hulls have Bounded Area",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-geometry-computing-largest-subsets-of-points-whose-convex-hulls-have-bounded-area-and-diameter/",
      "content": "Authors: Gianmarco Picarella, Marc van Kreveld, Frank Staals, Sjoerd de Vries\n\nWe study the problem of computing a convex region with bounded area and\ndiameter that contains the maximum number of points from a given point set $P$.\nWe show that this problem can be solved in $O(n^6k)$ time and $O(n^3k)$ space,\nwhere $n$ is the size of $P$ and $k$ is the maximum number of points in the\nfound region. We experimentally compare this new algorithm with an existing\nalgorithm that does the same but without the diameter constraint, which runs in\n$O(n^3k)$ time. For the new algorithm, we use different diameters. We use both\nsynthetic data and data from an application in cancer detection, which\nmotivated our research.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Approximation and Hardness of Polychromatic TSP",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-geometry-approximation-and-hardness-of-polychromatic-tsp/",
      "content": "Authors: Thomas Schibler, Subhash Suri, Jie Xue\n\nWe introduce the Polychromatic Traveling Salesman Problem (PCTSP), where the\ninput is an edge weighted graph whose vertices are partitioned into $k$\nequal-sized color classes, and the goal is to find a minimum-length Hamiltonian\ncycle that visits the classes in a fixed cyclic order. This generalizes the\nBipartite TSP (when $k = 2$) and the classical TSP (when $k = n$). We give a\npolynomial-time $(3 - 2 * 10^{-36})$-approximation algorithm for metric PCTSP.\nComplementing this, we show that Euclidean PCTSP is APX-hard even in $R^2$,\nruling out the existence of a PTAS unless P = NP.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Testing for Renamability to Classes of Clause Sets",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-testing-for-renamability-to-classes-of-clause-sets/",
      "content": "Authors: Albert Brandl, Christian G. Fermüller, Gernot Salzer\n\nThis paper investigates the problem of testing clause sets for membership in\nclasses known from literature. In particular, we are interested in classes\ndefined via renaming: Is it possible to rename the predicates in a way such\nthat positive and negative literals satisfy certain conditions? We show that\nfor classes like Horn or OCC1N, the existence of such renamings can be decided\nin polynomial time, whereas the same problem is NP-complete for class PVD. The\ndecision procedures are based on hyper-resolution; if a renaming exists, it can\nbe extracted from the final saturated clause set.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: PFCS: Prime Factorization Cache System for Deterministic Data",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-pfcs-prime-factorization-cache-system-for-deterministic-data-relationship-discovery/",
      "content": "Authors: Duy Le\n\nCache systems fundamentally limit modern computing performance due to their\ninability to precisely capture data relationships. While achieving 85-92% hit\nrates, traditional systems rely on statistical heuristics that cannot guarantee\nrelationship discovery, leading to suboptimal prefetching and resource waste.\nWe present PFCS (Prime Factorization Cache System), which leverages the\nmathematical uniqueness of prime factorization to achieve deterministic\nrelationship discovery with zero false positives. PFCS assigns unique primes to\ndata elements and represents relationships as composite numbers, enabling the\nrecovery of perfect relationships through factorization. A comprehensive\nevaluation across database, ML, and HPC workloads demonstrates an average\nperformance improvement of x 6.2, 98.9% hit rates, and a 38% power reduction\ncompared to state-of-the-art systems. The mathematical foundation provides\nformal guarantees impossible with approximation-based approaches, establishing\na new paradigm for cache system design\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Low sets for counting functions",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-low-sets-for-counting-functions/",
      "content": "Authors: Yaroslav Ivanashev\n\nIn this paper, we characterize the classes of languages and functions that\nare low for counting function classes. The classes #P and GapP have their low\nclasses exactly characterized: Low(#P) = UP $\\cap$ coUP and Low(GapP) = SPP. We\nprove that Low(TotP) = P, Low(SpanP) = NP $\\cap$ coNP, and give\ncharacterizations of low function classes for #P, GapP, TotP, and SpanP. We\nestablish the relations between NPSVt, UPSVt, and the counting function\nclasses. For each of the inclusions between these classes we give an equivalent\ninclusion between language classes. We also prove that SpanP $\\subseteq$ GapP\nif and only if NP $\\subseteq$ SPP, and the inclusion GapP+ $\\subseteq$ SpanP\nimplies PH = $\\Sigma_{2}^{P}$. For the classes #P, GapP, TotP, and SpanP we\nsummarize the known results and prove that each of these classes is closed\nunder left composition with FP+ if and only if it collapses to its low class of\nfunctions.\n\nRead original post\n"
    },
    
    {
      "title": "David Eppstein: Ready lists",
      "url": "/cstheoryrss/2025/07/07/david-eppstein-ready-lists/",
      "content": "Beginning computer science students learn about stacks, queues, and priority queues, different ways of organizing and ordering a collection of tasks to be performed. But more basic than any of those, and less frequently taught and formalized, is the ready list, a collection of tasks to be performed whose ordering is not important. All it needs to do is to allow new tasks to be added to the collection and to find and remove an arbitrary task from the collection.\n\nStandard algorithms that work with ready lists include:\n\n\n  Reachability\n  Input: a directed or undirected graph and a starting vertex in the graph\n  Output: the set of vertices that can be reached from the starting vertex\n  Algorithm:\n\n    \n      Initialize a set of reachable vertices, and a ready list of reachable but unprocessed vertices, both initially containing only the starting vertex.\n      While the ready list is non-empty:\n        \n          Find and remove a vertex (v) from the ready list\n          For each outgoing neighbor (w) of (v) that is not already in the reachable set, add (w) to both the reachable set and the ready list.\n        \n      \n      Return the reachable set\n    \n  \n  Topological ordering\n  Input: a directed acyclic graph\n  Output: a sequence of vertices, ordered so all edges go from earlier to later in the ordering\n  Algorithm:\n\n    \n      Initialize a ready list of vertices with no incoming edges\n      While the ready list is non-empty:\n        \n          Find and remove a vertex (v) from the ready list\n          Delete (v) from the graph and output (v)\n          Add to the ready list any former neighbor of (v) which, after the deletion, has no more incoming edges\n        \n      \n    \n  \n  Stable matching\n  Input: A set of job applicants and a set of employers, with each applicant having a preference ordering among the employers and each employer having a preference ordering among the applicants\n  Output: A stable matching\n  Algorithm:\n\n    \n      Initialize a ready list of job offers from each employer to its top applicant\n      While the ready list is non-empty:\n        \n          Find and remove an offer from employer (X) to applicant (A)\n          If (A) prefers their current situation over (X), add to the ready list a new job offer from (X) to (X)’s next applicant.\n          Otherwise, match (A) and (X); if (A) was previously matched, remove that match and add to the ready list a new job offer from (A)’s previous employer to its next applicant\n        \n      \n    \n  \n\n\nIn the cases of reachability and stable matching, the ordering chosen by the ready list is unimportant: you will always get the same reachable set and the same matching. In the case of topological ordering, you may get different orderings but regardless of order you will always output the same set of vertices for any given graph, even if the graph is not acyclic.\n\nThis invariance is usually proven algorithm-by-algorithm, but it is true very generally for a class of algorithms with three simple properties: First, an item that is added to the ready list stays there until it is processed. Second, each item is added to the ready list only once. And third, the condition for adding an item to the ready list should be a monotonic combination of which other items have already been processed: if a certain combination of processed items triggers an addition, then any superset of the same combination should trigger the same addition. The trigger for reachability is that some neighbor is processed, and the trigger for topological ordering is that all incoming neighbors are processed. For stable matching, the trigger for an offer from (X) to (A) is that (X)’s previous applicant has already received both an offer from (X) and an offer from another employer that they prefer over (X).\n\nThese three properties are enough to prove that the sequences in which items can be processed by an algorithm of this type form an antimatroid. The key axiom of antimatroid sequences that we need to prove is that, if two sequences (S) and (T) can both be generated, and (S) contains an item not in (T), then (S) contains an item (x) that can be processed next after (T), producing a sequence (Tx). To prove this, simply let (x) be the first item that belongs to (S) but not (T), and apply the monotonic trigger property.\n\nIn any antimatroid, all sequences that cannot be extended consist of the same set of items. Again, this is easy to prove: if two sequences had different sets of items, then one would contain an item by which the other could be extended. To translate this into terms more familiar to the beginning computer science students: if a ready list obeys the three properties given above, and we run an algorithm using it until the ready list becomes empty, then all runs of the algorithm process the same set of items.\n\nWhile exploring this I ran into another basic algorithm that in its usual form is based on integer priority queues but can be transformed into a ready list algorithm:\n\n\n  Degeneracy\n  Input: An undirected graph\n  Output: A subgraph whose minimum degree is as large as possible\n  Algorithm:\n\n    \n      Initialize an empty ready list\n      While the graph is non-empty:\n        \n          If the ready list is empty, set (d) to the minimum degree in the graph, set (S) to be an empty set, and add to the ready list all vertices of degree (d)\n          Find and remove a vertex (v) from the ready list\n          Delete (v) from the graph and add (v) to (S)\n          Add to the ready list any former neighbors of (v) for which this removal decreases the degree to (\\le d)\n        \n      \n      Output the subgraph induced in the original input graph by (S)\n    \n  \n\n\nThis can be made to run in linear time but the details of that are beyond the scope of this post. Proving monotonicity of the condition for triggering addition to the ready list is a little less obvious here. For each integer (k) we can define a subgraph called the (k)-core, the union of all subgraphs whose minimum degree is at least (k). The output is the (d)-core. The monotonic trigger for any vertex (v) to be added to the ready list is that all vertices not in the (k)-core have already been processed, where (k) is the largest value for which the (k)-core contains (v), and that (v) has at most (k) unprocessed neighbors.\n\nAbstractly, the decreasing degrees of the vertices can be seen as a kind of element quality that decreases as other elements are removed; we seek the subset maximizing the minimum quality of any of its elements. My latest preprint, “Decremental greedy polygons and polyhedra without sharp angles” (arXiv:2507.04538, to appear at this year’s Canadian Conference on Computational Geometry) looks at a general class of problems like this, and identifies several more. One of the simplest of these is to find a polygon through a subset of the points that maximizes the minimum interior angle.\n\n\n\nSo here is the algorithm; I think the similarities between this and the degeneracy algorithms are obvious.\n\n\n  Max-min angle polygon\n  Input: A set of points in (\\mathbb{R}^2)\n  Output: A polygon with the points as vertices whose sharpest angle is as large as possible\n  Algorithm:\n\n    \n      Initialize an empty ready list\n      While the set of points is non-empty:\n        \n          If the ready list is empty, set (\\theta) to the minimum angle of a convex hull vertex of the remaining points, set (S) to be an empty set, and add to the ready list all convex hull vertices of angle (\\theta)\n          Find and remove a point (p) from the ready list\n          Delete (p) from the points and add (p) to (S)\n          Add to the ready list any convex hull vertices for which this removal decreases the angle to (\\le\\theta)\n        \n      \n      Output the convex hull of (S)\n    \n  \n\n\nThis can be made to run in time (O(n\\log n)); for details see the preprint. I’ll finish with one more from the full version of the paper, on cycles in directed graphs.\n\n\n  Bottleneck cycle\n  Input: A directed graph with weighted edges\n  Output: A cycle whose minimum edge weight is as large as possible\n  Algorithm:\n\n    \n      Initialize a ready list of the edges out of all vertices that have no incoming edges, and the edges into all vertices that have no outgoing edges\n      Initialize an empty set (S)\n      While the set of graph edges is non-empty:\n        \n          If the ready list is empty, set (w) to the minimum weight of a remaining edge, set (S) to be an empty set, and add to the ready list all edges of weight (w)\n          Find and remove an edge ((u,v)) from the ready list\n          Delete edge ((u,v)) from the graph and add it to (S)\n          If (u) has no more outgoing edges, add to the ready list all its incoming edges.\n          If (v) has no more incoming edges, add to the ready list all its outgoing edges.\n        \n      \n      Find and output any cycle in the subgraph of edges in (S)\n    \n  \n\n\nFor this one, a direct implementation on a graph with (n) vertices and (m) edges would take time (O(m\\log n)), not really better than the obvious binary search. However, it can be made to run in linear time for graphs with edges already sorted by length, and this presorted version can be used as a subroutine in a different algorithm for graphs with unsorted edges, in time (O(m\\log^* n)). In turn, bottleneck cycles can be used as a subroutine in an algorithm for finding the max-min angle closed polygonal curve for 3d points, allowing the curve to pass repeatedly through points and segments, in time (O(n^3\\log^* n)). For details see the preprint.\n\n(Discuss on Mastodon)\n\nBy David Eppstein\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: You keep using that word",
      "url": "/cstheoryrss/2025/07/07/ben-recht-you-keep-using-that-word/",
      "content": "\n\nA friend sent me a fun article in FT Alphaville by Bryce Elder showing how dogma doesn’t need to make sense to make money. The article hooked me from the get-go:\n\n\n  “The Virtue of Complexity in Return Prediction — co-authored by Bryan Kelly with Semyon Malamud and Kangying Zhou — found that complex machine-learning models were better than simple ones at predicting stock prices and building portfolios.”\n\n\n\n  “The finding was a big deal because it contradicted one of machine learning’s guiding principles, the bias-variance trade-off, which says the predictive power of models weakens as they grow beyond some optimum level. Given too many parameters to play with, a bot will tend to overfit its output to random noise in the training data.”\n\n\nOh, I’ve written about this before, arguing we should remove the bias-variance tradeoff from the machine learning curriculum. Much love to everyone who references the ye olde argmin blog in the comments over on Alphville. I appreciate the shoutouts! However, many of my friends in finance have told me that their data was where statistical overfitting, the type of overfitting we teach in our undergraduate classes, was a real phenomenon. Here is a paper that apparently refutes their claims. According to Kelly et al., even in finance, the bias-variance tradeoff isn’t real. Elder continues:\n\n\n  “The finding was rooted in an AI concept known as double descent, which says deep learning algorithms make fewer mistakes when they have more variable parameters than training data points.”\n\n\nDouble descent, you say? Hmm. At this point in the article, I got a bit worried because that’s… not what double descent says. Well, now I had to go and download the paper from SSRN. It checks in at a crisp 141 pages.\n\nOnce you skip past the laborious theoretical analysis of a linear Gaussian model, you get to the experiments on page 41. The authors want to predict next month’s prices from a set of 15 indicators. They use a window of past pairs of indicators and prices from the last 12 months to make this prediction. They propose applying standard supervised learning to solve this problem. Translating their setup into machine learning language: their training dataset has 12 examples, each with 15 features. Yes, 12.\n\nWhat do they conclude? They find that if they use random Fourier features, then the training error continues to decrease as they add more and more features. In particular, using 12,000 random Fourier features still gives good performance.\n\nOh my. I know it’s been twenty years since Ali and I first wrote up our paper on random features, and our point seems to have been lost in time.1 The motivation was finding computationally efficient ways to approximate machine learning in kernel spaces. I realize no one learns about kernel methods anymore, but you can read about them in Chapter 4 of Patterns, Predictions, and Actions. For the purpose of this post: kernel methods give you a computationally efficient way to compute a prediction model that uses an infinite number of features. Through some fun linear algebra, it turns out you only need to solve a linear system with one variable for every training example. Kernel methods transform infinite-dimensional learning problems into finite-dimensional linear algebra problems.\n\nStill, kernel methods require more computation than standard linear regression methods (and deep learning methods for that matter). The time needed to solve a linear system scales with the cube of the number of data points. The time required to solve linear regression scales linearly with the number of data points. Ali and I initially stumbled upon random features as a way to approximate kernel methods by solving linear regression problems.\n\nBut you know folks, kernel methods aren’t that computationally expensive. Cubic time is still polynomial time. And high-dimensional linear regression has its own scaling issues. The solution time of a random Fourier features problem scales with the square of the number of features.2 Since random features approximate kernel methods, the prediction performance of kernel methods should always be as good or better.3\n\nTo reiterate, kernel ridge regression solves an infinite-dimensional regression problem. It is going to get you the solution promised by the asymptote of that double descent curve you are all so enamored with. Infinity is more than 12,000, and moar is always better, right? If you find yourself using 1000 times more random features than data points, you might want to consider reading a few tutorials on kernel regression. It’s not hard to implement! In Python on my laptop, I can solve a 12 example kernel ridge regression problem in microseconds.\n\nThe argmin blog is here to help you save money on GPU cloud credits.\n\nNow you might ask, would “ridgeless kernel regression,” that is, kernel regression that ignores the warnings of the bias-variance tradeoff, work well for time series analysis? This is a good question, and one asked by Emmanuel Parzen in his landmark 1961 paper, “An Approach to Time Series Analysis.”4 Parzen’s paper is one of the first to explicitly use reproducing kernels in prediction problems. In Section 6, he proposes using ridgeless kernel regression to solve the exact same problem studied by Kelly and coauthors.\n\nI’m not the first person to recognize this, as Elder notes in Alphaville. Stefan Nagel wrote a convincing rebuttal to Kelly et al., posted last week. Nagel notes that random Fourier features are approximating kernel regression. He also notes that the prediction function computed by kernel regression looks a lot like kernel smoothing. This means the data points that most influence the prediction will be the ones most recent in time. Nagel thus argues that Kelly et al. are making a bunch of appeals to deep learning hype to reinvent momentum investing.\n\nAnd about that bias-variance tradeoff? If you slog through Kelly et al, you’ll see that their theoretical analysis has a bias-variance tradeoff! And the optimum setting requires tuning the tradeoff!\n\n\n  “We show that machine learning portfolios tend to incrementally benefit from moving away from the ridgeless limit by introducing nontrivial shrinkage.”\n\n\nSigh.\n\nI realize that everyone has jumped on the deep learning train now, but cargo culting isn’t in your interest. For small problems (like training sets of size 12), you don’t need neural networks. You can use them, I guess. But you can get more understanding out of these small, infinite-dimensional models that people have been studying for seventy years.\n\nSadly, the hype cycle gets everyone confused. It’s hilarious that stylized statistical learning theory stories now find their way into the mainstream press. The Alphaville title is even confused here: “Are bigger AI models better stock pickers? Maybe, but probably not. Complexity ain’t all that, wonks say.” I mean, this contradicts the rest of the story. First, calling ordinary least squares “AI” is a bit of a stretch. Second, Nagel’s results show that in this restricted class of models, bigger models are indeed better. Moreover, those infinitely large models recover well-known, naive momentum strategies.\n\nKelly and his fund, AQR, weren’t happy about Elder’s article. They wrote a rebuttal, proclaiming:\n\n\n  “The empirical dominance of large models has been shown in every area of ML by heavyweight ML academics’ research, which has been conducted throughout the natural and applied sciences. Language and image modeling are most well-known applications that exemplify the success of large models. Do we really think that finance, economics, or other social sciences are special? The work of Kelly and team shows otherwise.”\n\n\nThis heavyweight ML academic offers a very reasonable consulting fee if you are at a hedge fund and need assistance understanding double descent and the no true Scotsman fallacy.\n\nSubscribe now\n\n1\n\n…like tears in rain.\n\n2\n\nYeah, you can do some stochastic gradient stuff to get that square down to linear, but let me not bore everyone with flop counting. We can save that for a more technical post.\n\n3\n\nI realize theory and practice don’t always align, but in my experience, this is always true.\n\n4\n\nWhat a title. Such modesty with indefinite articles would get you immediately desk rejected at NeurIPS.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Happy Birthday Saharon Shelah and Yuri Gurevich!",
      "url": "/cstheoryrss/2025/07/07/gil-kalai-happy-birthday-saharon-shelah-and-yuri-gurevich/",
      "content": "Let me briefly report on two birthday conferences for long-time friends and colleagues Saharon Shelah and Yuri Gurevich. Yuri fest took place in Munich and on Zoom between June 20–22 2025 and Shelah’s birthday conference will be held in Vienna on July 14–15, 2025.\n\n\n\nFor my general thoughts on celebrating colleagues’ birthdays in these tragic and dangerous times, see this post.\n\nSaharon Shelah is among the greatest and most decorated mathematicians of our time with groundbreaking contributions in model theory, set theory, combinatorics, and other areas. Among his most famous achievements are  the development of classification theory in model theory, his arithmetic cardinal theory (see this post), his proof that Whitehead’s conjecture is independent from ZFC, and his effective bounds for Van der Waerden numbers in combinatorics.\n\nYuri Gurevich is a renowned mathematical logician who transitioned to theoretical and practical computer science, software engineering, and later, quantum computing. One of the most natural average-case complete problems was introduced in a paper by Andreas Blass and Yuri Gurevich. (Andreas and Yuri have been long-time collaborators and friends.) Saharon and Yuri also coauthored a few important papers, including one on monadic second-order theories.\n\nI’ve known both Saharon and Yuri since the late 1970s. Over the years, I would occasionally visit Saharon’s office (and now that I think about it, I should have taken a picture of it) to discuss interesting problems. These conversations contributed to Saharon’s generalization of Arrow’s theorem and to his work with Micha Perles on “n-convexity.” Once, Saharon asked me to comment on an introduction for the general mathematical audience to his second book on classification theory. In 1994, Saharon and I shared the Pólya Prize in Combinatorics. My daughter was a classmate of Saharon’s son, so we also met occasionally at school events.\n\nMy friendship with Yuri began at Microsoft in the late 1990s. As a complete layman, I was fascinated by his approach to software engineering, which had a major impact on Microsoft. Yuri, in turn, was interested in my views on quantum computing—well before he became an active researcher in the field in 2013—and we discussed the topic frequently over the years. We also shared an interest in detecting deception using mathematical tools (see this post by Omer Reingold on his approach).\n\nHeartfelt congratulations to Saharon and Yuri!\n\nRonald de Wolf’s lecture on quantum proofs to classical theorems.\n\nAt YuriFest, Ronald de Wolf gave a great lecture on quantum proofs for classical theorems (the audio is a bit weak—turn the volume to 100%). One of his examples is discussed in this post. Yuri himself gave a wonderful talk titled The nature of nondeterministic probabilistic, quantum, etc. algorithms.\n\nReminder: Joram’s seminar on hypercontractivity and groups, Wednesday and Thursday, July 9 and 10, 2025.\n\nBy Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Approximability of Train Routing and the Min-Max Disjoint Paths",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/",
      "content": "Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch\n\nIn train routing, the headway is the minimum distance that must be maintained\nbetween successive trains for safety and robustness. We introduce a model for\ntrain routing that requires a fixed headway to be maintained between trains,\nand study the problem of minimizing the makespan, i.e., the arrival time of the\nlast train, in a single-source single-sink network. For this problem, we first\nshow that there exists an optimal solution where trains move in convoys, that\nis, the optimal paths for any two trains are either the same or are\narc-disjoint. Via this insight, we are able to reduce the approximability of\nour train routing problem to that of the min-max disjoint paths problem, which\nasks for a collection of disjoint paths where the maximum length of any path in\nthe collection is as small as possible. While min-max disjoint paths inherits a\nstrong inapproximability result on directed acyclic graphs from the multi-level\nbottleneck assignment problem, we show that a natural greedy composition\napproach yields a logarithmic approximation in the number of disjoint paths for\nseries-parallel graphs. We also present an alternative analysis of this\napproach that yields a guarantee depending on how often the decomposition tree\nof the series-parallel graph alternates between series and parallel\ncompositions on any root-leaf path.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Going Beyond Surfaces in Diameter Approximation",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-going-beyond-surfaces-in-diameter-approximation/",
      "content": "Authors: Michał Włodarczyk\n\nCalculating the diameter of an undirected graph requires quadratic running\ntime under the Strong Exponential Time Hypothesis and this barrier works even\nagainst any approximation better than 3/2. For planar graphs with positive edge\nweights, there are known $(1+\\varepsilon)$-approximation algorithms with\nrunning time $poly(1/\\epsilon, \\log n) \\cdot n$. However, these algorithms rely\non shortest path separators and this technique falls short to yield efficient\nalgorithms beyond graphs of bounded genus.\nIn this work we depart from embedding-based arguments and obtain diameter\napproximations relying on VC set systems and the local treewidth property. We\npresent two orthogonal extensions of the planar case by giving\n$(1+\\varepsilon)$-approximation algorithms with the following running times:\n\n  $O_h((1/\\varepsilon)^{O(h)} \\cdot n \\log^2 n)$-time algorithm for graphs\nexcluding an apex graph of size h as a minor,\n  $O_d((1/\\varepsilon)^{O(d)} \\cdot n \\log^2 n)$-time algorithm for the\nclass of d-apex graphs.\nAs a stepping stone, we obtain efficient (1+\\varepsilon)-approximate distance\noracles for graphs excluding an apex graph of size h as a minor. Our oracle has\npreprocessing time $O_h((1/\\varepsilon)^8\\cdot n \\log n \\log W)$ and query time\n$O((1/\\varepsilon)^2 * \\log n \\log W)$, where $W$ is the metric stretch. Such\noracles have been so far only known for bounded genus graphs. All our\nalgorithms are deterministic.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Discovering Algorithms with Computational Language Processing",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-discovering-algorithms-with-computational-language-processing/",
      "content": "Authors: Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai\n\nAlgorithms are the engine for reproducible problem-solving. We present a\nframework automating algorithm discovery by conceptualizing them as sequences\nof operations, represented as tokens. These computational tokens are chained\nusing a grammar, enabling the formation of increasingly sophisticated\nprocedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement\nlearning (RL) explores token chaining and drives the creation of new tokens.\nThis methodology rediscovers, improves, and generates new algorithms that\nsubstantially outperform existing methods for strongly NP-hard combinatorial\noptimization problems and foundational quantum computing approaches such as\nGrover’s and Quantum Approximate Optimization Algorithm. Operating at the\ncomputational rather than code-generation level, our framework produces\nalgorithms that can be tailored specifically to problem instances, not merely\nclasses.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bayesian Optimal Stopping with Maximum Value Knowledge",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-bayesian-optimal-stopping-with-maximum-value-knowledge/",
      "content": "Authors: Pieter Kleer, Daan Noordenbos\n\nWe consider an optimal stopping problem with n correlated offers where the\ngoal is to design a (randomized) stopping strategy that maximizes the expected\nvalue of the offer in the sequence at which we stop. Instead of assuming to\nknow the complete correlation structure, which is unrealistic in practice, we\nonly assume to have knowledge of the distribution of the maximum value of the\nsequence, and want to analyze the worst-case correlation structure whose\nmaximum follows this distribution. This can be seen as a trade-off between the\nsetting in which no distributional information is known, and the Bayesian\nsetting in which the (possibly correlated) distributions of all the individual\noffers are known. As our first main result we show that a deterministic\nthreshold strategy using the monopoly price of the distribution of the maximum\nvalue is asymptotically optimal assuming that the expectation of the maximum\nvalue grows sublinearly in n. In our second main result, we further tighten\nthis bound by deriving a tight quadratic convergence guarantee for sufficiently\nsmooth distributions of the maximum value. Our results also give rise to a more\nfine-grained picture regarding prophet inequalities with correlated values, for\nwhich distribution-free bounds often only yield a performance guarantee that is\nof the order 1/n.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Barvinok's interpolation method meets Weitz's correlation decay approach",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-barvinok-s-interpolation-method-meets-weitz-s-correlation-decay-approach/",
      "content": "Authors: Ferenc Bencs, Guus Regts\n\nIn this paper we take inspiration from Weit’z algorithm for approximating the\nindependence polynomial to provide a new algorithm for computing the\ncoefficients of the Taylor series of the logarithm of the independence\npolynomial. Hereby we provide a clear connections between Barvinok’s\ninterpolation method and Weitz’s algorithm. Our algorithm easily extends to\nother graph polynomials and partition functions and we illustrate this by\napplying it to the chromatic polynomial and to the graph homomorphism partition\nfunction. Our approach arguably yields a simpler and more transparent algorithm\nthan the algorithm of Patel and the second author.\nAs an application of our algorithmic approach we moreover derive, using the\ninterpolation method, a deterministic $O(n(m/\\varepsilon)^{7})$-time algorithm\nthat on input of an $n$-vertex and $m$-edge graph of minimum degree at least\n$3$ and $\\varepsilon&gt;0$ approximately computes the number of sink-free\norientations of $G$ up to a multiplicative $\\exp(\\varepsilon)$ factor.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Quantum Computation with Correlated Measurements: Implications for the",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-quantum-computation-with-correlated-measurements-implications-for-the-complexity-landscape/",
      "content": "Authors: David Miloschewsky, Supartha Podder\n\nIn 2004, Aaronson introduced the complexity class $\\mathsf{PostBQP}$\n($\\mathsf{BQP}$ with postselection) and showed that it is equal to\n$\\mathsf{PP}$. In this paper, we define a new complexity class,\n$\\mathsf{CorrBQP}$, a modification of $\\mathsf{BQP}$ which has the power to\nperform correlated measurements, i.e. measurements that output the same value\nacross a partition of registers. We show that $\\mathsf{CorrBQP}$ is exactly\nequal to $\\mathsf{BPP}^{\\mathsf{PP}}$, placing it “just above” $\\mathsf{PP}$.\nIn fact, we show that other metaphysical modifications of $\\mathsf{BQP}$, such\nas $\\mathsf{CBQP}$ (i.e. $\\mathsf{BQP}$ with the ability to clone arbitrary\nquantum states), are also equal to $\\mathsf{BPP}^{\\mathsf{PP}}$. Furthermore,\nwe show that $\\mathsf{CorrBQP}$ is self-low with respect to classical queries.\nIn contrast, if it were self-low under quantum queries, the counting hierarchy\n($\\mathsf{CH}$) would collapse to $\\mathsf{BPP}^{\\mathsf{PP}}$. Finally, we\nintroduce a variant of rational degree that lower-bounds the query complexity\nof $\\mathsf{BPP}^{\\mathsf{PP}}$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: On the Approximability of Train Routing and the Min-Max Disjoint Paths",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/",
      "content": "Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch\n\nIn train routing, the headway is the minimum distance that must be maintained\nbetween successive trains for safety and robustness. We introduce a model for\ntrain routing that requires a fixed headway to be maintained between trains,\nand study the problem of minimizing the makespan, i.e., the arrival time of the\nlast train, in a single-source single-sink network. For this problem, we first\nshow that there exists an optimal solution where trains move in convoys, that\nis, the optimal paths for any two trains are either the same or are\narc-disjoint. Via this insight, we are able to reduce the approximability of\nour train routing problem to that of the min-max disjoint paths problem, which\nasks for a collection of disjoint paths where the maximum length of any path in\nthe collection is as small as possible. While min-max disjoint paths inherits a\nstrong inapproximability result on directed acyclic graphs from the multi-level\nbottleneck assignment problem, we show that a natural greedy composition\napproach yields a logarithmic approximation in the number of disjoint paths for\nseries-parallel graphs. We also present an alternative analysis of this\napproach that yields a guarantee depending on how often the decomposition tree\nof the series-parallel graph alternates between series and parallel\ncompositions on any root-leaf path.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Complexity of learning matchings and half graphs via edge queries",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-complexity-of-learning-matchings-and-half-graphs-via-edge-queries/",
      "content": "Authors: Nikhil S. Mande, Swagato Sanyal, Viktor Zamaraev\n\nThe problem of learning or reconstructing an unknown graph from a known\nfamily via partial-information queries arises as a mathematical model in\nvarious contexts. The most basic type of access to the graph is via \\emph{edge\nqueries}, where an algorithm may query the presence/absence of an edge between\na pair of vertices of its choosing, at unit cost.\nWhile more powerful query models have been extensively studied in the context\nof graph reconstruction, the basic model of edge queries seems to have not\nattracted as much attention. In this paper we study the edge query complexity\nof learning a hidden bipartite graph, or equivalently its bipartite adjacency\nmatrix, in the classical as well as quantum settings. We focus on learning\nmatchings and half graphs, which are graphs whose bipartite adjacency matrices\nare a row/column permutation of the identity matrix and the lower triangular\nmatrix with all entries on and below the principal diagonal being 1,\nrespectively.\n\\begin{itemize}\n\\item For matchings of size $n$, we show a tight deterministic bound of\n$n(n-1)/2$ and an asymptotically tight randomized bound of $\\Theta(n^2)$. A\nquantum bound of $\\Theta(n^{1.5})$ was shown in a recent work of van Apeldoorn\net al.~[ICALP’21].\n\\item For half graphs whose bipartite adjacency matrix is a\ncolumn-permutation of the $n \\times n$ lower triangular matrix,\nwe give tight $\\Theta(n \\log n)$ bounds in both deterministic and randomized\nsettings, and an $\\Omega(n)$ quantum lower bound. \\item For general half\ngraphs,\nwe observe that the problem is equivalent to a natural generalization of the\nfamous nuts-and-bolts problem, leading to a tight $\\Theta(n \\log n)$ randomized\nbound.\nWe also present a simple quicksort-style method that instantiates to a $O(n\n\\log^2 n)$ randomized algorithm and a tight $O(n \\log n)$ quantum algorithm.\n\\end{itemize}\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Are Depth-2 Regular Expressions Hard to Intersect?",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-are-depth-2-regular-expressions-hard-to-intersect/",
      "content": "Authors: Rocco Ascone, Giulia Bernardini, Alessio Conte, Veronica Guerrini, Giulia Punzi\n\nWe study the basic regular expression intersection testing problem, which\nasks to determine whether the intersection of the languages of two regular\nexpressions is nonempty. A textbook solution to this problem is to construct\nthe nondeterministic finite automaton that accepts the language of both\nexpressions. This procedure results in a $\\Theta(mn)$ running time, where $m$\nand $n$ are the sizes of the two expressions, respectively. Following the\napproach of Backurs and Indyk [FOCS’16] and Bringmann, Gr{\\o}nlund, and Larsen\n[FOCS’17] on regular expression matching and membership testing, we study the\ncomplexity of intersection testing for homogeneous regular expressions of\nbounded depth involving concatenation, OR, Kleene star, and Kleene plus.\nSpecifically, we consider all combinations of types of depth-2 regular\nexpressions and classify the time complexity of intersection testing as either\nlinear or quadratic, assuming SETH. The most interesting result is a quadratic\nconditional lower bound for testing the intersection of a ‘‘concatenation of\n+s’’ expression with a ‘‘concatenation of ORs’’ expression: this is the only\nhard case that does not involve the Kleene star operator and is not implied by\nexisting lower bounds for the simpler membership testing problem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: A Near-Optimal Polynomial Distance Lemma Over Boolean Slices",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-a-near-optimal-polynomial-distance-lemma-over-boolean-slices/",
      "content": "Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan\n\nThe celebrated Ore-DeMillo-Lipton-Schwartz-Zippel (ODLSZ) lemma asserts that\nn-variate non-zero polynomial functions of degree d over a field $\\mathbb{F}$\nare non-zero over any “grid” $S^n$ for finite subset $S \\subseteq \\mathbb{F}$,\nwith probability at least $\\max{|S|^{-d/(|S|-1)},1-d/|S|}$ over the choice of\nrandom point from the grid. In particular, over the Boolean cube ($S = {0,1}\n\\subseteq \\mathbb{F}$), the lemma asserts non-zero polynomials are non-zero\nwith probability at least $2^{-d}$. In this work we extend the ODLSZ lemma\noptimally (up to lower-order terms) to “Boolean slices” i.e., points of Hamming\nweight exactly $k$. We show that non-zero polynomials on the slice are non-zero\nwith probability $(t/n)^{d}(1 - o_{n}(1))$ where $t = \\min{k,n-k}$ for every\n$d\\leq k\\leq (n-d)$. As with the ODLSZ lemma, our results extend to polynomials\nover Abelian groups. This bound is tight (upto the error term) as evidenced by\ndegree d multilinear monomials. A particularly interesting case is the\n“balanced slice” ($k=n/2$) where our lemma asserts that non-zero polynomials\nare non-zero with roughly the same probability on the slice as on the whole\ncube.\nThe behaviour of low-degree polynomials over Boolean slices has received much\nattention in recent years. However, the problem of proving a tight version of\nthe ODLSZ lemma does not seem to have been considered before, except for a\nrecent work of Amireddy, Behera, Paraashar, Srinivasan and Sudan (SODA 2025)\nwho established a sub-optimal bound of approximately $((k/n)\\cdot(1-(k/n)))^d$\nusing a proof similar to that of the standard ODLSZ lemma.\nWhile the statement of our result mimics that of the ODLSZ lemma, our proof\nis significantly more intricate and involves spectral reasoning which is\nemployed to show that a natural way of embedding a copy of the Boolean cube\ninside a balanced Boolean slice is a good sampler.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: The New Lower Bound on Busy Beaver of 6.",
      "url": "/cstheoryrss/2025/07/06/computational-complexity-the-new-lower-bound-on-busy-beaver-of-6/",
      "content": " We denote the busy beaver function by BB.\n\nBB(n) is the max time a Turing machine of size n takes to halt on the empty string.\n\n(A particular model of TM and a notion of size has become standardized.)\n\nBB(n) grows faster than any computable function. That is obviously interesting. What is less obvious (and  some of my co-bloggers disagree) the pursuit of actual values of BB is interesting. For an excellent overview of the BB numbers, written in 2020 (that is relevant) by Scott Aaronson, see here. (Computable and Aaronson are flagged by my spell check but I think they are spelled correctly.)\n\nWhen Scott’s article appeared, BB(5) was not known. In June 2024 the value of BB(5) was discovered.  See Scott’s blog on this, here. The value of BB(5) isn’t even that big- its just 47,176,870. That’s one of those numbers that is SMALL now but would have been LARGE in (say) 1964 (see my blog about a different number of that type here).\n\nWhat about BB(6)?\n\nNo, I am not going to announce that Scott announced it is now known.\n\nI am going to announced that Scott announced better lower bounds for BB(6) are now known.\n\nI won’t restate the lower bounds since (a) Scott already has, and (b) typesetting the bounds is hard (for me).\n\nSO, what to make of all this?\n\n1) At the time of Scott’s article it looked like BB(6) was large. How large was hard to say. Intuitions about how large BB(6) would be are hard to come by, so the new result is neither surprising nor unsurprising.\n\n2) We will never know BB(6). Shucky Darns!\n\n3) Many of the results on BB are not published in refereed journals. However, the ones mentioned in the context of BB(5) and BB(6) were verified in Coq.  I doubt other parts of math could take this approach;  however, it is interesting that results can be verified via computer in this field. Indeed- I doubt  referee could verify the results without a computer aid.\n\n4) Why the interest in BB? Some speculation\n\na) Computing power is such that one can actually get out some results (read Scott’s blog on BB(5) for more on that).\n\nb) The internet: there are not that many people working on BB but those that are can easily communicate with each other.\n\nc) Scott’s article and his blog posts on it helped generate interest. Since I asked Scott to write the article for my open problems column, I get some credit here also (very little).\n\nd) Results generate interest, and interest generates results.\n\ne) Items a,b,c,d,e all help to reinforce each other.\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-088 | Factorization norms and an inverse theorem for MaxCut |",
      "url": "/cstheoryrss/2025/07/06/eccc-papers-tr25-088-factorization-norms-and-an-inverse-theorem-for-maxcut-igor-balla-lianna-hambardzumyan-istvan-tomon/",
      "content": "We prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded normalized trace norm must contain a linear-sized all-ones or all-zeros submatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also present further structural results about Boolean matrices of bounded $\\gamma_2$-norm and discuss applications in communication complexity, operator theory, spectral graph theory, and extremal combinatorics.\nAs a key application, we establish an inverse theorem for MaxCut. A celebrated result of Edwards states that every graph $G$ with $m$ edges has a cut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality achieved by complete graphs with an odd number of vertices. To contrast this, we prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then $G$ must contain a clique of size $\\Omega(\\sqrt{m})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Conformal Prediction with Efficiency Guarantees",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-online-conformal-prediction-with-efficiency-guarantees/",
      "content": "Authors: Vaidehi Srinivas\n\nWe study the problem of conformal prediction in a novel online framework that\ndirectly optimizes efficiency. In our problem, we are given a target\nmiscoverage rate $\\alpha &gt; 0$, and a time horizon $T$. On each day $t \\le T$ an\nalgorithm must output an interval $I_t \\subseteq [0, 1]$, then a point $y_t \\in\n[0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is,\n$y_t \\in I_t$ on (close to) a $(1 - \\alpha)$-fraction of days, while\nmaintaining efficiency, that is, minimizing the average volume (length) of the\nintervals played. This problem is an online analogue to the problem of\nconstructing efficient confidence intervals.\nWe study this problem over arbitrary and exchangeable (random order) input\nsequences. For exchangeable sequences, we show that it is possible to construct\nintervals that achieve coverage $(1 - \\alpha) - o(1)$, while having length\nupper bounded by the best fixed interval that achieves coverage in hindsight.\nFor arbitrary sequences however, we show that any algorithm that achieves a\n$\\mu$-approximation in average length compared to the best fixed interval\nachieving coverage in hindsight, must make a multiplicative factor more\nmistakes than $\\alpha T$, where the multiplicative factor depends on $\\mu$ and\nthe aspect ratio of the problem. Our main algorithmic result is a matching\nalgorithm that can recover all Pareto-optimal settings of $\\mu$ and number of\nmistakes. Furthermore, our algorithm is deterministic and therefore robust to\nan adaptive adversary.\nThis gap between the exchangeable and arbitrary settings is in contrast to\nthe classical online learning problem. In fact, we show that no single\nalgorithm can simultaneously be Pareto-optimal for arbitrary sequences and\noptimal for exchangeable sequences. On the algorithmic side, we give an\nalgorithm that achieves the near-optimal tradeoff between the two cases.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Structure of Replicable Hypothesis Testers",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-structure-of-replicable-hypothesis-testers/",
      "content": "Authors: Anders Aamand, Maryam Aliakbarpour, Justin Y. Chen, Shyam Narayanan, Sandeep Silwal\n\nA hypothesis testing algorithm is replicable if, when run on two different\nsamples from the same distribution, it produces the same output with high\nprobability. This notion, defined by by Impagliazzo, Lei, Pitassi, and Sorell\n[STOC’22], can increase trust in testing procedures and is deeply related to\nalgorithmic stability, generalization, and privacy. We build general tools to\nprove lower and upper bounds on the sample complexity of replicable testers,\nunifying and quantitatively improving upon existing results.\nWe identify a set of canonical properties, and prove that any replicable\ntesting algorithm can be modified to satisfy these properties without worsening\naccuracy or sample complexity. A canonical replicable algorithm computes a\ndeterministic function of its input (i.e., a test statistic) and thresholds\nagainst a uniformly random value in $[0,1]$. It is invariant to the order in\nwhich the samples are received, and, if the testing problem is ``symmetric,’’\nthen the algorithm is also invariant to the labeling of the domain elements,\nresolving an open question by Liu and Ye [NeurIPS’24]. We prove new lower\nbounds for uniformity, identity, and closeness testing by reducing to the case\nwhere the replicable algorithm satisfies these canonical properties.\nWe systematize and improve upon a common strategy for replicable algorithm\ndesign based on test statistics with known expectation and bounded variance.\nOur framework allow testers which have been extensively analyzed in the\nnon-replicable setting to be made replicable with minimal overhead. As direct\napplications of our framework, we obtain constant-factor optimal bounds for\ncoin testing and closeness testing and get replicability for free in a large\nparameter regime for uniformity testing.\nWe also give state-of-the-art bounds for replicable Gaussian mean testing,\nand, unlike prior work, our algorithm runs in polynomial time.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Complexity of Knapsack under Explorable Uncertainty: Hardness and",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-complexity-of-knapsack-under-explorable-uncertainty-hardness-and-algorithms/",
      "content": "Authors: Jens Schlöter\n\nIn the knapsack problem under explorable uncertainty, we are given a knapsack\ninstance with uncertain item profits. Instead of having access to the precise\nprofits, we are only given uncertainty intervals that are guaranteed to contain\nthe corresponding profits. The actual item profit can be obtained via a query.\nThe goal of the problem is to adaptively query item profits until the revealed\ninformation suffices to compute an optimal (or approximate) solution to the\nunderlying knapsack instance. Since queries are costly, the objective is to\nminimize the number of queries.\nIn the offline variant of this problem, we assume knowledge of the precise\nprofits and the task is to compute a query set of minimum cardinality that a\nthird party without access to the profits could use to identify an optimal (or\napproximate) knapsack solution. We show that this offline variant is complete\nfor the second-level of the polynomial hierarchy, i.e., $\\Sigma_2^p$-complete,\nand cannot be approximated within a non-trivial factor unless $\\Sigma_2^p =\n\\Delta_2^p$. Motivated by these strong hardness results, we consider a\nresource-augmented variant of the problem where the requirements on the query\nset computed by an algorithm are less strict than the requirements on the\noptimal solution we compare against. More precisely, a query set computed by\nthe algorithm must reveal sufficient information to identify an approximate\nknapsack solution, while the optimal query set we compare against has to reveal\nsufficient information to identify an optimal solution. We show that this\nresource-augmented setting allows interesting non-trivial algorithmic results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Adversarial Robustness of Online Importance Sampling",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-adversarial-robustness-of-online-importance-sampling/",
      "content": "Authors: Yotam Kenneth-Mordoch, Shay Sapir\n\nThis paper studies the adversarial-robustness of importance-sampling (aka\nsensitivity sampling); a useful algorithmic technique that samples elements\nwith probabilities proportional to some measure of their importance. A\nstreaming or online algorithm is called adversarially-robust if it succeeds\nwith high probability on input streams that may change adaptively depending on\nprevious algorithm outputs. Unfortunately, the dependence between stream\nelements breaks the analysis of most randomized algorithms, and in particular\nthat of importance-sampling algorithms. Previously, Braverman et al. [NeurIPS\n2021] suggested that streaming algorithms based on importance-sampling may be\nadversarially-robust; however, they proved it only for well-behaved inputs.\nWe focus on the adversarial-robustness of online importance-sampling, a\nnatural variant where sampling decisions are irrevocable and made as data\narrives. Our main technical result shows that, given as input an adaptive\nstream of elements $x_1,\\ldots,x_T\\in \\mathbb{R}_+$, online importance-sampling\nmaintains a $(1\\pm\\epsilon)$-approximation of their sum while matching (up to\nlower order terms) the storage guarantees of the oblivious (non-adaptive) case.\nWe then apply this result to develop adversarially-robust online algorithms for\ntwo fundamental problems: hypergraph cut sparsification and $\\ell_p$ subspace\nembedding.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Numerical Linear Algebra in Linear Space",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-numerical-linear-algebra-in-linear-space/",
      "content": "Authors: Yiping Liu, Hoai-An Nguyen, Junzhao Yang\n\nWe present a randomized linear-space solver for general linear systems\n$\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ with $\\mathbf{A} \\in \\mathbb{Z}^{n \\times\nn}$ and $\\mathbf{b} \\in \\mathbb{Z}^n$, without any assumption on the condition\nnumber of $\\mathbf{A}$. For matrices whose entries are bounded by\n$\\mathrm{poly}(n)$, the solver returns a $(1+\\epsilon)$-multiplicative\nentry-wise approximation to vector $\\mathbf{x} \\in \\mathbb{Q}^{n}$ using\n$\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ bit operations and $O(n\n\\log n)$ bits of working space (i.e., linear in the size of a vector), where\n$\\mathrm{nnz}$ denotes the number of nonzero entries. Our solver works for\nright-hand vector $\\mathbf{b}$ with entries up to $n^{O(n)}$. To our knowledge,\nthis is the first linear-space linear system solver over the rationals that\nruns in $\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ time.\nWe also present several applications of our solver to numerical linear\nalgebra problems, for which we provide algorithms with efficient polynomial\nrunning time and near-linear space. In particular, we present results for\nlinear regression, linear programming, eigenvalues and eigenvectors, and\nsingular value decomposition.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: New algorithms for girth and cycle detection",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-new-algorithms-for-girth-and-cycle-detection/",
      "content": "Authors: Liam Roditty, Plia Trabelsi\n\nLet $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$\nedges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in\n$G$. We present a randomized algorithm with a running time of\n$\\tilde{O}\\big(\\ell \\cdot n^{1 + \\frac{1}{\\ell - \\varepsilon}}\\big)$ that\nreturns a cycle of length at most $ 2\\ell \\left\\lceil \\frac{g}{2} \\right\\rceil\n\n  2 \\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil\n\\right\\rfloor, $ where $\\ell \\geq 2$ is an integer and $\\varepsilon \\in [0,1]$,\nfor every graph with $g = polylog(n)$.\nOur algorithm generalizes an algorithm of Kadria \\etal{} [SODA’22] that\ncomputes a cycle of length at most $4\\left\\lceil \\frac{g}{2} \\right\\rceil -\n2\\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil \\right\\rfloor $\nin $\\tilde{O}\\big(n^{1 + \\frac{1}{2 - \\varepsilon}}\\big)$ time. Kadria \\etal{}\npresented also an algorithm that finds a cycle of length at most $ 2\\ell\n\\left\\lceil \\frac{g}{2} \\right\\rceil $ in $\\tilde{O}\\big(n^{1 +\n\\frac{1}{\\ell}}\\big)$ time, where $\\ell$ must be an integer. Our algorithm\ngeneralizes this algorithm, as well, by replacing the integer parameter $\\ell$\nin the running time exponent with a real-valued parameter $\\ell - \\varepsilon$,\nthereby offering greater flexibility in parameter selection and enabling a\nbroader spectrum of combinations between running times and cycle lengths.\nWe also show that for sparse graphs a better tradeoff is possible, by\npresenting an $\\tilde{O}(\\ell\\cdot m^{1+1/(\\ell-\\varepsilon)})$ time randomized\nalgorithm that returns a cycle of length at most $2\\ell(\\lfloor\n\\frac{g-1}{2}\\rfloor) - 2(\\lfloor \\varepsilon \\lfloor \\frac{g-1}{2}\\rfloor\n\\rfloor+1)$, where $\\ell\\geq 3$ is an integer and $\\varepsilon\\in [0,1)$, for\nevery graph with $g=polylog(n)$.\nTo obtain our algorithms we develop several techniques and introduce a formal\ndefinition of hybrid cycle detection algorithms. […]\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Indexing Tries within Entropy-Bounded Space",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-indexing-tries-within-entropy-bounded-space/",
      "content": "Authors: Lorenzo Carfagna, Carlo Tosoni\n\nWe study the problem of indexing and compressing tries using a BWT-based\napproach. Specifically, we consider a succinct and compressed representation of\nthe XBWT of Ferragina et al.\\ [FOCS ‘05, JACM ‘09] corresponding to the\nanalogous of the FM-index [FOCS ‘00, JACM ‘05] for tries. This representation\nallows to efficiently count the number of nodes reached by a given string\npattern. To analyze the space complexity of the above trie index, we propose a\nproof for the combinatorial problem of counting the number of tries with a\ngiven symbol distribution. We use this formula to define a worst-case entropy\nmeasure for tries, as well as a notion of k-th order empirical entropy. In\nparticular, we show that the relationships between these two entropy measures\nare similar to those between the corresponding well-known measures for strings.\nWe use these measures to prove that the XBWT of a trie can be encoded within a\nspace bounded by our k-th order empirical entropy plus a o(n) term, with n\nbeing the number of nodes in the trie. Notably, as happens for strings, this\nspace bound can be reached for every sufficiently small k simultaneously.\nFinally, we compare the space complexity of the above index with that of the\nr-index for tries proposed by Prezza [SODA ‘21] and we prove that in some cases\nthe FM-index for tries is asymptotically smaller.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-faster-algorithm-for-bounded-tree-edit-distance-in-the-low-distance-regime/",
      "content": "Authors: Tomasz Kociumaka, Ali Shahali\n\nThe tree edit distance is a natural dissimilarity measure between rooted\nordered trees whose nodes are labeled over an alphabet $\\Sigma$. It is defined\nas the minimum number of node edits (insertions, deletions, and relabelings)\nrequired to transform one tree into the other. In the weighted variant, the\nedits have associated costs (depending on the involved node labels) normalized\nso that each cost is at least one, and the goal is to minimize the total cost\nof edits.\nThe unweighted tree edit distance between two trees of total size $n$ can be\ncomputed in $O(n^{2.6857})$ time; in contrast, determining the weighted tree\nedit distance is fine-grained equivalent to the All-Pairs Shortest Paths\nproblem and requires $n^3/2^{\\Omega(\\sqrt{\\log n})}$ time [Nogler et al.;\nSTOC’25]. These super-quadratic running times are unattractive for large but\nvery similar trees, which motivates the bounded version of the problem, where\nthe runtime is parameterized by the computed distance $k$, potentially yielding\nfaster algorithms for $k\\ll n$.\nPrevious best algorithms for the bounded unweighted setting run in\n$O(nk^2\\log n)$ time [Akmal &amp; Jin; ICALP’21] and $O(n + k^7\\log k)$ time [Das\net al.; STOC’23]. For the weighted variant, the only known running time has\nbeen $O(n + k^{15})$.\nWe present an $O(n + k^6\\log k)$-time algorithm for computing the bounded\ntree edit distance in both the weighted and unweighted settings. Our approach\nbegins with an alternative $O(nk^2\\log n)$-time algorithm that handles weights\nand is significantly easier to analyze than the existing counterpart. We then\nintroduce a novel optimization that leverages periodic structures within the\ninput trees. To utilize it, we modify the $O(k^5)$-size $O(n)$-time universal\nkernel, the central component of the prior $O(n + k^{O(1)})$-time algorithms,\nso that it produces instances containing these periodic structures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Connected k-Median with Disjoint and Non-disjoint Clusters",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-connected-k-median-with-disjoint-and-non-disjoint-clusters/",
      "content": "Authors: Jan Eube, Kelin Luo, Dorian Reineccius, Heiko Röglin, Melanie Schmidt\n\nThe connected $k$-median problem is a constrained clustering problem that\ncombines distance-based $k$-clustering with connectivity information. The\nproblem allows to input a metric space and an unweighted undirected\nconnectivity graph that is completely unrelated to the metric space. The goal\nis to compute $k$ centers and corresponding clusters such that each cluster\nforms a connected subgraph of $G$, and such that the $k$-median cost is\nminimized.\nThe problem has applications in very different fields like geodesy\n(particularly districting), social network analysis (especially community\ndetection), or bioinformatics. We study a version with overlapping clusters\nwhere points can be part of multiple clusters which is natural for the use case\nof community detection. This problem variant is $\\Omega(\\log n)$-hard to\napproximate, and our main result is an $\\mathcal{O}(k^2 \\log n)$-approximation\nalgorithm for the problem. We complement it with an\n$\\Omega(n^{1-\\epsilon})$-hardness result for the case of disjoint clusters\nwithout overlap with general connectivity graphs, as well as an exact algorithm\nin this setting if the connectivity graph is a tree.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-bounded-weighted-edit-distance-dynamic-algorithms-and-matching-lower-bounds/",
      "content": "Authors: Itai Boneh, Egor Gorbachev, Tomasz Kociumaka\n\nThe edit distance $ed(X,Y)$ of two strings $X,Y\\in \\Sigma^*$ is the minimum\nnumber of character edits (insertions, deletions, and substitutions) needed to\ntransform $X$ into $Y$. Its weighted counterpart $ed^w(X,Y)$ minimizes the\ntotal cost of edits, which are specified using a function $w$, normalized so\nthat each edit costs at least one. The textbook dynamic-programming procedure,\ngiven strings $X,Y\\in \\Sigma^{\\le n}$ and oracle access to $w$, computes\n$ed^w(X,Y)$ in $O(n^2)$ time. Nevertheless, one can achieve better running\ntimes if the computed distance, denoted $k$, is small: $O(n+k^2)$ for unit\nweights [Landau and Vishkin; JCSS’88] and $\\tilde{O}(n+\\sqrt{nk^3})$ for\narbitrary weights [Cassis, Kociumaka, Wellnitz; FOCS’23].\nIn this paper, we study the dynamic version of the weighted edit distance\nproblem, where the goal is to maintain $ed^w(X,Y)$ for strings $X,Y\\in\n\\Sigma^{\\le n}$ that change over time, with each update specified as an edit in\n$X$ or $Y$. Very recently, Gorbachev and Kociumaka [STOC’25] showed that the\nunweighted distance $ed(X,Y)$ can be maintained in $\\tilde{O}(k)$ time per\nupdate after $\\tilde{O}(n+k^2)$-time preprocessing; here, $k$ denotes the\ncurrent value of $ed(X,Y)$. Their algorithm generalizes to small integer\nweights, but the underlying approach is incompatible with large weights.\nOur main result is a dynamic algorithm that maintains $ed^w(X,Y)$ in\n$\\tilde{O}(k^{3-\\gamma})$ time per update after $\\tilde{O}(nk^\\gamma)$-time\npreprocessing. Here, $\\gamma\\in [0,1]$ is a real trade-off parameter and $k\\ge\n1$ is an integer threshold fixed at preprocessing time, with $\\infty$ returned\nwhenever $ed^w(X,Y)&gt;k$. We complement our algorithm with conditional lower\nbounds showing fine-grained optimality of our trade-off for $\\gamma \\in\n[0.5,1)$ and justifying our choice to fix $k$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Easy Proof of a Weak Version of Chernoff inequality",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-an-easy-proof-of-a-weak-version-of-chernoff-inequality/",
      "content": "Authors: Sariel Har-Peled\n\nWe prove an easy but very weak version of Chernoff inequality. Namely, that\nthe probability that in $6M$ throws of a fair coin, one gets at most $M$ heads\nis $\\leq 1/2^M$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Computational Proof of the Highest-Scoring Boggle Board",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-a-computational-proof-of-the-highest-scoring-boggle-board/",
      "content": "Authors: Dan Vanderkam\n\nFinding all the words on a Boggle board is a classic computer programming\nproblem. With a fast Boggle solver, local optimization techniques such as\nhillclimbing and simulated annealing can be used to find particularly\nhigh-scoring boards. The sheer number of possible Boggle boards has\nhistorically prevented an exhaustive search for the global optimum board. We\napply Branch and Bound and a decision diagram-like data structure to perform\nthe first such search. We find that the highest-scoring boards found via\nhillclimbing are, in fact, the global optima.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Linear Time Algorithm for Finding Minimum Flip Sequences between Plane",
      "url": "/cstheoryrss/2025/07/04/arxiv-computational-geometry-a-linear-time-algorithm-for-finding-minimum-flip-sequences-between-plane-spanning-paths-in-convex-point-sets/",
      "content": "Authors: Oswin Aichholzer, Joseph Dorfer\n\nWe provide a linear time algorithm to determine the flip distance between two\nplane spanning paths on a point set in convex position. At the same time, we\nshow that the happy edge property does not hold in this setting. This has to be\nseen in contrast to several results for reconfiguration problems where the\nabsence of the happy edge property implies algorithmic hardness of the flip\ndistance problem. Further, we show that our algorithm can be adapted for (1)\ncompatible flips (2) local flips and (3) flips for plane spanning paths in\nsimple polygons.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Stiefel optimization is NP-hard",
      "url": "/cstheoryrss/2025/07/04/arxiv-computational-complexity-stiefel-optimization-is-np-hard/",
      "content": "Authors: Zehua Lai, Lek-Heng Lim, Tianyun Tang\n\nWe show that linearly constrained linear optimization over a Stiefel or\nGrassmann manifold is NP-hard in general. We show that the same is true for\nunconstrained quadratic optimization over a Stiefel manifold. We will establish\nthe nonexistence of FPTAS for these optimization problems over a Stiefel\nmanifold. As an aside we extend our results to flag manifolds. Combined with\nearlier findings, this shows that manifold optimization is a difficult endeavor\n– even the simplest problems like LP and unconstrained QP are already NP-hard\non the most common manifolds.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Standard error of what now?",
      "url": "/cstheoryrss/2025/07/03/ben-recht-standard-error-of-what-now/",
      "content": "\n\nScrolling through discourse about the evil vector, I stumbled across a group of people dismayed that the papers they were reviewing for NeurIPS didn’t include proper error bars. In fact, I learned that there’s a checklist that authors must fill out and attach to every NeurIPS submission. You can still learn things on social media.\n\nThe NeurIPS program chairs introduced the checklist in 2021. They argued that the community wanted “both more guidance around how to perform machine learning research responsibly and more flexibility in how they discuss this in their papers.” They came to this conclusion after listening at the “NeurIPS 2020 broader impacts workshop,” a fully remote workshop held during the cold, dark winter of the second wave of the covid pandemic. They argued that they would experiment with a checklist as a way to facilitate more responsible machine learning.\n\nThey called the checklist “experimental,” though there is no control group.1 They hoped that “future Program Chairs will continue to improve and evolve the checklist in subsequent years.” You don’t have to be a bureaucracy scholar to know that checklists “improve and evolve” by metastasizing in length and complexity. And that’s precisely what we’ve seen.\n\nThe NeurIPS paper checklist is now 3800 words long. This is twice as long as the original checklist, and has 3 times as many items to check off. It’s a lot of ridiculous infantilizing boilerplate. Item 1: “Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?” Come on, folks. You are required to check that you have read the code of ethics (another 2000 words here). You are asked to check whether you obtained the appropriate IRB approvals. Of course, this only applies if you are at a university. There’s a call out to the AI Safety dorks: “Do you have safeguards in place for responsible release of models with a high risk for misuse (e.g., pretrained language models)?” Come on, folks!\n\nBut I’m particularly fascinated by the weird obsession with statistics. I imagine Leo Breiman is chuckling up in heaven that one of the two cultures is trying to strangle the more successful one.2 In 2021, there was a single line about statistics:\n\n\n  2021: Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?\n\n\nHonestly, not the worst question in the world. So much of machine learning and AI is based on randomized algorithms, and it’s good to check whether you have a stable result (i.e., training a neural net for classification) or a wildly variable result (i.e., using reinforcement learning to game a robotics simulator). But someone on the steering committee decided we needed a longer rule set and more statistics. The statistics creep began in 2023:\n\n\n  2023: If you ran experiments, did you report error bars (e.g., with respect to the random seed after running experiments multiple times), or other information about the statistical significance of your experiments?\n\n\nAnd eventually, due to some unknown person’s lobbying, these were expanded further in 2024:\n\n\n  2024: “The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.). The assumptions made should be given (e.g., Normally distributed errors). It should be clear whether the error bar is the standard deviation or the standard error of the mean. It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). If error bars are reported in tables or plots, the authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.”\n\n\nWhat does this have to do with anything? If I run my code ten times, why should you care if I properly account for normal approximations? Who does this help?\n\nAnyway, I love that NeurIPS is proving my central thesis about statistics: Statistics is a bunch of arbitrary rules we use for approval. These arbitrary rules have now found their way into the machine learning publication machine. Whereas I understand why we require statistical tests when approving pharmaceuticals, no one has provided an explanation for why (or if) these statistical guidelines improve the quality of the thirty thousand NeurIPS submissions.\n\nIndeed, I can’t figure out why people have become so obsessed with error bars in machine learning. I have been told that it’s because data sets are “small” now. For example, some of the “can LLM solve human tests” data sets have a few dozen questions. The AIME benchmark has 15. But what do frequentist error bars buy you here? This isn’t like Fisher’s friend who tastes tea. If a machine can solve a single one of these problems, it’s interesting! LLM answers are variable by design. Trying to gauge this variability with “Gaussian approximations to the standard errors of the mean” misses the forest for the trees. Indeed, if you only have 15 questions in a dataset, you don’t need statistics. Just look at the answers! We’re not grading the LLM on a curve here.\n\nThe obsession with statistics is particularly ironic because the advances in machine learning from the past 15 years have been entirely based on optimaxxing vibes. While program committees and responsible ethics boards fixate on procedure, the big ideas have come from “this feels right,” whether they be bigger convnets, ADAM optimizers, attention mechanisms, or anything in RL. Do you think recent trends in transformer architectures like using RMSNorm instead of Layernorm or SwiGLU instead of ReLU are undergirded by deep statistical grounding?3\n\nWhat gives away the whole checklist charade here is bullet 4. The rules say that you must disclose the normal approximations in your error bars, but you don’t have to release code.\n\n\n  “While NeurIPS does not require releasing code, we do require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution.“\n\n\nWhy no code? It’s because a substantial fraction of NeurIPS papers come from private companies. The biggest models come from private companies. The conference exists to enrich Sam Altman. There’s no recruiting fair, no late-night parties, no signing bonuses based on Google Scholar profiles without the corporate commitment. So we can pat ourselves on the back and tell ourselves we’re being responsible researchers as we fill out our checklists and format our error bars. But let’s not kid ourselves about what we’re participating in.\n\nSubscribe now\n\n1\n\nI couldn’t find the preregistration plan.\n\n2\n\nThere is still no statistically significant evidence to support the existence of heaven.\n\n3\n\nLike you, I don’t know what any of these things are.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: SPARSE-PIVOT: Dynamic correlation clustering for node insertions",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-sparse-pivot-dynamic-correlation-clustering-for-node-insertions/",
      "content": "Authors: Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrović\n\nWe present a new Correlation Clustering algorithm for a dynamic setting where\nnodes are added one at a time. In this model, proposed by Cohen-Addad,\nLattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database\nqueries to access the input graph and updates the clustering as each new node\nis added. Our algorithm has the amortized update time of\n$O_{\\epsilon}(\\log^{O(1)}(n))$. Its approximation factor is $20+\\varepsilon$,\nwhich is a substantial improvement over the approximation factor of the\nalgorithm by Cohen-Addad et al. We complement our theoretical findings by\nempirically evaluating the approximation guarantee of our algorithm. The\nresults show that it outperforms the algorithm by Cohen-Addad et al.~in\npractice.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Optimal Dispersion Under Asynchrony",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-optimal-dispersion-under-asynchrony/",
      "content": "Authors: Debasish Pattanayak, Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma\n\nWe study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\nThe goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA’25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\nIn this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Algorithm for Second s,t-mincut and Breaking Quadratic barrier",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-faster-algorithm-for-second-s-t-mincut-and-breaking-quadratic-barrier-for-dual-edge-sensitivity-for-s-t-mincut/",
      "content": "Authors: Surender Baswana, Koustav Bhanja, Anupam Roy\n\nWe study (s,t)-cuts of second minimum capacity and present the following\nalgorithmic and graph-theoretic results.\n\n  Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for\ncomputing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum\n(s,t)-flow computations. For directed integer-weighted graphs, we significantly\nimprove this bound by designing an algorithm that computes an $(s,t)$-cut of\nsecond minimum capacity using $O(\\sqrt{n})$ maximum (s,t)-flow computations\nw.h.p. To achieve this result, a close relationship of independent interest is\nestablished between $(s,t)$-cuts of second minimum capacity and global mincuts\nin directed weighted graphs.\n  Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana,\nBhanja, and Pandey, ICALP 2022], which is a special case of second\n(s,t)-mincut.\n(a) For directed multi-graphs, we design an algorithm that, given any maximum\n(s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.\n(b) The existing structures for storing and characterizing all minimum+1\n(s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG\noccupying only $O(m)$ space that stores and characterizes all minimum+1\n(s,t)-cuts.\n  The study of minimum+1 (s,t)-cuts often turns out to be useful in\ndesigning dual edge sensitivity oracles – a compact data structure for\nefficiently reporting an (s,t)-mincut after insertion/failure of any given pair\nof query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual\nedge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy\n${\\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For\nsimple graphs, we break this quadratic barrier while achieving a non-trivial\nquery time.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Dynamic Similarity Graph Construction with Kernel Density Estimation",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-dynamic-similarity-graph-construction-with-kernel-density-estimation/",
      "content": "Authors: Steinar Laenen, Peter Macgregor, He Sun\n\nIn the kernel density estimation (KDE) problem, we are given a set $X$ of\ndata points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in\n\\mathbb{R}^d$, and the objective is to quickly output an estimate of\n$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider\n$\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that\nefficiently maintains the estimates for a set of query points as data points\nare added to $X$ over time. Based on this, we design a dynamic data structure\nthat maintains a sparse approximation of the fully connected similarity graph\non $X$, and develop a fast dynamic spectral clustering algorithm. We further\nevaluate the effectiveness of our algorithms on both synthetic and real-world\ndatasets.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Breaking the n{1.5} Additive Error Barrier for Private and Efficient",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-breaking-the-n-1-5-additive-error-barrier-for-private-and-efficient-graph-sparsification-via-private-expander-decomposition/",
      "content": "Authors: Anders Aamand, Justin Y. Chen, Mina Dalirrooyfard, Slobodan Mitrović, Yuriy Nevmyvaka, Sandeep Silwal, Yinzhan Xu\n\nWe study differentially private algorithms for graph cut sparsification, a\nfundamental problem in algorithms, privacy, and machine learning. While\nsignificant progress has been made, the best-known private and efficient cut\nsparsifiers on $n$-node graphs approximate each cut within\n$\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for\nany $\\gamma &gt; 0$ [Gupta, Roth, Ullman TCC’12]. In contrast, “inefficient”\nalgorithms, i.e., those requiring exponential time, can achieve an\n$\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error\n[Eli{'a}{\\v{s}}, Kapralov, Kulkarni, Lee SODA’20]. In this work, we break the\n$n^{1.5}$ additive error barrier for private and efficient cut sparsification.\nWe present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a\nnon-negative weighted graph, outputs a private synthetic graph approximating\nall cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 +\no(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$).\nAt the heart of our approach lies a private algorithm for expander\ndecomposition, a popular and powerful technique in (non-private) graph\nalgorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Deterministic Partition Tree and Applications",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-a-deterministic-partition-tree-and-applications/",
      "content": "Authors: Haitao Wang\n\nIn this paper, we present a deterministic variant of Chan’s randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan’s original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Search-Based Robot Motion Planning With Distance-Based Adaptive Motion",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-search-based-robot-motion-planning-with-distance-based-adaptive-motion-primitives/",
      "content": "Authors: Benjamin Kraljusic, Zlatan Ajanovic, Nermin Covic, Bakir Lacevic\n\nThis work proposes a motion planning algorithm for robotic manipulators that\ncombines sampling-based and search-based planning methods. The core\ncontribution of the proposed approach is the usage of burs of free\nconfiguration space (C-space) as adaptive motion primitives within the graph\nsearch algorithm. Due to their feature to adaptively expand in free C-space,\nburs enable more efficient exploration of the configuration space compared to\nfixed-sized motion primitives, significantly reducing the time to find a valid\npath and the number of required expansions. The algorithm is implemented within\nthe existing SMPL (Search-Based Motion Planning Library) library and evaluated\nthrough a series of different scenarios involving manipulators with varying\nnumber of degrees-of-freedom (DoF) and environment complexity. Results\ndemonstrate that the bur-based approach outperforms fixed-primitive planning in\ncomplex scenarios, particularly for high DoF manipulators, while achieving\ncomparable performance in simpler scenarios.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Multiple Watchman Routes in Staircase Polygons",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-multiple-watchman-routes-in-staircase-polygons/",
      "content": "Authors: Anna Brötzner, Bengt J. Nilsson, Christiane Schmidt\n\nWe consider the watchman route problem for multiple watchmen in staircase\npolygons, which are rectilinear $x$- and $y$-monotone polygons. For two\nwatchmen, we propose an algorithm to find an optimal solution that takes\nquadratic time, improving on the cubic time of a trivial solution. For $m \\geq\n3$ watchmen, we explain where this approach fails, and present an approximation\nalgorithm for the min-max criterion with only an additive error.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Stable and Theoretically Grounded Gromov-Wasserstein Distance for Reeb",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-stable-and-theoretically-grounded-gromov-wasserstein-distance-for-reeb-graph-comparison-using-persistence-images/",
      "content": "Authors: Erin W. Chambers, Guangyu Meng\n\nReeb graphs are a fundamental structure for analyzing the topological and\ngeometric properties of scalar fields. Comparing Reeb graphs is crucial for\nadvancing research in this domain, yet existing metrics are often\ncomputationally prohibitive or fail to capture essential topological features\neffectively. In this paper, we explore the application of the\nGromov-Wasserstein distance, a versatile metric for comparing metric measure\nspaces, to Reeb graphs. We propose a framework integrating a symmetric variant\nof the Reeb radius for robust geometric comparison, and a novel probabilistic\nweighting scheme based on Persistence Images derived from extended persistence\ndiagrams to effectively incorporate topological significance. A key\ncontribution of this work is the rigorous theoretical proof of the stability of\nour proposed Reeb Gromov-Wasserstein distance with respect to perturbations in\nthe underlying scalar fields. This ensures that small changes in the input data\nlead to small changes in the computed distance between Reeb graphs, a critical\nproperty for reliable analysis. We demonstrate the advantages of our approach,\nincluding its enhanced ability to capture topological features and its proven\nstability, through comparisons with other alternatives on several datasets,\nshowcasing its practical utility and theoretical soundness.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Deterministic Partition Tree and Applications",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-deterministic-partition-tree-and-applications/",
      "content": "Authors: Haitao Wang\n\nIn this paper, we present a deterministic variant of Chan’s randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan’s original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Symport/Antiport P Systems with Membrane Separation Characterize P#P",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-symport-antiport-p-systems-with-membrane-separation-characterize-p-p/",
      "content": "Authors: Vivien Ducros, Claudio Zandron\n\nMembrane systems represent a computational model that operates in a\ndistributed and parallel manner, inspired by the behavior of biological cells.\nThese systems feature objects that transform within a nested membrane\nstructure. This research concentrates on a specific type of these systems,\nbased on cellular symport/antiport communication of chemicals.\nResults in the literature show that systems of this type that also allow cell\ndivision can solve PSPACE problems. In our study, we investigate systems that\nuse membrane separation instead of cell division, for which only limited\nresults are available. Notably, it has been shown that any problem solvable by\nsuch systems in polynomial time falls within the complexity class P^(#P).\nBy implementing a system solving MIDSAT, a P^(#P)-complete problem, we\ndemonstrate that the reverse inclusion is true as well, thus providing an exact\ncharacterization of the problem class solvable by P systems with\nsymport/antiport and membrane separation.\nMoreover, our implementation uses rules of length at most three. With this\nlimit, systems were known to be able to solve NP-complete problems, whereas\nlimiting the rules by length two, they characterize P.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: PCPP-Based Reconfiguration Inapproximability: Query Complexity vs.",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-pcpp-based-reconfiguration-inapproximability-query-complexity-vs-soundness-gap-trade-offs/",
      "content": "Authors: Venkatesan Guruswami, Xuandi Ren, Kewen Wu\n\nThe Reconfiguration Inapproximability Hypothesis (RIH), recently established\nby Hirahara-Ohsaka (STOC’24) and Karthik-Manurangsi (ECCC’24), studies the\nhardness of reconfiguring one solution into another in constraint satisfaction\nproblems (CSP) when restricted to approximate intermediate solutions. In this\nwork, we make a tighter connection between RIH’s soundness gap and that of\nprobabilistically checkable proofs of proximity (PCPP). Consequently, we\nachieve an improved trade-off between soundness and query complexity in Gap CSP\nReconfiguration. Our approach leverages a parallelization framework, which also\nappears in some recent parameterized inapproximability results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Hardness of Quantum Distribution Learning and Quantum Cryptography",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-hardness-of-quantum-distribution-learning-and-quantum-cryptography/",
      "content": "Authors: Taiga Hiroka, Min-Hsiu Hsieh, Tomoyuki Morimae\n\nThe existence of one-way functions (OWFs) forms the minimal assumption in\nclassical cryptography. However, this is not necessarily the case in quantum\ncryptography. One-way puzzles (OWPuzzs), introduced by Khurana and Tomer,\nprovide a natural quantum analogue of OWFs. The existence of OWPuzzs implies\n$PP\\neq BQP$, while the converse remains open. In classical cryptography, the\nanalogous problem-whether OWFs can be constructed from $P \\neq NP$-has long\nbeen studied from the viewpoint of hardness of learning. Hardness of learning\nin various frameworks (including PAC learning) has been connected to OWFs or to\n$P \\neq NP$. In contrast, no such characterization previously existed for\nOWPuzzs. In this paper, we establish the first complete characterization of\nOWPuzzs based on the hardness of a well-studied learning model: distribution\nlearning. Specifically, we prove that OWPuzzs exist if and only if proper\nquantum distribution learning is hard on average. A natural question that\nfollows is whether the worst-case hardness of proper quantum distribution\nlearning can be derived from $PP \\neq BQP$. If so, and a worst-case to\naverage-case hardness reduction is achieved, it would imply OWPuzzs solely from\n$PP \\neq BQP$. However, we show that this would be extremely difficult: if\nworst-case hardness is PP-hard (in a black-box reduction), then $SampBQP \\neq\nSampBPP$ follows from the infiniteness of the polynomial hierarchy. Despite\nthat, we show that $PP \\neq BQP$ is equivalent to another standard notion of\nhardness of learning: agnostic. We prove that $PP \\neq BQP$ if and only if\nagnostic quantum distribution learning with respect to KL divergence is hard.\nAs a byproduct, we show that hardness of agnostic quantum distribution learning\nwith respect to statistical distance against $PPT^{\\Sigma_3^P}$ learners\nimplies $SampBQP \\neq SampBPP$.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: A Professor Again",
      "url": "/cstheoryrss/2025/07/02/computational-complexity-a-professor-again/",
      "content": "A new dean has taken my place, and I have returned to the professoriate at Illinois Tech, ending thirteen years in administration, six as dean and seven as department chair at Georgia Tech. I won’t rule out more administrative roles in the future, but only if the right role presents itself.\n\nI’ll teach intro theory in the fall, my first course since 2018, and take a sabbatical in the spring, mostly at Oxford. I plan to focus on writing, hoping to get out another book or books and other projects. It will be hard to go back to traditional computational complexity research, the field has changed considerably. I plan to spend some time understanding how AI changes the way we think about computation. Particularly why we see many of the benefits of P = NP while cryptography remains secure.\n\nAlso for the first time in 13 years I don’t have a “boss”. Technically I report to the department chair, who until a few days ago reported to me. But tenure protects my job, I choose my own research agenda, and teaching and service assignments are more of a negotiation than a top-down decision. Freedom!\n\nFor the blog, I have held back talking about the inner workings of universities while I had administrative roles. I’ll now be more open in giving my thoughts, at least in general terms.\n\nThe next chapter begins…\n\nBy Lance Fortnow\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Some Events",
      "url": "/cstheoryrss/2025/07/02/gil-kalai-some-events/",
      "content": "Annual meeting of the Israeli Mathematical Union and student talks day, July 6 and 7\n\nThe Annual meeting of the Israeli Mathematical Union will be held on Sunday, July 6th 2025 at Bar-Ilan University. The main speakers will be Elon Lindenstrauss, Amnon Shashua and  the 2025 Erdos Prize recipients Or Hershkovits and Eliran Subag. There will also be ten parallel sessions. The IMU student talks day 2025 will be held on Monday, July 7 at the same location. The Day will feature Plenary talks by the Wolf Prize laureate Noga Alon and Adi Shamir (see this post), and  the Nesiyahu prize recepient Pazit Haim-Kislev (see this post) and contributed talks by thirty one graduate students (program).\n\nJoram’s Seminar: Hypercontractivity and Groups, July 9 and 10\n\nThe Joram Seminar new dates are July 9-10.\nThis year the topic will be “Hypercontractivity and Groups”, and the speakers are Noam Lifshitz and Guy Kindler (Hebrew University), Nathan Keller (Bar Ilan University) and Dor Minzer (MIT). For information on hypercontractivity see this post and this post.\n\nAmitsur Memorial Symposum 2025, July 14\n\nThe symposium this year is in memoriam of Ilya (Eliyahu) Rips.\n\nBy Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum Speedups for Polynomial-Time Dynamic Programming Algorithms",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-quantum-speedups-for-polynomial-time-dynamic-programming-algorithms/",
      "content": "Authors: Susanna Caroppo, Giordano Da Lozzo, Giuseppe Di Battista, Michael T. Goodrich, Martin Nöllenburg\n\nWe introduce a quantum dynamic programming framework that allows us to\ndirectly extend to the quantum realm a large body of classical dynamic\nprogramming algorithms. The corresponding quantum dynamic programming\nalgorithms retain the same space complexity as their classical counterpart,\nwhile achieving a computational speedup. For a combinatorial (search or\noptimization) problem $\\mathcal P$ and an instance $I$ of $\\mathcal P$, such a\nspeedup can be expressed in terms of the average degree $\\delta$ of the\ndependency digraph $G_{\\mathcal{P}}(I)$ of $I$, determined by a recursive\nformulation of $\\mathcal P$. The nodes of this graph are the subproblems of\n$\\mathcal P$ induced by $I$ and its arcs are directed from each subproblem to\nthose on whose solution it relies. In particular, our framework allows us to\nsolve the considered problems in $\\tilde{O}(|V(G_{\\mathcal{P}}(I))|\n\\sqrt{\\delta})$ time. As an example, we obtain a quantum version of the\nBellman-Ford algorithm for computing shortest paths from a single source vertex\nto all the other vertices in a weighted $n$-vertex digraph with $m$ edges that\nruns in $\\tilde{O}(n\\sqrt{nm})$ time, which improves the best known classical\nupper bound when $m \\in \\Omega(n^{1.4})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the InApproximability of the Monitoring Edge Geodetic Set Problem",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-on-the-in-approximability-of-the-monitoring-edge-geodetic-set-problem/",
      "content": "Authors: Davide Bilò, Giodano Colli, Luca Forlizzi, Stefano Leucci\n\nWe study the minimum \\emph{Monitoring Edge Geodetic Set} (\\megset) problem\nintroduced in [Foucaud et al., CALDAM’23]: given a graph $G$, we say that an\nedge is monitored by a pair $u,v$ of vertices if \\emph{all} shortest paths\nbetween $u$ and $v$ traverse $e$; the goal of the problem consists in finding a\nsubset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at\nleast one pair of vertices in $M$, and $|M|$ is minimized.\nIn this paper, we prove that all polynomial-time approximation algorithms for\nthe minimum \\megset problem must have an approximation ratio of $\\Omega(\\log\nn)$, unless \\p = \\np. To the best of our knowledge, this is the first\nnon-constant inapproximability result known for this problem. We also\nstrengthen the known \\np-hardness of the problem on $2$-apex graphs by showing\nthat the same result holds for $1$-apex graphs. This leaves open the problem of\ndetermining whether the problem remains \\np-hard on planar (i.e., $0$-apex)\ngraphs.\nOn the positive side, we design an algorithm that computes good approximate\nsolutions for hereditary graph classes that admit efficiently computable\nbalanced separators of truly sublinear size. This immediately results in\npolynomial-time approximation algorithms achieving an approximation ratio of\n$O(n^{\\frac{1}{4}} \\sqrt{\\log n})$ on planar graphs, graphs with bounded genus,\nand $k$-apex graphs with $k=O(n^{\\frac{1}{4}})$. On graphs with bounded\ntreewidth, we obtain an approximation ratio of $O(\\log^{3/2} n)$ for any\nconstant $\\varepsilon &gt; 0$. This compares favorably with the best-known\napproximation algorithm for general graphs, which achieves an approximation\nratio of $O(\\sqrt{n \\log n})$ via a simple reduction to the \\textsc{Set Cover}\nproblem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Lazy B-Trees",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-lazy-b-trees/",
      "content": "Authors: Casper Moldrup Rysgaard, Sebastian Wild\n\nLazy search trees (Sandlund &amp; Wild FOCS 2020, Sandlund &amp; Zhang SODA 2022) are\nsorted dictionaries whose update and query performance smoothly interpolates\nbetween that of efficient priority queues and binary search trees -\nautomatically, depending on actual use; no adjustments are necessary to the\ndata structure to realize the cost savings. In this paper, we design lazy\nB-trees, a variant of lazy search trees suitable for external memory that\ngeneralizes the speedup of B-trees over binary search trees wrt. input/output\noperations to the same smooth interpolation regime.\nA key technical difficulty to overcome is the lack of a (fully satisfactory)\nexternal variant of biased search trees, on which lazy search trees crucially\nrely. We give a construction for a subset of performance guarantees sufficient\nto realize external-memory lazy search trees, which we deem of independent\ninterest.\nAs one special case, lazy B-trees can be used as an external-memory priority\nqueue, in which case they are competitive with some tailor-made heaps; indeed,\nthey offer faster decrease-key and insert operations than known data\nstructures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Hamiltonicity Parameterized by Mim-Width is Indeed Para-NP-Hard",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-hamiltonicity-parameterized-by-mim-width-is-indeed-para-np-hard/",
      "content": "Authors: Benjamin Bergougnoux, Lars Jaffke\n\nWe prove that Hamiltonian Path and Hamiltonian Cycle are NP-hard on graphs of\nlinear mim-width 26, even when a linear order of the input graph with mim-width\n26 is provided together with input. This fills a gap left by a broken proof of\nthe para-NP-hardness of Hamiltonicity problems parameterized by mim-width.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Best Agent Identification for General Game Playing",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-best-agent-identification-for-general-game-playing/",
      "content": "Authors: Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers\n\nWe present an efficient and generalised procedure to accurately identify the\nbest performing algorithm for each sub-task in a multi-problem domain. Our\napproach treats this as a set of best arm identification problems for\nmulti-armed bandits, where each bandit corresponds to a specific task and each\narm corresponds to a specific algorithm or agent. We propose an optimistic\nselection process based on the Wilson score interval (Optimistic-WS) that ranks\neach arm across all bandits in terms of their potential regret reduction. We\nevaluate the performance of Optimistic-WS on two of the most popular general\ngame domains, the General Video Game AI (GVGAI) framework and the Ludii general\ngame playing system, with the goal of identifying the highest performing agent\nfor each game within a limited number of trials. Compared to previous best arm\nidentification algorithms for multi-armed bandits, our results demonstrate a\nsubstantial performance improvement in terms of average simple regret. This\nnovel approach can be used to significantly improve the quality and accuracy of\nagent evaluation procedures for general game frameworks, as well as other\nmulti-task domains with high algorithm runtimes.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Simple Algorithm for Trimmed Multipoint Evaluation",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-trimmed-multipoint-evaluation/",
      "content": "Authors: Nick Fischer, Melvin Kallmayer, Leo Wennmann\n\nEvaluating a polynomial on a set of points is a fundamental task in computer\nalgebra. In this work, we revisit a particular variant called trimmed\nmultipoint evaluation: given an $n$-variate polynomial with bounded individual\ndegree $d$ and total degree $D$, the goal is to evaluate it on a natural class\nof input points. This problem arises as a key subroutine in recent algorithmic\nresults [Dinur; SODA ‘21], [Dell, Haak, Kallmayer, Wennmann; SODA ‘25]. It is\nknown that trimmed multipoint evaluation can be solved in near-linear time [van\nder Hoeven, Schost; AAECC ‘13] by a clever yet somewhat involved algorithm. We\ngive a simple recursive algorithm that avoids heavy computer-algebraic\nmachinery, and can be readily understood by researchers without specialized\nbackground.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Empirical Analysis Of Heuristic and Approximation Algorithms for the The",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-empirical-analysis-of-heuristic-and-approximation-algorithms-for-the-the-mutual-visibility-problem/",
      "content": "Authors: Vanja Stojanović, Bor Pangeršič\n\nThe NP-complete mutual-visibility (MV) problem currently lacks empirical\nanalysis on its practical behaviour despite theoretical studies. This paper\naddresses this gap by implementing and evaluating three distinct algorithms - a\ndirect greedy heuristic, a hypergraph-based approximation, and a genetic\nalgorithm - on diverse synthetic graph datasets, including those with\nanalytically known $\\mu(G)$ values and general graph models. Our results\ndemonstrate that for smaller graphs, the algorithms consistently achieve MV set\nsizes aligning with theoretical bounds. However, for larger instances, achieved\nsolution sizes notably diverge from theoretical limits; this, combined with the\nabsence of tight bounds, complicates absolute quality assessment. Nevertheless,\nvalidation on known optimal graphs showed the Genetic Algorithm and other\nheuristics empirically performing best among tested methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Compact Representation of Semilinear and Terrain-like Graphs",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-compact-representation-of-semilinear-and-terrain-like-graphs/",
      "content": "Authors: Jean Cardinal, Yelena Yuditsky\n\nWe consider the existence and construction of \\textit{biclique covers} of\ngraphs, consisting of coverings of their edge sets by complete bipartite\ngraphs. The \\textit{size} of such a cover is the sum of the sizes of the\nbicliques. Small-size biclique covers of graphs are ubiquitous in computational\ngeometry, and have been shown to be useful compact representations of graphs.\nWe give a brief survey of classical and recent results on biclique covers and\ntheir applications, and give new families of graphs having biclique covers of\nnear-linear size.\nIn particular, we show that semilinear graphs, whose edges are defined by\nlinear relations in bounded dimensional space, always have biclique covers of\nsize $O(n\\polylog n)$. This generalizes many previously known results on\nspecial classes of graphs including interval graphs, permutation graphs, and\ngraphs of bounded boxicity, but also new classes such as intersection graphs of\nL-shapes in the plane. It also directly implies the bounds for Zarankiewicz’s\nproblem derived by Basit, Chernikov, Starchenko, Tao, and Tran (\\textit{Forum\nMath. Sigma}, 2021).\nWe also consider capped graphs, also known as terrain-like graphs, defined as\nordered graphs forbidding a certain ordered pattern on four vertices.\nTerrain-like graphs contain the induced subgraphs of terrain visibility graphs.\nWe give an elementary proof that these graphs admit biclique partitions of size\n$O(n\\log^3 n)$. This provides a simple combinatorial analogue of a classical\nresult from Agarwal, Alon, Aronov, and Suri on polygon visibility graphs\n(\\textit{Discrete Comput. Geom.} 1994).\nFinally, we prove that there exists families of unit disk graphs on $n$\nvertices that do not admit biclique coverings of size $o(n^{4/3})$, showing\nthat we are unlikely to improve on Szemer'edi-Trotter type incidence bounds\nfor higher-degree semialgebraic graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-analyzing-time-varying-scalar-fields-using-piecewise-linear-morse-cerf-theory/",
      "content": "Authors: Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan\n\nMorse-Cerf theory considers a one-parameter family of smooth functions\ndefined on a manifold and studies the evolution of their critical points with\nthe parameter. This paper presents an adaptation of Morse-Cerf theory to a\nfamily of piecewise-linear (PL) functions. The vertex diagram and Cerf diagram\nare introduced as representations of the evolution of critical points of the PL\nfunction. The characterization of a crossing in the vertex diagram based on the\nhomology of the lower links of vertices leads to the definition of a\ntopological descriptor for time-varying scalar fields. An algorithm for\ncomputing the Cerf diagram and a measure for comparing two Cerf diagrams are\nalso described together with experimental results on time-varying scalar\nfields.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Sensitivity and Query Complexity under Uncertainty",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-complexity-sensitivity-and-query-complexity-under-uncertainty/",
      "content": "Authors: Deepu Benson, Balagopal Komarath, Nikhil Mande, Sai Soumya Nalli, Jayalal Sarma, Karteek Sreenivasaiah\n\nIn this paper, we study the query complexity of Boolean functions in the\npresence of uncertainty, motivated by parallel computation with an unlimited\nnumber of processors where inputs are allowed to be unknown. We allow each\nquery to produce three results: zero, one, or unknown. The output could also\nbe: zero, one, or unknown, with the constraint that we should output\n‘‘unknown’’ only when we cannot determine the answer from the revealed input\nbits. Such an extension of a Boolean function is called its hazard-free\nextension.\n\n  We prove an analogue of Huang’s celebrated sensitivity theorem [Annals of\nMathematics, 2019] in our model of query complexity with uncertainty.\n  We show that the deterministic query complexity of the hazard-free\nextension of a Boolean function is at most quadratic in its randomized query\ncomplexity and quartic in its quantum query complexity, improving upon the\nbest-known bounds in the Boolean world.\n  We exhibit an exponential gap between the smallest depth (size) of decision\ntrees computing a Boolean function, and those computing its hazard-free\nextension.\n  We present general methods to convert decision trees for Boolean functions\nto those for their hazard-free counterparts, and show optimality of this\nconstruction. We also parameterize this result by the maximum number of unknown\nvalues in the input.\n  We show lower bounds on size complexity of decision trees for hazard-free\nextensions of Boolean functions in terms of the number of prime implicants and\nprime implicates of the underlying Boolean function.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Logarithmic Depth Decomposition of Approximate Multi-Controlled",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-complexity-logarithmic-depth-decomposition-of-approximate-multi-controlled-single-qubit-gates-without-ancilla-qubits/",
      "content": "Authors: Jefferson D. S. Silva, Adenilton J. da Silva\n\nThe synthesis of quantum operators involves decomposing general quantum gates\ninto the gate set supported by a given quantum device. Multi-controlled gates\nare essential components in this process. In this work, we present improved\ndecompositions of multi-controlled NOT gates with logarithmic depth using a\nsingle ancilla qubit, while also reducing the constant factors in the circuit\ndepth compared to previous work. We optimize a previously proposed\ndecomposition of multi-target, multi-controlled special unitary SU(2) gates by\nidentifying the presence of a conditionally clean qubit. Additionally, we\nintroduce the best-known decomposition of multi-controlled approximate unitary\nU(2) gates without using ancilla qubits. This approach significantly reduces\nthe overall circuit depth and CNOT count while preserving an adjustable error\nparameter, yielding a more efficient and scalable solution for synthesizing\nlarge controlled-unitary gates. Our method is particularly suitable for both\nNISQ and fault-tolerant quantum architectures. All software developed in this\nproject is freely available.\n\nRead original post\n"
    },
    
    {
      "title": "David Eppstein: Geometric street art in Kanazawa",
      "url": "/cstheoryrss/2025/07/01/david-eppstein-geometric-street-art-in-kanazawa/",
      "content": "Kanazawa was this year’s host of Computational Geometry Week and the Symposium on Computational Geometry, and a great place to visit for lots of reasons. One of the lesser reasons is that it also hosts an interesting collection of geometric street art, some of which I photographed on my recent visit.\n\nThe first thing you see as you enter the city by the main entrance of its train station is Tsuzumimon, a massive ornamental wooden gate. The two pillars of the gate are made from wood beams in two layers that twist around each pillar in opposite directions. The lintel connecting the two pillars is a lattice of more wood, in a rounded form rather than the more traditional straight beam. The gate supports one end of an airy steel and glass space-frame dome, sheltering the plaza in front of the station from the frequent rain.\n\n\n\nTsuzumi are a certain type of Japanese hand drum, so Tsuzumimon means drum gate, because of the resemblance of the pillars to these drums. But instead, what it most reminds me of is a partition of space into skew lines that I ray-traced in 2010 and use as the header for my Mastodon account page.\n\n\n\nA short way along the road to the fish market (worth multiple visits), one encounters this piece, “Corpus Minor #1” by Janne Kristian Virkkunen. Another conference participant told me he thought it resembled a shipping mine, but what it brings to mind to me is either an atomic nucleus or a morula (the complex of cells of a multi-cell organism at the stage of reproduction before they differentiate).\n\n\n\nHere’s a more abstracted close-up look.\n\n\n\nI’m pretty sure its underlying geometric structure comes from a tetrakis hexahedron, whose edges form the prominent ribs of the sculpture. This would allow it to be constructed by bolting together 24 identical triangular pieces, each containing smoothed-together patches from three of the 14 spherical bulges of the sculpture.\n\n\n\nThe part of Kanazawa between the station and the fish market is dominated by major boulevards filled with cars, and long waits for crosswalks. To make it somewhat less unfriendly to pedestrian traffic, the city has installed underpasses at several of the major crossings. It’s easy to miss the next piece, at the central hub of the underpass connecting to the fish market itself.\n\n\n\nAlso seen but not photographed: another large ornamental gate near the back entrance of the station, made of slanted concrete pillars and resembling a support structure for an elevated highway; a black stone monkey saddle in the basement level of the station, near a scale model of Tsuzumimon; a tangled tree of shiny stainless steel tubes across the street from my hotel (a block south of the station); a stylized sundial between the station and the fish market (not very effective in the rain); and many public fountains.\n\n(Discuss on Mastodon)\n\nBy David Eppstein\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Two years of substacking",
      "url": "/cstheoryrss/2025/07/01/ben-recht-two-years-of-substacking/",
      "content": "\n\nToday marks the 2nd anniversary of this substack, and my elaborate blogging rule book compels me to write an annual reflection post. Whereas the first year was experimental and finding my footing, the second year has been decidedly more routine. That’s not a bad thing, as I love rituals. Wake up, brush my teeth, make two pour-over coffees, be harassed by the cat, blog.1 There’s a reassurance in these daily rituals themselves, where the process can be as rewarding as the product.\n\nI’m only half joking about having a blogging rule book. I’ve never written it down, but some of the rules are\n\n\n  Spend the first hour of each working day blogging.\n  Aim for 1000 words. If I hit that number, publish.\n  If I don’t hit 1000 words today, try to finish the piece tomorrow.\n  Make equations with LaTeXit, 14 pt font.\n  Every equation halves your readership (This is a Stephen Hawking rule.)\n  Don’t overthink the titles.\n  A banner by Isaac Sparks goes at the top of each post, subscribe button at the bottom.\n  14:00 GMT is international posting time. (This is a Brian Whitman rule.)\n  Aim for two posts a week. Don’t post more than four.\n\n\nI have a different set of rules for class liveblogging. I invented my own set of rules for working through Meehl’s course. Maybe I should spend more time writing these rules down. I’m sure there are many more I haven’t even articulated to myself.\n\nWhatever the case, I’ve got a process now and I’m sticking to it. The rules are oddly freeing. Rules give you a “freedom from choice,” paring down the degrees of freedom to one where you are able to create but are not overwhelmed by options. They are “constraints that deconstrain,” facilitating improvisation within the narrow boundaries of the ruleset.\n\nPart of my obsession with bureaucracy is that I love rules, and yet bureaucratic rules so frequently lack the deconstraining property that lets people flourish. Making matters worse, bureaucratic processes stifle course correction because by their nature. They are necessarily ossified and onerous to change. That’s a topic for a longer conversation in another post.\n\nIn any event, while I don’t have a clear idea of the topics I’ll be covering in year three of the argmin substack, I do know the starting rule book I’ll be using. And I’m trying to think a bit about rule changes for the upcoming season.2\n\nPart of these rule changes will be adapting to new goals for this season. One thing I haven’t been able to do is use my blogging time as “real writing” time. I’ve taken some mornings and tried to work on other writing projects during my allotted blogging time, and it hasn’t been helpful. That’s interesting in itself. This blog post writing is fundamentally different from the more archival writing, and the latter needs its own set of rules.\n\nI should figure those rules out because I am in a stage where I should write a few more papers. You know, blog posts with DOIs. I don’t want to write too many papers, but some folks have suggested that it would be helpful to collect and collate some of the meandering thoughts here into tighter arguments. My blog posts are first drafts of thoughts, not finished ones. I don’t consider any of the arguments here to be definitive. I love that you all think out loud with me. Nonetheless, some of them are worth preserving in academic amber, and I need to do my scholarly duties of mailing pdfs to my friends. I’ve written two blog posts with DOIs this year (this one, that one), and I have three or four more I should try to finish. I also have a few more books in me that I want to write. I will have more news on that front coming very soon. Finding the right way to balance writing time is going to be an important part of argmin year three.\n\nAnother goal is finding the best balance for the multiple audiences who read this. Some posts get very technical, but there is a slice of the readership that enjoys those. I have tried to maintain a balance that doesn’t alienate those who don’t want the math, while also engaging with those who do. I could split this blog into multiple newsletters, but that seems like a lot of unnecessary work, and I know everyone must have incredible substack subscription fatigue at this point. I could perhaps signal at the top of each post whether I’m going to get into the weeds. If you have any ideas on how to strike the right balance and send the right signals, please send me an email or leave a comment. Hopefully, you folks who agree to be spammed by me are fine with closing the posts that are too hypertechnical and selectively reading the ones that hook you.\n\nRegardless, I love the feedback you send me, and I apologize if I miss any or don’t reply. I read them all and value them all. I look forward to more of them in year three.\n\nSubscribe now\n\n1\n\nThe cat apparently also loves rituals.\n\n2\n\nArgmin blog will not be banning the tush push.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Passage-traversing optimal path planning with sampling-based algorithms",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-passage-traversing-optimal-path-planning-with-sampling-based-algorithms/",
      "content": "Authors: Jing Huang, Hao Su, Kwok Wai Samuel Au\n\nThis paper introduces a new paradigm of optimal path planning, i.e.,\npassage-traversing optimal path planning (PTOPP), that optimizes paths’\ntraversed passages for specified optimization objectives. In particular, PTOPP\nis utilized to find the path with optimal accessible free space along its\nentire length, which represents a basic requirement for paths in robotics. As\npassages are places where free space shrinks and becomes constrained, the core\nidea is to leverage the path’s passage traversal status to characterize its\naccessible free space comprehensively. To this end, a novel passage detection\nand free space decomposition method using proximity graphs is proposed,\nenabling fast detection of sparse but informative passages and environment\ndecompositions. Based on this preprocessing, optimal path planning with\naccessible free space objectives or constraints is formulated as PTOPP problems\ncompatible with sampling-based optimal planners. Then, sampling-based\nalgorithms for PTOPP, including their dependent primitive procedures, are\ndeveloped leveraging partitioned environments for fast passage traversal check.\nAll these methods are implemented and thoroughly tested for effectiveness and\nefficiency validation. Compared to existing approaches, such as clearance-based\nmethods, PTOPP demonstrates significant advantages in configurability, solution\noptimality, and efficiency, addressing prior limitations and incapabilities. It\nis believed to provide an efficient and versatile solution to accessible free\nspace optimization over conventional avenues and more generally, to a broad\nclass of path planning problems that can be formulated as PTOPP.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-moving-matter-using-a-single-simple-robot-to-reconfigure-a-connected-set-of-building-blocks/",
      "content": "Authors: Javier Garcia, Jonas Friemel, Ramin Kosfeld, Michael Yannuzzi, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt, Harm Kube, Dan Biediger, Sándor P. Fekete, Aaron T. Becker\n\nWe implement and evaluate different methods for the reconfiguration of a\nconnected arrangement of tiles into a desired target shape, using a single\nactive robot that can move along the tile structure. This robot can pick up,\ncarry, or drop off one tile at a time, but it must maintain a single connected\nconfiguration at all times.\nBecker et al. (CCCG 2025) recently proposed an algorithm that uses histograms\nas canonical intermediate configurations, guaranteeing performance within a\nconstant factor of the optimal solution if the start and target configuration\nare well-separated. We implement and evaluate this algorithm, both in a\nsimulated and practical setting, using an inchworm type robot to compare it\nwith two existing heuristic algorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Escher Tile Deformation via Closed-Form Solution",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-escher-tile-deformation-via-closed-form-solution/",
      "content": "Authors: Crane He Chen, Vladimir G. Kim\n\nWe present a real-time deformation method for Escher tiles – interlocking\norganic forms that seamlessly tessellate the plane following symmetry rules. We\nformulate the problem as determining a periodic displacement field. The goal is\nto deform Escher tiles without introducing gaps or overlaps. The resulting\ndisplacement field is obtained in closed form by an analytical solution. Our\nmethod processes tiles of 17 wallpaper groups across various representations\nsuch as images and meshes. Rather than treating tiles as mere boundaries, we\nconsider them as textured shapes, ensuring that both the boundary and interior\ndeform simultaneously. To enable fine-grained artistic input, our interactive\ntool features a user-controllable adaptive fall-off parameter, allowing precise\nadjustment of locality and supporting deformations with meaningful semantic\ncontrol. We demonstrate the effectiveness of our method through various\nexamples, including photo editing and shape sculpting, showing its use in\napplications such as fabrication and animation.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: C_4-free subgraphs of high degree with geometric applications",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-c-4-free-subgraphs-of-high-degree-with-geometric-applications/",
      "content": "Authors: Zach Hunter, Aleksa Milojević, Istvan Tomon, Benny Sudakov\n\nThe Zarankiewicz problem, a cornerstone problem in extremal graph theory,\nasks for the maximum number of edges in an $n$-vertex graph that does not\ncontain the complete bipartite graph $K_{s,s}$. While the problem remains\nwidely open in the case of general graphs, the past two decades have seen\nsignificant progress on this problem for various restricted graph classes –\nparticularly those arising from geometric settings – leading to a deeper\nunderstanding of their structure.\nIn this paper, we develop a new structural tool for addressing\nZarankiewicz-type problems. More specifically, we show that for any positive\ninteger $k$, every graph with average degree $d$ either contains an induced\n$C_4$-free subgraph with average degree at least $k$, or it contains a\n$d$-vertex subgraph with $\\Omega_k(d^2)$ edges. As an application of this\ndichotomy, we propose a unified approach to a large number of Zarankiewicz-type\nproblems in geometry, obtaining optimal bounds in each case.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Factorization norms and an inverse theorem for MaxCut",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-factorization-norms-and-an-inverse-theorem-for-maxcut/",
      "content": "Authors: Igor Balla, Lianna Hambardzumyan, István Tomon\n\nWe prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded\nnormalized trace norm must contain a linear-sized all-ones or all-zeros\nsubmatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also\npresent further structural results about Boolean matrices of bounded\n$\\gamma_2$-norm and discuss applications in communication complexity, operator\ntheory, spectral graph theory, and extremal combinatorics.\nAs a key application, we establish an inverse theorem for MaxCut. A\ncelebrated result of Edwards states that every graph $G$ with $m$ edges has a\ncut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality\nachieved by complete graphs with an odd number of vertices. To contrast this,\nwe prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then\n$G$ must contain a clique of size $\\Omega(\\sqrt{m})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Constant-depth circuits for polynomial GCD over any characteristic",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-constant-depth-circuits-for-polynomial-gcd-over-any-characteristic/",
      "content": "Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf\n\nWe show that the GCD of two univariate polynomials can be computed by\n(piece-wise) algebraic circuits of constant depth and polynomial size over any\nsufficiently large field, regardless of the characteristic. This extends a\nrecent result of Andrews &amp; Wigderson who showed such an upper bound over fields\nof zero or large characteristic.\nOur proofs are based on a recent work of Bhattacharjee, Kumar, Rai,\nRamanathan, Saptharishi \\&amp; Saraf that shows closure of constant depth algebraic\ncircuits under factorization. On our way to the proof, we show that any\n$n$-variate symmetric polynomial $P$ that has a small constant depth algebraic\ncircuit can be written as the composition of a small constant depth algebraic\ncircuit with elementary symmetric polynomials. This statement is a constant\ndepth version of a result of Bl\"{a}ser &amp; Jindal, who showed this for algebraic\ncircuits of unbounded depth. As an application of our techniques, we also\nstrengthen the closure results for factors of constant-depth circuits in the\nwork of Bhattacharjee et al. over fields for small characteristic.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Closure under factorization from a result of Furstenberg",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-closure-under-factorization-from-a-result-of-furstenberg/",
      "content": "Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu S. Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf\n\nWe show that algebraic formulas and constant-depth circuits are closed under\ntaking factors. In other words, we show that if a multivariate polynomial over\na field of characteristic zero has a small constant-depth circuit or formula,\nthen all its factors can be computed by small constant-depth circuits or\nformulas respectively.\nOur result turns out to be an elementary consequence of a fundamental and\nsurprising result of Furstenberg from the 1960s, which gives a non-iterative\ndescription of the power series roots of a bivariate polynomial. Combined with\nstandard structural ideas in algebraic complexity, we observe that this theorem\nyields the desired closure results.\nAs applications, we get alternative (and perhaps simpler) proofs of various\nknown results and strengthen the quantitative bounds in some of them. This\nincludes a unified proof of known closure results for algebraic models\n(circuits, branching programs and VNP), an extension of the analysis of the\nKabanets-Impagliazzo hitting set generator to formulas and constant-depth\ncircuits, and a (significantly) simpler proof of correctness as well as\nstronger guarantees on the output in the subexponential time deterministic\nalgorithm for factorization of constant-depth circuits from a recent work of\nBhattacharjee, Kumar, Ramanathan, Saptharishi &amp; Saraf.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Characterizing Small Circuit Classes from FAC0 to FAC1 via Discrete",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-characterizing-small-circuit-classes-from-fac-0-to-fac-1-via-discrete-ordinary-differential-equations/",
      "content": "Authors: Melissa Antonelli, Arnaud Durand, Juha Kontinen\n\nIn this paper, we provide a uniform framework for investigating small circuit\nclasses and bounds through the lens of ordinary differential equations (ODEs).\nFollowing an approach recently introduced to capture the class of\npolynomial-time computable functions via ODE-based recursion schemas and later\napplied to the context of functions computed by unbounded fan-in circuits of\nconstant depth (FAC^0), we study multiple relevant small circuit classes. In\nparticular, we show that natural restrictions on linearity and derivation along\nfunctions with specific growth rate correspond to kinds of functions that can\nbe proved to be in various classes, ranging from FAC^0 to FAC^1. This reveals\nan intriguing link between constraints over linear-length ODEs and circuit\ncomputation, providing new tools to tackle the complex challenge of\nestablishing bounds for classes in the circuit hierarchies and possibly\nenhancing our understanding of the role of counters in this setting.\nAdditionally, we establish several completeness results, in particular\nobtaining the first ODE-based characterizations for the classes of functions\ncomputable in constant depth with unbounded fan-in and Mod 2 gates (FACC[2])\nand in logarithmic depth with bounded fan-in Boolean gates (FNC1).\n\nRead original post\n"
    }
    
  ];

  const idx = lunr(function () {
    this.ref('url')
    this.field('title', {boost: 10})
    this.field('content')

    posts.forEach(function (doc) {
      this.add(doc)
    }, this)
  });

  const searchBox = document.getElementById('search-box');
  const postsList = document.getElementById('posts-list');

  function renderPosts(postsArray) {
    if (postsArray.length === 0) {
      postsList.innerHTML = '<li>No results found</li>';
      return;
    }
    postsList.innerHTML = postsArray.map(p => {
      if (p.url) {
        return `<li><a href="${p.url}">${p.title}</a> — <small></small></li>`;
      } else {
        const post = posts.find(post => post.url === p.ref);
        if (post) {
          return `<li><a href="${post.url}">${post.title}</a></li>`;
        }
        return '';
      }
    }).join('');
  }

  renderPosts(posts);

  searchBox.addEventListener('input', function () {
    let query = this.value.trim().toLowerCase();

    if (query === "") {
      renderPosts(posts);
      return;
    }

    let results = idx.search(query);
    if (results.length === 0) {
      const wildcardQuery = query.split(/\s+/).map(term => term + '*').join(' ');
      results = idx.search(wildcardQuery);
    }

    renderPosts(results);
  });
</script>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Gorav  Jindal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
