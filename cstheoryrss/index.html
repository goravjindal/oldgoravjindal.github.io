<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>CS Theory RSS | Gorav  Jindal</title>
    <meta name="author" content="Gorav  Jindal">
    <meta name="description" content="Gorav Jindal's personal and academic webpage
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://goravjindal.github.io/cstheoryrss/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Gorav </span>Jindal</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/cstheoryrss/">CS Theory RSS<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">CS Theory RSS</h1>
            <p class="post-description"></p>
          </header>

          <article>
            
<h1 id="cs-theory-rss-posts-last-6-months-from-httpstheoryreportatomxml">CS Theory RSS Posts (last 6 months), from <a href="https://theory.report/atom.xml" rel="external nofollow noopener" target="_blank">https://theory.report/atom.xml</a>
</h1>

<p><input type="text" id="search-box" placeholder="Search posts..." style="margin-bottom: 1em; width: 100%; padding: 0.5em; font-size: 1em;"></p>

<ul id="posts-list">
    
      <li>
        <a href="/cstheoryrss/2025/07/08/2025-07-08-arxiv-data-structures-and-algorithms-the-planar-edge-coloring-theorem-of-vizing-in-o-n-log-n-time/"></a> — <small>2025-07-08</small>
        <p></p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/cs-theory-events-proof-complexity-2025/">CS Theory Events: Proof Complexity 2025</a> — <small>2025-07-08</small>
        <p>August 11-13, 2025 Oxford, UK https://feasible-math.org/events/PC25/ Proof complexity is a vibrant area in the intersection of computational comple...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-truthful-credible-and-optimal-auctions-for-matroids-via-blockchains-and-commitments/">arXiv: Data Structures and Algorithms: Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments</a> — <small>2025-07-08</small>
        <p>Authors: Aadityan Ganesh, Qianfan Zhang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-tight-guarantees-for-cut-relative-survivable-network-design-via-a-decomposition-technique/">arXiv: Data Structures and Algorithms: Tight Guarantees for Cut-Relative Survivable Network Design via a Decomposition Technique</a> — <small>2025-07-08</small>
        <p>Authors: Nikhil Kumar, JJ Nan, Chaitanya Swamy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-fair-periodic-assignment-problem/">arXiv: Data Structures and Algorithms: The Fair Periodic Assignment Problem</a> — <small>2025-07-08</small>
        <p>Authors: Rolf van Lieshout, Bart van Rossum
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-recent-advances-in-maximum-entropy-sampling/">arXiv: Data Structures and Algorithms: Recent Advances in Maximum-Entropy Sampling</a> — <small>2025-07-08</small>
        <p>Authors: Marcia Fampa, Jon Lee
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-quantum-algorithms-for-bandits-with-knapsacks-with-improved-regret-and-time-complexities/">arXiv: Data Structures and Algorithms: Quantum Algorithms for Bandits with Knapsacks with Improved Regret and Time Complexities</a> — <small>2025-07-08</small>
        <p>Authors: Yuexin Su, Ziyi Yang, Peiyuan Huang, Tongyang Li, Yinyu Ye
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-makespan-scheduling-under-scenarios/">arXiv: Data Structures and Algorithms: Online Makespan Scheduling under Scenarios</a> — <small>2025-07-08</small>
        <p>Authors: Ekin Ergen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-convex-optimization-with-switching-cost-with-only-one-single-gradient-evaluation/">arXiv: Data Structures and Algorithms: Online Convex Optimization with Switching Cost with Only One Single Gradient Evaluation</a> — <small>2025-07-08</small>
        <p>Authors: Harsh Shah, Purna Chandrasekhar, Rahul Vaze
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-maximizing-the-margin-between-desirable-and-undesirable-elements-in-a-covering-problem/">arXiv: Data Structures and Algorithms: Maximizing the Margin between Desirable and Undesirable Elements in a Covering Problem</a> — <small>2025-07-08</small>
        <p>Authors: Sophie Boileau, Andrew Hong, David Liben-Nowell, Alistair Pattison, Anna N. Rafferty, Charlie Roslansky
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-liar-s-vertex-edge-domination-in-subclasses-of-chordal-graphs/">arXiv: Data Structures and Algorithms: Liar's vertex-edge domination in subclasses of chordal graphs</a> — <small>2025-07-08</small>
        <p>Authors: Debojyoti Bhattacharya, Subhabrata Paul
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-improved-algorithms-for-effective-resistance-computation-on-graphs/">arXiv: Data Structures and Algorithms: Improved Algorithms for Effective Resistance Computation on Graphs</a> — <small>2025-07-08</small>
        <p>Authors: Yichun Yang, Rong-Hua Li, Meihao Liao, Guoren Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-hipermotif-novel-parallel-subgraph-isomorphism-in-large-scale-property-graphs/">arXiv: Data Structures and Algorithms: HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property Graphs</a> — <small>2025-07-08</small>
        <p>Authors: Mohammad Dindoost, Oliver Alvarado Rodriguez, Bartosz Bryg, Ioannis Koutis, David A. Bader
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-heights-of-butterfly-trees/">arXiv: Data Structures and Algorithms: Heights of butterfly trees</a> — <small>2025-07-08</small>
        <p>Authors: John Peca-Medlin, Chenyang Zhong
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-greedy-dynamic-matching/">arXiv: Data Structures and Algorithms: Greedy Dynamic Matching</a> — <small>2025-07-08</small>
        <p>Authors: Nick Arnosti, Felipe Simon
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-distributed-approximation-algorithms-for-minimum-dominating-set-in-locally-nice-graphs/">arXiv: Data Structures and Algorithms: Distributed Approximation Algorithms for Minimum Dominating Set in Locally Nice Graphs</a> — <small>2025-07-08</small>
        <p>Authors: Marthe Bonamy, Cyril Gavoille, Timothé Picavet, Alexandra Wesolek
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/">arXiv: Data Structures and Algorithms: Decremental Greedy Polygons and Polyhedra Without Sharp Angles</a> — <small>2025-07-08</small>
        <p>Authors: David Eppstein
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-combination-generators-with-optimal-cache-utilization-and-communication-free-parallel-execution/">arXiv: Data Structures and Algorithms: Combination generators with optimal cache utilization and communication free parallel execution</a> — <small>2025-07-08</small>
        <p>Authors: Xi He, Max. A. Little
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-color-distance-oracles-and-snippets-separation-between-exact-and-approximate-solutions/">arXiv: Data Structures and Algorithms: Color Distance Oracles and Snippets: Separation Between Exact and Approximate Solutions</a> — <small>2025-07-08</small>
        <p>Authors: Noam Horowicz, Tsvi Kopelowitz
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-bicriteria-approximation-for-k-edge-connectivity/">arXiv: Data Structures and Algorithms: Bicriteria approximation for $k$-edge-connectivity</a> — <small>2025-07-08</small>
        <p>Authors: Zeev Nutov, Reut Cohen
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-agentic-distributed-computing/">arXiv: Data Structures and Algorithms: Agentic Distributed Computing</a> — <small>2025-07-08</small>
        <p>Authors: Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-combinatorial-n-fold-ilps-using-the-steinitz-lemma/">arXiv: Data Structures and Algorithms: A simple algorithm for Combinatorial n-fold ILPs using the Steinitz Lemma</a> — <small>2025-07-08</small>
        <p>Authors: Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-note-on-finding-long-directed-cycles-above-the-minimum-degree-bound-in-2-connected-digraphs/">arXiv: Data Structures and Algorithms: A note on finding long directed cycles above the minimum degree bound in 2-connected digraphs</a> — <small>2025-07-08</small>
        <p>Authors: Jadwiga Czyżewska, Marcin Pilipczuk
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-testing-for-renamability-to-classes-of-clause-sets/">arXiv: Computational Complexity: Testing for Renamability to Classes of Clause Sets</a> — <small>2025-07-08</small>
        <p>Authors: Albert Brandl, Christian G. Fermüller, Gernot Salzer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-pfcs-prime-factorization-cache-system-for-deterministic-data-relationship-discovery/">arXiv: Computational Complexity: PFCS: Prime Factorization Cache System for Deterministic Data Relationship Discovery</a> — <small>2025-07-08</small>
        <p>Authors: Duy Le
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/08/arxiv-computational-complexity-low-sets-for-counting-functions/">arXiv: Computational Complexity: Low sets for counting functions</a> — <small>2025-07-08</small>
        <p>Authors: Yaroslav Ivanashev
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/ben-recht-you-keep-using-that-word/">Ben Recht: You keep using that word</a> — <small>2025-07-07</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/gil-kalai-happy-birthday-saharon-shelah-and-yuri-gurevich/">Gil Kalai: Happy Birthday Saharon Shelah and Yuri Gurevich!</a> — <small>2025-07-07</small>
        <p>Let me briefly report on two birthday conferences for long-time friends and colleagues Saharon Shelah and Yuri Gurevich. Yuri fest took place in Mu...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/">arXiv: Data Structures and Algorithms: On the Approximability of Train Routing and the Min-Max Disjoint Paths Problem</a> — <small>2025-07-07</small>
        <p>Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-going-beyond-surfaces-in-diameter-approximation/">arXiv: Data Structures and Algorithms: Going Beyond Surfaces in Diameter Approximation</a> — <small>2025-07-07</small>
        <p>Authors: Michał Włodarczyk
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-discovering-algorithms-with-computational-language-processing/">arXiv: Data Structures and Algorithms: Discovering Algorithms with Computational Language Processing</a> — <small>2025-07-07</small>
        <p>Authors: Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-bayesian-optimal-stopping-with-maximum-value-knowledge/">arXiv: Data Structures and Algorithms: Bayesian Optimal Stopping with Maximum Value Knowledge</a> — <small>2025-07-07</small>
        <p>Authors: Pieter Kleer, Daan Noordenbos
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-barvinok-s-interpolation-method-meets-weitz-s-correlation-decay-approach/">arXiv: Data Structures and Algorithms: Barvinok's interpolation method meets Weitz's correlation decay approach</a> — <small>2025-07-07</small>
        <p>Authors: Ferenc Bencs, Guus Regts
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-quantum-computation-with-correlated-measurements-implications-for-the-complexity-landscape/">arXiv: Computational Complexity: Quantum Computation with Correlated Measurements: Implications for the Complexity Landscape</a> — <small>2025-07-07</small>
        <p>Authors: David Miloschewsky, Supartha Podder
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-complexity-of-learning-matchings-and-half-graphs-via-edge-queries/">arXiv: Computational Complexity: Complexity of learning matchings and half graphs via edge queries</a> — <small>2025-07-07</small>
        <p>Authors: Nikhil S. Mande, Swagato Sanyal, Viktor Zamaraev
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-are-depth-2-regular-expressions-hard-to-intersect/">arXiv: Computational Complexity: Are Depth-2 Regular Expressions Hard to Intersect?</a> — <small>2025-07-07</small>
        <p>Authors: Rocco Ascone, Giulia Bernardini, Alessio Conte, Veronica Guerrini, Giulia Punzi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/07/arxiv-computational-complexity-a-near-optimal-polynomial-distance-lemma-over-boolean-slices/">arXiv: Computational Complexity: A Near-Optimal Polynomial Distance Lemma Over Boolean Slices</a> — <small>2025-07-07</small>
        <p>Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/06/computational-complexity-the-new-lower-bound-on-busy-beaver-of-6/">Computational Complexity: The New Lower Bound on Busy Beaver of 6.</a> — <small>2025-07-06</small>
        <p> We denote the busy beaver function by BB.
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/06/eccc-papers-tr25-088-factorization-norms-and-an-inverse-theorem-for-maxcut-igor-balla-lianna-hambardzumyan-istvan-tomon/">ECCC Papers: TR25-088 |  Factorization norms and an inverse theorem for MaxCut |
Igor Balla,
Lianna Hambardzumyan,
Istvan Tomon</a> — <small>2025-07-06</small>
        <p>We prove that Boolean matrices with bounded $\gamma_2$-norm or bounded normalized trace norm must contain a linear-sized all-ones or all-zeros subm...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-online-conformal-prediction-with-efficiency-guarantees/">arXiv: Data Structures and Algorithms: Online Conformal Prediction with Efficiency Guarantees</a> — <small>2025-07-04</small>
        <p>Authors: Vaidehi Srinivas
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-structure-of-replicable-hypothesis-testers/">arXiv: Data Structures and Algorithms: On the Structure of Replicable Hypothesis Testers</a> — <small>2025-07-04</small>
        <p>Authors: Anders Aamand, Maryam Aliakbarpour, Justin Y. Chen, Shyam Narayanan, Sandeep Silwal
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-complexity-of-knapsack-under-explorable-uncertainty-hardness-and-algorithms/">arXiv: Data Structures and Algorithms: On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms</a> — <small>2025-07-04</small>
        <p>Authors: Jens Schlöter
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-adversarial-robustness-of-online-importance-sampling/">arXiv: Data Structures and Algorithms: On the Adversarial Robustness of Online Importance Sampling</a> — <small>2025-07-04</small>
        <p>Authors: Yotam Kenneth-Mordoch, Shay Sapir
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-numerical-linear-algebra-in-linear-space/">arXiv: Data Structures and Algorithms: Numerical Linear Algebra in Linear Space</a> — <small>2025-07-04</small>
        <p>Authors: Yiping Liu, Hoai-An Nguyen, Junzhao Yang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-new-algorithms-for-girth-and-cycle-detection/">arXiv: Data Structures and Algorithms: New algorithms for girth and cycle detection</a> — <small>2025-07-04</small>
        <p>Authors: Liam Roditty, Plia Trabelsi
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-indexing-tries-within-entropy-bounded-space/">arXiv: Data Structures and Algorithms: Indexing Tries within Entropy-Bounded Space</a> — <small>2025-07-04</small>
        <p>Authors: Lorenzo Carfagna, Carlo Tosoni
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-faster-algorithm-for-bounded-tree-edit-distance-in-the-low-distance-regime/">arXiv: Data Structures and Algorithms: Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime</a> — <small>2025-07-04</small>
        <p>Authors: Tomasz Kociumaka, Ali Shahali
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-connected-k-median-with-disjoint-and-non-disjoint-clusters/">arXiv: Data Structures and Algorithms: Connected k-Median with Disjoint and Non-disjoint Clusters</a> — <small>2025-07-04</small>
        <p>Authors: Jan Eube, Kelin Luo, Dorian Reineccius, Heiko Röglin, Melanie Schmidt
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-bounded-weighted-edit-distance-dynamic-algorithms-and-matching-lower-bounds/">arXiv: Data Structures and Algorithms: Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds</a> — <small>2025-07-04</small>
        <p>Authors: Itai Boneh, Egor Gorbachev, Tomasz Kociumaka
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-an-easy-proof-of-a-weak-version-of-chernoff-inequality/">arXiv: Data Structures and Algorithms: An Easy Proof of a Weak Version of Chernoff inequality</a> — <small>2025-07-04</small>
        <p>Authors: Sariel Har-Peled
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-a-computational-proof-of-the-highest-scoring-boggle-board/">arXiv: Data Structures and Algorithms: A Computational Proof of the Highest-Scoring Boggle Board</a> — <small>2025-07-04</small>
        <p>Authors: Dan Vanderkam
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-computational-geometry-a-linear-time-algorithm-for-finding-minimum-flip-sequences-between-plane-spanning-paths-in-convex-point-sets/">arXiv: Computational Geometry: A Linear Time Algorithm for Finding Minimum Flip Sequences between Plane Spanning Paths in Convex Point Sets</a> — <small>2025-07-04</small>
        <p>Authors: Oswin Aichholzer, Joseph Dorfer
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/04/arxiv-computational-complexity-stiefel-optimization-is-np-hard/">arXiv: Computational Complexity: Stiefel optimization is NP-hard</a> — <small>2025-07-04</small>
        <p>Authors: Zehua Lai, Lek-Heng Lim, Tianyun Tang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/ben-recht-standard-error-of-what-now/">Ben Recht: Standard error of what now?</a> — <small>2025-07-03</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-sparse-pivot-dynamic-correlation-clustering-for-node-insertions/">arXiv: Data Structures and Algorithms: SPARSE-PIVOT: Dynamic correlation clustering for node insertions</a> — <small>2025-07-03</small>
        <p>Authors: Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrović
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-optimal-dispersion-under-asynchrony/">arXiv: Data Structures and Algorithms: Optimal Dispersion Under Asynchrony</a> — <small>2025-07-03</small>
        <p>Authors: Debasish Pattanayak, Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-faster-algorithm-for-second-s-t-mincut-and-breaking-quadratic-barrier-for-dual-edge-sensitivity-for-s-t-mincut/">arXiv: Data Structures and Algorithms: Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut</a> — <small>2025-07-03</small>
        <p>Authors: Surender Baswana, Koustav Bhanja, Anupam Roy
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-dynamic-similarity-graph-construction-with-kernel-density-estimation/">arXiv: Data Structures and Algorithms: Dynamic Similarity Graph Construction with Kernel Density Estimation</a> — <small>2025-07-03</small>
        <p>Authors: Steinar Laenen, Peter Macgregor, He Sun
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-breaking-the-n-1-5-additive-error-barrier-for-private-and-efficient-graph-sparsification-via-private-expander-decomposition/">arXiv: Data Structures and Algorithms: Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition</a> — <small>2025-07-03</small>
        <p>Authors: Anders Aamand, Justin Y. Chen, Mina Dalirrooyfard, Slobodan Mitrović, Yuriy Nevmyvaka, Sandeep Silwal, Yinzhan Xu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-a-deterministic-partition-tree-and-applications/">arXiv: Data Structures and Algorithms: A Deterministic Partition Tree and Applications</a> — <small>2025-07-03</small>
        <p>Authors: Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-search-based-robot-motion-planning-with-distance-based-adaptive-motion-primitives/">arXiv: Computational Geometry: Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives</a> — <small>2025-07-03</small>
        <p>Authors: Benjamin Kraljusic, Zlatan Ajanovic, Nermin Covic, Bakir Lacevic
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-multiple-watchman-routes-in-staircase-polygons/">arXiv: Computational Geometry: Multiple Watchman Routes in Staircase Polygons</a> — <small>2025-07-03</small>
        <p>Authors: Anna Brötzner, Bengt J. Nilsson, Christiane Schmidt
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-stable-and-theoretically-grounded-gromov-wasserstein-distance-for-reeb-graph-comparison-using-persistence-images/">arXiv: Computational Geometry: A Stable and Theoretically Grounded Gromov-Wasserstein Distance for Reeb Graph Comparison using Persistence Images</a> — <small>2025-07-03</small>
        <p>Authors: Erin W. Chambers, Guangyu Meng
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-deterministic-partition-tree-and-applications/">arXiv: Computational Geometry: A Deterministic Partition Tree and Applications</a> — <small>2025-07-03</small>
        <p>Authors: Haitao Wang
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-symport-antiport-p-systems-with-membrane-separation-characterize-p-p/">arXiv: Computational Complexity: Symport/Antiport P Systems with Membrane Separation Characterize P^(#P)</a> — <small>2025-07-03</small>
        <p>Authors: Vivien Ducros, Claudio Zandron
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-pcpp-based-reconfiguration-inapproximability-query-complexity-vs-soundness-gap-trade-offs/">arXiv: Computational Complexity: PCPP-Based Reconfiguration Inapproximability: Query Complexity vs. Soundness Gap Trade-offs</a> — <small>2025-07-03</small>
        <p>Authors: Venkatesan Guruswami, Xuandi Ren, Kewen Wu
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/03/arxiv-computational-complexity-hardness-of-quantum-distribution-learning-and-quantum-cryptography/">arXiv: Computational Complexity: Hardness of Quantum Distribution Learning and Quantum Cryptography</a> — <small>2025-07-03</small>
        <p>Authors: Taiga Hiroka, Min-Hsiu Hsieh, Tomoyuki Morimae
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/computational-complexity-a-professor-again/">Computational Complexity: A Professor Again</a> — <small>2025-07-02</small>
        <p>A new dean has taken my place, and I have returned to the professoriate at Illinois Tech, ending thirteen years in administration, six as dean and ...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/gil-kalai-some-events/">Gil Kalai: Some Events</a> — <small>2025-07-02</small>
        <p>Annual meeting of the Israeli Mathematical Union and student talks day, July 6 and 7
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-quantum-speedups-for-polynomial-time-dynamic-programming-algorithms/">arXiv: Data Structures and Algorithms: Quantum Speedups for Polynomial-Time Dynamic Programming Algorithms</a> — <small>2025-07-02</small>
        <p>Authors: Susanna Caroppo, Giordano Da Lozzo, Giuseppe Di Battista, Michael T. Goodrich, Martin Nöllenburg
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-on-the-in-approximability-of-the-monitoring-edge-geodetic-set-problem/">arXiv: Data Structures and Algorithms: On the (In)Approximability of the Monitoring Edge Geodetic Set Problem</a> — <small>2025-07-02</small>
        <p>Authors: Davide Bilò, Giodano Colli, Luca Forlizzi, Stefano Leucci
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-lazy-b-trees/">arXiv: Data Structures and Algorithms: Lazy B-Trees</a> — <small>2025-07-02</small>
        <p>Authors: Casper Moldrup Rysgaard, Sebastian Wild
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-hamiltonicity-parameterized-by-mim-width-is-indeed-para-np-hard/">arXiv: Data Structures and Algorithms: Hamiltonicity Parameterized by Mim-Width is (Indeed) Para-NP-Hard</a> — <small>2025-07-02</small>
        <p>Authors: Benjamin Bergougnoux, Lars Jaffke
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-best-agent-identification-for-general-game-playing/">arXiv: Data Structures and Algorithms: Best Agent Identification for General Game Playing</a> — <small>2025-07-02</small>
        <p>Authors: Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-trimmed-multipoint-evaluation/">arXiv: Data Structures and Algorithms: A Simple Algorithm for Trimmed Multipoint Evaluation</a> — <small>2025-07-02</small>
        <p>Authors: Nick Fischer, Melvin Kallmayer, Leo Wennmann
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-empirical-analysis-of-heuristic-and-approximation-algorithms-for-the-the-mutual-visibility-problem/">arXiv: Computational Geometry: Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem</a> — <small>2025-07-02</small>
        <p>Authors: Vanja Stojanović, Bor Pangeršič
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-compact-representation-of-semilinear-and-terrain-like-graphs/">arXiv: Computational Geometry: Compact Representation of Semilinear and Terrain-like Graphs</a> — <small>2025-07-02</small>
        <p>Authors: Jean Cardinal, Yelena Yuditsky
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-geometry-analyzing-time-varying-scalar-fields-using-piecewise-linear-morse-cerf-theory/">arXiv: Computational Geometry: Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory</a> — <small>2025-07-02</small>
        <p>Authors: Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-complexity-sensitivity-and-query-complexity-under-uncertainty/">arXiv: Computational Complexity: Sensitivity and Query Complexity under Uncertainty</a> — <small>2025-07-02</small>
        <p>Authors: Deepu Benson, Balagopal Komarath, Nikhil Mande, Sai Soumya Nalli, Jayalal Sarma, Karteek Sreenivasaiah
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/02/arxiv-computational-complexity-logarithmic-depth-decomposition-of-approximate-multi-controlled-single-qubit-gates-without-ancilla-qubits/">arXiv: Computational Complexity: Logarithmic Depth Decomposition of Approximate Multi-Controlled Single-Qubit Gates Without Ancilla Qubits</a> — <small>2025-07-02</small>
        <p>Authors: Jefferson D. S. Silva, Adenilton J. da Silva
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/david-eppstein-geometric-street-art-in-kanazawa/">David Eppstein: Geometric street art in Kanazawa</a> — <small>2025-07-01</small>
        <p>Kanazawa was this year’s host of Computational Geometry Week and the Symposium on Computational Geometry, and a great place to visit for lots of re...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/ben-recht-two-years-of-substacking/">Ben Recht: Two years of substacking</a> — <small>2025-07-01</small>
        <p>
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-passage-traversing-optimal-path-planning-with-sampling-based-algorithms/">arXiv: Computational Geometry: Passage-traversing optimal path planning with sampling-based algorithms</a> — <small>2025-07-01</small>
        <p>Authors: Jing Huang, Hao Su, Kwok Wai Samuel Au
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-moving-matter-using-a-single-simple-robot-to-reconfigure-a-connected-set-of-building-blocks/">arXiv: Computational Geometry: Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks</a> — <small>2025-07-01</small>
        <p>Authors: Javier Garcia, Jonas Friemel, Ramin Kosfeld, Michael Yannuzzi, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt, Harm Kube,...</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-escher-tile-deformation-via-closed-form-solution/">arXiv: Computational Geometry: Escher Tile Deformation via Closed-Form Solution</a> — <small>2025-07-01</small>
        <p>Authors: Crane He Chen, Vladimir G. Kim
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-geometry-c-4-free-subgraphs-of-high-degree-with-geometric-applications/">arXiv: Computational Geometry: $C_4$-free subgraphs of high degree with geometric applications</a> — <small>2025-07-01</small>
        <p>Authors: Zach Hunter, Aleksa Milojević, Istvan Tomon, Benny Sudakov
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-factorization-norms-and-an-inverse-theorem-for-maxcut/">arXiv: Computational Complexity: Factorization norms and an inverse theorem for MaxCut</a> — <small>2025-07-01</small>
        <p>Authors: Igor Balla, Lianna Hambardzumyan, István Tomon
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-constant-depth-circuits-for-polynomial-gcd-over-any-characteristic/">arXiv: Computational Complexity: Constant-depth circuits for polynomial GCD over any characteristic</a> — <small>2025-07-01</small>
        <p>Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-closure-under-factorization-from-a-result-of-furstenberg/">arXiv: Computational Complexity: Closure under factorization from a result of Furstenberg</a> — <small>2025-07-01</small>
        <p>Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu S. Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf
</p>
      </li>
    
      <li>
        <a href="/cstheoryrss/2025/07/01/arxiv-computational-complexity-characterizing-small-circuit-classes-from-fac-0-to-fac-1-via-discrete-ordinary-differential-equations/">arXiv: Computational Complexity: Characterizing Small Circuit Classes from FAC^0 to FAC^1 via Discrete Ordinary Differential Equations</a> — <small>2025-07-01</small>
        <p>Authors: Melissa Antonelli, Arnaud Durand, Juha Kontinen
</p>
      </li>
    
  </ul>

<script src="https://unpkg.com/lunr/lunr.js"></script>

<script>
  const posts = [
    
    {
      "title": null,
      "url": "/cstheoryrss/2025/07/08/2025-07-08-arxiv-data-structures-and-algorithms-the-planar-edge-coloring-theorem-of-vizing-in-o-n-log-n-time/",
      "content": "Authors: Patryk Jędrzejczak, Łukasz Kowalik\n\nIn 1965, Vizing [Diskret. Analiz, 1965] showed that every planar graph of\nmaximum degree $\\Delta\\ge 8$ can be edge-colored using $\\Delta$ colors. The\ndirect implementation of the Vizing’s proof gives an algorithm that finds the\ncoloring in $O(n^2)$ time for an $n$-vertex input graph. Chrobak and Nishizeki\n[J. Algorithms, 1990] have shown a more careful algorithm, which improves the\ntime to $O(n\\log n)$ time, though only for $\\Delta\\ge 9$. In this paper, we\nextend their ideas to get an algorithm also for the missing case $\\Delta=8$. To\nthis end, we modify the original recoloring procedure of Vizing. This\ngeneralizes to bounded genus graphs.\n\nRead original post\n"
    },
    
    {
      "title": "CS Theory Events: Proof Complexity 2025",
      "url": "/cstheoryrss/2025/07/08/cs-theory-events-proof-complexity-2025/",
      "content": "August 11-13, 2025 Oxford, UK https://feasible-math.org/events/PC25/ Proof complexity is a vibrant area in the intersection of computational complexity, algorithms and mathematical logic exploring the inherent difficulty of proving statements in different formal proof systems. This workshop aims to cover both traditional topics and emerging trends in the field, including lower bounds on lengths of proofs, … Continue reading Proof Complexity 2025\n\nBy shacharlovett\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-truthful-credible-and-optimal-auctions-for-matroids-via-blockchains-and-commitments/",
      "content": "Authors: Aadityan Ganesh, Qianfan Zhang\n\nWe consider a revenue-optimizing auctioneer in single-dimensional\nenvironments with matroid feasibility constraints. Akbarpour and Li (2020)\nargue that any revenue-optimal, truthful, and credible mechanism requires\nunbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et\nal., 2022; Chitra et al., 2024) circumvent their impossibility for the\nsingle-item setting through the use of cryptographic commitments and\nblockchains. We extend their results to matroid feasibility constraints.\nAt a high level, the two-round Deferred-Revelation Auction (DRA) discussed by\nFerreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to\nsubmit a deposit, which is slashed upon presenting verifiable evidence\nindicating a deviation from the behaviour prescribed by the mechanism. We prove\nthat the DRA satisfies truthfulness, credibility and revenue-optimality for all\nmatroid environments when bidders’ values are drawn from $\\alpha$-strongly\nregular distributions for $\\alpha &gt; 0$. Further, we argue that the DRA is not\ncredible for any feasibility constraint beyond matroids and for any smaller\ndeposits than suggested by previous literature even in single-item\nenvironments.\nFinally, we modify the Ascending Deferred-Revelation Auction (ADRA) for\nsingle-item settings proposed by Essaidi et al., (2022) for arbitrary bidder\nvalue distributions. We implement a deferred-revelation variant of the\ndeferred-acceptance auction for matroids due to Bikhchandani et al., (2011),\nwhich requires the same bounded communication as the ADRA.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Tight Guarantees for Cut-Relative Survivable Network Design via a Decomposition Technique",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-tight-guarantees-for-cut-relative-survivable-network-design-via-a-decomposition-technique/",
      "content": "Authors: Nikhil Kumar, JJ Nan, Chaitanya Swamy\n\nIn the classical \\emph{survivable-network-design problem} (SNDP), we are\ngiven an undirected graph $G = (V, E)$, non-negative edge costs, and some\n$(s_i,t_i,r_i)$ tuples, where $s_i,t_i\\in V$ and $r_i\\in\\mathbb{Z}_+$. We seek\na minimum-cost subset $H \\subseteq E$ such that each $s_i$-$t_i$ pair remains\nconnected even if any $r_i-1$ edges fail. It is well-known that SNDP can be\nequivalently modeled using a weakly-supermodular \\emph{cut-requirement\nfunction} $f$, where we seek a minimum-cost edge-set containing at least $f(S)$\nedges across every cut $S \\subseteq V$.\nRecently, Dinitz et al. proposed a variant of SNDP that enforces a\n\\emph{relative} level of fault tolerance with respect to $G$, where the goal is\nto find a solution $H$ that is at least as fault-tolerant as $G$ itself. They\nformalize this in terms of paths and fault-sets, which gives rise to\n\\emph{path-relative SNDP}. Along these lines, we introduce a new model of\nrelative network design, called \\emph{cut-relative SNDP} (CR-SNDP), where the\ngoal is to select a minimum-cost subset of edges that satisfies the given\n(weakly-supermodular) cut-requirement function to the maximum extent possible,\ni.e., by picking $\\min{f(S),|\\delta_G(S)|}$ edges across every cut\n$S\\subseteq V$.\nUnlike SNDP, the cut-relative and path-relative versions of SNDP are not\nequivalent. The resulting cut-requirement function for CR-SNDP (as also\npath-relative SNDP) is not weakly supermodular, and extreme-point solutions to\nthe natural LP-relaxation need not correspond to a laminar family of tight cut\nconstraints. Consequently, standard techniques cannot be used directly to\ndesign approximation algorithms for this problem. We develop a \\emph{novel\ndecomposition technique} to circumvent this difficulty and use it to give a\n\\emph{tight $2$-approximation algorithm for CR-SNDP}. We also show new hardness\nresults for these relative-SNDP problems.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: The Fair Periodic Assignment Problem",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-the-fair-periodic-assignment-problem/",
      "content": "Authors: Rolf van Lieshout, Bart van Rossum\n\nWe study the periodic assignment problem, in which a set of periodically\nrepeating tasks must be assigned to workers within a repeating schedule. The\nclassical efficiency objective is to minimize the number of workers required to\noperate the schedule. We propose a O(n log n) algorithm to solve this problem.\nNext, we formalize a notion of fairness among workers, and impose that each\nworker performs the same work over time. We analyze the resulting trade-off\nbetween efficiency and fairness, showing that the price of fairness is at most\none extra worker, and that such a fair solution can always be found using the\nNearest Neighbor heuristic. We characterize all instances that admit a solution\nthat is both fair and efficient, and use this result to develop a O(n log n)\nexact algorithm for the fair periodic assignment problem. Finally, we show that\nallowing aperiodic schedules never reduces the price of fairness.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Recent Advances in Maximum-Entropy Sampling",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-recent-advances-in-maximum-entropy-sampling/",
      "content": "Authors: Marcia Fampa, Jon Lee\n\nIn 2022, we published a book, \\emph{Maximum-Entropy Sampling: Algorithms and\nApplication (Springer)}. Since then, there have been several notable\nadvancements on this topic. In this manuscript, we survey some recent\nhighlights.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum Algorithms for Bandits with Knapsacks with Improved Regret and Time Complexities",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-quantum-algorithms-for-bandits-with-knapsacks-with-improved-regret-and-time-complexities/",
      "content": "Authors: Yuexin Su, Ziyi Yang, Peiyuan Huang, Tongyang Li, Yinyu Ye\n\nBandits with knapsacks (BwK) constitute a fundamental model that combines\naspects of stochastic integer programming with online learning. Classical\nalgorithms for BwK with a time horizon $T$ achieve a problem-independent regret\nbound of ${O}(\\sqrt{T})$ and a problem-dependent bound of ${O}(\\log T)$. In\nthis paper, we initiate the study of the BwK model in the setting of quantum\ncomputing, where both reward and resource consumption can be accessed via\nquantum oracles. We establish both problem-independent and problem-dependent\nregret bounds for quantum BwK algorithms. For the problem-independent case, we\ndemonstrate that a quantum approach can improve the classical regret bound by a\nfactor of $(1+\\sqrt{B/\\mathrm{OPT}_\\mathrm{LP}})$, where $B$ is budget\nconstraint in BwK and $\\mathrm{OPT}_{\\mathrm{LP}}$ denotes the optimal value of\na linear programming relaxation of the BwK problem. For the problem-dependent\nsetting, we develop a quantum algorithm using an inexact quantum linear\nprogramming solver. This algorithm achieves a quadratic improvement in terms of\nthe problem-dependent parameters, as well as a polynomial speedup of time\ncomplexity on problem’s dimensions compared to classical counterparts. Compared\nto previous works on quantum algorithms for multi-armed bandits, our study is\nthe first to consider bandit models with resource constraints and hence shed\nlight on operations research.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Makespan Scheduling under Scenarios",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-makespan-scheduling-under-scenarios/",
      "content": "Authors: Ekin Ergen\n\nWe consider a natural extension of online makespan scheduling on identical\nparallel machines by introducing scenarios. A scenario is a subset of jobs, and\nthe task of our problem is to find a global assignment of the jobs to machines\nso that the maximum makespan under a scenario, i.e., the maximum makespan of\nany schedule restricted to a scenario, is minimized.\nFor varying values of the number of scenarios and machines, we explore the\ncompetitiveness of online algorithms. We prove tight and near-tight bounds,\nseveral of which are achieved through novel constructions. In particular, we\nleverage the interplay between the unit processing time case of our problem and\nthe hypergraph coloring problem both ways: We use hypergraph coloring\ntechniques to steer an adversarial family of instances proving lower bounds,\nwhich in turn leads to lower bounds for several variants of online hypergraph\ncoloring.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Convex Optimization with Switching Cost with Only One Single Gradient Evaluation",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-online-convex-optimization-with-switching-cost-with-only-one-single-gradient-evaluation/",
      "content": "Authors: Harsh Shah, Purna Chandrasekhar, Rahul Vaze\n\nOnline convex optimization with switching cost is considered under the frugal\ninformation setting where at time $t$, before action $x_t$ is taken, only a\nsingle function evaluation and a single gradient is available at the previously\nchosen action $x_{t-1}$ for either the current cost function $f_t$ or the most\nrecent cost function $f_{t-1}$. When the switching cost is linear, online\nalgorithms with optimal order-wise competitive ratios are derived for the\nfrugal setting. When the gradient information is noisy, an online algorithm\nwhose competitive ratio grows quadratically with the noise magnitude is\nderived.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Maximizing the Margin between Desirable and Undesirable Elements in a Covering Problem",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-maximizing-the-margin-between-desirable-and-undesirable-elements-in-a-covering-problem/",
      "content": "Authors: Sophie Boileau, Andrew Hong, David Liben-Nowell, Alistair Pattison, Anna N. Rafferty, Charlie Roslansky\n\nIn many covering settings, it is natural to consider the simultaneous\npresence of desirable elements (that we seek to include) and undesirable\nelements (that we seek to avoid). This paper introduces a novel combinatorial\nproblem formalizing this tradeoff: from a collection of sets containing both\n“desirable” and “undesirable” items, pick the subcollection that maximizes the\nmargin between the number of desirable and undesirable elements covered. We\ncall this the Target Approximation Problem (TAP) and argue that many real-world\nscenarios are naturally modeled via this objective. We first show that TAP is\nhard, even when restricted to cases where the given sets are small or where\nelements appear in only a small number of sets. In a large subset of these\ncases, we show that TAP is hard to even approximate. We then exhibit exact\npolynomial-time algorithms for other restricted cases and provide an efficient\n0.5-approximation for the case where elements occur at most twice, derived\nthrough a tight connection to the greedy algorithm for Unweighted Set Cover.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Liar's vertex-edge domination in subclasses of chordal graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-liar-s-vertex-edge-domination-in-subclasses-of-chordal-graphs/",
      "content": "Authors: Debojyoti Bhattacharya, Subhabrata Paul\n\nLet $G=(V, E)$ be an undirected graph. The set $N_G[x]={y\\in V|xy\\in E}\\cup\n{x}$ is called the closed neighbourhood of a vertex $x\\in V$ and for an edge\n$e=xy\\in E$, the closed neighbourhood of $e$ is the set $N_G[x]\\cup N_G[y]$,\nwhich is denoted by $N_G[e]$ or $N_G[xy]$. A set $L\\subseteq V$ is called\n\\emph{liar’s vertex-edge dominating set} of a graph $G=(V,E)$ if for every\n$e_i\\in E$, $|N_G[e_i]\\cap L|\\geq 2$ and for every pair of distinct edges\n$e_i,e_j\\in E$, $|(N_G[e_i]\\cup N_G[e_j])\\cap L|\\geq 3$. The notion of liar’s\nvertex-edge domination arises naturally from some applications in communication\nnetworks. Given a graph $G$, the \\textsc{Minimum Liar’s Vertex-Edge Domination\nProblem} (\\textsc{MinLVEDP}) asks to find a liar’s vertex-edge dominating set\nof $G$ of minimum cardinality. In this paper, we study this problem from an\nalgorithmic point of view. We design two linear time algorithms for\n\\textsc{MinLVEDP} in block graphs and proper interval graphs, respectively. On\nthe negative side, we show that the decision version of liar’s vertex-edge\ndomination problem is NP-complete for undirected path graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Improved Algorithms for Effective Resistance Computation on Graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-improved-algorithms-for-effective-resistance-computation-on-graphs/",
      "content": "Authors: Yichun Yang, Rong-Hua Li, Meihao Liao, Guoren Wang\n\nEffective Resistance (ER) is a fundamental tool in various graph learning\ntasks. In this paper, we address the problem of efficiently approximating ER on\na graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ with $n$ vertices and $m$\nedges. First, we focus on local online-computation algorithms for ER\napproximation, aiming to improve the dependency on the approximation error\nparameter $\\epsilon$. Specifically, for a given vertex pair $(s,t)$, we propose\na local algorithm with a time complexity of $\\tilde{O}(\\sqrt{d}/\\epsilon)$ to\ncompute an $\\epsilon$-approximation of the $s,t$-ER value for expander graphs,\nwhere $d=\\min {d_s,d_t}$. This improves upon the previous state-of-the-art,\nincluding an $\\tilde{O}(1/\\epsilon^2)$ time algorithm based on random walk\nsampling by Andoni et al. (ITCS’19) and Peng et al. (KDD’21). Our method\nachieves this improvement by combining deterministic search with random walk\nsampling to reduce variance. Second, we establish a lower bound for ER\napproximation on expander graphs. We prove that for any $\\epsilon\\in (0,1)$,\nthere exist an expander graph and a vertex pair $(s,t)$ such that any local\nalgorithm requires at least $\\Omega(1/\\epsilon)$ time to compute the\n$\\epsilon$-approximation of the $s,t$-ER value. Finally, we extend our\ntechniques to index-based algorithms for ER computation. We propose an\nalgorithm with $\\tilde{O}(\\min {m+n/\\epsilon^{1.5},\\sqrt{nm}/\\epsilon})$\nprocessing time, $\\tilde{O}(n/\\epsilon)$ space complexity and $O(1)$ query\ncomplexity, which returns an $\\epsilon$-approximation of the $s,t$-ER value for\nany $s,t\\in \\mathcal{V}$ for expander graphs. Our approach improves upon the\nstate-of-the-art $\\tilde{O}(m/\\epsilon)$ processing time by Dwaraknath et al.\n(NeurIPS’24) and the $\\tilde{O}(m+n/\\epsilon^2)$ processing time by Li and\nSachdeva (SODA’23).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property Graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-hipermotif-novel-parallel-subgraph-isomorphism-in-large-scale-property-graphs/",
      "content": "Authors: Mohammad Dindoost, Oliver Alvarado Rodriguez, Bartosz Bryg, Ioannis Koutis, David A. Bader\n\nSubgraph isomorphism, essential for pattern detection in large-scale graphs,\nfaces scalability challenges in attribute-rich property graphs used in\nneuroscience, systems biology, and social network analysis. Traditional\nalgorithms explore search spaces vertex-by-vertex from empty mappings, leading\nto extensive early-stage exploration with limited pruning opportunities. We\nintroduce HiPerMotif, a novel hybrid parallel algorithm that fundamentally\nshifts the search initialization strategy. After structurally reordering the\npattern graph to prioritize high-degree vertices, HiPerMotif systematically\nidentifies all possible mappings for the first edge (vertices 0,1) in the\ntarget graph, validates these edge candidates using efficient vertex and edge\nvalidators, and injects the validated partial mappings as states at depth 2.\nThe algorithm then continues with traditional vertex-by-vertex exploration from\nthese pre-validated starting points, effectively pruning the expensive early\nsearch tree branches while enabling natural parallelization over edge\ncandidates. Our contributions include the edge-centric initialization paradigm\nwith state injection, a structural reordering strategy achieving up to 5x\nspeedup, rapid edge and vertex validators for attribute-rich graphs, and\nefficient parallel enumeration over target graph edges. Implemented in the\nopen-source Arachne framework, HiPerMotif achieves up to 66x speedup over\nstate-of-the-art baselines (VF2-PS, VF3P, Glasgow) on diverse datasets where\nbaselines successfully complete execution. Additionally, HiPerMotif\nsuccessfully processes massive datasets such as the H01 connectome with 147\nmillion edges, which existing methods cannot handle due to memory constraints.\nComprehensive evaluation across synthetic and real-world graphs demonstrates\nHiPerMotif’s scalability, enabling advanced analysis in computational\nneuroscience and beyond.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Heights of butterfly trees",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-heights-of-butterfly-trees/",
      "content": "Authors: John Peca-Medlin, Chenyang Zhong\n\nBinary search trees (BSTs) are fundamental data structures whose performance\nis largely governed by tree height. We introduce a block model for constructing\nBSTs by embedding internal BSTs into the nodes of an external BST – a\nstructure motivated by parallel data architectures – corresponding to\ncomposite permutations formed via Kronecker or wreath products. Extending\nDevroye’s result that the height $h_n$ of a random BST satisfies $h_n / \\log n\n\\to c^* \\approx 4.311$, we show that block BSTs with $nm$ nodes and fixed\nexternal size $m$ satisfy $h_{n,m} / \\log n \\to c^* + h_m$ in distribution. We\nthen analyze height growth under iterated products. For simple butterfly trees\n(from iterated Kronecker products of $S_2$), we give a full distributional\ndescription showing polynomial height growth: $\\mathbb{E}\nh_n^{\\operatorname{B}} = \\Theta(N^\\alpha)$ with $\\alpha \\approx 0.58496$. For\nnonsimple butterfly trees (from wreath products), we prove power-law bounds:\n$cN^\\alpha\\cdot (1 + o(1)) \\le \\mathbb{E} h_n^{\\operatorname{B}} \\le\ndN^\\beta\\cdot (1 + o(1))$, with $\\beta \\approx 0.913189$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Greedy Dynamic Matching",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-greedy-dynamic-matching/",
      "content": "Authors: Nick Arnosti, Felipe Simon\n\nWe study a foundational model of dynamic matching market with abandonment.\nThis model has been studied by Collina et al (2020) and Aouad and Saritac\n(2022), and many other papers have considered special cases. We compare the\nperformance of greedy policies – which identify a set of “acceptable” matches\nup front, and perform these matches as soon as possible – to that of an\nomniscient benchmark which knows the full arrival and departure sequence.\nWe use a novel family of linear programs ($LP^{ALG}$) to identify which\ngreedy policy to follow. We show that the value of $LP^ALG$ is a *lower bound*\non the value of the greedy policy that it identifies in two settings of\ninterest:\n-When all types have the same departure rate.\n-The bipartite case where types on the same side of the market have the same\ndeparture rate.\nThe proofs of these results use a new result (Lemma 1), which relates the\n*probability* that at least one agent from a set of types is present in the\nsystem to the expected number of such agents.\nWe also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rate\nearned by the omniscient policy (Proposition 4). Therefore, for both settings\nabove, our greedy policy provably earns at least half of the omniscient reward\nrate. This improves upon the bound of 1/8 from Collina (2020). In both settings\nour competitive ratio of 1/2 is the best possible: no online policy can provide\na better guarantee (Theorem 2).\nTo show these results we introduce a new linear program that upper bounds the\nobjective value of the omniscient policy (Proposition 3). This improves upon\nthe upper bounds presented by Collina et al (2020) and Kessel et al (2022).\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Distributed Approximation Algorithms for Minimum Dominating Set in Locally Nice Graphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-distributed-approximation-algorithms-for-minimum-dominating-set-in-locally-nice-graphs/",
      "content": "Authors: Marthe Bonamy, Cyril Gavoille, Timothé Picavet, Alexandra Wesolek\n\nWe give a new, short proof that graphs embeddable in a given Euler genus-$g$\nsurface admit a simple $f(g)$-round $\\alpha$-approximation distributed\nalgorithm for Minimum Dominating Set (MDS), where the approximation ratio\n$\\alpha \\le 906$. Using tricks from Heydt et al. [European Journal of\nCombinatorics (2025)], we in fact derive that $\\alpha \\le 34 +\\varepsilon$,\ntherefore improving upon the current state of the art of $24g+O(1)$ due to\nAmiri et al. [ACM Transactions on Algorithms (2019)]. It also improves the\napproximation ratio of $91+\\varepsilon$ due to Czygrinow et al. [Theoretical\nComputer Science (2019)] in the particular case of orientable surfaces.\nAll our distributed algorithms work in the deterministic LOCAL model. They do\nnot require any preliminary embedding of the graph and only rely on two things:\na LOCAL algorithm for MDS on planar graphs with uniform'' approximation\nguarantees and the knowledge that graphs embeddable in bounded Euler genus\nsurfaces have asymptotic dimension $2$.\nMore generally, our algorithms work in any graph class of bounded asymptotic\ndimension wheremost vertices’’ are locally in a graph class that admits a\nLOCAL algorithm for MDS with uniform approximation guarantees.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Decremental Greedy Polygons and Polyhedra Without Sharp Angles",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-decremental-greedy-polygons-and-polyhedra-without-sharp-angles/",
      "content": "Authors: David Eppstein\n\nWe show that the max-min-angle polygon in a planar point set can be found in\ntime $O(n\\log n)$ and a max-min-solid-angle convex polyhedron in a\nthree-dimensional point set can be found in time $O(n^2)$. We also study the\nmaxmin-angle polygonal curve in 3d, which we show to be $\\mathsf{NP}$-hard to\nfind if repetitions are forbidden but can be found in near-cubic time if\nrepeated vertices or line segments are allowed, by reducing the problem to\nfinding a bottleneck cycle in a graph. We formalize a class of problems on\nwhich a decremental greedy algorithm can be guaranteed to find an optimal\nsolution, generalizing our max-min-angle and bottleneck cycle algorithms,\ntogether with a known algorithm for graph degeneracy.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Combination generators with optimal cache utilization and communication free parallel execution",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-combination-generators-with-optimal-cache-utilization-and-communication-free-parallel-execution/",
      "content": "Authors: Xi He, Max. A. Little\n\nWe introduce an efficient and elegant combination generator for producing all\ncombinations of size less than or equal to K, designed for exhaustive\ngeneration and combinatorial optimization tasks. This generator can be\nimplemented to achieve what we define as optimal efficiency: constant amortized\ntime, optimal cache utilization, embarrassingly parallel execution, and a\nrecursive structure compatible with pruning-based search. These properties are\ndifficult to satisfy simultaneously in existing generators. For example,\nclassical Gray code or lexicographic generators are typically list-based and\nsequentially defined, making them difficult to vectorized, inefficient in cache\nusage, and inherently hard to parallelize. Generators based on unranking\nmethods, while easy to parallelize, are non-recursive. These limitations reduce\ntheir applicability in our target applications, where both computational\nefficiency and recursion are crucial. We adapt Bird’s algebra of\nprogramming-style calculation to derive our algorithms, a formalism for\ndeveloping correct-by-construction programs from specifications. As a result,\nall generators in this paper are first formulated in their clearest\nspecification, and efficient definitions are derived constructively through\nequational reasoning, resulting in concise and elegant divide-and-conquer\ndefinitions. Beyond presenting a combination generator, we extend our approach\nto construct generators for K-permutations, nested combinations of\ncombinations, and nested permutation-combination structures. To the best of our\nknowledge, the literature has not previously reported generators for these\nnested structures. We also develop sequential variants that produce\nconfigurations in Gray code-compatible orders – such as the revolving door\nordering – which are particularly useful for constructing nested generators.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Color Distance Oracles and Snippets: Separation Between Exact and Approximate Solutions",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-color-distance-oracles-and-snippets-separation-between-exact-and-approximate-solutions/",
      "content": "Authors: Noam Horowicz, Tsvi Kopelowitz\n\nIn the snippets problem, the goal is to preprocess text $T$ so that given two\npatterns $P_1$ and $P_2$, one can locate the occurrences of the two patterns in\n$T$ that are closest to each other, or report their distance. Kopelowitz and\nKrauthgamer [CPM2016] showed upper bound tradeoffs and conditional lower bounds\ntradeoffs for the snippets problem, by utilizing connections between the\nsnippets problem and the problem of constructing a color distance oracle (CDO),\nwhich is a data structure that preprocess a set of points with associated\ncolors so that given two colors $c$ and $c’$ one can quickly find the (distance\nbetween the) closest pair of points with colors $c$ and $c’$. However, the\nexisting upper bound and lower bound curves are not tight.\nInspired by recent advances by Kopelowitz and Vassilevska-Williams\n[ICALP2020] regarding Set-disjointness data structures, we introduce new\nconditionally optimal algorithms for $(1+\\varepsilon)$ approximation versions\nof the snippets problem and the CDO problem, by applying fast matrix\nmultiplication. For example, for CDO on $n$ points in an array with\npreprocessing time $\\tilde{O}(n^a)$ and query time $\\tilde{O}(n^b)$, assuming\nthat $\\omega=2$ (where $\\omega$ is the exponent of $n$ in the runtime of the\nfastest matrix multiplication algorithm on two squared matrices of size\n$n\\times n$), we show that approximate CDO can be solved with the following\ntradeoff\n\\(a + 2b = 2 \\text{ if } 0 \\leq b \\leq \\frac1 3\\) \\(2a + b = 3 \\text{ if }\n\\frac13\\leq b \\leq 1.\\)\nMoreover, we prove that for exact CDO on points in an array, the algorithm of\nKopelowitz and Krauthgamer [CPM2016], is essentially optimal assuming that the\nstrong APSP hypothesis holds for randomized algorithms. Thus, the exact version\nof CDO is strictly harder than the approximate version.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bicriteria approximation for $k$-edge-connectivity",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-bicriteria-approximation-for-k-edge-connectivity/",
      "content": "Authors: Zeev Nutov, Reut Cohen\n\nIn the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a\n(multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost\n$k$-edge-connected spanning subgraph of $G$. The problem admits a\n$2$-approximation algorithm and no better approximation ratio is known.\nRecently, Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria\n$(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected\nspanning subgraph of cost at most the optimal value of a standard Cut-LP for\n$k$-ECSS. We improve the bicriteria approximation to $(1,k-4)$, and also give\nanother non-trivial bicriteria approximation $(3/2,k-2)$. The\n$k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost the\nsame as $k$-ECSS, except that any edge can be selected multiple times at the\nsame cost. A $(1,k-p)$ bicriteria approximation for $k$-ECSS w.r.t. Cut-LP\nimplies approximation ratio $1+p/k$ for $k$-ECSM, hence our result also\nimproves the approximation ratio for $k$-ECSM.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Agentic Distributed Computing",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-agentic-distributed-computing/",
      "content": "Authors: Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma\n\nThe most celebrated and extensively studied model of distributed computing is\nthe {\\em message-passing model,} in which each vertex/node of the (distributed\nnetwork) graph corresponds to a static computational device that communicates\nwith other devices through passing messages. In this paper, we consider the\n{\\em agentic model} of distributed computing which extends the message-passing\nmodel in a new direction. In the agentic model, computational devices are\nmodeled as relocatable or mobile computational devices (called agents in this\npaper), i.e., each vertex/node of the graph serves as a container for the\ndevices, and hence communicating with another device requires relocating to the\nsame node. We study two fundamental graph level tasks, leader election, and\nminimum spanning tree, in the agentic model, which will enhance our\nunderstanding of distributed computation across paradigms. The objective is to\nminimize both time and memory complexities. Following the literature, we\nconsider the synchronous setting in which each agent performs its operations\nsynchronously with others, and hence the time complexity can be measured in\nrounds. In this paper, we present two deterministic algorithms for leader\nelection: one for the case of $k\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A simple algorithm for Combinatorial n-fold ILPs using the Steinitz Lemma",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-combinatorial-n-fold-ilps-using-the-steinitz-lemma/",
      "content": "Authors: Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi\n\nWe present an algorithm for a class of $n$-fold ILPs: whose existing\nalgorithms in literature typically (1) are based on the \\textit{augmentation\nframework} where one starts with an arbitrary solution and then iteratively\nmoves towards an optimal solution by solving appropriate programs; and (2)\nrequire solving a linear relaxation of the program. Combinatorial $n$-fold ILPs\nis a class introduced and studied by Knop et al. [MP2020] that captures several\nother problems in a variety of domains. We present a simple and direct\nalgorithm that solves Combinatorial $n$-fold ILPs with unbounded non-negative\nvariables via an application of the Steinitz lemma, a classic result regarding\nreordering of vectors. Depending on the structure of the input, we also improve\nupon the existing algorithms in literature in terms of the running time,\nthereby showing an improvement that mirrors the one shown by Rohwedder\n[ICALP2025] contemporaneously and independently.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A note on finding long directed cycles above the minimum degree bound in 2-connected digraphs",
      "url": "/cstheoryrss/2025/07/08/arxiv-data-structures-and-algorithms-a-note-on-finding-long-directed-cycles-above-the-minimum-degree-bound-in-2-connected-digraphs/",
      "content": "Authors: Jadwiga Czyżewska, Marcin Pilipczuk\n\nFor a directed graph $G$, let $\\mathrm{mindeg}(G)$ be the minimum among\nin-degrees and out-degrees of all vertices of $G$. It is easy to see that $G$\ncontains a directed cycle of length at least $\\mathrm{mindeg}(G)+1$. In this\nnote, we show that, even if $G$ is $2$-connected, it is NP-hard to check if $G$\ncontains a cycle of length at least $\\mathrm{mindeg}(G)+3$. This is in contrast\nwith recent algorithmic results of Fomin, Golovach, Sagunov, and Simonov [SODA\n2022] for analogous questions in undirected graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Testing for Renamability to Classes of Clause Sets",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-testing-for-renamability-to-classes-of-clause-sets/",
      "content": "Authors: Albert Brandl, Christian G. Fermüller, Gernot Salzer\n\nThis paper investigates the problem of testing clause sets for membership in\nclasses known from literature. In particular, we are interested in classes\ndefined via renaming: Is it possible to rename the predicates in a way such\nthat positive and negative literals satisfy certain conditions? We show that\nfor classes like Horn or OCC1N, the existence of such renamings can be decided\nin polynomial time, whereas the same problem is NP-complete for class PVD. The\ndecision procedures are based on hyper-resolution; if a renaming exists, it can\nbe extracted from the final saturated clause set.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: PFCS: Prime Factorization Cache System for Deterministic Data Relationship Discovery",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-pfcs-prime-factorization-cache-system-for-deterministic-data-relationship-discovery/",
      "content": "Authors: Duy Le\n\nCache systems fundamentally limit modern computing performance due to their\ninability to precisely capture data relationships. While achieving 85-92% hit\nrates, traditional systems rely on statistical heuristics that cannot guarantee\nrelationship discovery, leading to suboptimal prefetching and resource waste.\nWe present PFCS (Prime Factorization Cache System), which leverages the\nmathematical uniqueness of prime factorization to achieve deterministic\nrelationship discovery with zero false positives. PFCS assigns unique primes to\ndata elements and represents relationships as composite numbers, enabling the\nrecovery of perfect relationships through factorization. A comprehensive\nevaluation across database, ML, and HPC workloads demonstrates an average\nperformance improvement of x 6.2, 98.9% hit rates, and a 38% power reduction\ncompared to state-of-the-art systems. The mathematical foundation provides\nformal guarantees impossible with approximation-based approaches, establishing\na new paradigm for cache system design\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Low sets for counting functions",
      "url": "/cstheoryrss/2025/07/08/arxiv-computational-complexity-low-sets-for-counting-functions/",
      "content": "Authors: Yaroslav Ivanashev\n\nIn this paper, we characterize the classes of languages and functions that\nare low for counting function classes. The classes #P and GapP have their low\nclasses exactly characterized: Low(#P) = UP $\\cap$ coUP and Low(GapP) = SPP. We\nprove that Low(TotP) = P, Low(SpanP) = NP $\\cap$ coNP, and give\ncharacterizations of low function classes for #P, GapP, TotP, and SpanP. We\nestablish the relations between NPSVt, UPSVt, and the counting function\nclasses. For each of the inclusions between these classes we give an equivalent\ninclusion between language classes. We also prove that SpanP $\\subseteq$ GapP\nif and only if NP $\\subseteq$ SPP, and the inclusion GapP+ $\\subseteq$ SpanP\nimplies PH = $\\Sigma_{2}^{P}$. For the classes #P, GapP, TotP, and SpanP we\nsummarize the known results and prove that each of these classes is closed\nunder left composition with FP+ if and only if it collapses to its low class of\nfunctions.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: You keep using that word",
      "url": "/cstheoryrss/2025/07/07/ben-recht-you-keep-using-that-word/",
      "content": "\n\nA friend sent me a fun article in FT Alphaville by Bryce Elder showing how dogma doesn’t need to make sense to make money. The article hooked me from the get-go:\n\n\n  “The Virtue of Complexity in Return Prediction — co-authored by Bryan Kelly with Semyon Malamud and Kangying Zhou — found that complex machine-learning models were better than simple ones at predicting stock prices and building portfolios.”\n\n\n\n  “The finding was a big deal because it contradicted one of machine learning’s guiding principles, the bias-variance trade-off, which says the predictive power of models weakens as they grow beyond some optimum level. Given too many parameters to play with, a bot will tend to overfit its output to random noise in the training data.”\n\n\nOh, I’ve written about this before, arguing we should remove the bias-variance tradeoff from the machine learning curriculum. Much love to everyone who references the ye olde argmin blog in the comments over on Alphville. I appreciate the shoutouts! However, many of my friends in finance have told me that their data was where statistical overfitting, the type of overfitting we teach in our undergraduate classes, was a real phenomenon. Here is a paper that apparently refutes their claims. According to Kelly et al., even in finance, the bias-variance tradeoff isn’t real. Elder continues:\n\n\n  “The finding was rooted in an AI concept known as double descent, which says deep learning algorithms make fewer mistakes when they have more variable parameters than training data points.”\n\n\nDouble descent, you say? Hmm. At this point in the article, I got a bit worried because that’s… not what double descent says. Well, now I had to go and download the paper from SSRN. It checks in at a crisp 141 pages.\n\nOnce you skip past the laborious theoretical analysis of a linear Gaussian model, you get to the experiments on page 41. The authors want to predict next month’s prices from a set of 15 indicators. They use a window of past pairs of indicators and prices from the last 12 months to make this prediction. They propose applying standard supervised learning to solve this problem. Translating their setup into machine learning language: their training dataset has 12 examples, each with 15 features. Yes, 12.\n\nWhat do they conclude? They find that if they use random Fourier features, then the training error continues to decrease as they add more and more features. In particular, using 12,000 random Fourier features still gives good performance.\n\nOh my. I know it’s been twenty years since Ali and I first wrote up our paper on random features, and our point seems to have been lost in time.1 The motivation was finding computationally efficient ways to approximate machine learning in kernel spaces. I realize no one learns about kernel methods anymore, but you can read about them in Chapter 4 of Patterns, Predictions, and Actions. For the purpose of this post: kernel methods give you a computationally efficient way to compute a prediction model that uses an infinite number of features. Through some fun linear algebra, it turns out you only need to solve a linear system with one variable for every training example. Kernel methods transform infinite-dimensional learning problems into finite-dimensional linear algebra problems.\n\nStill, kernel methods require more computation than standard linear regression methods (and deep learning methods for that matter). The time needed to solve a linear system scales with the cube of the number of data points. The time required to solve linear regression scales linearly with the number of data points. Ali and I initially stumbled upon random features as a way to approximate kernel methods by solving linear regression problems.\n\nBut you know folks, kernel methods aren’t that computationally expensive. Cubic time is still polynomial time. And high-dimensional linear regression has its own scaling issues. The solution time of a random Fourier features problem scales with the square of the number of features.2 Since random features approximate kernel methods, the prediction performance of kernel methods should always be as good or better.3\n\nTo reiterate, kernel ridge regression solves an infinite-dimensional regression problem. It is going to get you the solution promised by the asymptote of that double descent curve you are all so enamored with. Infinity is more than 12,000, and moar is always better, right? If you find yourself using 1000 times more random features than data points, you might want to consider reading a few tutorials on kernel regression. It’s not hard to implement! In Python on my laptop, I can solve a 12 example kernel ridge regression problem in microseconds.\n\nThe argmin blog is here to help you save money on GPU cloud credits.\n\nNow you might ask, would “ridgeless kernel regression,” that is, kernel regression that ignores the warnings of the bias-variance tradeoff, work well for time series analysis? This is a good question, and one asked by Emmanuel Parzen in his landmark 1961 paper, “An Approach to Time Series Analysis.”4 Parzen’s paper is one of the first to explicitly use reproducing kernels in prediction problems. In Section 6, he proposes using ridgeless kernel regression to solve the exact same problem studied by Kelly and coauthors.\n\nI’m not the first person to recognize this, as Elder notes in Alphaville. Stefan Nagel wrote a convincing rebuttal to Kelly et al., posted last week. Nagel notes that random Fourier features are approximating kernel regression. He also notes that the prediction function computed by kernel regression looks a lot like kernel smoothing. This means the data points that most influence the prediction will be the ones most recent in time. Nagel thus argues that Kelly et al. are making a bunch of appeals to deep learning hype to reinvent momentum investing.\n\nAnd about that bias-variance tradeoff? If you slog through Kelly et al, you’ll see that their theoretical analysis has a bias-variance tradeoff! And the optimum setting requires tuning the tradeoff!\n\n\n  “We show that machine learning portfolios tend to incrementally benefit from moving away from the ridgeless limit by introducing nontrivial shrinkage.”\n\n\nSigh.\n\nI realize that everyone has jumped on the deep learning train now, but cargo culting isn’t in your interest. For small problems (like training sets of size 12), you don’t need neural networks. You can use them, I guess. But you can get more understanding out of these small, infinite-dimensional models that people have been studying for seventy years.\n\nSadly, the hype cycle gets everyone confused. It’s hilarious that stylized statistical learning theory stories now find their way into the mainstream press. The Alphaville title is even confused here: “Are bigger AI models better stock pickers? Maybe, but probably not. Complexity ain’t all that, wonks say.” I mean, this contradicts the rest of the story. First, calling ordinary least squares “AI” is a bit of a stretch. Second, Nagel’s results show that in this restricted class of models, bigger models are indeed better. Moreover, those infinitely large models recover well-known, naive momentum strategies.\n\nKelly and his fund, AQR, weren’t happy about Elder’s article. They wrote a rebuttal, proclaiming:\n\n\n  “The empirical dominance of large models has been shown in every area of ML by heavyweight ML academics’ research, which has been conducted throughout the natural and applied sciences. Language and image modeling are most well-known applications that exemplify the success of large models. Do we really think that finance, economics, or other social sciences are special? The work of Kelly and team shows otherwise.”\n\n\nThis heavyweight ML academic offers a very reasonable consulting fee if you are at a hedge fund and need assistance understanding double descent and the no true Scotsman fallacy.\n\nSubscribe now\n\n1\n\n…like tears in rain.\n\n2\n\nYeah, you can do some stochastic gradient stuff to get that square down to linear, but let me not bore everyone with flop counting. We can save that for a more technical post.\n\n3\n\nI realize theory and practice don’t always align, but in my experience, this is always true.\n\n4\n\nWhat a title. Such modesty with indefinite articles would get you immediately desk rejected at NeurIPS.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Happy Birthday Saharon Shelah and Yuri Gurevich!",
      "url": "/cstheoryrss/2025/07/07/gil-kalai-happy-birthday-saharon-shelah-and-yuri-gurevich/",
      "content": "Let me briefly report on two birthday conferences for long-time friends and colleagues Saharon Shelah and Yuri Gurevich. Yuri fest took place in Munich and on Zoom between June 20–22 2025 and Shelah’s birthday conference will be held in Vienna on July 14–15, 2025.\n\n\n\nFor my general thoughts on celebrating colleagues’ birthdays in these tragic and dangerous times, see this post.\n\nSaharon Shelah is among the greatest and most decorated mathematicians of our time with groundbreaking contributions in model theory, set theory, combinatorics, and other areas. Among his most famous achievements are  the development of classification theory in model theory, his arithmetic cardinal theory (see this post), his proof that Whitehead’s conjecture is independent from ZFC, and his effective bounds for Van der Waerden numbers in combinatorics.\n\nYuri Gurevich is a renowned mathematical logician who transitioned to theoretical and practical computer science, software engineering, and later, quantum computing. One of the most natural average-case complete problems was introduced in a paper by Andreas Blass and Yuri Gurevich. (Andreas and Yuri have been long-time collaborators and friends.) Saharon and Yuri also coauthored a few important papers, including one on monadic second-order theories.\n\nI’ve known both Saharon and Yuri since the late 1970s. Over the years, I would occasionally visit Saharon’s office (and now that I think about it, I should have taken a picture of it) to discuss interesting problems. These conversations contributed to Saharon’s generalization of Arrow’s theorem and to his work with Micha Perles on “n-convexity.” Once, Saharon asked me to comment on an introduction for the general mathematical audience to his second book on classification theory. In 1994, Saharon and I shared the Pólya Prize in Combinatorics. My daughter was a classmate of Saharon’s son, so we also met occasionally at school events.\n\nMy friendship with Yuri began at Microsoft in the late 1990s. As a complete layman, I was fascinated by his approach to software engineering, which had a major impact on Microsoft. Yuri, in turn, was interested in my views on quantum computing—well before he became an active researcher in the field in 2013—and we discussed the topic frequently over the years. We also shared an interest in detecting deception using mathematical tools (see this post by Omer Reingold on his approach).\n\nHeartfelt congratulations to Saharon and Yuri!\n\nRonald de Wolf’s lecture on quantum proofs to classical theorems.\n\nAt YuriFest, Ronald de Wolf gave a great lecture on quantum proofs for classical theorems (the audio is a bit weak—turn the volume to 100%). One of his examples is discussed in this post. Yuri himself gave a wonderful talk titled The nature of nondeterministic probabilistic, quantum, etc. algorithms.\n\nReminder: Joram’s seminar on hypercontractivity and groups, Wednesday and Thursday, July 9 and 10, 2025.\n\nBy Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Approximability of Train Routing and the Min-Max Disjoint Paths Problem",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-on-the-approximability-of-train-routing-and-the-min-max-disjoint-paths-problem/",
      "content": "Authors: Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch\n\nIn train routing, the headway is the minimum distance that must be maintained\nbetween successive trains for safety and robustness. We introduce a model for\ntrain routing that requires a fixed headway to be maintained between trains,\nand study the problem of minimizing the makespan, i.e., the arrival time of the\nlast train, in a single-source single-sink network. For this problem, we first\nshow that there exists an optimal solution where trains move in convoys, that\nis, the optimal paths for any two trains are either the same or are\narc-disjoint. Via this insight, we are able to reduce the approximability of\nour train routing problem to that of the min-max disjoint paths problem, which\nasks for a collection of disjoint paths where the maximum length of any path in\nthe collection is as small as possible. While min-max disjoint paths inherits a\nstrong inapproximability result on directed acyclic graphs from the multi-level\nbottleneck assignment problem, we show that a natural greedy composition\napproach yields a logarithmic approximation in the number of disjoint paths for\nseries-parallel graphs. We also present an alternative analysis of this\napproach that yields a guarantee depending on how often the decomposition tree\nof the series-parallel graph alternates between series and parallel\ncompositions on any root-leaf path.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Going Beyond Surfaces in Diameter Approximation",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-going-beyond-surfaces-in-diameter-approximation/",
      "content": "Authors: Michał Włodarczyk\n\nCalculating the diameter of an undirected graph requires quadratic running\ntime under the Strong Exponential Time Hypothesis and this barrier works even\nagainst any approximation better than 3/2. For planar graphs with positive edge\nweights, there are known $(1+\\varepsilon)$-approximation algorithms with\nrunning time $poly(1/\\epsilon, \\log n) \\cdot n$. However, these algorithms rely\non shortest path separators and this technique falls short to yield efficient\nalgorithms beyond graphs of bounded genus.\nIn this work we depart from embedding-based arguments and obtain diameter\napproximations relying on VC set systems and the local treewidth property. We\npresent two orthogonal extensions of the planar case by giving\n$(1+\\varepsilon)$-approximation algorithms with the following running times:\n\n  $O_h((1/\\varepsilon)^{O(h)} \\cdot n \\log^2 n)$-time algorithm for graphs\nexcluding an apex graph of size h as a minor,\n  $O_d((1/\\varepsilon)^{O(d)} \\cdot n \\log^2 n)$-time algorithm for the\nclass of d-apex graphs.\nAs a stepping stone, we obtain efficient (1+\\varepsilon)-approximate distance\noracles for graphs excluding an apex graph of size h as a minor. Our oracle has\npreprocessing time $O_h((1/\\varepsilon)^8\\cdot n \\log n \\log W)$ and query time\n$O((1/\\varepsilon)^2 * \\log n \\log W)$, where $W$ is the metric stretch. Such\noracles have been so far only known for bounded genus graphs. All our\nalgorithms are deterministic.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Discovering Algorithms with Computational Language Processing",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-discovering-algorithms-with-computational-language-processing/",
      "content": "Authors: Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai\n\nAlgorithms are the engine for reproducible problem-solving. We present a\nframework automating algorithm discovery by conceptualizing them as sequences\nof operations, represented as tokens. These computational tokens are chained\nusing a grammar, enabling the formation of increasingly sophisticated\nprocedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement\nlearning (RL) explores token chaining and drives the creation of new tokens.\nThis methodology rediscovers, improves, and generates new algorithms that\nsubstantially outperform existing methods for strongly NP-hard combinatorial\noptimization problems and foundational quantum computing approaches such as\nGrover’s and Quantum Approximate Optimization Algorithm. Operating at the\ncomputational rather than code-generation level, our framework produces\nalgorithms that can be tailored specifically to problem instances, not merely\nclasses.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bayesian Optimal Stopping with Maximum Value Knowledge",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-bayesian-optimal-stopping-with-maximum-value-knowledge/",
      "content": "Authors: Pieter Kleer, Daan Noordenbos\n\nWe consider an optimal stopping problem with n correlated offers where the\ngoal is to design a (randomized) stopping strategy that maximizes the expected\nvalue of the offer in the sequence at which we stop. Instead of assuming to\nknow the complete correlation structure, which is unrealistic in practice, we\nonly assume to have knowledge of the distribution of the maximum value of the\nsequence, and want to analyze the worst-case correlation structure whose\nmaximum follows this distribution. This can be seen as a trade-off between the\nsetting in which no distributional information is known, and the Bayesian\nsetting in which the (possibly correlated) distributions of all the individual\noffers are known. As our first main result we show that a deterministic\nthreshold strategy using the monopoly price of the distribution of the maximum\nvalue is asymptotically optimal assuming that the expectation of the maximum\nvalue grows sublinearly in n. In our second main result, we further tighten\nthis bound by deriving a tight quadratic convergence guarantee for sufficiently\nsmooth distributions of the maximum value. Our results also give rise to a more\nfine-grained picture regarding prophet inequalities with correlated values, for\nwhich distribution-free bounds often only yield a performance guarantee that is\nof the order 1/n.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Barvinok's interpolation method meets Weitz's correlation decay approach",
      "url": "/cstheoryrss/2025/07/07/arxiv-data-structures-and-algorithms-barvinok-s-interpolation-method-meets-weitz-s-correlation-decay-approach/",
      "content": "Authors: Ferenc Bencs, Guus Regts\n\nIn this paper we take inspiration from Weit’z algorithm for approximating the\nindependence polynomial to provide a new algorithm for computing the\ncoefficients of the Taylor series of the logarithm of the independence\npolynomial. Hereby we provide a clear connections between Barvinok’s\ninterpolation method and Weitz’s algorithm. Our algorithm easily extends to\nother graph polynomials and partition functions and we illustrate this by\napplying it to the chromatic polynomial and to the graph homomorphism partition\nfunction. Our approach arguably yields a simpler and more transparent algorithm\nthan the algorithm of Patel and the second author.\nAs an application of our algorithmic approach we moreover derive, using the\ninterpolation method, a deterministic $O(n(m/\\varepsilon)^{7})$-time algorithm\nthat on input of an $n$-vertex and $m$-edge graph of minimum degree at least\n$3$ and $\\varepsilon&gt;0$ approximately computes the number of sink-free\norientations of $G$ up to a multiplicative $\\exp(\\varepsilon)$ factor.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Quantum Computation with Correlated Measurements: Implications for the Complexity Landscape",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-quantum-computation-with-correlated-measurements-implications-for-the-complexity-landscape/",
      "content": "Authors: David Miloschewsky, Supartha Podder\n\nIn 2004, Aaronson introduced the complexity class $\\mathsf{PostBQP}$\n($\\mathsf{BQP}$ with postselection) and showed that it is equal to\n$\\mathsf{PP}$. In this paper, we define a new complexity class,\n$\\mathsf{CorrBQP}$, a modification of $\\mathsf{BQP}$ which has the power to\nperform correlated measurements, i.e. measurements that output the same value\nacross a partition of registers. We show that $\\mathsf{CorrBQP}$ is exactly\nequal to $\\mathsf{BPP}^{\\mathsf{PP}}$, placing it “just above” $\\mathsf{PP}$.\nIn fact, we show that other metaphysical modifications of $\\mathsf{BQP}$, such\nas $\\mathsf{CBQP}$ (i.e. $\\mathsf{BQP}$ with the ability to clone arbitrary\nquantum states), are also equal to $\\mathsf{BPP}^{\\mathsf{PP}}$. Furthermore,\nwe show that $\\mathsf{CorrBQP}$ is self-low with respect to classical queries.\nIn contrast, if it were self-low under quantum queries, the counting hierarchy\n($\\mathsf{CH}$) would collapse to $\\mathsf{BPP}^{\\mathsf{PP}}$. Finally, we\nintroduce a variant of rational degree that lower-bounds the query complexity\nof $\\mathsf{BPP}^{\\mathsf{PP}}$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Complexity of learning matchings and half graphs via edge queries",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-complexity-of-learning-matchings-and-half-graphs-via-edge-queries/",
      "content": "Authors: Nikhil S. Mande, Swagato Sanyal, Viktor Zamaraev\n\nThe problem of learning or reconstructing an unknown graph from a known\nfamily via partial-information queries arises as a mathematical model in\nvarious contexts. The most basic type of access to the graph is via \\emph{edge\nqueries}, where an algorithm may query the presence/absence of an edge between\na pair of vertices of its choosing, at unit cost.\nWhile more powerful query models have been extensively studied in the context\nof graph reconstruction, the basic model of edge queries seems to have not\nattracted as much attention. In this paper we study the edge query complexity\nof learning a hidden bipartite graph, or equivalently its bipartite adjacency\nmatrix, in the classical as well as quantum settings. We focus on learning\nmatchings and half graphs, which are graphs whose bipartite adjacency matrices\nare a row/column permutation of the identity matrix and the lower triangular\nmatrix with all entries on and below the principal diagonal being 1,\nrespectively.\n\\begin{itemize}\n\\item For matchings of size $n$, we show a tight deterministic bound of\n$n(n-1)/2$ and an asymptotically tight randomized bound of $\\Theta(n^2)$. A\nquantum bound of $\\Theta(n^{1.5})$ was shown in a recent work of van Apeldoorn\net al.~[ICALP’21].\n\\item For half graphs whose bipartite adjacency matrix is a\ncolumn-permutation of the $n \\times n$ lower triangular matrix,\nwe give tight $\\Theta(n \\log n)$ bounds in both deterministic and randomized\nsettings, and an $\\Omega(n)$ quantum lower bound. \\item For general half\ngraphs,\nwe observe that the problem is equivalent to a natural generalization of the\nfamous nuts-and-bolts problem, leading to a tight $\\Theta(n \\log n)$ randomized\nbound.\nWe also present a simple quicksort-style method that instantiates to a $O(n\n\\log^2 n)$ randomized algorithm and a tight $O(n \\log n)$ quantum algorithm.\n\\end{itemize}\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Are Depth-2 Regular Expressions Hard to Intersect?",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-are-depth-2-regular-expressions-hard-to-intersect/",
      "content": "Authors: Rocco Ascone, Giulia Bernardini, Alessio Conte, Veronica Guerrini, Giulia Punzi\n\nWe study the basic regular expression intersection testing problem, which\nasks to determine whether the intersection of the languages of two regular\nexpressions is nonempty. A textbook solution to this problem is to construct\nthe nondeterministic finite automaton that accepts the language of both\nexpressions. This procedure results in a $\\Theta(mn)$ running time, where $m$\nand $n$ are the sizes of the two expressions, respectively. Following the\napproach of Backurs and Indyk [FOCS’16] and Bringmann, Gr{\\o}nlund, and Larsen\n[FOCS’17] on regular expression matching and membership testing, we study the\ncomplexity of intersection testing for homogeneous regular expressions of\nbounded depth involving concatenation, OR, Kleene star, and Kleene plus.\nSpecifically, we consider all combinations of types of depth-2 regular\nexpressions and classify the time complexity of intersection testing as either\nlinear or quadratic, assuming SETH. The most interesting result is a quadratic\nconditional lower bound for testing the intersection of a ‘‘concatenation of\n+s’’ expression with a ‘‘concatenation of ORs’’ expression: this is the only\nhard case that does not involve the Kleene star operator and is not implied by\nexisting lower bounds for the simpler membership testing problem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: A Near-Optimal Polynomial Distance Lemma Over Boolean Slices",
      "url": "/cstheoryrss/2025/07/07/arxiv-computational-complexity-a-near-optimal-polynomial-distance-lemma-over-boolean-slices/",
      "content": "Authors: Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan\n\nThe celebrated Ore-DeMillo-Lipton-Schwartz-Zippel (ODLSZ) lemma asserts that\nn-variate non-zero polynomial functions of degree d over a field $\\mathbb{F}$\nare non-zero over any “grid” $S^n$ for finite subset $S \\subseteq \\mathbb{F}$,\nwith probability at least $\\max{|S|^{-d/(|S|-1)},1-d/|S|}$ over the choice of\nrandom point from the grid. In particular, over the Boolean cube ($S = {0,1}\n\\subseteq \\mathbb{F}$), the lemma asserts non-zero polynomials are non-zero\nwith probability at least $2^{-d}$. In this work we extend the ODLSZ lemma\noptimally (up to lower-order terms) to “Boolean slices” i.e., points of Hamming\nweight exactly $k$. We show that non-zero polynomials on the slice are non-zero\nwith probability $(t/n)^{d}(1 - o_{n}(1))$ where $t = \\min{k,n-k}$ for every\n$d\\leq k\\leq (n-d)$. As with the ODLSZ lemma, our results extend to polynomials\nover Abelian groups. This bound is tight (upto the error term) as evidenced by\ndegree d multilinear monomials. A particularly interesting case is the\n“balanced slice” ($k=n/2$) where our lemma asserts that non-zero polynomials\nare non-zero with roughly the same probability on the slice as on the whole\ncube.\nThe behaviour of low-degree polynomials over Boolean slices has received much\nattention in recent years. However, the problem of proving a tight version of\nthe ODLSZ lemma does not seem to have been considered before, except for a\nrecent work of Amireddy, Behera, Paraashar, Srinivasan and Sudan (SODA 2025)\nwho established a sub-optimal bound of approximately $((k/n)\\cdot(1-(k/n)))^d$\nusing a proof similar to that of the standard ODLSZ lemma.\nWhile the statement of our result mimics that of the ODLSZ lemma, our proof\nis significantly more intricate and involves spectral reasoning which is\nemployed to show that a natural way of embedding a copy of the Boolean cube\ninside a balanced Boolean slice is a good sampler.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: The New Lower Bound on Busy Beaver of 6.",
      "url": "/cstheoryrss/2025/07/06/computational-complexity-the-new-lower-bound-on-busy-beaver-of-6/",
      "content": " We denote the busy beaver function by BB.\n\nBB(n) is the max time a Turing machine of size n takes to halt on the empty string.\n\n(A particular model of TM and a notion of size has become standardized.)\n\nBB(n) grows faster than any computable function. That is obviously interesting. What is less obvious (and  some of my co-bloggers disagree) the pursuit of actual values of BB is interesting. For an excellent overview of the BB numbers, written in 2020 (that is relevant) by Scott Aaronson, see here. (Computable and Aaronson are flagged by my spell check but I think they are spelled correctly.)\n\nWhen Scott’s article appeared, BB(5) was not known. In June 2024 the value of BB(5) was discovered.  See Scott’s blog on this, here. The value of BB(5) isn’t even that big- its just 47,176,870. That’s one of those numbers that is SMALL now but would have been LARGE in (say) 1964 (see my blog about a different number of that type here).\n\nWhat about BB(6)?\n\nNo, I am not going to announce that Scott announced it is now known.\n\nI am going to announced that Scott announced better lower bounds for BB(6) are now known.\n\nI won’t restate the lower bounds since (a) Scott already has, and (b) typesetting the bounds is hard (for me).\n\nSO, what to make of all this?\n\n1) At the time of Scott’s article it looked like BB(6) was large. How large was hard to say. Intuitions about how large BB(6) would be are hard to come by, so the new result is neither surprising nor unsurprising.\n\n2) We will never know BB(6). Shucky Darns!\n\n3) Many of the results on BB are not published in refereed journals. However, the ones mentioned in the context of BB(5) and BB(6) were verified in Coq.  I doubt other parts of math could take this approach;  however, it is interesting that results can be verified via computer in this field. Indeed- I doubt  referee could verify the results without a computer aid.\n\n4) Why the interest in BB? Some speculation\n\na) Computing power is such that one can actually get out some results (read Scott’s blog on BB(5) for more on that).\n\nb) The internet: there are not that many people working on BB but those that are can easily communicate with each other.\n\nc) Scott’s article and his blog posts on it helped generate interest. Since I asked Scott to write the article for my open problems column, I get some credit here also (very little).\n\nd) Results generate interest, and interest generates results.\n\ne) Items a,b,c,d,e all help to reinforce each other.\n\nBy gasarch\n\nRead original post\n"
    },
    
    {
      "title": "ECCC Papers: TR25-088 |  Factorization norms and an inverse theorem for MaxCut |\nIgor Balla,\nLianna Hambardzumyan,\nIstvan Tomon",
      "url": "/cstheoryrss/2025/07/06/eccc-papers-tr25-088-factorization-norms-and-an-inverse-theorem-for-maxcut-igor-balla-lianna-hambardzumyan-istvan-tomon/",
      "content": "We prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded normalized trace norm must contain a linear-sized all-ones or all-zeros submatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also present further structural results about Boolean matrices of bounded $\\gamma_2$-norm and discuss applications in communication complexity, operator theory, spectral graph theory, and extremal combinatorics.\nAs a key application, we establish an inverse theorem for MaxCut. A celebrated result of Edwards states that every graph $G$ with $m$ edges has a cut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality achieved by complete graphs with an odd number of vertices. To contrast this, we prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then $G$ must contain a clique of size $\\Omega(\\sqrt{m})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Online Conformal Prediction with Efficiency Guarantees",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-online-conformal-prediction-with-efficiency-guarantees/",
      "content": "Authors: Vaidehi Srinivas\n\nWe study the problem of conformal prediction in a novel online framework that\ndirectly optimizes efficiency. In our problem, we are given a target\nmiscoverage rate $\\alpha &gt; 0$, and a time horizon $T$. On each day $t \\le T$ an\nalgorithm must output an interval $I_t \\subseteq [0, 1]$, then a point $y_t \\in\n[0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is,\n$y_t \\in I_t$ on (close to) a $(1 - \\alpha)$-fraction of days, while\nmaintaining efficiency, that is, minimizing the average volume (length) of the\nintervals played. This problem is an online analogue to the problem of\nconstructing efficient confidence intervals.\nWe study this problem over arbitrary and exchangeable (random order) input\nsequences. For exchangeable sequences, we show that it is possible to construct\nintervals that achieve coverage $(1 - \\alpha) - o(1)$, while having length\nupper bounded by the best fixed interval that achieves coverage in hindsight.\nFor arbitrary sequences however, we show that any algorithm that achieves a\n$\\mu$-approximation in average length compared to the best fixed interval\nachieving coverage in hindsight, must make a multiplicative factor more\nmistakes than $\\alpha T$, where the multiplicative factor depends on $\\mu$ and\nthe aspect ratio of the problem. Our main algorithmic result is a matching\nalgorithm that can recover all Pareto-optimal settings of $\\mu$ and number of\nmistakes. Furthermore, our algorithm is deterministic and therefore robust to\nan adaptive adversary.\nThis gap between the exchangeable and arbitrary settings is in contrast to\nthe classical online learning problem. In fact, we show that no single\nalgorithm can simultaneously be Pareto-optimal for arbitrary sequences and\noptimal for exchangeable sequences. On the algorithmic side, we give an\nalgorithm that achieves the near-optimal tradeoff between the two cases.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Structure of Replicable Hypothesis Testers",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-structure-of-replicable-hypothesis-testers/",
      "content": "Authors: Anders Aamand, Maryam Aliakbarpour, Justin Y. Chen, Shyam Narayanan, Sandeep Silwal\n\nA hypothesis testing algorithm is replicable if, when run on two different\nsamples from the same distribution, it produces the same output with high\nprobability. This notion, defined by by Impagliazzo, Lei, Pitassi, and Sorell\n[STOC’22], can increase trust in testing procedures and is deeply related to\nalgorithmic stability, generalization, and privacy. We build general tools to\nprove lower and upper bounds on the sample complexity of replicable testers,\nunifying and quantitatively improving upon existing results.\nWe identify a set of canonical properties, and prove that any replicable\ntesting algorithm can be modified to satisfy these properties without worsening\naccuracy or sample complexity. A canonical replicable algorithm computes a\ndeterministic function of its input (i.e., a test statistic) and thresholds\nagainst a uniformly random value in $[0,1]$. It is invariant to the order in\nwhich the samples are received, and, if the testing problem is ``symmetric,’’\nthen the algorithm is also invariant to the labeling of the domain elements,\nresolving an open question by Liu and Ye [NeurIPS’24]. We prove new lower\nbounds for uniformity, identity, and closeness testing by reducing to the case\nwhere the replicable algorithm satisfies these canonical properties.\nWe systematize and improve upon a common strategy for replicable algorithm\ndesign based on test statistics with known expectation and bounded variance.\nOur framework allow testers which have been extensively analyzed in the\nnon-replicable setting to be made replicable with minimal overhead. As direct\napplications of our framework, we obtain constant-factor optimal bounds for\ncoin testing and closeness testing and get replicability for free in a large\nparameter regime for uniformity testing.\nWe also give state-of-the-art bounds for replicable Gaussian mean testing,\nand, unlike prior work, our algorithm runs in polynomial time.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-complexity-of-knapsack-under-explorable-uncertainty-hardness-and-algorithms/",
      "content": "Authors: Jens Schlöter\n\nIn the knapsack problem under explorable uncertainty, we are given a knapsack\ninstance with uncertain item profits. Instead of having access to the precise\nprofits, we are only given uncertainty intervals that are guaranteed to contain\nthe corresponding profits. The actual item profit can be obtained via a query.\nThe goal of the problem is to adaptively query item profits until the revealed\ninformation suffices to compute an optimal (or approximate) solution to the\nunderlying knapsack instance. Since queries are costly, the objective is to\nminimize the number of queries.\nIn the offline variant of this problem, we assume knowledge of the precise\nprofits and the task is to compute a query set of minimum cardinality that a\nthird party without access to the profits could use to identify an optimal (or\napproximate) knapsack solution. We show that this offline variant is complete\nfor the second-level of the polynomial hierarchy, i.e., $\\Sigma_2^p$-complete,\nand cannot be approximated within a non-trivial factor unless $\\Sigma_2^p =\n\\Delta_2^p$. Motivated by these strong hardness results, we consider a\nresource-augmented variant of the problem where the requirements on the query\nset computed by an algorithm are less strict than the requirements on the\noptimal solution we compare against. More precisely, a query set computed by\nthe algorithm must reveal sufficient information to identify an approximate\nknapsack solution, while the optimal query set we compare against has to reveal\nsufficient information to identify an optimal solution. We show that this\nresource-augmented setting allows interesting non-trivial algorithmic results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the Adversarial Robustness of Online Importance Sampling",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-on-the-adversarial-robustness-of-online-importance-sampling/",
      "content": "Authors: Yotam Kenneth-Mordoch, Shay Sapir\n\nThis paper studies the adversarial-robustness of importance-sampling (aka\nsensitivity sampling); a useful algorithmic technique that samples elements\nwith probabilities proportional to some measure of their importance. A\nstreaming or online algorithm is called adversarially-robust if it succeeds\nwith high probability on input streams that may change adaptively depending on\nprevious algorithm outputs. Unfortunately, the dependence between stream\nelements breaks the analysis of most randomized algorithms, and in particular\nthat of importance-sampling algorithms. Previously, Braverman et al. [NeurIPS\n2021] suggested that streaming algorithms based on importance-sampling may be\nadversarially-robust; however, they proved it only for well-behaved inputs.\nWe focus on the adversarial-robustness of online importance-sampling, a\nnatural variant where sampling decisions are irrevocable and made as data\narrives. Our main technical result shows that, given as input an adaptive\nstream of elements $x_1,\\ldots,x_T\\in \\mathbb{R}_+$, online importance-sampling\nmaintains a $(1\\pm\\epsilon)$-approximation of their sum while matching (up to\nlower order terms) the storage guarantees of the oblivious (non-adaptive) case.\nWe then apply this result to develop adversarially-robust online algorithms for\ntwo fundamental problems: hypergraph cut sparsification and $\\ell_p$ subspace\nembedding.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Numerical Linear Algebra in Linear Space",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-numerical-linear-algebra-in-linear-space/",
      "content": "Authors: Yiping Liu, Hoai-An Nguyen, Junzhao Yang\n\nWe present a randomized linear-space solver for general linear systems\n$\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ with $\\mathbf{A} \\in \\mathbb{Z}^{n \\times\nn}$ and $\\mathbf{b} \\in \\mathbb{Z}^n$, without any assumption on the condition\nnumber of $\\mathbf{A}$. For matrices whose entries are bounded by\n$\\mathrm{poly}(n)$, the solver returns a $(1+\\epsilon)$-multiplicative\nentry-wise approximation to vector $\\mathbf{x} \\in \\mathbb{Q}^{n}$ using\n$\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ bit operations and $O(n\n\\log n)$ bits of working space (i.e., linear in the size of a vector), where\n$\\mathrm{nnz}$ denotes the number of nonzero entries. Our solver works for\nright-hand vector $\\mathbf{b}$ with entries up to $n^{O(n)}$. To our knowledge,\nthis is the first linear-space linear system solver over the rationals that\nruns in $\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ time.\nWe also present several applications of our solver to numerical linear\nalgebra problems, for which we provide algorithms with efficient polynomial\nrunning time and near-linear space. In particular, we present results for\nlinear regression, linear programming, eigenvalues and eigenvectors, and\nsingular value decomposition.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: New algorithms for girth and cycle detection",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-new-algorithms-for-girth-and-cycle-detection/",
      "content": "Authors: Liam Roditty, Plia Trabelsi\n\nLet $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$\nedges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in\n$G$. We present a randomized algorithm with a running time of\n$\\tilde{O}\\big(\\ell \\cdot n^{1 + \\frac{1}{\\ell - \\varepsilon}}\\big)$ that\nreturns a cycle of length at most $ 2\\ell \\left\\lceil \\frac{g}{2} \\right\\rceil\n\n  2 \\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil\n\\right\\rfloor, $ where $\\ell \\geq 2$ is an integer and $\\varepsilon \\in [0,1]$,\nfor every graph with $g = polylog(n)$.\nOur algorithm generalizes an algorithm of Kadria \\etal{} [SODA’22] that\ncomputes a cycle of length at most $4\\left\\lceil \\frac{g}{2} \\right\\rceil -\n2\\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil \\right\\rfloor $\nin $\\tilde{O}\\big(n^{1 + \\frac{1}{2 - \\varepsilon}}\\big)$ time. Kadria \\etal{}\npresented also an algorithm that finds a cycle of length at most $ 2\\ell\n\\left\\lceil \\frac{g}{2} \\right\\rceil $ in $\\tilde{O}\\big(n^{1 +\n\\frac{1}{\\ell}}\\big)$ time, where $\\ell$ must be an integer. Our algorithm\ngeneralizes this algorithm, as well, by replacing the integer parameter $\\ell$\nin the running time exponent with a real-valued parameter $\\ell - \\varepsilon$,\nthereby offering greater flexibility in parameter selection and enabling a\nbroader spectrum of combinations between running times and cycle lengths.\nWe also show that for sparse graphs a better tradeoff is possible, by\npresenting an $\\tilde{O}(\\ell\\cdot m^{1+1/(\\ell-\\varepsilon)})$ time randomized\nalgorithm that returns a cycle of length at most $2\\ell(\\lfloor\n\\frac{g-1}{2}\\rfloor) - 2(\\lfloor \\varepsilon \\lfloor \\frac{g-1}{2}\\rfloor\n\\rfloor+1)$, where $\\ell\\geq 3$ is an integer and $\\varepsilon\\in [0,1)$, for\nevery graph with $g=polylog(n)$.\nTo obtain our algorithms we develop several techniques and introduce a formal\ndefinition of hybrid cycle detection algorithms. […]\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Indexing Tries within Entropy-Bounded Space",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-indexing-tries-within-entropy-bounded-space/",
      "content": "Authors: Lorenzo Carfagna, Carlo Tosoni\n\nWe study the problem of indexing and compressing tries using a BWT-based\napproach. Specifically, we consider a succinct and compressed representation of\nthe XBWT of Ferragina et al.\\ [FOCS ‘05, JACM ‘09] corresponding to the\nanalogous of the FM-index [FOCS ‘00, JACM ‘05] for tries. This representation\nallows to efficiently count the number of nodes reached by a given string\npattern. To analyze the space complexity of the above trie index, we propose a\nproof for the combinatorial problem of counting the number of tries with a\ngiven symbol distribution. We use this formula to define a worst-case entropy\nmeasure for tries, as well as a notion of k-th order empirical entropy. In\nparticular, we show that the relationships between these two entropy measures\nare similar to those between the corresponding well-known measures for strings.\nWe use these measures to prove that the XBWT of a trie can be encoded within a\nspace bounded by our k-th order empirical entropy plus a o(n) term, with n\nbeing the number of nodes in the trie. Notably, as happens for strings, this\nspace bound can be reached for every sufficiently small k simultaneously.\nFinally, we compare the space complexity of the above index with that of the\nr-index for tries proposed by Prezza [SODA ‘21] and we prove that in some cases\nthe FM-index for tries is asymptotically smaller.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-faster-algorithm-for-bounded-tree-edit-distance-in-the-low-distance-regime/",
      "content": "Authors: Tomasz Kociumaka, Ali Shahali\n\nThe tree edit distance is a natural dissimilarity measure between rooted\nordered trees whose nodes are labeled over an alphabet $\\Sigma$. It is defined\nas the minimum number of node edits (insertions, deletions, and relabelings)\nrequired to transform one tree into the other. In the weighted variant, the\nedits have associated costs (depending on the involved node labels) normalized\nso that each cost is at least one, and the goal is to minimize the total cost\nof edits.\nThe unweighted tree edit distance between two trees of total size $n$ can be\ncomputed in $O(n^{2.6857})$ time; in contrast, determining the weighted tree\nedit distance is fine-grained equivalent to the All-Pairs Shortest Paths\nproblem and requires $n^3/2^{\\Omega(\\sqrt{\\log n})}$ time [Nogler et al.;\nSTOC’25]. These super-quadratic running times are unattractive for large but\nvery similar trees, which motivates the bounded version of the problem, where\nthe runtime is parameterized by the computed distance $k$, potentially yielding\nfaster algorithms for $k\\ll n$.\nPrevious best algorithms for the bounded unweighted setting run in\n$O(nk^2\\log n)$ time [Akmal &amp; Jin; ICALP’21] and $O(n + k^7\\log k)$ time [Das\net al.; STOC’23]. For the weighted variant, the only known running time has\nbeen $O(n + k^{15})$.\nWe present an $O(n + k^6\\log k)$-time algorithm for computing the bounded\ntree edit distance in both the weighted and unweighted settings. Our approach\nbegins with an alternative $O(nk^2\\log n)$-time algorithm that handles weights\nand is significantly easier to analyze than the existing counterpart. We then\nintroduce a novel optimization that leverages periodic structures within the\ninput trees. To utilize it, we modify the $O(k^5)$-size $O(n)$-time universal\nkernel, the central component of the prior $O(n + k^{O(1)})$-time algorithms,\nso that it produces instances containing these periodic structures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Connected k-Median with Disjoint and Non-disjoint Clusters",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-connected-k-median-with-disjoint-and-non-disjoint-clusters/",
      "content": "Authors: Jan Eube, Kelin Luo, Dorian Reineccius, Heiko Röglin, Melanie Schmidt\n\nThe connected $k$-median problem is a constrained clustering problem that\ncombines distance-based $k$-clustering with connectivity information. The\nproblem allows to input a metric space and an unweighted undirected\nconnectivity graph that is completely unrelated to the metric space. The goal\nis to compute $k$ centers and corresponding clusters such that each cluster\nforms a connected subgraph of $G$, and such that the $k$-median cost is\nminimized.\nThe problem has applications in very different fields like geodesy\n(particularly districting), social network analysis (especially community\ndetection), or bioinformatics. We study a version with overlapping clusters\nwhere points can be part of multiple clusters which is natural for the use case\nof community detection. This problem variant is $\\Omega(\\log n)$-hard to\napproximate, and our main result is an $\\mathcal{O}(k^2 \\log n)$-approximation\nalgorithm for the problem. We complement it with an\n$\\Omega(n^{1-\\epsilon})$-hardness result for the case of disjoint clusters\nwithout overlap with general connectivity graphs, as well as an exact algorithm\nin this setting if the connectivity graph is a tree.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-bounded-weighted-edit-distance-dynamic-algorithms-and-matching-lower-bounds/",
      "content": "Authors: Itai Boneh, Egor Gorbachev, Tomasz Kociumaka\n\nThe edit distance $ed(X,Y)$ of two strings $X,Y\\in \\Sigma^*$ is the minimum\nnumber of character edits (insertions, deletions, and substitutions) needed to\ntransform $X$ into $Y$. Its weighted counterpart $ed^w(X,Y)$ minimizes the\ntotal cost of edits, which are specified using a function $w$, normalized so\nthat each edit costs at least one. The textbook dynamic-programming procedure,\ngiven strings $X,Y\\in \\Sigma^{\\le n}$ and oracle access to $w$, computes\n$ed^w(X,Y)$ in $O(n^2)$ time. Nevertheless, one can achieve better running\ntimes if the computed distance, denoted $k$, is small: $O(n+k^2)$ for unit\nweights [Landau and Vishkin; JCSS’88] and $\\tilde{O}(n+\\sqrt{nk^3})$ for\narbitrary weights [Cassis, Kociumaka, Wellnitz; FOCS’23].\nIn this paper, we study the dynamic version of the weighted edit distance\nproblem, where the goal is to maintain $ed^w(X,Y)$ for strings $X,Y\\in\n\\Sigma^{\\le n}$ that change over time, with each update specified as an edit in\n$X$ or $Y$. Very recently, Gorbachev and Kociumaka [STOC’25] showed that the\nunweighted distance $ed(X,Y)$ can be maintained in $\\tilde{O}(k)$ time per\nupdate after $\\tilde{O}(n+k^2)$-time preprocessing; here, $k$ denotes the\ncurrent value of $ed(X,Y)$. Their algorithm generalizes to small integer\nweights, but the underlying approach is incompatible with large weights.\nOur main result is a dynamic algorithm that maintains $ed^w(X,Y)$ in\n$\\tilde{O}(k^{3-\\gamma})$ time per update after $\\tilde{O}(nk^\\gamma)$-time\npreprocessing. Here, $\\gamma\\in [0,1]$ is a real trade-off parameter and $k\\ge\n1$ is an integer threshold fixed at preprocessing time, with $\\infty$ returned\nwhenever $ed^w(X,Y)&gt;k$. We complement our algorithm with conditional lower\nbounds showing fine-grained optimality of our trade-off for $\\gamma \\in\n[0.5,1)$ and justifying our choice to fix $k$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: An Easy Proof of a Weak Version of Chernoff inequality",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-an-easy-proof-of-a-weak-version-of-chernoff-inequality/",
      "content": "Authors: Sariel Har-Peled\n\nWe prove an easy but very weak version of Chernoff inequality. Namely, that\nthe probability that in $6M$ throws of a fair coin, one gets at most $M$ heads\nis $\\leq 1/2^M$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Computational Proof of the Highest-Scoring Boggle Board",
      "url": "/cstheoryrss/2025/07/04/arxiv-data-structures-and-algorithms-a-computational-proof-of-the-highest-scoring-boggle-board/",
      "content": "Authors: Dan Vanderkam\n\nFinding all the words on a Boggle board is a classic computer programming\nproblem. With a fast Boggle solver, local optimization techniques such as\nhillclimbing and simulated annealing can be used to find particularly\nhigh-scoring boards. The sheer number of possible Boggle boards has\nhistorically prevented an exhaustive search for the global optimum board. We\napply Branch and Bound and a decision diagram-like data structure to perform\nthe first such search. We find that the highest-scoring boards found via\nhillclimbing are, in fact, the global optima.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Linear Time Algorithm for Finding Minimum Flip Sequences between Plane Spanning Paths in Convex Point Sets",
      "url": "/cstheoryrss/2025/07/04/arxiv-computational-geometry-a-linear-time-algorithm-for-finding-minimum-flip-sequences-between-plane-spanning-paths-in-convex-point-sets/",
      "content": "Authors: Oswin Aichholzer, Joseph Dorfer\n\nWe provide a linear time algorithm to determine the flip distance between two\nplane spanning paths on a point set in convex position. At the same time, we\nshow that the happy edge property does not hold in this setting. This has to be\nseen in contrast to several results for reconfiguration problems where the\nabsence of the happy edge property implies algorithmic hardness of the flip\ndistance problem. Further, we show that our algorithm can be adapted for (1)\ncompatible flips (2) local flips and (3) flips for plane spanning paths in\nsimple polygons.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Stiefel optimization is NP-hard",
      "url": "/cstheoryrss/2025/07/04/arxiv-computational-complexity-stiefel-optimization-is-np-hard/",
      "content": "Authors: Zehua Lai, Lek-Heng Lim, Tianyun Tang\n\nWe show that linearly constrained linear optimization over a Stiefel or\nGrassmann manifold is NP-hard in general. We show that the same is true for\nunconstrained quadratic optimization over a Stiefel manifold. We will establish\nthe nonexistence of FPTAS for these optimization problems over a Stiefel\nmanifold. As an aside we extend our results to flag manifolds. Combined with\nearlier findings, this shows that manifold optimization is a difficult endeavor\n– even the simplest problems like LP and unconstrained QP are already NP-hard\non the most common manifolds.\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Standard error of what now?",
      "url": "/cstheoryrss/2025/07/03/ben-recht-standard-error-of-what-now/",
      "content": "\n\nScrolling through discourse about the evil vector, I stumbled across a group of people dismayed that the papers they were reviewing for NeurIPS didn’t include proper error bars. In fact, I learned that there’s a checklist that authors must fill out and attach to every NeurIPS submission. You can still learn things on social media.\n\nThe NeurIPS program chairs introduced the checklist in 2021. They argued that the community wanted “both more guidance around how to perform machine learning research responsibly and more flexibility in how they discuss this in their papers.” They came to this conclusion after listening at the “NeurIPS 2020 broader impacts workshop,” a fully remote workshop held during the cold, dark winter of the second wave of the covid pandemic. They argued that they would experiment with a checklist as a way to facilitate more responsible machine learning.\n\nThey called the checklist “experimental,” though there is no control group.1 They hoped that “future Program Chairs will continue to improve and evolve the checklist in subsequent years.” You don’t have to be a bureaucracy scholar to know that checklists “improve and evolve” by metastasizing in length and complexity. And that’s precisely what we’ve seen.\n\nThe NeurIPS paper checklist is now 3800 words long. This is twice as long as the original checklist, and has 3 times as many items to check off. It’s a lot of ridiculous infantilizing boilerplate. Item 1: “Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?” Come on, folks. You are required to check that you have read the code of ethics (another 2000 words here). You are asked to check whether you obtained the appropriate IRB approvals. Of course, this only applies if you are at a university. There’s a call out to the AI Safety dorks: “Do you have safeguards in place for responsible release of models with a high risk for misuse (e.g., pretrained language models)?” Come on, folks!\n\nBut I’m particularly fascinated by the weird obsession with statistics. I imagine Leo Breiman is chuckling up in heaven that one of the two cultures is trying to strangle the more successful one.2 In 2021, there was a single line about statistics:\n\n\n  2021: Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?\n\n\nHonestly, not the worst question in the world. So much of machine learning and AI is based on randomized algorithms, and it’s good to check whether you have a stable result (i.e., training a neural net for classification) or a wildly variable result (i.e., using reinforcement learning to game a robotics simulator). But someone on the steering committee decided we needed a longer rule set and more statistics. The statistics creep began in 2023:\n\n\n  2023: If you ran experiments, did you report error bars (e.g., with respect to the random seed after running experiments multiple times), or other information about the statistical significance of your experiments?\n\n\nAnd eventually, due to some unknown person’s lobbying, these were expanded further in 2024:\n\n\n  2024: “The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.). The assumptions made should be given (e.g., Normally distributed errors). It should be clear whether the error bar is the standard deviation or the standard error of the mean. It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). If error bars are reported in tables or plots, the authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.”\n\n\nWhat does this have to do with anything? If I run my code ten times, why should you care if I properly account for normal approximations? Who does this help?\n\nAnyway, I love that NeurIPS is proving my central thesis about statistics: Statistics is a bunch of arbitrary rules we use for approval. These arbitrary rules have now found their way into the machine learning publication machine. Whereas I understand why we require statistical tests when approving pharmaceuticals, no one has provided an explanation for why (or if) these statistical guidelines improve the quality of the thirty thousand NeurIPS submissions.\n\nIndeed, I can’t figure out why people have become so obsessed with error bars in machine learning. I have been told that it’s because data sets are “small” now. For example, some of the “can LLM solve human tests” data sets have a few dozen questions. The AIME benchmark has 15. But what do frequentist error bars buy you here? This isn’t like Fisher’s friend who tastes tea. If a machine can solve a single one of these problems, it’s interesting! LLM answers are variable by design. Trying to gauge this variability with “Gaussian approximations to the standard errors of the mean” misses the forest for the trees. Indeed, if you only have 15 questions in a dataset, you don’t need statistics. Just look at the answers! We’re not grading the LLM on a curve here.\n\nThe obsession with statistics is particularly ironic because the advances in machine learning from the past 15 years have been entirely based on optimaxxing vibes. While program committees and responsible ethics boards fixate on procedure, the big ideas have come from “this feels right,” whether they be bigger convnets, ADAM optimizers, attention mechanisms, or anything in RL. Do you think recent trends in transformer architectures like using RMSNorm instead of Layernorm or SwiGLU instead of ReLU are undergirded by deep statistical grounding?3\n\nWhat gives away the whole checklist charade here is bullet 4. The rules say that you must disclose the normal approximations in your error bars, but you don’t have to release code.\n\n\n  “While NeurIPS does not require releasing code, we do require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution.“\n\n\nWhy no code? It’s because a substantial fraction of NeurIPS papers come from private companies. The biggest models come from private companies. The conference exists to enrich Sam Altman. There’s no recruiting fair, no late-night parties, no signing bonuses based on Google Scholar profiles without the corporate commitment. So we can pat ourselves on the back and tell ourselves we’re being responsible researchers as we fill out our checklists and format our error bars. But let’s not kid ourselves about what we’re participating in.\n\nSubscribe now\n\n1\n\nI couldn’t find the preregistration plan.\n\n2\n\nThere is still no statistically significant evidence to support the existence of heaven.\n\n3\n\nLike you, I don’t know what any of these things are.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: SPARSE-PIVOT: Dynamic correlation clustering for node insertions",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-sparse-pivot-dynamic-correlation-clustering-for-node-insertions/",
      "content": "Authors: Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrović\n\nWe present a new Correlation Clustering algorithm for a dynamic setting where\nnodes are added one at a time. In this model, proposed by Cohen-Addad,\nLattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database\nqueries to access the input graph and updates the clustering as each new node\nis added. Our algorithm has the amortized update time of\n$O_{\\epsilon}(\\log^{O(1)}(n))$. Its approximation factor is $20+\\varepsilon$,\nwhich is a substantial improvement over the approximation factor of the\nalgorithm by Cohen-Addad et al. We complement our theoretical findings by\nempirically evaluating the approximation guarantee of our algorithm. The\nresults show that it outperforms the algorithm by Cohen-Addad et al.~in\npractice.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Optimal Dispersion Under Asynchrony",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-optimal-dispersion-under-asynchrony/",
      "content": "Authors: Debasish Pattanayak, Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma\n\nWe study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\nThe goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA’25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\nIn this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-faster-algorithm-for-second-s-t-mincut-and-breaking-quadratic-barrier-for-dual-edge-sensitivity-for-s-t-mincut/",
      "content": "Authors: Surender Baswana, Koustav Bhanja, Anupam Roy\n\nWe study (s,t)-cuts of second minimum capacity and present the following\nalgorithmic and graph-theoretic results.\n\n  Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for\ncomputing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum\n(s,t)-flow computations. For directed integer-weighted graphs, we significantly\nimprove this bound by designing an algorithm that computes an $(s,t)$-cut of\nsecond minimum capacity using $O(\\sqrt{n})$ maximum (s,t)-flow computations\nw.h.p. To achieve this result, a close relationship of independent interest is\nestablished between $(s,t)$-cuts of second minimum capacity and global mincuts\nin directed weighted graphs.\n  Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana,\nBhanja, and Pandey, ICALP 2022], which is a special case of second\n(s,t)-mincut.\n(a) For directed multi-graphs, we design an algorithm that, given any maximum\n(s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.\n(b) The existing structures for storing and characterizing all minimum+1\n(s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG\noccupying only $O(m)$ space that stores and characterizes all minimum+1\n(s,t)-cuts.\n  The study of minimum+1 (s,t)-cuts often turns out to be useful in\ndesigning dual edge sensitivity oracles – a compact data structure for\nefficiently reporting an (s,t)-mincut after insertion/failure of any given pair\nof query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual\nedge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy\n${\\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For\nsimple graphs, we break this quadratic barrier while achieving a non-trivial\nquery time.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Dynamic Similarity Graph Construction with Kernel Density Estimation",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-dynamic-similarity-graph-construction-with-kernel-density-estimation/",
      "content": "Authors: Steinar Laenen, Peter Macgregor, He Sun\n\nIn the kernel density estimation (KDE) problem, we are given a set $X$ of\ndata points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in\n\\mathbb{R}^d$, and the objective is to quickly output an estimate of\n$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider\n$\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that\nefficiently maintains the estimates for a set of query points as data points\nare added to $X$ over time. Based on this, we design a dynamic data structure\nthat maintains a sparse approximation of the fully connected similarity graph\non $X$, and develop a fast dynamic spectral clustering algorithm. We further\nevaluate the effectiveness of our algorithms on both synthetic and real-world\ndatasets.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-breaking-the-n-1-5-additive-error-barrier-for-private-and-efficient-graph-sparsification-via-private-expander-decomposition/",
      "content": "Authors: Anders Aamand, Justin Y. Chen, Mina Dalirrooyfard, Slobodan Mitrović, Yuriy Nevmyvaka, Sandeep Silwal, Yinzhan Xu\n\nWe study differentially private algorithms for graph cut sparsification, a\nfundamental problem in algorithms, privacy, and machine learning. While\nsignificant progress has been made, the best-known private and efficient cut\nsparsifiers on $n$-node graphs approximate each cut within\n$\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for\nany $\\gamma &gt; 0$ [Gupta, Roth, Ullman TCC’12]. In contrast, “inefficient”\nalgorithms, i.e., those requiring exponential time, can achieve an\n$\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error\n[Eli{'a}{\\v{s}}, Kapralov, Kulkarni, Lee SODA’20]. In this work, we break the\n$n^{1.5}$ additive error barrier for private and efficient cut sparsification.\nWe present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a\nnon-negative weighted graph, outputs a private synthetic graph approximating\nall cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 +\no(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$).\nAt the heart of our approach lies a private algorithm for expander\ndecomposition, a popular and powerful technique in (non-private) graph\nalgorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Deterministic Partition Tree and Applications",
      "url": "/cstheoryrss/2025/07/03/arxiv-data-structures-and-algorithms-a-deterministic-partition-tree-and-applications/",
      "content": "Authors: Haitao Wang\n\nIn this paper, we present a deterministic variant of Chan’s randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan’s original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-search-based-robot-motion-planning-with-distance-based-adaptive-motion-primitives/",
      "content": "Authors: Benjamin Kraljusic, Zlatan Ajanovic, Nermin Covic, Bakir Lacevic\n\nThis work proposes a motion planning algorithm for robotic manipulators that\ncombines sampling-based and search-based planning methods. The core\ncontribution of the proposed approach is the usage of burs of free\nconfiguration space (C-space) as adaptive motion primitives within the graph\nsearch algorithm. Due to their feature to adaptively expand in free C-space,\nburs enable more efficient exploration of the configuration space compared to\nfixed-sized motion primitives, significantly reducing the time to find a valid\npath and the number of required expansions. The algorithm is implemented within\nthe existing SMPL (Search-Based Motion Planning Library) library and evaluated\nthrough a series of different scenarios involving manipulators with varying\nnumber of degrees-of-freedom (DoF) and environment complexity. Results\ndemonstrate that the bur-based approach outperforms fixed-primitive planning in\ncomplex scenarios, particularly for high DoF manipulators, while achieving\ncomparable performance in simpler scenarios.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Multiple Watchman Routes in Staircase Polygons",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-multiple-watchman-routes-in-staircase-polygons/",
      "content": "Authors: Anna Brötzner, Bengt J. Nilsson, Christiane Schmidt\n\nWe consider the watchman route problem for multiple watchmen in staircase\npolygons, which are rectilinear $x$- and $y$-monotone polygons. For two\nwatchmen, we propose an algorithm to find an optimal solution that takes\nquadratic time, improving on the cubic time of a trivial solution. For $m \\geq\n3$ watchmen, we explain where this approach fails, and present an approximation\nalgorithm for the min-max criterion with only an additive error.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Stable and Theoretically Grounded Gromov-Wasserstein Distance for Reeb Graph Comparison using Persistence Images",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-stable-and-theoretically-grounded-gromov-wasserstein-distance-for-reeb-graph-comparison-using-persistence-images/",
      "content": "Authors: Erin W. Chambers, Guangyu Meng\n\nReeb graphs are a fundamental structure for analyzing the topological and\ngeometric properties of scalar fields. Comparing Reeb graphs is crucial for\nadvancing research in this domain, yet existing metrics are often\ncomputationally prohibitive or fail to capture essential topological features\neffectively. In this paper, we explore the application of the\nGromov-Wasserstein distance, a versatile metric for comparing metric measure\nspaces, to Reeb graphs. We propose a framework integrating a symmetric variant\nof the Reeb radius for robust geometric comparison, and a novel probabilistic\nweighting scheme based on Persistence Images derived from extended persistence\ndiagrams to effectively incorporate topological significance. A key\ncontribution of this work is the rigorous theoretical proof of the stability of\nour proposed Reeb Gromov-Wasserstein distance with respect to perturbations in\nthe underlying scalar fields. This ensures that small changes in the input data\nlead to small changes in the computed distance between Reeb graphs, a critical\nproperty for reliable analysis. We demonstrate the advantages of our approach,\nincluding its enhanced ability to capture topological features and its proven\nstability, through comparisons with other alternatives on several datasets,\nshowcasing its practical utility and theoretical soundness.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: A Deterministic Partition Tree and Applications",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-geometry-a-deterministic-partition-tree-and-applications/",
      "content": "Authors: Haitao Wang\n\nIn this paper, we present a deterministic variant of Chan’s randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan’s original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Symport/Antiport P Systems with Membrane Separation Characterize P^(#P)",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-symport-antiport-p-systems-with-membrane-separation-characterize-p-p/",
      "content": "Authors: Vivien Ducros, Claudio Zandron\n\nMembrane systems represent a computational model that operates in a\ndistributed and parallel manner, inspired by the behavior of biological cells.\nThese systems feature objects that transform within a nested membrane\nstructure. This research concentrates on a specific type of these systems,\nbased on cellular symport/antiport communication of chemicals.\nResults in the literature show that systems of this type that also allow cell\ndivision can solve PSPACE problems. In our study, we investigate systems that\nuse membrane separation instead of cell division, for which only limited\nresults are available. Notably, it has been shown that any problem solvable by\nsuch systems in polynomial time falls within the complexity class P^(#P).\nBy implementing a system solving MIDSAT, a P^(#P)-complete problem, we\ndemonstrate that the reverse inclusion is true as well, thus providing an exact\ncharacterization of the problem class solvable by P systems with\nsymport/antiport and membrane separation.\nMoreover, our implementation uses rules of length at most three. With this\nlimit, systems were known to be able to solve NP-complete problems, whereas\nlimiting the rules by length two, they characterize P.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: PCPP-Based Reconfiguration Inapproximability: Query Complexity vs. Soundness Gap Trade-offs",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-pcpp-based-reconfiguration-inapproximability-query-complexity-vs-soundness-gap-trade-offs/",
      "content": "Authors: Venkatesan Guruswami, Xuandi Ren, Kewen Wu\n\nThe Reconfiguration Inapproximability Hypothesis (RIH), recently established\nby Hirahara-Ohsaka (STOC’24) and Karthik-Manurangsi (ECCC’24), studies the\nhardness of reconfiguring one solution into another in constraint satisfaction\nproblems (CSP) when restricted to approximate intermediate solutions. In this\nwork, we make a tighter connection between RIH’s soundness gap and that of\nprobabilistically checkable proofs of proximity (PCPP). Consequently, we\nachieve an improved trade-off between soundness and query complexity in Gap CSP\nReconfiguration. Our approach leverages a parallelization framework, which also\nappears in some recent parameterized inapproximability results.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Hardness of Quantum Distribution Learning and Quantum Cryptography",
      "url": "/cstheoryrss/2025/07/03/arxiv-computational-complexity-hardness-of-quantum-distribution-learning-and-quantum-cryptography/",
      "content": "Authors: Taiga Hiroka, Min-Hsiu Hsieh, Tomoyuki Morimae\n\nThe existence of one-way functions (OWFs) forms the minimal assumption in\nclassical cryptography. However, this is not necessarily the case in quantum\ncryptography. One-way puzzles (OWPuzzs), introduced by Khurana and Tomer,\nprovide a natural quantum analogue of OWFs. The existence of OWPuzzs implies\n$PP\\neq BQP$, while the converse remains open. In classical cryptography, the\nanalogous problem-whether OWFs can be constructed from $P \\neq NP$-has long\nbeen studied from the viewpoint of hardness of learning. Hardness of learning\nin various frameworks (including PAC learning) has been connected to OWFs or to\n$P \\neq NP$. In contrast, no such characterization previously existed for\nOWPuzzs. In this paper, we establish the first complete characterization of\nOWPuzzs based on the hardness of a well-studied learning model: distribution\nlearning. Specifically, we prove that OWPuzzs exist if and only if proper\nquantum distribution learning is hard on average. A natural question that\nfollows is whether the worst-case hardness of proper quantum distribution\nlearning can be derived from $PP \\neq BQP$. If so, and a worst-case to\naverage-case hardness reduction is achieved, it would imply OWPuzzs solely from\n$PP \\neq BQP$. However, we show that this would be extremely difficult: if\nworst-case hardness is PP-hard (in a black-box reduction), then $SampBQP \\neq\nSampBPP$ follows from the infiniteness of the polynomial hierarchy. Despite\nthat, we show that $PP \\neq BQP$ is equivalent to another standard notion of\nhardness of learning: agnostic. We prove that $PP \\neq BQP$ if and only if\nagnostic quantum distribution learning with respect to KL divergence is hard.\nAs a byproduct, we show that hardness of agnostic quantum distribution learning\nwith respect to statistical distance against $PPT^{\\Sigma_3^P}$ learners\nimplies $SampBQP \\neq SampBPP$.\n\nRead original post\n"
    },
    
    {
      "title": "Computational Complexity: A Professor Again",
      "url": "/cstheoryrss/2025/07/02/computational-complexity-a-professor-again/",
      "content": "A new dean has taken my place, and I have returned to the professoriate at Illinois Tech, ending thirteen years in administration, six as dean and seven as department chair at Georgia Tech. I won’t rule out more administrative roles in the future, but only if the right role presents itself.\n\nI’ll teach intro theory in the fall, my first course since 2018, and take a sabbatical in the spring, mostly at Oxford. I plan to focus on writing, hoping to get out another book or books and other projects. It will be hard to go back to traditional computational complexity research, the field has changed considerably. I plan to spend some time understanding how AI changes the way we think about computation. Particularly why we see many of the benefits of P = NP while cryptography remains secure.\n\nAlso for the first time in 13 years I don’t have a “boss”. Technically I report to the department chair, who until a few days ago reported to me. But tenure protects my job, I choose my own research agenda, and teaching and service assignments are more of a negotiation than a top-down decision. Freedom!\n\nFor the blog, I have held back talking about the inner workings of universities while I had administrative roles. I’ll now be more open in giving my thoughts, at least in general terms.\n\nThe next chapter begins…\n\nBy Lance Fortnow\n\nRead original post\n"
    },
    
    {
      "title": "Gil Kalai: Some Events",
      "url": "/cstheoryrss/2025/07/02/gil-kalai-some-events/",
      "content": "Annual meeting of the Israeli Mathematical Union and student talks day, July 6 and 7\n\nThe Annual meeting of the Israeli Mathematical Union will be held on Sunday, July 6th 2025 at Bar-Ilan University. The main speakers will be Elon Lindenstrauss, Amnon Shashua and  the 2025 Erdos Prize recipients Or Hershkovits and Eliran Subag. There will also be ten parallel sessions. The IMU student talks day 2025 will be held on Monday, July 7 at the same location. The Day will feature Plenary talks by the Wolf Prize laureate Noga Alon and Adi Shamir (see this post), and  the Nesiyahu prize recepient Pazit Haim-Kislev (see this post) and contributed talks by thirty one graduate students (program).\n\nJoram’s Seminar: Hypercontractivity and Groups, July 9 and 10\n\nThe Joram Seminar new dates are July 9-10.\nThis year the topic will be “Hypercontractivity and Groups”, and the speakers are Noam Lifshitz and Guy Kindler (Hebrew University), Nathan Keller (Bar Ilan University) and Dor Minzer (MIT). For information on hypercontractivity see this post and this post.\n\nAmitsur Memorial Symposum 2025, July 14\n\nThe symposium this year is in memoriam of Ilya (Eliyahu) Rips.\n\nBy Gil Kalai\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Quantum Speedups for Polynomial-Time Dynamic Programming Algorithms",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-quantum-speedups-for-polynomial-time-dynamic-programming-algorithms/",
      "content": "Authors: Susanna Caroppo, Giordano Da Lozzo, Giuseppe Di Battista, Michael T. Goodrich, Martin Nöllenburg\n\nWe introduce a quantum dynamic programming framework that allows us to\ndirectly extend to the quantum realm a large body of classical dynamic\nprogramming algorithms. The corresponding quantum dynamic programming\nalgorithms retain the same space complexity as their classical counterpart,\nwhile achieving a computational speedup. For a combinatorial (search or\noptimization) problem $\\mathcal P$ and an instance $I$ of $\\mathcal P$, such a\nspeedup can be expressed in terms of the average degree $\\delta$ of the\ndependency digraph $G_{\\mathcal{P}}(I)$ of $I$, determined by a recursive\nformulation of $\\mathcal P$. The nodes of this graph are the subproblems of\n$\\mathcal P$ induced by $I$ and its arcs are directed from each subproblem to\nthose on whose solution it relies. In particular, our framework allows us to\nsolve the considered problems in $\\tilde{O}(|V(G_{\\mathcal{P}}(I))|\n\\sqrt{\\delta})$ time. As an example, we obtain a quantum version of the\nBellman-Ford algorithm for computing shortest paths from a single source vertex\nto all the other vertices in a weighted $n$-vertex digraph with $m$ edges that\nruns in $\\tilde{O}(n\\sqrt{nm})$ time, which improves the best known classical\nupper bound when $m \\in \\Omega(n^{1.4})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: On the (In)Approximability of the Monitoring Edge Geodetic Set Problem",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-on-the-in-approximability-of-the-monitoring-edge-geodetic-set-problem/",
      "content": "Authors: Davide Bilò, Giodano Colli, Luca Forlizzi, Stefano Leucci\n\nWe study the minimum \\emph{Monitoring Edge Geodetic Set} (\\megset) problem\nintroduced in [Foucaud et al., CALDAM’23]: given a graph $G$, we say that an\nedge is monitored by a pair $u,v$ of vertices if \\emph{all} shortest paths\nbetween $u$ and $v$ traverse $e$; the goal of the problem consists in finding a\nsubset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at\nleast one pair of vertices in $M$, and $|M|$ is minimized.\nIn this paper, we prove that all polynomial-time approximation algorithms for\nthe minimum \\megset problem must have an approximation ratio of $\\Omega(\\log\nn)$, unless \\p = \\np. To the best of our knowledge, this is the first\nnon-constant inapproximability result known for this problem. We also\nstrengthen the known \\np-hardness of the problem on $2$-apex graphs by showing\nthat the same result holds for $1$-apex graphs. This leaves open the problem of\ndetermining whether the problem remains \\np-hard on planar (i.e., $0$-apex)\ngraphs.\nOn the positive side, we design an algorithm that computes good approximate\nsolutions for hereditary graph classes that admit efficiently computable\nbalanced separators of truly sublinear size. This immediately results in\npolynomial-time approximation algorithms achieving an approximation ratio of\n$O(n^{\\frac{1}{4}} \\sqrt{\\log n})$ on planar graphs, graphs with bounded genus,\nand $k$-apex graphs with $k=O(n^{\\frac{1}{4}})$. On graphs with bounded\ntreewidth, we obtain an approximation ratio of $O(\\log^{3/2} n)$ for any\nconstant $\\varepsilon &gt; 0$. This compares favorably with the best-known\napproximation algorithm for general graphs, which achieves an approximation\nratio of $O(\\sqrt{n \\log n})$ via a simple reduction to the \\textsc{Set Cover}\nproblem.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Lazy B-Trees",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-lazy-b-trees/",
      "content": "Authors: Casper Moldrup Rysgaard, Sebastian Wild\n\nLazy search trees (Sandlund &amp; Wild FOCS 2020, Sandlund &amp; Zhang SODA 2022) are\nsorted dictionaries whose update and query performance smoothly interpolates\nbetween that of efficient priority queues and binary search trees -\nautomatically, depending on actual use; no adjustments are necessary to the\ndata structure to realize the cost savings. In this paper, we design lazy\nB-trees, a variant of lazy search trees suitable for external memory that\ngeneralizes the speedup of B-trees over binary search trees wrt. input/output\noperations to the same smooth interpolation regime.\nA key technical difficulty to overcome is the lack of a (fully satisfactory)\nexternal variant of biased search trees, on which lazy search trees crucially\nrely. We give a construction for a subset of performance guarantees sufficient\nto realize external-memory lazy search trees, which we deem of independent\ninterest.\nAs one special case, lazy B-trees can be used as an external-memory priority\nqueue, in which case they are competitive with some tailor-made heaps; indeed,\nthey offer faster decrease-key and insert operations than known data\nstructures.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Hamiltonicity Parameterized by Mim-Width is (Indeed) Para-NP-Hard",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-hamiltonicity-parameterized-by-mim-width-is-indeed-para-np-hard/",
      "content": "Authors: Benjamin Bergougnoux, Lars Jaffke\n\nWe prove that Hamiltonian Path and Hamiltonian Cycle are NP-hard on graphs of\nlinear mim-width 26, even when a linear order of the input graph with mim-width\n26 is provided together with input. This fills a gap left by a broken proof of\nthe para-NP-hardness of Hamiltonicity problems parameterized by mim-width.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: Best Agent Identification for General Game Playing",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-best-agent-identification-for-general-game-playing/",
      "content": "Authors: Matthew Stephenson, Alex Newcombe, Eric Piette, Dennis Soemers\n\nWe present an efficient and generalised procedure to accurately identify the\nbest performing algorithm for each sub-task in a multi-problem domain. Our\napproach treats this as a set of best arm identification problems for\nmulti-armed bandits, where each bandit corresponds to a specific task and each\narm corresponds to a specific algorithm or agent. We propose an optimistic\nselection process based on the Wilson score interval (Optimistic-WS) that ranks\neach arm across all bandits in terms of their potential regret reduction. We\nevaluate the performance of Optimistic-WS on two of the most popular general\ngame domains, the General Video Game AI (GVGAI) framework and the Ludii general\ngame playing system, with the goal of identifying the highest performing agent\nfor each game within a limited number of trials. Compared to previous best arm\nidentification algorithms for multi-armed bandits, our results demonstrate a\nsubstantial performance improvement in terms of average simple regret. This\nnovel approach can be used to significantly improve the quality and accuracy of\nagent evaluation procedures for general game frameworks, as well as other\nmulti-task domains with high algorithm runtimes.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Data Structures and Algorithms: A Simple Algorithm for Trimmed Multipoint Evaluation",
      "url": "/cstheoryrss/2025/07/02/arxiv-data-structures-and-algorithms-a-simple-algorithm-for-trimmed-multipoint-evaluation/",
      "content": "Authors: Nick Fischer, Melvin Kallmayer, Leo Wennmann\n\nEvaluating a polynomial on a set of points is a fundamental task in computer\nalgebra. In this work, we revisit a particular variant called trimmed\nmultipoint evaluation: given an $n$-variate polynomial with bounded individual\ndegree $d$ and total degree $D$, the goal is to evaluate it on a natural class\nof input points. This problem arises as a key subroutine in recent algorithmic\nresults [Dinur; SODA ‘21], [Dell, Haak, Kallmayer, Wennmann; SODA ‘25]. It is\nknown that trimmed multipoint evaluation can be solved in near-linear time [van\nder Hoeven, Schost; AAECC ‘13] by a clever yet somewhat involved algorithm. We\ngive a simple recursive algorithm that avoids heavy computer-algebraic\nmachinery, and can be readily understood by researchers without specialized\nbackground.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-empirical-analysis-of-heuristic-and-approximation-algorithms-for-the-the-mutual-visibility-problem/",
      "content": "Authors: Vanja Stojanović, Bor Pangeršič\n\nThe NP-complete mutual-visibility (MV) problem currently lacks empirical\nanalysis on its practical behaviour despite theoretical studies. This paper\naddresses this gap by implementing and evaluating three distinct algorithms - a\ndirect greedy heuristic, a hypergraph-based approximation, and a genetic\nalgorithm - on diverse synthetic graph datasets, including those with\nanalytically known $\\mu(G)$ values and general graph models. Our results\ndemonstrate that for smaller graphs, the algorithms consistently achieve MV set\nsizes aligning with theoretical bounds. However, for larger instances, achieved\nsolution sizes notably diverge from theoretical limits; this, combined with the\nabsence of tight bounds, complicates absolute quality assessment. Nevertheless,\nvalidation on known optimal graphs showed the Genetic Algorithm and other\nheuristics empirically performing best among tested methods.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Compact Representation of Semilinear and Terrain-like Graphs",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-compact-representation-of-semilinear-and-terrain-like-graphs/",
      "content": "Authors: Jean Cardinal, Yelena Yuditsky\n\nWe consider the existence and construction of \\textit{biclique covers} of\ngraphs, consisting of coverings of their edge sets by complete bipartite\ngraphs. The \\textit{size} of such a cover is the sum of the sizes of the\nbicliques. Small-size biclique covers of graphs are ubiquitous in computational\ngeometry, and have been shown to be useful compact representations of graphs.\nWe give a brief survey of classical and recent results on biclique covers and\ntheir applications, and give new families of graphs having biclique covers of\nnear-linear size.\nIn particular, we show that semilinear graphs, whose edges are defined by\nlinear relations in bounded dimensional space, always have biclique covers of\nsize $O(n\\polylog n)$. This generalizes many previously known results on\nspecial classes of graphs including interval graphs, permutation graphs, and\ngraphs of bounded boxicity, but also new classes such as intersection graphs of\nL-shapes in the plane. It also directly implies the bounds for Zarankiewicz’s\nproblem derived by Basit, Chernikov, Starchenko, Tao, and Tran (\\textit{Forum\nMath. Sigma}, 2021).\nWe also consider capped graphs, also known as terrain-like graphs, defined as\nordered graphs forbidding a certain ordered pattern on four vertices.\nTerrain-like graphs contain the induced subgraphs of terrain visibility graphs.\nWe give an elementary proof that these graphs admit biclique partitions of size\n$O(n\\log^3 n)$. This provides a simple combinatorial analogue of a classical\nresult from Agarwal, Alon, Aronov, and Suri on polygon visibility graphs\n(\\textit{Discrete Comput. Geom.} 1994).\nFinally, we prove that there exists families of unit disk graphs on $n$\nvertices that do not admit biclique coverings of size $o(n^{4/3})$, showing\nthat we are unlikely to improve on Szemer'edi-Trotter type incidence bounds\nfor higher-degree semialgebraic graphs.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-geometry-analyzing-time-varying-scalar-fields-using-piecewise-linear-morse-cerf-theory/",
      "content": "Authors: Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan\n\nMorse-Cerf theory considers a one-parameter family of smooth functions\ndefined on a manifold and studies the evolution of their critical points with\nthe parameter. This paper presents an adaptation of Morse-Cerf theory to a\nfamily of piecewise-linear (PL) functions. The vertex diagram and Cerf diagram\nare introduced as representations of the evolution of critical points of the PL\nfunction. The characterization of a crossing in the vertex diagram based on the\nhomology of the lower links of vertices leads to the definition of a\ntopological descriptor for time-varying scalar fields. An algorithm for\ncomputing the Cerf diagram and a measure for comparing two Cerf diagrams are\nalso described together with experimental results on time-varying scalar\nfields.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Sensitivity and Query Complexity under Uncertainty",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-complexity-sensitivity-and-query-complexity-under-uncertainty/",
      "content": "Authors: Deepu Benson, Balagopal Komarath, Nikhil Mande, Sai Soumya Nalli, Jayalal Sarma, Karteek Sreenivasaiah\n\nIn this paper, we study the query complexity of Boolean functions in the\npresence of uncertainty, motivated by parallel computation with an unlimited\nnumber of processors where inputs are allowed to be unknown. We allow each\nquery to produce three results: zero, one, or unknown. The output could also\nbe: zero, one, or unknown, with the constraint that we should output\n‘‘unknown’’ only when we cannot determine the answer from the revealed input\nbits. Such an extension of a Boolean function is called its hazard-free\nextension.\n\n  We prove an analogue of Huang’s celebrated sensitivity theorem [Annals of\nMathematics, 2019] in our model of query complexity with uncertainty.\n  We show that the deterministic query complexity of the hazard-free\nextension of a Boolean function is at most quadratic in its randomized query\ncomplexity and quartic in its quantum query complexity, improving upon the\nbest-known bounds in the Boolean world.\n  We exhibit an exponential gap between the smallest depth (size) of decision\ntrees computing a Boolean function, and those computing its hazard-free\nextension.\n  We present general methods to convert decision trees for Boolean functions\nto those for their hazard-free counterparts, and show optimality of this\nconstruction. We also parameterize this result by the maximum number of unknown\nvalues in the input.\n  We show lower bounds on size complexity of decision trees for hazard-free\nextensions of Boolean functions in terms of the number of prime implicants and\nprime implicates of the underlying Boolean function.\n\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Logarithmic Depth Decomposition of Approximate Multi-Controlled Single-Qubit Gates Without Ancilla Qubits",
      "url": "/cstheoryrss/2025/07/02/arxiv-computational-complexity-logarithmic-depth-decomposition-of-approximate-multi-controlled-single-qubit-gates-without-ancilla-qubits/",
      "content": "Authors: Jefferson D. S. Silva, Adenilton J. da Silva\n\nThe synthesis of quantum operators involves decomposing general quantum gates\ninto the gate set supported by a given quantum device. Multi-controlled gates\nare essential components in this process. In this work, we present improved\ndecompositions of multi-controlled NOT gates with logarithmic depth using a\nsingle ancilla qubit, while also reducing the constant factors in the circuit\ndepth compared to previous work. We optimize a previously proposed\ndecomposition of multi-target, multi-controlled special unitary SU(2) gates by\nidentifying the presence of a conditionally clean qubit. Additionally, we\nintroduce the best-known decomposition of multi-controlled approximate unitary\nU(2) gates without using ancilla qubits. This approach significantly reduces\nthe overall circuit depth and CNOT count while preserving an adjustable error\nparameter, yielding a more efficient and scalable solution for synthesizing\nlarge controlled-unitary gates. Our method is particularly suitable for both\nNISQ and fault-tolerant quantum architectures. All software developed in this\nproject is freely available.\n\nRead original post\n"
    },
    
    {
      "title": "David Eppstein: Geometric street art in Kanazawa",
      "url": "/cstheoryrss/2025/07/01/david-eppstein-geometric-street-art-in-kanazawa/",
      "content": "Kanazawa was this year’s host of Computational Geometry Week and the Symposium on Computational Geometry, and a great place to visit for lots of reasons. One of the lesser reasons is that it also hosts an interesting collection of geometric street art, some of which I photographed on my recent visit.\n\nThe first thing you see as you enter the city by the main entrance of its train station is Tsuzumimon, a massive ornamental wooden gate. The two pillars of the gate are made from wood beams in two layers that twist around each pillar in opposite directions. The lintel connecting the two pillars is a lattice of more wood, in a rounded form rather than the more traditional straight beam. The gate supports one end of an airy steel and glass space-frame dome, sheltering the plaza in front of the station from the frequent rain.\n\n\n\nTsuzumi are a certain type of Japanese hand drum, so Tsuzumimon means drum gate, because of the resemblance of the pillars to these drums. But instead, what it most reminds me of is a partition of space into skew lines that I ray-traced in 2010 and use as the header for my Mastodon account page.\n\n\n\nA short way along the road to the fish market (worth multiple visits), one encounters this piece, “Corpus Minor #1” by Janne Kristian Virkkunen. Another conference participant told me he thought it resembled a shipping mine, but what it brings to mind to me is either an atomic nucleus or a morula (the complex of cells of a multi-cell organism at the stage of reproduction before they differentiate).\n\n\n\nHere’s a more abstracted close-up look.\n\n\n\nI’m pretty sure its underlying geometric structure comes from a tetrakis hexahedron, whose edges form the prominent ribs of the sculpture. This would allow it to be constructed by bolting together 24 identical triangular pieces, each containing smoothed-together patches from three of the 14 spherical bulges of the sculpture.\n\n\n\nThe part of Kanazawa between the station and the fish market is dominated by major boulevards filled with cars, and long waits for crosswalks. To make it somewhat less unfriendly to pedestrian traffic, the city has installed underpasses at several of the major crossings. It’s easy to miss the next piece, at the central hub of the underpass connecting to the fish market itself.\n\n\n\nAlso seen but not photographed: another large ornamental gate near the back entrance of the station, made of slanted concrete pillars and resembling a support structure for an elevated highway; a black stone monkey saddle in the basement level of the station, near a scale model of Tsuzumimon; a tangled tree of shiny stainless steel tubes across the street from my hotel (a block south of the station); a stylized sundial between the station and the fish market (not very effective in the rain); and many public fountains.\n\n(Discuss on Mastodon)\n\nBy David Eppstein\n\nRead original post\n"
    },
    
    {
      "title": "Ben Recht: Two years of substacking",
      "url": "/cstheoryrss/2025/07/01/ben-recht-two-years-of-substacking/",
      "content": "\n\nToday marks the 2nd anniversary of this substack, and my elaborate blogging rule book compels me to write an annual reflection post. Whereas the first year was experimental and finding my footing, the second year has been decidedly more routine. That’s not a bad thing, as I love rituals. Wake up, brush my teeth, make two pour-over coffees, be harassed by the cat, blog.1 There’s a reassurance in these daily rituals themselves, where the process can be as rewarding as the product.\n\nI’m only half joking about having a blogging rule book. I’ve never written it down, but some of the rules are\n\n\n  Spend the first hour of each working day blogging.\n  Aim for 1000 words. If I hit that number, publish.\n  If I don’t hit 1000 words today, try to finish the piece tomorrow.\n  Make equations with LaTeXit, 14 pt font.\n  Every equation halves your readership (This is a Stephen Hawking rule.)\n  Don’t overthink the titles.\n  A banner by Isaac Sparks goes at the top of each post, subscribe button at the bottom.\n  14:00 GMT is international posting time. (This is a Brian Whitman rule.)\n  Aim for two posts a week. Don’t post more than four.\n\n\nI have a different set of rules for class liveblogging. I invented my own set of rules for working through Meehl’s course. Maybe I should spend more time writing these rules down. I’m sure there are many more I haven’t even articulated to myself.\n\nWhatever the case, I’ve got a process now and I’m sticking to it. The rules are oddly freeing. Rules give you a “freedom from choice,” paring down the degrees of freedom to one where you are able to create but are not overwhelmed by options. They are “constraints that deconstrain,” facilitating improvisation within the narrow boundaries of the ruleset.\n\nPart of my obsession with bureaucracy is that I love rules, and yet bureaucratic rules so frequently lack the deconstraining property that lets people flourish. Making matters worse, bureaucratic processes stifle course correction because by their nature. They are necessarily ossified and onerous to change. That’s a topic for a longer conversation in another post.\n\nIn any event, while I don’t have a clear idea of the topics I’ll be covering in year three of the argmin substack, I do know the starting rule book I’ll be using. And I’m trying to think a bit about rule changes for the upcoming season.2\n\nPart of these rule changes will be adapting to new goals for this season. One thing I haven’t been able to do is use my blogging time as “real writing” time. I’ve taken some mornings and tried to work on other writing projects during my allotted blogging time, and it hasn’t been helpful. That’s interesting in itself. This blog post writing is fundamentally different from the more archival writing, and the latter needs its own set of rules.\n\nI should figure those rules out because I am in a stage where I should write a few more papers. You know, blog posts with DOIs. I don’t want to write too many papers, but some folks have suggested that it would be helpful to collect and collate some of the meandering thoughts here into tighter arguments. My blog posts are first drafts of thoughts, not finished ones. I don’t consider any of the arguments here to be definitive. I love that you all think out loud with me. Nonetheless, some of them are worth preserving in academic amber, and I need to do my scholarly duties of mailing pdfs to my friends. I’ve written two blog posts with DOIs this year (this one, that one), and I have three or four more I should try to finish. I also have a few more books in me that I want to write. I will have more news on that front coming very soon. Finding the right way to balance writing time is going to be an important part of argmin year three.\n\nAnother goal is finding the best balance for the multiple audiences who read this. Some posts get very technical, but there is a slice of the readership that enjoys those. I have tried to maintain a balance that doesn’t alienate those who don’t want the math, while also engaging with those who do. I could split this blog into multiple newsletters, but that seems like a lot of unnecessary work, and I know everyone must have incredible substack subscription fatigue at this point. I could perhaps signal at the top of each post whether I’m going to get into the weeds. If you have any ideas on how to strike the right balance and send the right signals, please send me an email or leave a comment. Hopefully, you folks who agree to be spammed by me are fine with closing the posts that are too hypertechnical and selectively reading the ones that hook you.\n\nRegardless, I love the feedback you send me, and I apologize if I miss any or don’t reply. I read them all and value them all. I look forward to more of them in year three.\n\nSubscribe now\n\n1\n\nThe cat apparently also loves rituals.\n\n2\n\nArgmin blog will not be banning the tush push.\n\nBy Ben Recht\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Passage-traversing optimal path planning with sampling-based algorithms",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-passage-traversing-optimal-path-planning-with-sampling-based-algorithms/",
      "content": "Authors: Jing Huang, Hao Su, Kwok Wai Samuel Au\n\nThis paper introduces a new paradigm of optimal path planning, i.e.,\npassage-traversing optimal path planning (PTOPP), that optimizes paths’\ntraversed passages for specified optimization objectives. In particular, PTOPP\nis utilized to find the path with optimal accessible free space along its\nentire length, which represents a basic requirement for paths in robotics. As\npassages are places where free space shrinks and becomes constrained, the core\nidea is to leverage the path’s passage traversal status to characterize its\naccessible free space comprehensively. To this end, a novel passage detection\nand free space decomposition method using proximity graphs is proposed,\nenabling fast detection of sparse but informative passages and environment\ndecompositions. Based on this preprocessing, optimal path planning with\naccessible free space objectives or constraints is formulated as PTOPP problems\ncompatible with sampling-based optimal planners. Then, sampling-based\nalgorithms for PTOPP, including their dependent primitive procedures, are\ndeveloped leveraging partitioned environments for fast passage traversal check.\nAll these methods are implemented and thoroughly tested for effectiveness and\nefficiency validation. Compared to existing approaches, such as clearance-based\nmethods, PTOPP demonstrates significant advantages in configurability, solution\noptimality, and efficiency, addressing prior limitations and incapabilities. It\nis believed to provide an efficient and versatile solution to accessible free\nspace optimization over conventional avenues and more generally, to a broad\nclass of path planning problems that can be formulated as PTOPP.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-moving-matter-using-a-single-simple-robot-to-reconfigure-a-connected-set-of-building-blocks/",
      "content": "Authors: Javier Garcia, Jonas Friemel, Ramin Kosfeld, Michael Yannuzzi, Peter Kramer, Christian Rieck, Christian Scheffer, Arne Schmidt, Harm Kube, Dan Biediger, Sándor P. Fekete, Aaron T. Becker\n\nWe implement and evaluate different methods for the reconfiguration of a\nconnected arrangement of tiles into a desired target shape, using a single\nactive robot that can move along the tile structure. This robot can pick up,\ncarry, or drop off one tile at a time, but it must maintain a single connected\nconfiguration at all times.\nBecker et al. (CCCG 2025) recently proposed an algorithm that uses histograms\nas canonical intermediate configurations, guaranteeing performance within a\nconstant factor of the optimal solution if the start and target configuration\nare well-separated. We implement and evaluate this algorithm, both in a\nsimulated and practical setting, using an inchworm type robot to compare it\nwith two existing heuristic algorithms.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: Escher Tile Deformation via Closed-Form Solution",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-escher-tile-deformation-via-closed-form-solution/",
      "content": "Authors: Crane He Chen, Vladimir G. Kim\n\nWe present a real-time deformation method for Escher tiles – interlocking\norganic forms that seamlessly tessellate the plane following symmetry rules. We\nformulate the problem as determining a periodic displacement field. The goal is\nto deform Escher tiles without introducing gaps or overlaps. The resulting\ndisplacement field is obtained in closed form by an analytical solution. Our\nmethod processes tiles of 17 wallpaper groups across various representations\nsuch as images and meshes. Rather than treating tiles as mere boundaries, we\nconsider them as textured shapes, ensuring that both the boundary and interior\ndeform simultaneously. To enable fine-grained artistic input, our interactive\ntool features a user-controllable adaptive fall-off parameter, allowing precise\nadjustment of locality and supporting deformations with meaningful semantic\ncontrol. We demonstrate the effectiveness of our method through various\nexamples, including photo editing and shape sculpting, showing its use in\napplications such as fabrication and animation.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Geometry: $C_4$-free subgraphs of high degree with geometric applications",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-geometry-c-4-free-subgraphs-of-high-degree-with-geometric-applications/",
      "content": "Authors: Zach Hunter, Aleksa Milojević, Istvan Tomon, Benny Sudakov\n\nThe Zarankiewicz problem, a cornerstone problem in extremal graph theory,\nasks for the maximum number of edges in an $n$-vertex graph that does not\ncontain the complete bipartite graph $K_{s,s}$. While the problem remains\nwidely open in the case of general graphs, the past two decades have seen\nsignificant progress on this problem for various restricted graph classes –\nparticularly those arising from geometric settings – leading to a deeper\nunderstanding of their structure.\nIn this paper, we develop a new structural tool for addressing\nZarankiewicz-type problems. More specifically, we show that for any positive\ninteger $k$, every graph with average degree $d$ either contains an induced\n$C_4$-free subgraph with average degree at least $k$, or it contains a\n$d$-vertex subgraph with $\\Omega_k(d^2)$ edges. As an application of this\ndichotomy, we propose a unified approach to a large number of Zarankiewicz-type\nproblems in geometry, obtaining optimal bounds in each case.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Factorization norms and an inverse theorem for MaxCut",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-factorization-norms-and-an-inverse-theorem-for-maxcut/",
      "content": "Authors: Igor Balla, Lianna Hambardzumyan, István Tomon\n\nWe prove that Boolean matrices with bounded $\\gamma_2$-norm or bounded\nnormalized trace norm must contain a linear-sized all-ones or all-zeros\nsubmatrix, verifying a conjecture of Hambardzumyan, Hatami, and Hatami. We also\npresent further structural results about Boolean matrices of bounded\n$\\gamma_2$-norm and discuss applications in communication complexity, operator\ntheory, spectral graph theory, and extremal combinatorics.\nAs a key application, we establish an inverse theorem for MaxCut. A\ncelebrated result of Edwards states that every graph $G$ with $m$ edges has a\ncut of size at least $\\frac{m}{2}+\\frac{\\sqrt{8m+1}-1}{8}$, with equality\nachieved by complete graphs with an odd number of vertices. To contrast this,\nwe prove that if the MaxCut of $G$ is at most $\\frac{m}{2}+O(\\sqrt{m})$, then\n$G$ must contain a clique of size $\\Omega(\\sqrt{m})$.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Constant-depth circuits for polynomial GCD over any characteristic",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-constant-depth-circuits-for-polynomial-gcd-over-any-characteristic/",
      "content": "Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf\n\nWe show that the GCD of two univariate polynomials can be computed by\n(piece-wise) algebraic circuits of constant depth and polynomial size over any\nsufficiently large field, regardless of the characteristic. This extends a\nrecent result of Andrews &amp; Wigderson who showed such an upper bound over fields\nof zero or large characteristic.\nOur proofs are based on a recent work of Bhattacharjee, Kumar, Rai,\nRamanathan, Saptharishi \\&amp; Saraf that shows closure of constant depth algebraic\ncircuits under factorization. On our way to the proof, we show that any\n$n$-variate symmetric polynomial $P$ that has a small constant depth algebraic\ncircuit can be written as the composition of a small constant depth algebraic\ncircuit with elementary symmetric polynomials. This statement is a constant\ndepth version of a result of Bl\"{a}ser &amp; Jindal, who showed this for algebraic\ncircuits of unbounded depth. As an application of our techniques, we also\nstrengthen the closure results for factors of constant-depth circuits in the\nwork of Bhattacharjee et al. over fields for small characteristic.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Closure under factorization from a result of Furstenberg",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-closure-under-factorization-from-a-result-of-furstenberg/",
      "content": "Authors: Somnath Bhattacharjee, Mrinal Kumar, Shanthanu S. Rai, Varun Ramanathan, Ramprasad Saptharishi, Shubhangi Saraf\n\nWe show that algebraic formulas and constant-depth circuits are closed under\ntaking factors. In other words, we show that if a multivariate polynomial over\na field of characteristic zero has a small constant-depth circuit or formula,\nthen all its factors can be computed by small constant-depth circuits or\nformulas respectively.\nOur result turns out to be an elementary consequence of a fundamental and\nsurprising result of Furstenberg from the 1960s, which gives a non-iterative\ndescription of the power series roots of a bivariate polynomial. Combined with\nstandard structural ideas in algebraic complexity, we observe that this theorem\nyields the desired closure results.\nAs applications, we get alternative (and perhaps simpler) proofs of various\nknown results and strengthen the quantitative bounds in some of them. This\nincludes a unified proof of known closure results for algebraic models\n(circuits, branching programs and VNP), an extension of the analysis of the\nKabanets-Impagliazzo hitting set generator to formulas and constant-depth\ncircuits, and a (significantly) simpler proof of correctness as well as\nstronger guarantees on the output in the subexponential time deterministic\nalgorithm for factorization of constant-depth circuits from a recent work of\nBhattacharjee, Kumar, Ramanathan, Saptharishi &amp; Saraf.\n\nRead original post\n"
    },
    
    {
      "title": "arXiv: Computational Complexity: Characterizing Small Circuit Classes from FAC^0 to FAC^1 via Discrete Ordinary Differential Equations",
      "url": "/cstheoryrss/2025/07/01/arxiv-computational-complexity-characterizing-small-circuit-classes-from-fac-0-to-fac-1-via-discrete-ordinary-differential-equations/",
      "content": "Authors: Melissa Antonelli, Arnaud Durand, Juha Kontinen\n\nIn this paper, we provide a uniform framework for investigating small circuit\nclasses and bounds through the lens of ordinary differential equations (ODEs).\nFollowing an approach recently introduced to capture the class of\npolynomial-time computable functions via ODE-based recursion schemas and later\napplied to the context of functions computed by unbounded fan-in circuits of\nconstant depth (FAC^0), we study multiple relevant small circuit classes. In\nparticular, we show that natural restrictions on linearity and derivation along\nfunctions with specific growth rate correspond to kinds of functions that can\nbe proved to be in various classes, ranging from FAC^0 to FAC^1. This reveals\nan intriguing link between constraints over linear-length ODEs and circuit\ncomputation, providing new tools to tackle the complex challenge of\nestablishing bounds for classes in the circuit hierarchies and possibly\nenhancing our understanding of the role of counters in this setting.\nAdditionally, we establish several completeness results, in particular\nobtaining the first ODE-based characterizations for the classes of functions\ncomputable in constant depth with unbounded fan-in and Mod 2 gates (FACC[2])\nand in logarithmic depth with bounded fan-in Boolean gates (FNC1).\n\nRead original post\n"
    }
    
  ];

  const idx = lunr(function () {
    this.ref('url')
    this.field('title', {boost: 10})
    this.field('content')

    posts.forEach(function (doc) {
      this.add(doc)
    }, this)
  });

  const searchBox = document.getElementById('search-box');
  const postsList = document.getElementById('posts-list');

  function renderPosts(postsArray) {
    if (postsArray.length === 0) {
      postsList.innerHTML = '<li>No results found</li>';
      return;
    }
    postsList.innerHTML = postsArray.map(p => {
      if (p.url) {
        return `<li><a href="${p.url}">${p.title}</a> — <small></small></li>`;
      } else {
        const post = posts.find(post => post.url === p.ref);
        if (post) {
          return `<li><a href="${post.url}">${post.title}</a></li>`;
        }
        return '';
      }
    }).join('');
  }

  renderPosts(posts);

  searchBox.addEventListener('input', function () {
    let query = this.value.trim().toLowerCase();

    if (query === "") {
      renderPosts(posts);
      return;
    }

    let results = idx.search(query);
    if (results.length === 0) {
      const wildcardQuery = query.split(/\s+/).map(term => term + '*').join(' ');
      results = idx.search(wildcardQuery);
    }

    renderPosts(results);
  });
</script>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Gorav  Jindal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
