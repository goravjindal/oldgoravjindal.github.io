---
layout: post
category: cstheoryrss
title: "arXiv: Data Structures and Algorithms: Addressing Bias in Algorithmic Solutions: Exploring Vertex Cover and"
date: 2025-07-22T00:00:00
---

**Authors:** [Sheikh Shakil Akhtar](https://dblp.uni-trier.de/search?q=Sheikh+Shakil+Akhtar), [Jayakrishnan Madathil](https://dblp.uni-trier.de/search?q=Jayakrishnan+Madathil), [Pranabendu Misra](https://dblp.uni-trier.de/search?q=Pranabendu+Misra), [Geevarghese Philip](https://dblp.uni-trier.de/search?q=Geevarghese+Philip)

A typical goal of research in combinatorial optimization is to come up with
fast algorithms that find optimal solutions to a computational problem. The
process that takes a real-world problem and extracts a clean mathematical
abstraction of it often throws out a lot of "side information" which is deemed
irrelevant. However, the discarded information could be of real significance to
the end-user of the algorithm's output. All solutions of the same cost are not
necessarily of equal impact in the real-world; some solutions may be much more
desirable than others, even at the expense of additional increase in cost. If
the impact, positive or negative, is mostly felt by some specific (minority)
subgroups of the population, the population at large will be largely unaware of
it. In this work we ask the question of finding solutions to combinatorial
optimization problems that are "unbiased" with respect to a collection of
specified subgroups of the total population.

[Read original post](http://arxiv.org/abs/2507.14509v1)
