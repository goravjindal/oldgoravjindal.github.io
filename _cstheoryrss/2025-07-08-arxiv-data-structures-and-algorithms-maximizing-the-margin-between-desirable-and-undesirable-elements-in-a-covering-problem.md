---
layout: post
category: cstheoryrss
title: "arXiv: Data Structures and Algorithms: Maximizing the Margin between Desirable and Undesirable Elements in a"
date: 2025-07-08T00:00:00
---

**Authors:** [Sophie Boileau](https://dblp.uni-trier.de/search?q=Sophie+Boileau), [Andrew Hong](https://dblp.uni-trier.de/search?q=Andrew+Hong), [David Liben-Nowell](https://dblp.uni-trier.de/search?q=David+Liben-Nowell), [Alistair Pattison](https://dblp.uni-trier.de/search?q=Alistair+Pattison), [Anna N. Rafferty](https://dblp.uni-trier.de/search?q=Anna+N.+Rafferty), [Charlie Roslansky](https://dblp.uni-trier.de/search?q=Charlie+Roslansky)

In many covering settings, it is natural to consider the simultaneous
presence of desirable elements (that we seek to include) and undesirable
elements (that we seek to avoid). This paper introduces a novel combinatorial
problem formalizing this tradeoff: from a collection of sets containing both
"desirable" and "undesirable" items, pick the subcollection that maximizes the
margin between the number of desirable and undesirable elements covered. We
call this the Target Approximation Problem (TAP) and argue that many real-world
scenarios are naturally modeled via this objective. We first show that TAP is
hard, even when restricted to cases where the given sets are small or where
elements appear in only a small number of sets. In a large subset of these
cases, we show that TAP is hard to even approximate. We then exhibit exact
polynomial-time algorithms for other restricted cases and provide an efficient
0.5-approximation for the case where elements occur at most twice, derived
through a tight connection to the greedy algorithm for Unweighted Set Cover.

[Read original post](http://arxiv.org/abs/2507.03817v1)
